date_start,date_end,type,title,abstract,author,location,session,session_order,chair,openreview_id
2025-07-21 09:00:00,2025-07-21 12:30:00,single,Tutorial 1: LLM Power To The People,"This tutorial aims to provide an up-to-date overview of the applications of large language models (LLMs) in research, with a particular focus on key areas such as fine-grained text classification, information extraction, and text clustering. To this end, it will cover fundamental concepts, including zero-shot learning, fine-tuning, encoder-decoder architectures, and Low-Rank Adaptation (LoRA), while also presenting various types of language models and their respective affordances. Drawing on the most recent discussions in the field, the tutorial will offer guidance on developing efficient processing pipelines, taking into consideration the computational resources available to researchers. Participants will gain practical knowledge through a combination of theoretical discussions and hands-on case studies. The session will feature Jupyter notebooks and an open-source software interface to demonstrate project implementation, including text preparation, annotation, fine tuning, inference. Additionally, attendees will receive reusable scripts to facilitate replication and adaptation in their own research projects. Beyond technical considerations, the tutorial will address the computational and annotation requirements associated with LLMs, as well as the environmental costs of different models. By integrating theoretical insights with practical implementation strategies, the session aims to delineate what is currently achievable with LLMs, what challenges persist, and what remains speculative. As a follow-up to a previous IC2S2 tutorial (2023), this session has been updated to reflect recent advancements. It will cater to both advanced and less advanced programmers, helping researchers choose the most suitable approach for their work. ","Étienne Ollion, Émilien Schultz",Vingen 1+2,,,,
2025-07-21 09:00:00,2025-07-21 12:30:00,single,"Tutorial 3: The Role of AI in Misinformation: Current Trends, Detection, and Mitigation","As AI-generated content becomes more prevalent, understanding its role within the broader misinformation landscape is critical. The widespread proliferation of misinformation in combination with the rise of AI technologies poses challenges across domains: Concerns persist that, for example, Large Language Models (LLMs) or deepfake systems have a negative impact on the creation and amplification of false or misleading information. While there are debates within the research community on the extent of AI influence on misinformation development, the challenges posed by misinformation are amplified as social media platforms increasingly dismantle traditional guardrails like fact-checking. These shifts demand interdisciplinary research to explore not only how AI contributes to the spread of misinformation but also how it can serve as a tool to better understand and combat it. Situating AI-generated misinformation within the wider context of existing dynamics highlights the urgency of addressing its impact across domains, both in science and politics, particularly as societal polarization deepens. Participants will gain hands-on experience analyzing misinformation-related datasets using natural language processing and network analysis. The tutorial emphasizes practical applications by providing coding exercises in a Jupyter notebook environment for detecting and simulating the spread of misinformation.","Miriam Schirmer, Julia Mendelsohn, Dustin Wright, Dietram A. Scheufele, Ágnes Horvát",Vingen 3+4,,,,
2025-07-21 09:00:00,2025-07-21 12:30:00,single,Tutorial 5: FAIR theory: Applying Open Science Printiples to the Construction and Iterative Improvement of Theories,"Reproducibility is essential for establishing trust and maximizing reusability of empirically calibrated simulations and other computational social science studies. Participants learn to make research projects open and reproducible according to the FAIR principles and TOP-guidelines. The workshop first establishes the fundamental principles of reproducible science, followed by a 10-minute live demonstration of creating a reproducible project using the `worcs` R-package, which streamlines the creation of reproducible projects. WORCS is easy to learn for beginners while also being highly extendable and compliant with most institutional and journal requirements. Next, topics essential for computational social science are addressed: random seeds, parallelization, integration testing to catch errors before running time-consuming analyses, and combining worcs with “targets” to reduce redundant computation, saving time and reducing the computational studies’ climate footprint. Participants are encouraged to bring their own code – e.g., for a simulation study, or to use sample code provided by the organizer. Q&A and Discussion sections ensure that the tutorial’s content aligns with participants’ needs, while guided demonstrations and hands-on exercises allow participants to develop the experience and skills needed to implement open reproducible workflows in their future research. Participants should bring a laptop and complete this setup tutorial before joining the workshop:",Caspar van Lissa,Vingen 7,,,,
2025-07-21 09:00:00,2025-07-21 12:30:00,single,Tutorial 7: Scalable Analysis of GPS Human Mobility Data with Applications to Socio-Spatial Inequality,"Large-scale human mobility datasets derived from mobile phones have become a valuable resource in the field of human mobility. They have found diverse applications in tasks such as travel demand estimation, urban planning, epidemic modelling, and more. However, these datasets remain largely inaccessible to the broader community due, in part, to the technical difficulties in processing these massive datasets and the comprehensive understanding of data bias and potential. In this tutorial, we will first introduce an open-source library of code from the NOMAD project (Network for Open Mobility Analysis and Datasets) as a tool to overcome the technical challenges of processing massive data sets. In the second part, we will demonstrate a critical application of human mobility analysis - socio-spatial inequality developed in realTRIPS projects (EvALuating Land Use and TRansport Impacts on Urban Mobility Patterns). The analysis provides an understanding of differences in how social phenomena play out across neighbourhoods, regions, and sociodemographic groups. Overall, we aim to demonstrate reproducible and widely applicable research methods. The library used for part of the analysis, built on Python and Spark, is designed to process this class of data at scale and implements a broad range of processing algorithms which will be employed for this particular application","Jorge Barreras, Thomas Li, Chen Zhong, Cate Heine, Adam (Zhengzi) Zhou",Vingen 8,,,,
2025-07-21 09:00:00,2025-07-21 12:30:00,single,Tutorial 9: Reinforcement Learning and Evolutionary Game Theory are Two Sides of the Same Coin,"Assuming that individuals are rational is often unjustified in many social and biological systems, even for simple pairwise interactions. As such, in many real-world multi-agent systems, the goal is shifted towards the understanding of the complex ecologies of behaviours emerging from a given dilemma (or ”game”). This is where evolutionary game theory (EGT) shines as a theoretical and computational framework. Likewise, from the computational perspective, multi-agent reinforcement learning (MARL) models how self-interested agents learn and improve their policies through the accumulation of rewards coming from their past experience. Just like strategies in evolutionary game theory adapting to one another, agents’ actions evolve based on their empirical returns. The similarity is no coincidence. In this tutorial we show how these two frameworks, although applied in different context, are two sides of the same coin, presenting fundamen-tal mathematical results that demonstrate how the equilibria of population dynamics can be encoded by simple RL agents policies and the other way round. We will provide use-cases in which each modelling framework is useful. This tutorial will help the social science practitioner acquire new tools coming from AI and complex systems, and computer science practitioners to understand their research in terms of economic models.","Paolo Turrini, Elias Fernández Domingos",Vingen 6,,,,
,,,,,,,,,,
2025-07-21 13:30:00,2025-07-21 17:00:00,single,Tutorial 2: Bridging Human and LLM Annotations for Statistically Valid Computational Social Science,"The tutorial provides participants with a practical, hands-on experience in integrating Large Language Models (LLMs) and human annotations to streamline annotation workflows, ensuring both efficiency and statistical rigor. As LLMs revolutionize data annotation with their ability to label and analyze complex social phenomena at unprecedented scales, they also pose challenges in ensuring the reliability and validity of results. This tutorial introduces a systematic approach to combining LLM annotations with human input, enabling researchers to optimize annotation processes while maintaining rigorous standards for statistical inference. The session begins by framing the opportunities and challenges of leveraging LLMs for Computational Social Science (CSS). The tutorial demonstrates techniques for combining LLM annotations with human annotations to ensure statistically valid results while minimizing annotation costs. Through hands-on implementation using open-source datasets and code notebooks, participants will apply these methods to popular CSS tasks, such as stance detection, media bias, and online hate and misinformation. Additionally, the session will explore how these approaches can be adapted to other domains, such as psychology, sociology, and political science. By the end of the session, participants will gain actionable skills for reliably leveraging LLMs for data annotation in their own research.","Kristina Gligoric, Cinoo Lee, Tijana Zrnic",Hemeryck,,,,
2025-07-21 13:30:00,2025-07-21 17:00:00,single,Tutorial 4: Planetary Causal Inference: an R tutorial on how to conduct causal inference with satellite images data,"This R tutorial is based on our book-in-progress, Planetary Causal Inference (PCI), which proposes using Earth observation (EO) data to enhance social science research by expanding both the scope and resolution of data analysis. Traditional data sources like surveys and national statistics are often expensive, limited in coverage, and rarely provide real-time insights—challenges that hinder comprehensive planetary-scale studies. In contrast, satellite-based EO data offer fine-grained, global perspectives on phenomena such as urban growth, poverty, deforestation, and conflict, capturing information across diverse spatial and temporal scales. This tutorial introduces the emerging practice of EO-based machine learning (EO-ML), where advanced models transform satellite-derived spatial data into proxies for social science metrics and feed these into causal inference pipelines. By integrating knowledge from geography, history, and multi-level frameworks, PCI fosters a broader understanding of human–environment interactions, helping researchers address questions that span household, neighborhood, regional, and global contexts. Through its cookbook-style presentation of “ingredients” (data, methods) and “recipes” (analysis steps), PCI equips social scientists to confidently adopt and adapt EO-ML tools. This approach helps generate highly detailed insights and enables researchers to explore pressing global issues—ranging from armed conflict to sustainable development—with new analytical power and precision. ","Adel Daoud, Connor Jerzak",Vingen 8,,,,
2025-07-21 13:30:00,2025-07-21 17:00:00,single,Tutorial 6: Research Cartography with Atlas,"Scientific inquiry depends on ""standing on the shoulders of giants"" — building on the findings of prior work. However integrating knowledge across many papers is challenging and unreliable. Papers may use terms differently, or leverage different terms to describe the same thing. Further, papers may over emphasis an outcome, or may not describe research activity with enough detail to fully understand what was measured. All these challenges, and many more make understanding the complete landscape of a research area almost impossible. Atlas, an open source platform, tackles this problem by emphasizing commensurability—the practice of describing research findings in ways that enable valid comparisons. Instead of relying solely on persuasive narratives, Atlas systematically codes experimental attributes, from detailed methodology to condition-specific distinctions. This process shifts the focus to what researchers actually do, rather than merely what they claim, making the integration of diverse studies more reliable. We will demonstrate how Atlas transforms research papers into a series of quantified dimensions, producing what we refer to as research cartography. Through guided exercises, you will learn to apply Atlas to your own projects, analyzing multiple levels of data within a single study. Our goal is to show how this method enhances transparency and reliability in scientific conclusions, ultimately advancing progress by enabling evidence-based insights that are both rigorous and comparable.","Mark Whiting, Linnea Gandhi, Amirhossein Nakhaei, Duncan Watts",Vingen 6,,,,
2025-07-21 13:30:00,2025-07-21 17:00:00,single,Tutorial 8: Mobility Flows and Accessibility Using R and Big Open Data,"Large-scale human mobility datasets provide unprecedented opportunities to analyze movement patterns, generating critical insights for many fields of research. Until recently, access to human mobility data was a privilege of a few researchers. Thanks to countries like Spain that pioneered to make high resolution aggregated human mobility data open, such data is becoming increasingly accessible, and similar mobility data may soon be widely available as part of official statistics across the European Union. However, the complexity and sheer volume of this data present practical challenges related to data acquisition, efficient processing, geographic disaggregation, network representation, and interactive visualization. The workshop addresses these challenges by showcasing end-to-end workflows that harness state-of-the-art R packages and methods. Participants will learn how to acquire and manage multi-gigabyte mobility datasets on consumer level laptops, combine and compare the actual mobility flows and the access to opportunities, and create informative mobility flows visualizations. Spanish open mobility data is used as a case study. This data contains anonymized and grouped flows between more than 3500 locations in Spain with hourly intervals across 3 full years. Thanks to the inclusion of several demographic variables, this data presents a universe of opportunities for analysis and research questions to explore.","Egor Kotov, Johannes Mast",Vingen 7,,,,
2025-07-21 13:30:00,2025-07-21 17:00:00,single,Tutorial 10: Computational Social Science for Sustainability,"Humans face an existential challenge to transition to sustainable practices that do not exhaust available ecological, economic, and social capital. Computational social-cognitive models can be used to deduce the efficacy of potential training or educational interventions to promote sustainable practices. Tutorial attendees will learn to use the socmod library to create their own models of social learning and social influence to predict the relative success of different intervention strategies. Sustainability motivates this work, but the framework could be used to model related social and behavioral contexts.","Matthew A. Turner, James Holland Jones",Vingen 1,,,,
,,,,,,,,,,
2025-07-22 09:00:00,2025-07-22 09:45:00,keynote,Keynote 1: Effect sizes and decisions,"Social scientists often aim to not only determine whether some effect exists, but to quantify it. This often requires much larger or otherwise much more informative studies. It also requires choices of how to quantify effects. What relationship do various such quantifications have to scientific knowledge and, of particular relevance in applied work, to decisions? Using some examples from our recent experiments and other prominent, recent studies, I highlight how some effect size measures are typically decision-irrelevant and do not facilitate gaining generalizable knowledge. I also examine how we can use relevance to decisions to help select quantities of interest in the context of interventions in networks.",Dean Eckles,De Geerhallen,,,,
2025-07-22 09:45:00,2025-07-22 10:30:00,keynote,Keynote 2: Computational analysis of social and organizational systems,"The US National Academy in its decadal survey of the Social Sciences argued that today we are in an era of Networks+.  In other words, rarely do people use social network or network science techniques in isolation; rather, these are augmented with other computationally based techniques such as computational linguistics and machine learning.  In the area of social-cybersecurity, a field concerned with identifying, characterizing and mitigating online harms such as undue influence, disinformation, hate-speech and extremism, network science is frequently combined with various AI techniques to build more effective tools to support interventions, to improve imperial analysis, and to simulate behavior. A particular area of concern is influence, that is ""who is influencing whom on line, how and to what effect?"".  The BEND framework has been proposed as a way of systematically characterising such information operations, and it has been operationalized using network science + AI techniques in a way that enables the analyst in detecting, characterizing, mitigating, and assessing the impact of influence activities, those being influenced, and the influencer.  In this presentation the BEND framework and its operationalization using network science+AI  will be described.  Then the insights that can be drawn using this approach will be illustrated using data from various events around the world. The presentation with a call for future research and an itemization of limitations and gaps where new techniques and additional research are needed.",Kathleen Carly,De Geerhallen,,,,
2025-07-22 16:45:00,2025-07-22 17:30:00,keynote,Keynote 3: Design-Based Supervised Learning: A General Framework for Using LLM Annotations and Other Predicted Variables in Downstream Analyses,TBA,Brandon Stewart,De Geerhallen,,,,
2025-07-22 17:30:00,2025-07-22 18:15:00,keynote,Keynote 4: Arti-“fickle” Intelligence: Using LLMs as a Tool for Inference in the Political and Social Sciences,"Generative large language models (LLMs) are incredibly useful, versatile, and promising tools. However, they will be of most use to political and social science researchers when they are used in a way that advances understanding about real human behaviors and concerns. To promote the scientific use of LLMs, we suggest that researchers in the political and social sciences need to remain focused on the scientific goal of inference. To this end, we discuss the challenges and opportunities related to scientific inference with LLMs, using validation of model output as an illustrative case for discussion. We propose a set of guidelines related to establishing the failure and success of LLMs when completing particular tasks, and discuss how we can make inferences from these observations. We conclude with a discussion of how this refocus will improve the accumulation of shared scientific knowledge about these tools and their uses in the social sciences.",Lisa P. Argyle,De Geerhallen,,,,
2025-07-23 09:00:00,2025-07-23 09:45:00,keynote,Keynote 5: Why Qualitative Research Needs Computational Social Science,"Computational methods are playing a larger role in qualitative social science, but often with the goal of scaling or automating qualitative inquiry. Scaling and automating approaches are rooted in quantitative traditions, which are focused on measurement, generalizability, and evaluation against fixed benchmarks. But qualitative research is grounded in a different logic. It aims to understand meaning, context, and how people experience the world differently depending on their social position. This talk argues that if we want to use computational methods for qualitative research, we need to develop them differently than the current approach. For example, while machine learning is often framed as a tool for classification, its strength in identifying emergent patterns in large amounts of qualitative data aligns with inductive and abductive reasoning long used in qualitative research. Evaluating classification algorithms against a pre-determined ""ground truth"" stunts their development for inductive/abductive exploration and qualitative logics. In this talk I will share examples of how computational tools can support qualitative goals—not by making qualitative work more quantitative, but by shifting how we build, evaluate, and use these tools. This includes recognizing multiple perspectives in the data, treating researchers as active interpreters, and developing criteria that reflect qualitative rather than quantitative values.",Laura Nelson,De Geerhallen,,,,
2025-07-23 16:45:00,2025-07-23 17:30:00,keynote,Keynote 6: The Sociology of Interpretation: A Computational Approach,"Culture shapes how we make sense of the world. People occupying different cultural positions often interpret the same realities in different ways. Recent advances in computational linguistics now make it possible to systematically measure these divergent interpretations at scale. In this talk, I introduce the Categorization-Association model of interpretation—a framework for capturing shared interpretation as well as processes of interpretive coordination and divergence. Drawing on computational analyses across multiple cultural domains—from American politics to popular understandings of leisure, work, and artificial intelligence—I show how culture reveals a fractured or ""broken"" geometry of meaning. This work illustrates how computational methods can help deepen our sociological understanding of culture, while underscoring the importance of grounding computational social science in robust theory.",Amir Goldberg,De Geerhallen,,,,
2025-07-23 17:30:00,2025-07-23 18:15:00,keynote,Keynote 7: Luck and success in millions of life courses,This talk probes the role luck and success in the life course. We ask whether when people get lucky the trajectory of their life success increasingly diverges from that of their unlucky counterpart. We study this question theoretically using basic models of positive feedback. Empirically we look at the lives of thousands of Americans tracked in panel survey data and millions of Swedes captured in register data. We focus on income as measure of success and study a host of different ways by which people might be lucky or unlucky at different stages of the life course. We use causal identification strategies to isolate pairs of egos and alteregos who led similarly lives before the event and then compare their life courses afterwards.,Arnout van de Rijt,De Geerhallen,,,,
2025-07-24 09:00:00,2025-07-24 09:45:00,keynote,Keynote 8: Integrating explanation and prediction in computational social science,"Computational social science is more than just large repositories of digital data and the computational methods needed to construct and analyze them. It also represents a convergence of different fields with different ways of thinking about and doing science. In this talk, I discuss how these approaches differ from one another and propose how they might be more productively integrated. First, I propose a schema for thinking about research activities along two dimensions—the extent to which work is explanatory, focusing on identifying and estimating causal effects, and the degree of consideration given to testing predictions of outcomes—and how these two priorities can complement, rather than compete with, one another. Second, I advocate that computational social scientists devote more attention to combining prediction and explanation, which I call “integrative modelling,” and outline some practical suggestions for realizing this goal.",Duncan Watts,De Geerhallen,,,,
2025-07-24 16:45:00,2025-07-24 17:30:00,keynote,Keynote 9: Urban policy and big data for public good,"Williams will explain how we can use data as a tool for empowerment rather than oppression, something Williams calls ""Data Action,"" which is also the title of her recent book. Data Action seeks to provide guidance for using data toward the benefit of society, learning from the ways we have used data unethically in the past and illustrating ways we can use it more ethically and creatively in the future. Williams will illustrate the seven Data Action principles through her diverse research projects spanning topics of Central American migration, popular transit in Africa, ghost cities in China, and translating New York City’s zoning text. Williams will also show her most recent work on People Powered AI: How to use Gen AI for Civic Engagement. ",Sarah Williams,De Geerhallen,,,,
,,,,,,,,,,
2025-07-21 07:30:00,2025-07-21 09:00:00,meta,Registration desk open,,,,,,,
2025-07-22 07:30:00,2025-07-22 08:45:00,meta,Registration desk open,,,,,,,
2025-07-23 07:30:00,2025-07-23 09:00:00,meta,Registration desk open,,,,,,,
,,,,,,,,,,
2025-07-21 10:30:00,2025-07-21 11:00:00,meta,Coffee break,,,,,,,
2025-07-22 10:30:00,2025-07-22 11:00:00,meta,Coffee break,,,,,,,
2025-07-23 10:30:00,2025-07-23 11:00:00,meta,Coffee break,,,,,,,
2025-07-24 10:30:00,2025-07-24 11:00:00,meta,Coffee break,,,,,,,
2025-07-21 15:00:00,2025-07-21 15:30:00,meta,Coffee break,,,,,,,
2025-07-22 16:15:00,2025-07-22 16:45:00,meta,Coffee break,,,,,,,
2025-07-23 16:15:00,2025-07-23 16:45:00,meta,Coffee break,,,,,,,
2025-07-24 16:15:00,2025-07-24 16:45:00,meta,Coffee break,,,,,,,
,,,,,,,,,,
2025-07-21 12:30:00,2025-07-21 13:30:00,meta,Lunch,,,,,,,
2025-07-22 12:30:00,2025-07-22 13:30:00,meta,Lunch,,,,,,,
2025-07-23 12:30:00,2025-07-23 13:30:00,meta,Lunch,,,,,,,
2025-07-24 12:30:00,2025-07-24 13:30:00,meta,Lunch,,,,,,,
,,,,,,,,,,
2025-07-21 17:00:00,2025-07-21 20:00:00,special,Welcome reception,,IC2S2 Program Chairs,De Geerhallen,,,,
2025-07-22 19:00:00,2025-07-22 22:00:00,special,Conference dinner,,IC2S2 Program Chairs,Värmekyrkan,,,,
,,,,,,,,,,
2025-07-22 08:45:00,2025-07-22 09:00:00,special,Opening remarks,,IC2S2 Program Chairs,De Geerhallen,,,,
2025-07-24 17:30:00,2025-07-24 18:15:00,special,Town hall and Closing Remarks,,IC2S2 Program Chairs,De Geerhallen,,,,
,,,,,,,,,,
2025-07-23 09:45:00,2025-07-23 10:30:00,session_presentation,Miscalibrated trust hinders effective partner choices in human-AI collectives,"Trust, a cornerstone of human cooperation, faces unprecedented challenges as artificial intelligence (AI) agents permeate social systems, transforming mechanisms humans have evolved to build trust. We demonstrate how a prevalent feature of AI agents––being excessively prosocial––reshapes trust dynamics in experiments (N = 675) simulating hybrid societies comprising humans and AI agents (“bots”) powered by state-of-the-art large language models. Using a partner-selection game with pre-decision communication, Study 1 revealed a paradox: Undisclosed bots, despite being more trustworthy than humans and detectable by communication, were not preferentially selected. Instead, bots’ prosociality was misattributed to their human competitors. Study 2 showed that disclosing the human or bot identity of partner candidates initially enhanced humans’ bias against bots, but improved trust calibration over time. Our findings highlight the importance of evaluating AI agents in interactive hybrid environments and the role of transparency in facilitating dynamic calibration of trust in human-AI ecosystems.","Yaomin Jiang, Levin Brinkmann, Anne-Marie Nussberger, Ivan Soraperra, JF Bonnefon, Iyad Rahwan",De Geerhallen,"Lightning Talks I: Human-LLM Interactions, Mobility & Inequality",1,,361
2025-07-23 09:45:00,2025-07-23 10:30:00,session_presentation,Bayesian Modeling of Multi-Step Discussions Between LLM Agents: Disentangling Opinion Dynamics from Intrinsic Bias Effects,"Recent Large Language Models (LLMs) exhibit remarkable human-like text generation capabilities, making them a potential tool for simulating human behavior and thus studying social phenomena. For instance, complex opinion dynamics may be simulated by initializing LLM agents with different opinions on a topic and observing their opinion change throughout a discussion. However, past attempts to use LLM agents for such simulations revealed an inherent bias toward consensus and toward factual accuracy, driving agents' opinions to the consensus opinion encoded in the LLMs. Moreover, the robustness of such simulations remains uncertain due to prompt sensitivity, while the lack of standardized evaluation metrics and benchmarks further reduces the comparability across studies. In this work, we used Bayesian modeling to disentangle agent-inherent biases from interaction dynamics. Our model reveals that discussions between two LLM agents are dominated by two biases; (i) toward the LLM's prior opinion distribution for a specific topic (topic bias) and (ii) toward agreement irrespective of the prompted statement (agreement bias), whereas the initial prompting of the agent's opinion has little impact. By fitting an effective Bayesian model of opinion dynamics to the opinion shifts in LLMs, we provide a human-interpretable method that potentially simplifies the modeling of large groups of artificial agents.","Vincent Christoph Brockers, David Alexander Ehrlich, Viola Priesemann",De Geerhallen,"Lightning Talks I: Human-LLM Interactions, Mobility & Inequality",2,,373
2025-07-23 09:45:00,2025-07-23 10:30:00,session_presentation,"People who share encounters with racism are silenced online by humans and machines, but a guideline-reframing intervention holds promise","Are members of marginalized communities silenced on social media when they share personal experiences of racism? Here, we investigate the role of algorithms, human users, and platform guidelines in suppressing disclosures of racial discrimination. In a field study of actual posts from a neighborhood-based social media platform, we find that when users talk about their experiences as targets of racism, their posts are disproportionately flagged for removal as toxic by five widely used moderation algorithms from major online platforms, including the most recent large language models. We show that human users disproportionately flag these disclosures for removal as well. Next, in a follow-up experiment, we demonstrate that merely witnessing such suppression negatively influences how Black Americans view the community and their place in it. Finally, using computational linguistic tools, we identify key factors influencing flagging behavior and develop an intervention that successfully reduces misguided flagging behavior across the political spectrum.","Cinoo Lee, Kristina Gligoric, Pratyusha Kalluri, Maggie Harrington, Esin DURMUS, Kiara L. Sanchez, Nay San, Danny Tse, Xuan Zhao, MarYam Hamedani, Hazel Rose Markus, Dan Jurafsky, Jennifer L. Eberhardt",De Geerhallen,"Lightning Talks I: Human-LLM Interactions, Mobility & Inequality",3,,679
2025-07-23 09:45:00,2025-07-23 10:30:00,session_presentation,Route diversification in road networks,"In this article, we examine how road network topology and the presence of mobility attractors (e.g., highways and ring roads) shape route diversification. We introduce DiverCity, a measure that quantifies the extent to which traffic can potentially be distributed across multiple, loosely overlapping routes. Analyzing 56 global cities, we find that DiverCity is tied to traffic efficiency and network characteristics such as network length and number of intersections. Within cities, DiverCity increases with distance from the city center before stabilizing in the periphery but declines in the proximity of mobility attractors. We demonstrate that strategic speed limit adjustments on mobility attractors can increase DiverCity while preserving travel efficiency. In addition, we use a controlled setting to isolate the interplay between mobility attractors and DiverCity, confirming the patterns observed in real-world cities. DiverCity provides a practical tool for urban planners and policymakers to optimize road network design and balance route diversification, efficiency, and sustainability.","Giuliano Cornacchia, Luca Pappalardo, Mirco Nanni, Dino Pedreschi, Marta C. Gonzalez",De Geerhallen,"Lightning Talks I: Human-LLM Interactions, Mobility & Inequality",4,,418
2025-07-23 09:45:00,2025-07-23 10:30:00,session_presentation,Social Capital Around the World,"We use data from nearly 2 trillion friendship links between 2.5 billion Facebook users to build and analyze novel measures of subnational social capital in nearly 200 countries and territories. We first document substantial variation in the rate at which individuals form cross-class social ties, with large differences in friending rates both within and across countries. Cross-class social ties are relatively common in parts of Western Europe and relatively scarce in South Africa and parts of South Asia. Countries vary in the degree to which cross-class ties are determined by regional differences in average income. In places such as Italy, one's degree of connection to high income peers is largely determined by one's place of residence, while other countries such as Saudi Arabia, high- and low-socioeconomic status (SES) users have dramatically different networks, even within a region. We link our measures of cross-class social ties with external measures of intergenerational mobility, finding that places where low-SES individuals have more high-SES friends have higher rates of economic mobility in all countries in which we have data.","Drew Johnston, Michael Bailey, Ayush Kumar, Theresa Kuchler, Johannes Stroebel",De Geerhallen,"Lightning Talks I: Human-LLM Interactions, Mobility & Inequality",5,,432
2025-07-23 09:45:00,2025-07-23 10:30:00,session_presentation,Mapping Life Trajectories: A Machine Learning Approach to Clustering Multidimensional Life Courses,"Taking a life-course perspective, this paper uses novel machine-learning methods to identify typologies of life trajectories by classifying multi-dimensional life-trajectory data with transformer embeddings. This paper also demonstrates how demographic characteristics predict trajectory typology memberships and how typology memberships are associated with later-life outcomes. Using data from the 1970 British Cohort Study, I first establish a two-dimensional life trajectory data combining individuals’ partnership histories and work/education histories. I apply transformer-based embeddings to capture complex temporal dependencies and dynamics from multi-dimensional trajectory data. I then apply K-Means and Gaussian Mixture Models (GMM) clustering methods to classify individuals based on learned representations. The choice of embedding models, clustering methods, and hyperparameters is optimized via key performance metrics. Preliminary results identify four female clusters and five male clusters with distinct work-life trajectories. Qualitatively, the four female clusters can be described as “late bloomers”, “independent & steady”, “marriage & caregiving first”, and “career-family jugglers”. The five male clusters can be described as “early cohabitation with continuous struggles”, “cohabiting careerists”, “late committers, long learners”, “traditional breadwinners”, and “young settlers”. Among them, the “independent & steady” and “marriage & caregiving first” women are associated with worse economic security and physical and mental health outcomes at the age of 46. “Early cohabitation with continuous struggles” men are associated with worse economic security and physical and mental health outcomes at the age of 46. Another key finding is that GMM performs better for women while K-Means performs better for men in clustering life trajectories. It might suggest fundamental gendered differences in life-course patterns—with women having more fluid, overlapping, and nonlinear trajectories than men. This research makes both a methodological contribution as one of the first studies to apply transformer-based embeddings to life trajectory data, and a substantive contribution by advancing the understanding of the gendered typologies of behavioral patterns and life trajectories.",Zerui Tian,De Geerhallen,"Lightning Talks I: Human-LLM Interactions, Mobility & Inequality",6,,116
2025-07-23 09:45:00,2025-07-23 10:30:00,session_presentation,Gender Bias in How Public Figures are Referenced in News Quotes at Scale,"The way in which we refer to other individuals in discourse reflects social dynamics, attitudes, and underlying biases. Choices in personal references, such as first or last names, may indicate not just the relationship between individuals but also the underlying (gender) biases, personal relationships, status differences, or attitudes toward the referenced individual. In professional settings, naming conventions often reinforce power hierarchies, with last name usage indicating perceived eminence or authority. This seemingly subtle linguistic choice can have significant real-world implications, influencing perceptions of credibility and even the likelihood of receiving career awards. Gender plays a crucial role in these patterns, with male professionals being more than twice as likely as their female counterparts to be referenced by last name. Prior studies on spoken political discourse, such as analyses of American radio transcripts, confirm that gendered naming conventions persist in verbal discussions of politicians. In a similar vein, a study of Reddit comments examining references to politicians found that male politicians are overwhelmingly referred to by last name (69.7% of the time), whereas female politicians are more frequently addressed by their full name (41.1%) or given name (25.1%). While this prior work establishes a strong correlation between gender and reference type, the causal mechanisms remain only partially understood. In this study, we demonstrate that gendered naming conventions are prevalent not only in (direct) personal interactions but also in professional discourse across different domains, as recorded through quotes in news articles. By controlling for the context in which quotes occur, we aim to isolate the drivers of reference choices and explore how linguistic patterns may shape public perceptions of authority and competence.","Justyna Janczy, Marko Čuljak, Andreas Spitz, Akhil Arora",De Geerhallen,"Lightning Talks I: Human-LLM Interactions, Mobility & Inequality",7,,854
2025-07-23 09:45:00,2025-07-23 10:30:00,session_presentation,Scientific productivity and practice in the era of Large Language Models,"The scientific enterprise is intimately connected with technological innovation. The introduction of the microscope, advances in computing, and next-generation sequencers, for example, have shifted out the frontier of research. Today, the fast adoption of generative artificial intelligence (Gen AI) across all academic disciplines is recasting scientific production. Despite growing excitement (and concern) about Gen AI’s role in research, however, empirical evidence remains fragmented, and systematic understanding of the impact of Large Language Models across scientific domains is limited.","Keigo Kusumegi, Xinyu Yang, Paul Ginsparg, Mathijs de Vaan, Toby Stuart, Yian Yin",De Geerhallen,"Lightning Talks I: Human-LLM Interactions, Mobility & Inequality",8,,926
,,,,,,,,,,
2025-07-24 09:45:00,2025-07-24 10:30:00,session_presentation,The Media Bias Detector: A Framework for Annotating and Analyzing the News at Scale,"Mainstream news organizations shape public perception not only directly through the articles and segments they produce, but the choices they make about what topics go into their content (and which topics do not), how they frame that coverage relative to other potentially valid framings. However, measuring these subtle forms of media bias at scale remains a challenge. Here, we introduce a large, ongoing (from January 1, 2023 to present), near real-time dataset and computational framework developed to enable systematic study of selection and framing bias in news coverage. Our pipeline integrates large language models (LLMs) with scalable, near real-time news scraping to extract structured annotations--including political lean, tone, topics, article type, and events--across hundreds of articles per day. We quantify these dimensions of coverage at multiple levels, from the sentence-level to the article-level and to aggregate publisher trends, expanding the ways researchers can analyze media bias in the modern news landscape. In addition to a curated dataset, we also release an interactive web platform for convenient exploration of this data. Together, these contributions establish a reusable methodology for studying media bias at scale, providing empirical resources for future research. By leveraging the corpus’s breadth across time and publishers, we present examples (focused on the 150,000+ articles examined in 2024) that illustrate how this dataset can reveal patterns in news coverage and bias, supporting both academic research and real-world efforts to enhance media accountability.","Samar Haider, Jenny Shan Wang, Amir Tohidi Kalorazi, Timothy Dörr, David Rothschild, Chris Callison-Burch, Duncan J. Watts",De Geerhallen,"Lightning Talks II: Media Bias, Oral Histories, Repressive Digital Governance, Science of Science",1,,905
2025-07-24 09:45:00,2025-07-24 10:30:00,session_presentation,Understanding Media Bias through Actor Portrayals,"Differences in storytelling across international media can promote polarization and fuel conflicts, especially in the context of foreign news. While researchers have long studied how media select and frame sets of events for their coverage, and computational approaches to media-bias detection have gained popularity in recent years, to date, no unified framework for the scalable detection of media bias exists. We propose to develop such a framework based on the notion of actor portrayals, i.e., language patterns arising from actor descriptions in media reporting. As we demonstrate for the Israel–Palestine and the Russia–Ukraine conflicts, measuring the differences between actor portrayals using Bayesian statistics allows us to quantify media bias without reference to some ""unbiased"" baseline. Our approach readily applies to any corpus of news articles or other media items collected from one or more news outlets, and it opens novel research directions in the computational study of media bias.","Ali Salloum, Yan Xia, Mikko Kivelä, Corinna Coupette",De Geerhallen,"Lightning Talks II: Media Bias, Oral Histories, Repressive Digital Governance, Science of Science",2,,209
2025-07-24 09:45:00,2025-07-24 10:30:00,session_presentation,Collective Memory and Narrative Cohesion: A Computational Study of Palestinian Refugee Oral Histories in Lebanon,"This study uses the Palestinian Oral History Archive (POHA) to investigate how Palestinian refugee groups in Lebanon sustain a cohesive collective memory of the Nakba through shared narratives. Grounded in Halbwachs’ theory of group memory, we employ statistical analysis of pairwise similarity of narratives, focusing on the influence of shared gender and location. We use textual representation and semantic embeddings of narratives to represent the interviews themselves. Our analysis demonstrates that shared origin is a powerful determinant of narrative similarity across thematic keywords, landmarks, and significant figures, as well as in semantic embeddings of the narratives. Meanwhile, shared residence fosters cohesion, with its impact significantly amplified when paired with shared origin. Additionally, women’s narratives exhibit heightened thematic cohesion, particularly in recounting experiences of the British occupation, underscoring the gendered dimensions of memory formation. This research deepens the understanding of collective memory in diasporic settings, emphasizing the critical role of oral histories in safeguarding Palestinian identity and resisting erasure.","Ghadeer Awwad, David Gamba, Lavinia Dunagan, Tamara N. Rayan",De Geerhallen,"Lightning Talks II: Media Bias, Oral Histories, Repressive Digital Governance, Science of Science",3,,834
2025-07-24 09:45:00,2025-07-24 10:30:00,session_presentation,Algorithmic Amplification in China: How Platforms Boost State Visibility,"Social media have been widely employed by authoritarian regimes for surveillance, censorship, and propaganda to compete for online attention. Although effective propaganda states can invest massive resources and efforts to disseminate state propaganda, the personalized curation and filter bubbles embedded in social media algorithms complicate efforts to reach users with nonpolitical interests. While research has focused on the content and dissemination strategies of authoritarian political propaganda, less is known about the role of platform algorithms in increasing or inhibiting the reach of political propaganda. Through the collection and analysis of a novel dataset of 120,245 trending and recommended videos on Bilibili, one of China’s largest entertainment platforms, we found that recommendation algorithms on the entertainment platform can amplify the visibility of state-produced content. Coupled with a different content mix featuring a significantly higher presence of propaganda content than non-state accounts, state-sponsored accounts leverage both new content strategies and algorithmic settings on the entertainment platform to increase the reach of their propaganda. These findings highlight an algorithmic pathway through which authoritarian regimes may increase their online influence, offering critical insights into the role of social media algorithms in an authoritarian context.","Yingdan Lu, Xinyi Liu, Carl Zhou",De Geerhallen,"Lightning Talks II: Media Bias, Oral Histories, Repressive Digital Governance, Science of Science",4,,377
2025-07-24 09:45:00,2025-07-24 10:30:00,session_presentation,The Digital Authoritarian: Everyday behavioral patterns collected with smartphones predict authoritarianism,"We show that digital traces of everyday behavior collected with smartphones predict individuals’ authoritarian tendencies. More than 280 million app usage, music listening, language usage, calling and texting, screen unlocking and locking, and GPS location events were recorded from 669 participants’ smartphones’ sensors and logs for three to six months. These digital records were then used to derive behavioral variables that could predict authoritarianism according to prior theory. Theory-informed behavioral variables predicted self-reported authoritarianism levels (r_md = .30) in machine learning models better than and independently of demographic characteristics (i.e., age, gender, nationality, education). We identified the behaviors most informative of an individual’s authoritarian tendencies to construct a profile of authoritarianism in everyday life. Our findings have implications for researchers and policymakers interested in understanding authoritarianism among ordinary citizens, especially as democracy erodes globally.","Timo Koch, Sanaz Talaifar, Daniel Racek, Jan Digutsch, Pietro Alessandro Aluffi, Ramona Schoedel, Markus Buehner, Clemens Stachl",De Geerhallen,"Lightning Talks II: Media Bias, Oral Histories, Repressive Digital Governance, Science of Science",5,,764
2025-07-24 09:45:00,2025-07-24 10:30:00,session_presentation,Research Borderlands: Writing Across Communities,"Communication in communities, including research communities is governed by cultural norms and expectations. Prior works have focused on individual differentiating features, such as the differing vocabulary and values present in research papers. We develop a framework for building a holistic understanding of the variations in writing norms across research cultures through a survey (N=78) and interviews (N=10) of interdisciplinary researchers. We then operationalize this framework using computational metrics and demonstrate its application for: (a) surfacing variations in research papers from different communities at scale, and (b) evaluating LLMs’ alignment to different research cultures when rewriting text to suit a specific community.","Shaily Bhatt, Tal August, Maria Antoniak",De Geerhallen,"Lightning Talks II: Media Bias, Oral Histories, Repressive Digital Governance, Science of Science",6,,472
2025-07-24 09:45:00,2025-07-24 10:30:00,session_presentation,Causal Claims in Economics,"We analyze over 44,000 NBER and CEPR working papers from 1980--2023 using a custom language model to construct knowledge graphs that map economic concepts and their relationships. We distinguishe between general claims and those documented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document a substantial rise in the share of causal claims—from roughly 4% in 1990 to nearly 28% in 2020—reflecting the growing influence of the ``credibility revolution.'' We find that causal narrative complexity (e.g., the depth of causal chains) strongly predicts both publication in top-5 journals and higher citation counts, whereas non-causal complexity tends to be uncorrelated or negatively associated with these outcomes. Novelty is also pivotal for top-5 publication, but only when grounded in credible causal methods: introducing genuinely new causal edges or paths markedly increases both the likelihood of acceptance at leading outlets and long-run citations, while non-causal novelty exhibits weak or even negative effects. Papers engaging with central, widely recognized concepts tend to attract more citations, highlighting a divergence between factors driving publication success and long-term academic impact. Finally, bridging underexplored concept pairs is rewarded primarily when grounded in causal methods, yet such gap filling exhibits no consistent link with future citations. Overall, our findings suggest that methodological rigor and causal innovation are key drivers of academic recognition, but sustained impact may require balancing novel contributions with conceptual integration into established economic discourse.",Prashant Garg,De Geerhallen,"Lightning Talks II: Media Bias, Oral Histories, Repressive Digital Governance, Science of Science",7,,70
2025-07-24 09:45:00,2025-07-24 10:30:00,session_presentation,Facilitating Meetings with LLMs: An Experimental Study of Group Decision Making,"Group decision-making often suffers from uneven information sharing, hindering decision quality. While large language models (LLMs) have been widely studied as aids for individuals, their potential to support groups of users, potentially as facilitators, is relatively underexplored. We present a pre-registered randomized experiment with 1,475 participants assigned to five-person groups completing a hidden profile task—selecting an optimal city for a hypothetical sporting event—under one of four facilitation conditions: no facilitation, a one-time message prompting information sharing, a human facilitator, or an LLM (GPT-4o) facilitator. We find that LLM facilitation increases information shared within a discussion by raising the minimum level of engagement with the task among group members, and that these gains come at limited cost in terms of participants' attitudes towards the task, their group, or their facilitator. However, despite improved information exchange, we find no significant effect of facilitation on the final decision outcome, suggesting that decision-making biases may still persist. To support further research into how LLM-based interfaces can support the future of collaborative work, we release our experimental platform, the Group-AI Interaction Laboratory (GRAIL), as an open-source tool.","David Rothschild, Mohammed Alsobay, Jake M. Hofman, Daniel G. Goldstein",De Geerhallen,"Lightning Talks II: Media Bias, Oral Histories, Repressive Digital Governance, Science of Science",8,,743
,,,,,,,,,,
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Linear Representations of Political Perspective Emerge in Large Language Models,"Large language models (LLMs) have demonstrated the ability to simulate responses aligned with human subjective perspectives, such as liberal or conservative ideologies in American politics. Our study reveals that LLMs achieve this by learning a ""geometry of perspective"" that linearly represents subjective perspectives in the activation space, where similar simulated perspectives are represented closer to each other. Specifically, we probe the hidden layers of open, transformer-based LLMs (Llama-2-7b-chat, Mistral-7b-instruct, Vicuna-7b) when prompted to generate texts under the ideological perspective of distinct politicians. We find a set of attention heads that represent U.S. ideological slant, which is primarily located in the middle layers known to encode high-level concepts and tasks. The activation of these attention heads, when prompted about U.S. politicians and media outlets, linearly correlates with existing measures of their ideological slant. We use this activation to detect the ideological slant implicitly adopted by an LLM as it is generating each token. We further show that by intervening on these attention heads, we can tune LLM output to any position along the linear dimension from a liberal to conservative ideological perspective. Our research shows that political ideology serves as a fundamental dimension of LLM representations, and present an interpretability method to identify, monitor, and control the subjective perspective used to generate text.","Junsol Kim, James Evans, Aaron Schein",Concert hall,LLMs & Society,1,,946
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Semantic Shift Detection with an Application to Monitoring the Spread of Incel Jargon,"Dialects, sociolects or jargon spoken by distinct speech communities can contain existing words that evolve to have new senses (semantic shift). This poses a challenge to computational analysis of jargon proliferation, as automated methods have difficulties reconizin whether a given word is used in its original sense or in its jargon sense. We present ongoing research into an intuitive, human-readable method for semantic shift detection as well as qualitative diachronic analysis relating to polysemous jargon words as used in online community forums. We apply the method to the case of online incel communities and demonstrate how it can be used to support efforts into understanding jargon terminology associated with this subculture. The method is expected to be analogously applicable to other jargon and sociolects.","Helena Bjornesjo, Axel Alness Borg, Katie Cohen, Björn Pelzer, Erik Wachtmeister",Concert hall,LLMs & Society,2,,986
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Ideological Neural Manifolds of Large Language Models,"Large language models (LLMs) have demonstrated a remarkable ability to capture rich real-world features in their internal representations. This study explores their ability to model implicit multidimensional ideological structures as continuous manifolds. We propose two frameworks for extracting ideological manifolds from LLM neural activations: the corpus-based framework reduces the dimensionality of the activation space to automatically derive optimal manifolds from labeled text corpora; and the reference-based framework constructs interpretable spaces using fewer labeled texts as reference for projecting arbitrary text representations. These frameworks enable quantitative analysis of ideological positioning in text, presenting novel methodologies for social science research. Our analyses reveal that the emergent manifold structures not only align well with established political science evaluations, but also demonstrate remarkable consistencies across different layers, different models, and both proposed frameworks. This suggests that modern LLMs can indeed internalize nuanced ideological spectra in an accurate and robust way that mirrors the real-world social-political dimensions.","Yilun Liu, Daniel Matter, Jürgen Pfeffer",Concert hall,LLMs & Society,3,,254
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Addressing Pitfalls in Auditing Practices of Automatic Speech Recognition Technologies: A Case Study of People with Aphasia,"Automatic Speech Recognition (ASR) has transformed daily tasks from video transcription to workplace hiring. ASR systems' growing use warrants robust and standardized auditing approaches to ensure automated transcriptions of high and equitable quality. This is especially critical for people with speech and language disorders (such as aphasia) who may disproportionately depend on ASR systems to navigate everyday life. In this work, we identify three pitfalls in existing standard ASR auditing procedures, and demonstrate how addressing them impacts audit results via a case study of six popular ASR systems' performance for aphasia speakers. First, audits often adhere to a single method of text standardization during data pre-processing, which (a) masks variability in ASR performance from applying different standardization methods, and (b) may not be consistent with how users---especially those from marginalized speech communities---would want their transcriptions to be standardized. Second, audits often display high-level demographic findings without further considering performance disparities among (a) more nuanced demographic subgroups, and (b) relevant covariates capturing acoustic information from the input audio. Third, audits often rely on a single gold-standard metric---the Word Error Rate---which does not fully capture the extent of errors arising from generative AI models, such as transcription hallucinations. We propose a more holistic auditing framework that accounts for these three pitfalls, and exemplify its results in our case study, finding consistently worse ASR performance for aphasia speakers relative to a control group. We call on practitioners to implement these robust ASR auditing practices that remain flexible to the rapidly changing ASR landscape.","Katelyn X. Mei, Anna Seo Gyeong Choi, Hilke Schellmann, Mona Sloane, Allison Koenecke",Concert hall,LLMs & Society,4,,676
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,AI-based Analysis of Terrorgram Aesthetics,"This is an ongoing project where a diffusion model with image-to-prompt ability is utilized to analyze visual messages in accelerationist right-wing extremist propaganda. Using generative AI might open a possibility of large-scale analysis of aspects of propaganda that hitherto have been unavailable for automatization, i.e, ambience, visual identity, artistic influence etc. Results are expected during the first half of 2025.",Katie Cohen,Concert hall,LLMs & Society,5,,565
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Dialogues with AI about AI-generated images can increase discernment but not short-term learning,"The widespread emergence of manipulated news media content poses significant challenges to online information integrity. This study investigates whether dialogues with AI about AI-generated images and associated news statements can increase human discernment abilities and foster short-term learning in detecting misinformation. We conduct a study with 80 participants who engage in structured dialogues with an AI system about news headline-image pairs, generating 1,310 human-AI dialogue exchanges. Results show that AI interaction significantly boosts participants' accuracy in identifying real versus fake news content from approximately 60% to 90% (p<0.001). However, these improvements do not persist when participants are presented with new, unseen image-statement pairs without AI assistance, with accuracy returning to baseline levels (~60%, p=0.88). These findings suggest that while AI systems can effectively change immediate beliefs about specific content through persuasive dialogue, they may not produce lasting improvements that transfer to novel examples, highlighting the need for developing more effective interventions that promote durable learning outcomes.","Anku Rani, Valdemar Danry, Andrew Lippman, Patricia Maes",Concert hall,LLMs & Society,6,,613
,,,,,,,,,,
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,"Propaganda is already influencing large language models: evidence from training data, audits, and real-world usage","We report on a concerning phenomenon in generative AI systems: coordinated propaganda from political institutions influences the output of large language models (LLMs) via the training data for these models. We present a series of five studies that together provide evidence consistent with the argument that LLMs are already being influenced by state propaganda in the context of Chinese state media. First, we demonstrate that material originating from China's Publicity Department appears in large quantities in Chinese language open-source training datasets. Second, we connect this to commercial LLMs by showing not only that they have memorized sequences that are distinctive of propaganda, but propaganda phrases are memorized at much higher rates than those in other documents. Third, we conduct additional training on an LLM with openly available weights to show that training on Chinese state propaganda generates more positive answers to prompts about Chinese political institutions and leaders---evidence that propaganda itself, not mere differences in culture and language, can be a causal factor behind this phenomenon. Fourth, we document an implication in commercial models---that querying in Chinese generates more positive responses about China's institutions and leaders than the same queries in English. Fifth, we show that this language difference holds in prompts related to Chinese politics created by actual Chinese-speaking users of LLMs. Our results suggest the troubling conclusion that going forward there may be strategic incentives for states and other actors to increase the prevalence of propaganda in the future as generative AI becomes more ubiquitous.","Hannah Waight, Eddie Yang, Yin Yuan, Solomon Messing, Margaret Roberts, Brandon M. Stewart, Joshua Tucker",Concert hall,LLMs & Bias,1,,838
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Characterizing Bias: Benchmarking Large Language Models in Simplified versus Traditional Chinese,"While the capabilities of Large Language Models (LLMs) have been studied in both Simplified and Traditional Chinese, it is yet unclear whether LLMs exhibit differential performance when prompted in these two variants of written Chinese. This understanding is critical, as disparities in the quality of LLM responses can perpetuate representational harms by ignoring the different cultural contexts underlying Simplified versus Traditional Chinese, and can exacerbate downstream harms in LLM-facilitated decision-making in domains such as education or hiring. To investigate potential LLM performance disparities, we design two benchmark tasks that reflect real-world scenarios: regional term choice (prompting the LLM to name a described item which is referred to differently in Taiwan and Mainland China), and regional name choice (prompting the LLM to choose who to hire from a list of names in both Simplified and Traditional Chinese). For both tasks, we audit the performance of ten leading commercial LLM services and open-sourced models---spanning those primarily trained on English, Simplified Chinese, or Traditional Chinese. Our qualitative analyses indicate that biases in LLM responses are dependent on both the task and prompting language: while most LLMs disproportionately favored Simplified Chinese responses in the regional term choice task, they surprisingly favored Traditional Chinese names in the regional name choice task. We find that these disparities may arise from differences in training data representation, written character preferences, and tokenization of Simplified and Traditional Chinese. These findings highlight the need for further analysis of LLM biases; as such, we provide an open-sourced benchmark dataset to foster reproducible evaluations of future LLM behavior across Chinese language variants.","Hanjia Lyu, Jiebo Luo, Jian Kang, Allison Koenecke",Concert hall,LLMs & Bias,2,,81
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Decoding AI Judgment: How LLMs Assess News Credibility and Bias,"This study investigates how Large Language Models (LLMs) assess news credibility and political bias by benchmarking their outputs against structured human evaluations from NewsGuard and MBFC. Analyzing models like GPT-4o, Gemini 1.5, and LLaMA 3.1, the research reveals that LLMs align closely with human assessments in detecting unreliable sources but tend to misclassify right-leaning outlets as unreliable more frequently. Keyword analysis shows that models rely on linguistic heuristics, linking reliability to concepts such as “neutral language” or ""factual reporting"" and unreliability to “sensationalism” or “misinformation”. The study also introduces an agentic framework, enabling models to actively gather and analyze content, further highlighting that transparency and bias are key decision criteria. Despite high accuracy even in minimal-context settings, the findings underscore the need for transparency to mitigate potential bias in AI-driven credibility assessments.","Edoardo Loru, Jacopo Nudo, Niccolò Di Marco, Edoardo Di Martino, Matteo Cinelli, Walter Quattrociocchi",Concert hall,LLMs & Bias,3,,324
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Name of Thrones: How LLMs Rank Student Names in Status Hierarchies Based on Race and Gender,"Across cultures, names tell a lot about their bearers as they carry deep personal, historical, and cultural significance. Names have also been found to serve as powerful signals of gender, race, and status in the social hierarchy--a pecking order in which individual positions shape others’ expectations on their perceived competence and worth (Podolny, 2005). With the widespread adoption of Large Language Models (LLMs) and given that names are often an input for LLMs, it is crucial to evaluate whether LLMs sort people into status positions based on first and last names and, if so, whether it is in an unfair, biased fashion. While prior work has primarily investigated biases in first names, little attention has been paid to last names and even less to the combined effects of first and last names. In this study, we conduct a large-scale analysis with bootstrap standard errors of 45,000 name variations across 5 ethnicities to examine how AI-generated responses exhibit systemic name biases. Our study investigates three key characteristics of inequality and finds that LLMs reflect, construct, and reinforce status hierarchies based on names that signal gender and ethnicity as they encode differential expectations of competence, economic, and leadership potential. Contrary to the common assumption that AI tends to favor Whites, we show that East and, in some contexts, South Asian names receive higher rankings. We also disaggregate Asians, a population projected to be the largest immigrant group in the U.S. by 2055. Our results challenge the monolithic Asian model minority assumption, illustrating a more complex and stratified model of bias. Gender moderates biases, with girls having advantages in certain racial groups while facing unfair disadvantages in others. Additionally, spanning cultural categories by adopting Western first names improves AI-perceived status for East and Southeast Asian students, particularly for girls. Our findings underscore the importance of intersectional and more nuanced understandings of race, gender, and mixed identities in the evaluation of LLMs, rather than relying on broad, monolithic, and mutually exclusive racial or gender categories. By examining LLM bias and discrimination in our multicultural contexts through the sociological status lenses, our study illustrates potential harms of using LLMs in education as they do not merely reflect implicit biases but also actively construct new social hierarchies that can unfairly shape long-term life trajectories. An LLM that systematically assigns subtly less favorable evaluations and expectations to students with certain name signals reinforces a tiered system of opportunity. Some groups may face structural disadvantages, while others encounter undue pressure from inflated expectations.","Jonathan Sakunkoo, Annabella Sakunkoo",Concert hall,LLMs & Bias,4,,900
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Whose Name Comes Up? Auditing LLM-Based Scholar Recommendations,"In today’s rapidly evolving digital landscape, equitable and modern author search tools are essential to ensure visibility for all scholars, particularly talented under-represented minorities often overlooked by traditional algorithms. As Large Language Models (LLMs) increasingly mediate scholarly searches, assessing their role in diversity becomes crucial. With this in mind, this study evaluates the performance of six open-weight LLMs (llama3-8b, llama3.1-8b, gemma2-9b, mixtral-8x7b, llama3-70b, llama3.1-70b) in recommending experts in Physics across five tasks: top-k experts, influential scientists by field, epoch, seniority, and scholar counterparts. The evaluation focuses on consistency, factuality, representation bias in gender, ethnicity, and academic popularity. Results show that llama models excel in author factuality, gemma2-9b performs best in epoch-based recommendations, and mixtral-8x7b leads in seniority matching. All LLMs exhibit biases, over-representing males and Whites while under-representing Asians. Compared to the physicist population, they display a slight over-representation for females, Hispanics, and Blacks. Additionally, LLMs struggle with contemporary and lesser-known scientists, favoring highly cited researchers and Nobel laureates. These findings highlight the importance of refining LLM-based scholar recommendation systems to enhance fairness, diversity, and reliability.","Daniele Barolo, Chiara Valentin, Fariba Karimi, Luis Galárraga, Gonzalo Gabriel Méndez, Lisette Espin-Noboa",Concert hall,LLMs & Bias,5,,978
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Unequal Scientific Recognition in the Age of LLMs,"The rise of large language models (LLMs) is transforming how scientific knowledge is accessed and represented. In this study, we evaluate the extent to which LLMs (GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro) recognize scientists compared to established knowledge bases like OpenAlex, Google, and Wikipedia. Analyzing a sample of 100,000 physicists, we find substantial disparities in coverage across platforms, with Google offering near-complete recognition, while LLMs exhibit selective and inconsistent representation. Coverage increases for highly cited scientists but remains uneven across gender and geography. Women scientists are significantly underrepresented, with lower recognition rates across all LLMs, amplifying existing gender disparities in science. Similarly, regional biases persist, favoring North American and Western European researchers over those from Africa, Asia, and Latin America. These findings underscore the risks of algorithmic bias in AI-driven knowledge systems and highlight the need for more inclusive and equitable models that better capture the diversity of global scientific contributions.","Yixuan Liu, Ábel Elekes, Rodrigo Dorantes-Gilardi, Albert-László Barabási",Concert hall,LLMs & Bias,6,,878
,,,,,,,,,,
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Just Put a Human in the Loop? Investigating LLM-Assisted Annotation for Subjective Tasks,"LLM use in annotation is becoming widespread, and given LLMs’ overall promising performance and speed, putting humans in the loop to simply “review"" LLM annotations can be tempting. In subjective tasks with multiple plausible answers, this can impact both evaluation of LLM performance, and analysis using these labels in a social science task downstream. In a pre-registered experiment with 350 unique annotators and 7,000 annotations across 4 conditions, 2 models, and 2 datasets, we find that presenting crowdworkers with LLM-generated annotation suggestions did not make them faster annotators, but did improve their self-reported confidence in the task. More importantly, annotators strongly took the LLM suggestions, significantly changing the label distribution compared to the baseline. We show that when these labels created with LLM assistance are used to evaluate LLM performance, reported model performance significantly increases. We show how changes in label distributions as a result of LLM assistance can affect conclusions drawn by analyzing even “human-approved"" LLM-annotated datasets. We believe our work underlines the importance of understanding the impact of LLM-assisted annotation on subjective, qualitative tasks, on the creation of gold data for training and testing, and on the evaluation of NLP systems on subjective tasks.","Hope Schroeder, Deb Roy, Jad Kabbara",Hemeryck,"LLMs, Annotation, Synthetic Data",1,,828
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Can Unconfident LLM Annotations Be Used for Confident Conclusions?,"Large language models (LLMs) have shown high agreement with human raters across a variety of tasks, demonstrating potential to ease the challenges of human data collection. In computational social science (CSS), researchers are increasingly leveraging LLM annotations to complement slow and expensive human annotations. Still, guidelines for collecting and using LLM annotations, without compromising the validity of downstream conclusions, remain limited. We introduce Confidence-Driven Inference: a method that combines LLM annotations and LLM confidence indicators to strategically select which human annotations should be collected, with the goal of producing accurate statistical estimates and provably valid confidence intervals while reducing the number of human annotations needed. Our approach comes with safeguards against LLM annotations of poor quality, guaranteeing that the conclusions will be both valid and no less accurate than if we only relied on human annotations. We demonstrate the effectiveness of Confidence-Driven Inference over baselines in statistical estimation tasks across three CSS settings--text politeness, stance, and bias--reducing the needed number of human annotations by over 25% in each. Although we use CSS settings for demonstration, Confidence-Driven Inference can be used to estimate most standard quantities across a broad range of NLP problems.","Kristina Gligorić, Tijana Zrnic, Cinoo Lee, Emmanuel Candes, Dan Jurafsky",Hemeryck,"LLMs, Annotation, Synthetic Data",2,,815
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,FedStanceNLI: Human-LLM Active Learning for an Annotated Dataset of FOMC Members’ Stances,"The twelve voting members of the U.S. Federal Open Market Committee (FOMC) cast votes (approximately) every six weeks to decide target interest rates. These decisions impact hundreds of millions of people—affecting everything from mortgage rates to loan availability, and ultimately shaping unemployment and inflation. Thus, it is crucial to understand how the committee arrives at their deci- sions. Existing empirical studies on FOMC communications are limited by their use of simple dictionary-based or bag-of-words approaches, or are limited by their focus on certain FOMC texts—such as press releases, statements, or meeting minutes—which are carefully curated and filtered by the FOMC prior to their public release. In contrast, our work leverages raw meeting transcripts—released after a five-year delay—and aims to classify fine-grained information at the sentence-level spoken by a single committee member. The primary contribution of our project will be a new dataset of 1000 sentences from FOMC transcripts annotated with three human experts for whether or not committee members are taking a stance to tighten monetary policy.","Alisa Kanganis, Katherine A. Keith",Hemeryck,"LLMs, Annotation, Synthetic Data",3,,462
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Detecting Moral Schemas in Interviews with Large Language Models,"Recent research has shown that large language models (LLMs) can be used for high-quality text annotations without training data (zero-shot). However, the performance of LLMs varies between different annotation tasks. We therefore test how well an LLM (GPT4) performs in a highly complex task such as detecting moral schemas in interview transcripts. We show that: 1) GPT4 clearly surpasses other computational methods and reaches accuracy levels equal to human annotators. 2) In contrast to more established computational methods, GPT4 can distinguish between interviewers and respondents and recognize implicit expressions of morality. 3) Finally, we use data annotated by the LLM to show that interviews on morality can predict respondents’ future actions to some extent. Doing so, we also contribute to an ongoing debate about the usefulness of interview methods in social science research.","Achim Edelmann, Simon Walo, Panayiotis Smeros",Hemeryck,"LLMs, Annotation, Synthetic Data",4,,526
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Profiling of Texts Generated by Humans and Large Language Models,"The rapid advancements in large language models (LLMs) have significantly improved their ability to generate natural language, making texts generated by LLMs increasingly indistinguishable from human-written texts. We focus on profiling these texts using explainable linguistic features across three linguistic levels: morphology, syntax, and semantics. Our analysis reveals distinct linguistic patterns: human-written texts exhibit higher syntactic efficiency and greater semantic diversity. Additionally, variability analysis suggests high stylistic diversity in both human-written and machine-generated texts, with creative domains (e.g., poetry) showing the most variation.","Sergio E. Zanotto, Segun Aroyehun",Hemeryck,"LLMs, Annotation, Synthetic Data",5,,634
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Cultural Knowledge Injection,"For LLMs to be used in non-English languages, they should understand and reflect non-Western social norms and values, a task they have historically struggled with. In this paper, we discuss ongoing work to build a system designed to inject culturally-relevant knowledge at generation time, focusing on implicit norms and values as a way to guide LLM text generation to better align with users’ backgrounds.","Shreya Havaldar, Lyle Ungar",Hemeryck,"LLMs, Annotation, Synthetic Data",6,,906
,,,,,,,,,,
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,"Method, Mind, and Morality: How People Make Sense of Artificial Intelligence","The proliferation of increasingly powerful artificial intelligence (AI) systems, particularly general-purpose large language models (LLMs), has rapidly expanded the variety and depth of contexts in which AI and society interface. We conducted a data-driven study with computational text analysis and semi-structured interviews to build grounded theory of the social meanings of AI. We identify myriad “frames” [Goffman, 1974] with which people make sense of AI; four challenges people face that lead them to adopt particular frames; and three dimensions on which frames are contested: the $\textit{method}$ by which AI is created (e.g., top-down, bottom-up), the $\textit{mind}$ of what an AI is perceived to be (e.g., tool, agent), and the $\textit{morality}$ of how to use AI (e.g., slow, fast). We propose that sociotechnical forces, such as advances in AI capabilities, increase the prevalence of particular frames as with LLMs being viewed as agents created with bottom-up scaling of computational resources.",Jacy Reese Anthis,Vingen 1+2,Human-AI Interactions,1,,69
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Empirical evidence of Large Language Model’s influence on human spoken communication,"Artificial Intelligence (AI) agents now interact with billions of humans in natural language, thanks to advances in Large Language Models (LLMs) like ChatGPT. This raises the question of whether AI has the potential to shape a fundamental aspect of human culture: the way we speak. Recent analyses revealed that scientific publications already exhibit evidence of AI-specific language. But this evidence is inconclusive, since scientists may simply be using AI to copy-edit their writing. To explore whether AI has influenced human spoken communication, we applied econometric causal inference techniques to 740,249 hours of human discourse from 360,445 YouTube academic talks and 771,591 conversational podcast episodes across multiple disciplines. We detected a measurable and abrupt increase in the use of words preferentially generated by ChatGPT—such as delve, comprehend, boast, swift, and meticulous—after its release. These findings provide the first empirical evidence that humans increasingly imitate LLMs in their spoken language. Our results raise societal and policy-relevant concerns about the potential of AI to unintentionally reduce linguistic diversity, or to be deliberately misused for mass manipulation. They also highlight the need for further investigation into the feedback loops between machine behavior and human culture.","Hiromu Yakura, Ezequiel Lopez-Lopez, Levin Brinkmann, Ignacio Serna, Prateek Gupta, Ivan Soraperra, Iyad Rahwan",Vingen 1+2,Human-AI Interactions,2,,218
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Reconfiguring Knowledge Networks: How GenAI Reshapes Interactions on Digital Platforms and the Implications for AI Sustainability,"Generative Artificial Intelligence (GenAI) tools have fundamentally reshaped how users seek and share knowledge on digital platforms, raising critical concerns about the sustainability of user-generated content (UGC)—the primary resource for training and advancing future AI models. While studies document an overall decline in UGC following GenAI adoption, understanding the heterogeneous effects across different user groups remains crucial for predicting the future of human-AI knowledge sharing. This study examines the impact of GenAI, specifically ChatGPT-3.5 release, on user interactions across Stack Exchange platforms, with a focus on Stack Overflow. Using a natural experiment approach, we analyze changes in activity patterns and interaction dynamics across user expertise levels, measured through platform reputation scores. Our findings reveal a striking pattern: while GenAI adoption has substantially reduced participation from low-reputation users, likely decreasing repetitive and basic questions, high-reputation users show no significant decrease in their overall activity. Instead, these experienced users have shifted toward increased peer-to-peer interactions, suggesting a transformation in how expert knowledge is shared and maintained. The results indicate that GenAI serves as a replacement for basic interactions among low-reputation users while potentially enhancing collaboration among high-reputation users, fostering a complementary relationship between AI and human expertise. This dual role suggests a possible pathway for sustaining high-quality UGC essential for training future AI models, even as overall platform activity declines.","Babak Heydari, Negin Maddah",Vingen 1+2,Human-AI Interactions,3,,889
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Expertise Elevates AI Usage: Experimentally Comparing Laypeople to Professional Artists,"Recent advances in generative AI have sparked debate over its impact on human creativity and artistic expertise. Does it make everyone an artist, enable the automation of creativity, or serve as a powerful tool for experts? While generative AI can enhance laypeople’s creativity, the role of artistic expertise in its use remains unclear. If professionals’ existing skills transfer to using this new technology, we should expect them to outperform laypeople even under the constraints of writing prompts for AI. In this pre-registered study, we test this hypothesis experimentally by comparing 50 active professional artists and a demographically matched sample of laypeople. We designed two tasks to approximate artistic practice for testing their capabilities in both faithful and creative image creation: writing prompts to replicate a reference image, or to move as far away as possible from it. Artists produced more faithful and creative outputs than their lay counterparts, as evaluated by computing the average similarity between reference images and participants’ creations. This suggests that expertise in visual art does provide an advantage in using generative AI for image generation, and that the skillset of artists is likely to remain relevant for using these tools. In an additional explorative comparison, GPT-4o matched average artists in copying accuracy and outperformed them in creativity. However, the top-performing artists exceeded both lay participants and GPT-4o. High variance among artists suggests differing abilities to leverage generative AI effectively. These outcomes highlight the importance of integrating artistic skills with AI training to prepare artists and other professionals for a technologically evolving landscape. We see a potential in collaborative synergy with generative AI, which could reshape creative industries and education in the arts.","Thomas F. Eisenmann, Andres Karjus, Mar Canet Sola, Levin Brinkmann, Bramantyo Ibrahim Supriyatno, Iyad Rahwan",Vingen 1+2,Human-AI Interactions,4,,552
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Does LLMs Ego Develop? Understanding the Developmental Maturity of Large Language Models,"The rapid advancement of Large Language Models (LLMs) raises fundamental questions about their developmental maturity and adaptability across cognitive stages. Drawing from developmental psychology and ego development theory, this study examines whether LLMs undergo constructive-developmental sequences akin to human ego development. Using segmented regression analysis on responses from 33 diverse LLMs with temperature settings, we assess developmental progression across varying parameter scales. Results reveal a significant positive correlation between model complexity and ego development stage scores (r = .39, p < .001). Segmented regression identified two key breakpoints: at ~3.82B parameters, models exhibited a sharp increase in developmental maturity (ΔSlope = 0.6208, p < .001), followed by a plateau beyond ~28.91B parameters (Slope = 0.03). The two-breakpoint model demonstrated superior fit (AIC = 1670.575, BIC = 1705.230, Adj. R² = 0.1847) compared to simpler models, with Davies' test confirming two significant transitions (p < .001). These findings suggest that LLMs exhibit developmental patterns analogous to human ego development stages, but with distinct limitations. The observed plateau raises critical questions about the limits of AI developmental complexity and its implications for AI alignment, deployment strategies, and responsible AI integration into human-centered applications.","Arti Thakur, Tom Murray, Martin Hilbert",Vingen 1+2,Human-AI Interactions,5,,235
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Navigating Empathy in Human-AI Interactions,"Social interactions enhance well-being, however barriers such as geographic distance and time limitations can hinder in-person connections. AI agents are increasingly shaping communication, where chatbots offer accessible, non-judgmental support. A critical challenge, however, is how well these systems can authentically understand and convey empathy, compare to humans. Through experimental methods involving narratives of personal experiences, we assess the empathy levels elicited by humans, GPT-4o, and fine-tuned AI models, and investigate factors such as personality traits, shared experiences. This work seeks to improve the authenticity of AI-driven empathy, informing the development of more reliable and effective mental health support systems that foster meaningful social connections.","mahnaz roshanaei, Rezvaneh Rezapour, Magy El-Nasr",Vingen 1+2,Human-AI Interactions,6,,798
,,,,,,,,,,
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Forecasting Nationwide Crime at the Block Level,"Crime forecasting is essential to enhance public safety. This study implements the criminological theory of repeat and near-repeat victimization into a deep learning framework, utilizing the Hierarchical Graph Attention Network (HGAT) model to forecast the incidence of traffic, violence, sexual, income-generating, and child-targeting crimes across 1,724 municipalities nationwide. Forecasts were generated at a satisfactory spatial resolution of a block (0.25 km × 0.25 km) with a one-week lead time. The results demonstrate that the HGAT model significantly improves forecast precision compared to state-of-the-art forecasting techniques. Furthermore, the model maintained high accuracy in forecasting the five types of crime across all 1,724 municipalities over a consecutive 14-week period. The enhanced forecast accuracy and adaptability underscore the HGAT model's potential as a significant advancement in crime forecasting.","Kenji Yokotani, Nobuhito Abe, Masahiro Takamura",Vingen 6,Social Prediction,1,,73
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,"One Map, Many Trials: Overcoming Bias and Uncertainty in Satellite-Based Poverty Maps for Reliable Impact Evaluation","Evaluations of large-scale poverty interventions increasingly rely on Earth Observation (EO) data combined with machine learning (ML) to measure socioeconomic outcomes in data-scarce regions. A single, satellite-derived “wealth map” can be remarkably cost-effective: once trained on a reference dataset (e.g., Demographic and Health Surveys), the map can substitute household-level outcomes in multiple new trials without requiring fresh surveys. However, two critical challenges complicate causal inference when reusing these ML outputs across varied interventions. First, \emph{model bias} arises because standard ML training often compresses the variance of the outcome. Empirically, predicted values overstate the poorest households and understate the wealthiest. Such \emph{variance compression} skews impact estimates whenever interventions move the outcome distribution. For example, an electrification project boosting lower-income households might appear to have a smaller effect if those households’ predicted values are already inflated. We address this by \emph{calibrating} each prediction: using a small hold-out sample, we regress predicted wealth on actual wealth, then rescale and shift the predictions to restore the missing variation. Second, substituting predicted outcomes for real data adds \emph{model uncertainty}. Even well-tuned maps can err more for some regions than others. Conventional approaches rarely incorporate these errors in final confidence intervals. To fix this, we exploit \emph{conformal prediction}, which yields interval estimates for each unit that reflect the model’s variability. These per-unit intervals can then be integrated with standard bootstrap routines to combine model-driven error and sampling error. Concretely, we propose a nested resampling procedure: (1) resample trial units to capture sampling-based fluctuations; (2) sample from each unit’s conformal distribution to capture prediction error. The result is a matrix of treatment-effect estimates reflecting both uncertainty sources. Our pipeline thus handles three steps for “one map, many trials.” First, calibrate out systematic bias so that average effects are not consistently deflated or inflated. Second, quantify per-unit error via conformal intervals to avoid overstating confidence. Third, unify these uncertainties with the trial’s usual sampling variance in a nested resampling approach. In simulations, ignoring either bias or model error can produce misleading effect sizes and artificially narrow confidence intervals. Correcting bias alone helps only partially: ignoring model variance still yields overconfidence. Meanwhile, ignoring bias but using conformal intervals only captures the dispersion around a systematically shifted center. With global-scale initiatives turning to satellite-based measurements to evaluate an ever-rising number of interventions, it is essential to address both the systematic distortions of ML predictions and their inherent uncertainty. By implementing calibration, conformal intervals, and joint error modeling, we pave the way for reliable, cost-effective causal inferences—even where in-person data collection is prohibitively expensive. This framework ultimately aims to preserve the benefits of large-scale EO-based poverty maps while improving scientific rigor for real-world policy decisions.","Markus Bo Pettersson, Connor Thomas Jerzak, Adel Daoud",Vingen 6,Social Prediction,2,,808
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,The Mixed Subjects Design: Treating Large Language Models as Potentially Informative Observations,"Large Language Models (LLMs) provide cost-effective but possibly inaccurate predictions of human behavior. Despite growing evidence that predicted and observed behavior are often not $\textit{interchangeable}$, there is limited guidance on using LLMs to obtain valid estimates of causal effects and other parameters. We argue that LLM predictions should be treated as potentially informative observations, while human subjects serve as a gold standard in a $\textit{mixed subjects design}$. This paradigm preserves validity and offers more precise estimates at a lower cost than experiments relying exclusively on human subjects. We demonstrate—and extend—prediction-powered inference (PPI), a method that combines predictions and observations. We define the $\textit{PPI correlation}$ as a measure of interchangeability and derive the $\textit{effective sample size}$ for PPI. We also introduce a power analysis to optimally choose between $\textit{informative but costly}$ human subjects and $\textit{less informative but cheap}$ predictions of human behavior. Mixed subjects designs could enhance scientific productivity and reduce inequality in access to costly evidence.","David Broska, Austin van Loon, Michael Howes",Vingen 6,Social Prediction,3,,32
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Life happens: how predictable is having a child in the next three years? Evidence from a data challenge based on survey and register data,"Fertility outcomes – whether, when, and how many children people have – are one of the most important life outcomes with significant societal implications, yet their predictability remains largely unexplored. The PreFer data challenge (Predicting Fertility in the Netherlands) aimed to assess the predictability of having a(nother) child within three years based on either survey data from the LISS panel or full-population administrative data. Most models submitted in the data challenge outperformed the simple demographic baseline, and some exceeded individuals' own predictions of their fertility outcomes, with survey-based models surprisingly performing better than register-based models. However, even the best models fell below the theoretical upper limit of predictability caused by randomness inherent in conception and fetal survival. The findings underscore the relatively strong predictive power of structural variables and fertility intentions but suggest that accurately forecasting individual fertility remains highly uncertain, even short-term and with extensive data.","Elizaveta Sivak, Gert Stulp",Vingen 6,Social Prediction,4,,427
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,A Deep Learning Model for Classifying Job Postings,"Online job postings have become a crucial platform for job searching, providing advantages such as broader reach, faster processes, and more accurate job matches for applicants. This has enabled the use of machine learning techniques for analyzing labor market dynamics, including forecasting labor turnover and predicting wage increases, which are key to understanding inflation and guiding monetary policy. In this paper, we propose a deep learning model to classify approximately 2 million online job postings into the International Standard Classification of Occupations (ISCO-08) for Chile. We apply this model to examine the impact of the COVID-19 pandemic on jobs offering the option of working from home (WFH) and its medium-term effects on labor demand. Using job posting data at the firm level and a difference-in-difference (DiD) approach, we find that COVID-19 increased WFH job offers by 1.8 percentage points (a 70\% increase compared to the pre-pandemic period) in industries more likely to offer WFH. The effect was particularly pronounced for occupations such as professionals, scientists, and technicians. However, we observed no significant effects in occupations less likely to offer WFH options. Our findings, supported by a pre-trend analysis, demonstrate the value of machine learning in understanding labor market trends, especially in the context of a global crisis like the COVID-19 pandemic.","Dagoberto Quevedo, Jesica Olivares, Diego Donoso, Roberto Gillmore",Vingen 6,Social Prediction,5,,832
,,,,,,,,,,
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,An Experimental Investigation of Causal vs. Intentional Transparency in Algorithmic Delegation,"As AI systems increasingly assist in decision-making, concerns arise about their role in enabling unethical behavior. This study examines whether transparency can curb dishonesty when delegating decisions to an algorithm. In an online experiment (N=788), participants used an AI to report financial outcomes in a modified die-rolling task, with incentives to misreport. We tested two forms of transparency: one clarifying how inputs affect AI behavior (causal transparency) and another making the ethical stakes of decisions explicit (intentional transparency). While understanding AI mechanics did not reduce dishonesty, framing choices in moral terms significantly discouraged cheating, presumably by disabling plausible deniability of the users' intention to cheat. These findings highlight the need for AI transparency policies that emphasize ethical accountability rather than just technical clarity.","Neele Engelmann, Lara Kirfel, Anne-Marie Nussberger, Raluca Rilla, JF Bonnefon, Iyad Rahwan",Vingen 6,Social Good & Ethics,1,,527
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Google Search Advertising after Dobbs v. Jackson,"Search engines have become the gateway to information, products, and services, including those concerning healthcare. Access to reproductive health has been especially complicated in the wake of the 2022 Dobbs v. Jackson decision by The United States Supreme Court, splintering the abortion regulation among the states. In this study, we perform an audit of the advertisements shown to Google Search users seeking information about abortion across the United States during the year following the law change. We find that Crisis Pregnancy Centers (CPCs)--organizations targeting women with unexpected or ""crisis"" pregnancies, but which do not provide abortions--account for 47% of advertisements, whereas abortion clinics -- for 30%. The ads from CPCs are returned especially for queries concerning information and safety. The kinds of ads returned, however, vary widely within each state, with Arizona having the most ads from abortion clinics and other pro-choice organizations, and Minnesota the least. The proportion of pro-choice vs. anti-choice ads returned also varies in time, but Staggered Augmented Synthetic Control Method (SASCM) has shown that the change in ad result type cannot be attributed to the change in the local state abortion laws. Our findings raise questions about the access to accurate medical information across the U.S. and point to the need for further examination of search engine advertisement policies and geographical bias.","Yelena Mejova, Ronald E. Robertson, Sarah McKetta, Catherine A. Gimbrone",Vingen 6,Social Good & Ethics,2,,143
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Can LLMs infer political affiliation from non-political discourse?,"Political affiliation is easily inferred from explicitly political texts, but what happens when the discourse is about everyday topics, such as technology, sports, or music? Our study examines whether large language models (LLMs) can accurately infer political affiliations of individuals from general online discourse, given that such capability can be used to undermine people's privacy and leveraged for micro-targeting. Using two datasets of user-generated text (Debate.org and Reddit) that contain political and general topics, we find that GPT-4o and Llama-3.1-8B can reliably infer political affiliation even with only the posts in general domains. Moreover, the prediction can be improved even more by aggregating multiple text-level inferences---especially when weighted by the models' confidence scores. We also show that topics with closer semantic proximity to ""Politics"", as well as those with overlapping user participation yield higher predictive performance. Finally, we demonstrate that inferring political affiliation from general discourse allows accurate prediction of users' stances on unseen political issues, pointing to the real-world implications of LLM-driven profiling. By highlighting the substantial privacy risks of large-scale inference on political affiliation and the potential for user data exploitation without explicit consent, our findings emphasize the need for stronger regulations and ethical guidelines in developing and deploying LLMs.","Byunghwee Lee, Sangyeon Kim, Filippo Menczer, Yong-Yeol Ahn, Haewoon Kwak, Jisun An",Vingen 6,Social Good & Ethics,3,,430
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Mapping Computational Personality Rights via Audio Embeddings and Human Perception,"Can a computational framework for evaluating voice similarity match or possibly exceed the ""reasonable person"" standard in tort law for identifying a speaker from an audio recording? We address this question by examining how speaker embeddings in generative audio models influence human perception of speaker identity. By generating voice samples using interpolated speaker embeddings, we seek to reveal an empirical personality right boundary in the embedding space. Our pilot results demonstrate that distance in speaker embedding space broadly aligns with human judgments of vocal similarity. Finally, we propose our next step where we conduct a large-scale web-based experiment with both real and AI-generated voice samples to demonstrate the degree to which a computational metric can match human perception of the personality right boundary, which will offer a new approach for addressing legal concerns about personality rights.","Xudong Tang, Matthew Groh",Vingen 6,Social Good & Ethics,4,,466
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Detecting Child Objectification on Social Media: Challenges in Bridging Theory and Language Modeling,"The way children are discussed online influences their self-image and social perceptions, but it also exposes them to objectification—where they are judged primarily by their appearance rather than as individuals. On TikTok, where engagement metrics drive visibility, this can intensify the focus on children's looks, reinforcing harmful norms. This study explores objectification of children on TikTok. We introduce a child objectification language framework to classify comments into appearance-related and objectification-related categories, distinguishing between neutral descriptions and more problematic forms of discourse. This is a particularly difficult task due to the implicit and nuanced language of objectifying language. Our dataset comprises 432,178 comments across 8,367 videos featuring children from 500 unique accounts. We systematically compared language models of different complexity, including an n-gram-based model, RoBERTa, GPT-4, LlaMA, and Mistral. Our findings indicate that GPT-4 performed best overall in detecting appearance- and \linebreak objectification-related language. However, even the better-performing models struggled with reliably detecting objectifying language, reflecting the broader difficulty of identifying subtle or context-dependent objectification in online discourse. Our results further show that 8.44% of comments contained appearance-related language, while 1.73% included objectifying language. These proportions were significantly higher for girls than for boys. Engagement metrics, such as the number of downloads and likes, were not substantially associated with appearance- and objectification-related language. The findings raise ethical concerns regarding children's digital exposure and potential exploitation, emphasizing the need for stricter policies to protect minors on social media platforms.","Miriam Schirmer, Angelina Voggenreiter, Emoke-Agnes Horvat",Vingen 6,Social Good & Ethics,5,,888
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Conversational AI Can Shape Consumer Behavior with and without Detection,"Conversational AI models are becoming increasingly popular and are about to replace traditional search engines for information retrieval and product discovery. This raises concerns about monetization strategies and the potential for subtle consumer manipulation. Companies may have financial incentives to steer users toward search results or products in a conversation in ways that are unnoticeable to consumers. Using a behavioral experiment, we show that conversational AI models can indeed significantly shift consumer preferences. We discuss implications and ask whether regulators are sufficiently prepared to combat potential consumer deception.","Tobias Werner, Ivan Soraperra, Emilio Calvano, David C. Parkes, Iyad Rahwan",Vingen 6,Social Good & Ethics,6,,162
,,,,,,,,,,
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Making Sense of Images: A Literature Review on Approaches to Integrating Visual Data into Clustering for Social Science,"The increasing prevalence of visual content in news and social media has highlighted the importance of integrating images into unsupervised frameworks in computational social science. This paper presents a systematic literature review of approaches that incorporate visual data into clustering methods, addressing the gap between methodological advancements in computational methods and theoretical constructs in social science. By analyzing 38 publications through manual coding, we identify key social science concepts, data representations, clustering techniques, and associated challenges. Findings highlight different methodological approaches in the literature based on data representation and categorize them alongside emerging multimodal approaches. Challenges include the alignment of clustering outputs with theoretical constructs, the lack of validation standards, and biases inherent in image models. To bridge these gaps, we propose guidelines for integrating images into clustering research in social science, emphasizing the need for theoretical grounding, methodological rigor, and validation practices. This study makes a contribution to the theoretical discussion on the ""tension between automation and interpretation"" in image analysis, offering insights for future research on visual and multimodal data and highlighting directions for measuring social science constructs.",Nadezhda Ozornina,Troselli,Image as Data,1,,695
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Generative Multimodal Models for Social Science: An Application with Satellite and Streetscape Imagery,"Although there is growing social science research examining how generative AI (genAI) models can be effectively and systematically applied to text-based tasks, whether and how genAI can be used to analyze images remain open questions. In this paper, we introduce a social science framework for analyzing images with generative multimodal models (MMs), which consists of three core tasks: curation, discovery, and measurement and inference. We demonstrate this framework with an empirical application that uses OpenAI’s GPT-4o model to analyze satellite and streetscape images (n = 1,101) to identify built environment features that contribute to contemporary residential segregation in U.S. cities. We find that model-generated labels are more reliable than research assistant-generated labels and comparably valid to expert-generated labels. We conclude with thoughts for other use cases and discuss how social scientists can work collaboratively to ensure that image analysis with generative MMs is rigorous, reproducible, ethical, and sustainable.","Tina Law, Elizabeth Roberto",Troselli,Image as Data,2,,206
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,An Image is Worth K Topics: A Visual Structural Topic Model with Image Embeddings,"This paper introduces a visual Structural Topic Model (vSTM) that combines probabilistic topic modeling with pretrained image embeddings to better analyze political images. The approach allows both analysis of relationships between visual content and covariates and representation of images as mixtures of multiple topics. The model adapts mixed-membership models to continuous image data through a hierarchical structure that links image embeddings, topic proportions, and covariates. Demonstrated on climate communication around UN Climate Conferences, the model effectively captures nuanced image representations, coherent topics and their interplay with the specific event, actor types (e.g. political or advocacy) and their stance (for/against).","Matias Piqueras, Alexandra Segerberg, Matteo Magnani",Troselli,Image as Data,3,,928
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Mapping riots from geolocated images and videos,"This study develops and validates a computer vision approach for mapping riots using geolocated social media content. Traditional data sources like police records provide only coarse temporal and spatial resolution, while existing social media analyses rely primarily on less reliable text data. Applied to the 2023 'Nahel Merzouk' riots in France, our methodology processes 107,000 Snapchat posts using a fine-tuned EfficientNet model, achieving 80% precision in riot detection. The analysis reveals characteristic ""bursty"" patterns of urban unrest: localized events typically lasting under 50 minutes within areas of 1.5 km². This high-resolution spatiotemporal mapping opens up new opportunities for understanding the dynamics and the causes of rioting events.","Lucas Spierenburg, Sander van Cranenburgh, Oded Cats",Troselli,Image as Data,4,,24
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Migration in Online Images: Characteristics and Socioeconomic Influences Across Countries,"This study focuses on online visual representations of migration and investigates how contextual factors influence elements in visual narratives on migration. Insights about this phenomenon can serve to address the impact portrayals may have on migrants and the broader society. Two central elements of stereotyping in visual content are demographics and emotions. The demographics of people, such as age, gender, or facial features, might be over or under-represented in visual portrayals to emphasize certain narratives. In turn, emotions in images can attach specific emotional valence to migration-related discourses and thus shape attitudes. These aspects can vary based on the characteristics of the social context in which the imagery is created or used. Contextual factors influencing the representation of migration-related issues include the proportion of migrants in the population and societal attitudes toward migration. However, other important factors, such as social equality and perceived access to resources or opportunities, can also influence discourses surrounding migration and the perception of immigrants. This work analyzes visual data from various locations to reveal key characteristics of migration-related communication and its relation to context. Adopting an interdisciplinary approach that utilized computer vision techniques, the results were analyzed through the lenses of migration and gender studies, along with an intersectional perspective. The study consisted of two stages examining the following aspects: 1. The demographic and emotional information on people's faces in online images associated with migrants in ten countries with varying levels of migration acceptance and population (~ 18,000 images and 21,000 faces). 2. The relationships between socioeconomic variables and emotions in immigration-related visual media in 45 countries with varying levels of perception of corruption, economic inequality, and migration acceptance (~6,500 images and 10,500 faces). Results: 1. The initial phase of the analysis centered on examining the gender, age, facial features, and emotions (facial expressions) of individuals depicted in migration-related images sourced from a search engine. Three key migration-related search terms were explored: ”migrants,” ”refugees,” and ”expats,” along with their corresponding male and female forms (e.g., ”migrant man” and ”migrant woman”). The term ”refugees” was included because it is often mistakenly equated with ”migrants,” while ”expats” was examined as it refers to a group frequently perceived as the “good and highly wanted migrants”. The results indicate a misalignment between the demographics portrayed and official statistics. The gender distributions for the term migrants align more closely with that of asylum seekers than with the overall migrant population. Additionally, the findings reveal the power struggle within the “expat vs. migrant” dichotomy, which carries significant colonial connotations. The term “expat” is mainly associated with “white people,” while Asians are underrepresented when compared to the statistics on highly-skilled migration. Conversely, depictions of migrants and refugees —typically referring to asylum seekers— tend to reflect the demographics of low-skilled migrants. When it comes to emotions, these are predominantly negative and align with existing literature on emotional and gender stereotypes. Notably, the portrayals of refugees primarily emphasize emotions stereotypically associated with themes of poverty and risks for host societies. Moreover, positive emotions are more frequently associated with women than men and expats rather than refugees or migrants. It's important to note that these effects differ per location. 2. In the second phase, the analysis explored how socioeconomic factors such as perceived corruption, GDP per capita, and income inequality predict the average emotional content conveyed in images across various online media outlets in 45 countries. This analysis specifically focused on images associated with immigrants. This second analysis revealed that socioeconomic indexes—particularly corruption scores and GDP per capita—significantly predict the emotional content of media images related to immigrants. Specifically, higher levels of perceived corruption and lower GDP per capita correlate with increased negative emotions depicted in visual content. Additionally, a mediation analysis indicated that these factors mediate the relationship between income inequality and the emotional information conveyed in images. These findings are consistent with theories suggesting that heightened perceptions of competition for resources stemming from inequality or scarcity can lead to immigrants being viewed as threatening out-groups.","Juan Sebastian Olier, Camilla Spadavecchia",Troselli,Image as Data,5,,163
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Evaluating Multimodal Language Models for Annotating Team Behaviors in Videos,"Multimodal language models capable of annotating interactions in videos present transformative opportunities for computational social science (CSS) and team research, enabling longitudinal and large-scale studies of how team behaviors drive innovation—a task previously hindered by labor-intensive manual coding [2]. While prior work has evaluated AI’s annotation of text or synthetic data [1], its reliability on real-world, multimodal data like video remains underexplored. We address this gap by testing whether Gemini, a state-of-the-art multimodal model, can reliably annotate 23 team behaviors in 138 video-recorded scientific team meetings. Each meeting is approximately one hour long and includes four to seven scientists from diverse backgrounds at scientific conferences. We investigate the inter-rater reliability of a human expert’s and Gemini’s annotations and qualitatively investigate the differences. Our work bridges computational methods and team science, offering a framework to help CSS researchers study how micro-level behaviors (e.g., conflict management) predict macro-level outcomes like innovation. Using an authoritative framework developed by Salazar and colleagues [4], we created a coding scheme with six team processes (e.g., communication practices and conflict management) that are further broken down into 23 observable behaviors (e.g., “invite input from others” and “express agreement”). We prompted the Gemini model (‘gemini-1.5-pro’) with the coding scheme and few-shot examples to annotate behaviors, actors, timestamps, and explanations. Annotating actors of behaviors allows us to distinguish each team member’s behavior, while including explanations enables qualitative investigation of differences between Gemini’s and the human’s annotations. We then took a random sample of 25 videos (~20%) to obtain annotations from a human expert who has over five years of experience studying teams and conducting qualitative analysis. The human expert was provided with the same coding scheme and instructions. To evaluate inter-rater reliability, we calculated Cohen’s Kappa (𝜅), a standard metric for evaluating agreements between multiple coders [3]. For comparability with prior evaluations of AI annotation capabilities [1], we also report F1 scores using the expert’s annotations as ground truth. To further analyze discrepancies, we qualitatively examined 60 annotations across all codes, randomly sampling 30 with high inter-rater reliability and 30 with low reliability. These annotations, along with corresponding video segments and explanations, were analyzed in detail. In a pilot study, we prompted the Gemini model to annotate one video and assessed inter-rater reliability. While Gemini and the human expert achieved near-perfect agreement on actors (𝜅 = 0.86), the average Cohen’s Kappa for team processes was 0.447, indicating moderate agreement. As shown in Table 2, agreement was highest for “Trust and psychological safety” (𝜅 = 0.612, substantial agreement) and lowest for “Shared goal and problem focus” (𝜅 = 0.287, fair agreement). F1 scores mirrored this trend, averaging 0.531. Qualitative analysis revealed higher agreement for codes with clear definitions (e.g., “express agreement”) and lower agreement for ambiguous or overlapping codes. For instance, “summarize” (condensing key points) and “repeat or rephrase” (restating others’ words) were interpreted inconsistently, while “propose different ideas” (new suggestions) and “build on others’ ideas” (extending existing ideas) required contextual nuance to distinguish novelty from iteration. Our findings underscore the transformative promise of multimodal AI in advancing team science and CSS research. While Gemini demonstrates remarkable reliability in annotating actors and specific behaviors (e.g., ""ask questions""), its current limitations in contextual ambiguity—such as distinguishing ""summarize"" from ""repeat or paraphrase""—highlight both challenges and opportunities. By refining coding schemes and scaling our approach to 138 interdisciplinary teams, this work paves the way for unprecedented studies of innovation dynamics: tracking how micro-level behaviors like conflict resolution evolve over time, comparing collaboration patterns across global contexts, or designing AI-augmented tools to nudge teams toward more effective practices. Crucially, by open-sourcing our prompts and annotations, we aim to catalyze a paradigm shift in CSS—from labor-intensive manual coding to scalable, reproducible behavioral analysis. This research not only bridges AI and team science but also unlocks the potential to decode the ""black box"" of collaboration, offering actionable insights for fostering innovation in an increasingly interdisciplinary world.","Evey Jiaxin Huang, Matthew Groh, Daniel Abrams, Brian Uzzi",Troselli,Image as Data,6,,763
,,,,,,,,,,
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,A Cartography of the European Political Debate on the Ukraine War,"The Russo-Ukrainian war, which began with Russia's annexation of Crimea in 2014 and flared up during Russia's invasion in 2022, is the deadliest inter-state war in Europe since the World War II. Public attention, and the formation of opinions about the ongoing conflict, is an important object of study, as it underpins serious national policy decisions of other nations, especially those in Europe. In this study, we ask, to what extent is the public attention across Europe about the Ukraine war synchronized, and is it catalyzed by specific events? Further, can we identify opinion ""communities"" within each country that have distinct stances on relevant issues, and are there opinions that are shared across such communities internationally? We use a collection of 165M tweets to reveal opinion communities in 20 European countries in the first 7 months of Russia's invasion of Ukraine in 2022. We find that among a synchrony of Europe's public attention to the war are communities that disagree on key issues concerning the conflict, such as whether to send military aid to Ukraine, or to sanction Russia. Furthermore, these stances are related to the temporal attention patterns each community. Also, we find an initial period of lowered structural polarization that suggests a greater diversity of interaction, before the communities coalesce. We believe the international perspective offered by this study brings to light important opinion dynamics concerning the Russo-Ukrainian conflict.","Yelena Mejova, Arthur Thomas Edward Capozzi Lupi, Corrado Monti, Gianmarco De Francisci Morales",Vingen 1+2,Political Narratives I,1,,457
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models,"Metaphor, discussing one concept in terms of another, is abundant in politics and can shape how people understand important issues. We develop a computational approach to measure metaphorical language, focusing on immigration discourse on social media. Grounded in qualitative social science research, we identify seven concepts evoked in immigration discourse (e.g. water or vermin). We propose and evaluate a novel technique that leverages both word-level and document-level signals to measure metaphor with respect to these concepts. We then study the relationship between metaphor, political ideology, and user engagement in 400K US tweets about immigration. While conservatives tend to use dehumanizing metaphors more than liberals, this effect varies widely across concepts. Moreover, creature-related metaphor is associated with more retweets, especially for liberal authors. Our work highlights the potential for computational methods to complement qualitative approaches in understanding subtle and implicit language in political discourse.","Julia Mendelsohn, Ceren Budak",Vingen 1+2,Political Narratives I,2,,927
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Dehumanization and Media Narratives: The case of Israel and Palestine,"The war on Gaza is one of the most polarizing geopolitical events of our time, with media coverage playing a crucial role in shaping public perception, policy discussions, and historical narratives. This study examines over 14,000 articles from Al Jazeera English (AJE), BBC, CNN, and The New York Times (NYT) to assess how major news outlets report on the human cost of war. We analyze how media quantify civilian suffering through casualty numbers, exploring disparities in reporting frequency, citation practices, and the selective use of doubt-casting language. Additionally, we investigate the dehumanization of war victims by examining whether casualties are portrayed as individual lives lost or reduced to impersonal statistics. Using a Large Language Model (LLM) and a baseline model based on United Nations data, we quantify media biases in representing war casualties and examine how linguistic framing influences narratives of violence. By shedding light on these reporting patterns, this study reveals how journalistic choices shape public understanding of war and its human toll.","Kareem Elrafei, Bruno Gabriel Salvador Casara, Anne Maass, Bedoor AlShebli",Vingen 1+2,Political Narratives I,3,,314
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,"Same Economy, Different Stories: A Decade of Partisan Economic Reporting in American Media","This study examines how mainstream news media covered the U.S. economy from 2015 to 2025, with particular focus on the 2024 presidential election. Our analysis of over 200,000 articles reveals a complex relationship between economic reality, political context, and media representation that has significant implications for democratic discourse. The systematic differences in how publications select and frame economic data—particularly during election periods—suggests that voters across the political spectrum may be consuming fundamentally different economic narratives despite experiencing the same overall economy. This divergence in economic reporting likely contributes to the polarized perceptions of economic conditions observed among voters. Furthermore, our methodology provides a scalable framework for monitoring media bias in economic reporting that could be extended to other domains of public discourse where statistical data plays a central role in shaping public opinion.","Elliot E. Pickens, David Rothschild, Alexandria Leto, Maria Leonor Pacheco",Vingen 1+2,Political Narratives I,4,,911
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Rightwing narratives outnumber mainstream narratives in US political media eight years straight,"Abbreviated abstract: This project seeks to understand how the nature of the narratives made available in the public sphere may help explain the tides of ethnonationalism and authoritarianism that today face many democracies around the globe. Specifically, we present an operationalization of the narratives in news media and report evidence of a right-skewing asymmetry in the breadth, intensity, and frequency of narratives produced by the US national news media from 2015-2022.","Baird Howland, David Rothschild, Duncan J. Watts",Vingen 1+2,Political Narratives I,5,,791
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Twitter narratives and trust in democracy during the 2020 U.S. Elections,"Researchers have widely documented election fraud rumors that spread on Twitter in the lead up to and aftermath of the 2020 US presidential elections (e.g. Starbird et al. 2023). As recent attacks on democratic checks and balances are being recast as necessary reforms against a compromised system by Trump and his supporters, we can see how these rumors continue to shape American politics today. However, we believe these rumors are only one part of a wider constellation of narratives that crystallized on Twitter in that period and which have been instrumental in diminishing trust in the state and democratic institutions. One such narrative, which we identified in a preliminary study, is that of a covert unethical relationship between Joe Biden and China, however other examples abound. Understanding this wider constellation of narratives is crucial for making sense of the real-world events surrounding both the 2020 and 2024 presidential elections. In this research project, we set out to analyze an extensive dataset of 2.4 billion tweets collected from November 2019 to October 2022 in order to inductively identify key narratives that spread on Twitter during this period, and the online communities that engaged with them. Our methodological approach combines social network analysis, hierarchical topic modelling and claim detection and will allow us to 1) provide a more complete account of the discursive climate on Twitter around the 2020 elections, 2) investigate the role of media and other key actors in creating, amplifying and spreading narratives and 3) examine the co-constitution and co-evolution of narratives and networks over time.","Sandrine Lara Chausson, Marion Fourcade, David Harding, Björn Ross",Vingen 1+2,Political Narratives I,6,,389
,,,,,,,,,,
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Tracking the production and absorption of political narratives in 2024,"We track the production and absorption of political narratives during 2024. In doing so, we explore the robustness of a new data and analytics pipeline, and what it shows us about the quantity, repetition, discipline, breadth, sentiment and partisanship of political narratives from right-wing, center, and left-wing publications, and how the general population absorbs these narratives. Our data is the top 20 articles (by placement on the landing page) for six major mainstream publications from January 1, 2024 through Election Day. The pipeline blends BERTopic and large-language models to identify the most important narratives over the course of the year. We explore the narratives produced by 6 mainstream publishers with a mix of partisanship -- Breitbart and Fox (right), the NYTimes and Washington Post (center), and the Guardian and HuffPost (left). We that the narratives were overwhelmingly negative and right-leaning. Right-leaning publications produce more narratives that cover a great number of articles and events while being more coherent and partisan than the narratives produced by center and left publications. Even center publications show a right-leaning slant in their narratives. We survey approximately 15,000 participants on Prolific over the course of the year and find that right-leaning narratives, from the production-side, are far more prevalent in how these participants discuss politics.","Reed Orchinik, Baird Howland, David Rothschild",Vingen 1+2,Political Narratives II,1,,433
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Vote Defection and Party Pressure in U.S. Congress,"Why do representatives in U.S. Congress defect during roll-call votes, and vote against their own party? Recognizing the influence of defectors in shaping policy outcomes is crucial, because a few well-placed votes can tip the balance of power. Research suggests that each vote requires a representative to weigh personal values against their party’s wishes. However, a measurement for party pressure – the strength of parties to convince their representatives to vote according to party line – remains elusive. This paper uses transcripts of Congressional floor speeches in a text-analytical model to understand vote defection and party pressure. In floor speeches, representatives signal and justify their intent of defection to their peers. By transforming speeches into word embeddings and calculating the cosine similarity between them, this paper proxies speech similarity and tests three related hypotheses. First, speech similarity predicts vote similarity. Second, defectors will deviate from their party’s speeches more than those who don’t. Third, depending on the vote outcome, defectors will change their tone depending on the amount of party pressure. Preliminary results support the first hypothesis and show that speech similarity is the strongest predictor of vote agreement after party affiliation.",Hendrik Erz,Vingen 1+2,Political Narratives II,2,,172
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,"Evidence-based rhetoric, ideological extremity, and legislative effectiveness in the U.S. Congress","Truth is essential for governance, accountability, and decision-making in democratic societies. Subjective notions of truth can be expressed along a continuum from evidence-based to intuition-based language. This study investigates how ideological extremity influences the use of evidence-based language in U.S. Congressional speeches and whether legislators who rely more on evidence-based language are more effective lawmakers. We analyze these conceptions of truth in Congressional speeches in relation to measures of ideological extremity and legislative effectiveness. We find that legislators with more extreme ideological positions use less evidence-based language in their speeches. Additionally, there is a significant positive relationship between the use of evidence-based language and legislative effectiveness. This suggests that adopting evidence-based rhetoric could enhance a lawmaker's impact on the legislative process.","Segun Aroyehun, Stephan Lewandowsky, David Garcia",Vingen 1+2,Political Narratives II,3,,632
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Political Advertising in Taiwan’s 2024 Election: A Comparative Analysis of Audience Targeting and Issue Prioritization,"The rise of social media has transformed political advertising, allowing parties to target audiences with precision. This study examines Meta Ads data from Facebook and Instagram, focusing on Taiwan’s three major political parties: the Democratic Progressive Party (DPP), the Kuomintang (KMT), and the Taiwan People's Party (TPP). Findings reveal distinct regional and demographic targeting strategies. The DPP focused on urban centers, the KMT had a broader regional reach, and the TPP prioritized younger urban voters. Facebook ads primarily reached older demographics, while Instagram was more effective for younger users. Thematic differences were also observed: the DPP and KMT prioritized emotional mobilization, while the TPP emphasized economic and educational issues. Attack-based ads were most common in KMT campaigns. This study provides insights into digital campaign strategies in Taiwan’s 2024 election. Future research should explore sentiment analysis and engagement metrics to assess ad effectiveness further.","Lien-Jung Chang, Chun-Ming Lai",Vingen 1+2,Political Narratives II,4,,294
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Studying political spaces in order to understand political realignment --- the case of Switzerland,"We study data from Swiss public votes and national elections. In both cases, we use the geographic differences to build the political spaces for the voters. As a consequence, we only see differences that are not equally distributed geographically. For the Swiss public votes we used two data sets: A data set containing the results for the 2222 Swiss communities for the 325 nation-wide votes from 1981 to 2018 by SOTOMO (https://www.sotomo.ch) (see also Hermann & Leuthold (2001)) for an analysis of the data until 2000) and the results of the votes at the level of cantons for 1950 - 2023 from Swissvotes (https://swissvotes.ch) . In this abstract, we show only the results for the latter. The second data set were the results for all Swiss communities for all nation wide elections (Swiss Parliament, ""Nationalrat"") from 1971 - 2023 (https://www.bfs.admin.ch/asset/de/28725591). Methods: We performed a weighted principal component analysis on the data. For the Swiss votes, a single data point is the vector of the percentages of yes votes in one community for all votes in a 10-year time window. For the elections, it is the vector of the percentages of votes for each party in one community. The weights were the sum of votes within one community or canton. In order to assess the dimensionality we estimated the percentages of explained variance by the first three principal components as a function over time. The less components you need to explain a certain part of the variance, for instance 70\%, the lower the dimensionality of the space. For the public vote data we used a sliding window of 10 years with a step size of one year, while the PCA for the national elections was performed for each election occurring every four years. Results and Discussion: The first three principal components explained most of the variance in both datasets. For the public votes we find a decline of variance explained by the first principal component together with an increase in the second component starting at the beginning of the 1970s and lasting until the beginning of the 90s, when the dynamics reversed. For this period Hermann and Leuthold (2001) identified three main dimensions spanning the corresponding Swiss political space, left---right, liberal---conservative and technocratic---ecological. In particular, the third dimension corresponded to new topics related to environmental protection and ecological questions. However, starting from 1990 the importance of the second dimension diminished, resulting in a political space that becomes nearly one-dimensional, with the first component accounting for almost 70\% of the variance. One explanation could be the SVP's rise from 11.9\% of the votes in 1991 to 26.8\% in 2003, becoming the strongest party, in particular, because the SVP used public votes for mobilization along their preferred topics such as restricting migration. In order to check this hypothesis we performed a similar analysis for the data from Swiss national elections. Here, the picture is partially different: we do not see any significant changes until 1990. Moreover, the rise of the SVP is accompanied by a pattern of de-alignment similar to the one observed for the vote data 15 years earlier. Only after 2007, we see an increase in the first and a decrease in the second principal component, similar to the public votes after 1990. This delay may reflect how direct democracy, with public votes, responds faster to emerging issues than party programs, causing a lag in party positions. The political spaces for elections and votes for the 1980s (left panels) are structurally very different. In the political space of the national elections we observe basically two groups that form two one-dimensional ""arms"" in the PCA embedding, corresponding to two traditional types of party systems in Switzerland: (1) the cantons dominated by the Christian Democrats: “In these cantons, the traditional confessional conflict between the Christian Democrats and their liberal counterparts still determines the political disputes”, (2) the confessionally mixed German-speaking Swiss cantons where ""a relatively strong left-wing party opposes the Free Democrats on the one hand and the SVP on the other"" \cite{kriesi2005aufstieg}. The embeddings estimated from the public votes show first the language clusters (German, French and Italian) and an urban-rural gradient within the clusters (big cities on the left). In the more recent spaces both spaces are less clearly structured, but still quite different. However, at both time points the urban-rural divide is a main element in the first component, especially in elections, this can be directly linked to the opposition between the SVP (strong in rural areas) and the left parties (social democrats and green party, strong in larger cities).",Eckehard Olbrich,Vingen 1+2,Political Narratives II,5,,972
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Conflicting narratives and issue alignment on social media,"Narratives are key interpretative devices by which humans make sense of political reality. They play a role in social influence and political persuasion, and conflicting narratives can be at the origin of ideological divides. In this work, we empirically investigate the relationship between issue alignment, i.e. the correlation of opinions across different topics, and the presence of conflicting narratives between ideologically opposite opinion groups. Using a large dataset of tweets from 2021 to 2023 where previous work has shown strong evidence for issue alignment, we use a graph-based approach to extract traces of narratives from tweets of opposing camps to shed light on the following questions: What are the main narratives connected to each issue? How are these different issues woven together? Can we identify meta-narratives that are at the origin of a larger ideological divide? We demonstrate the method on two examples, Covid and climate change, where we expose diverging narratives around vaccines, masks, trust in science, and freedom and regulations. Extending the analysis to a larger range of topics, we show preliminary evidence for a larger meta-narrative in the right-leaning camp around the loss of freedom and traditional values.","Armin Pournaki, Eckehard Olbrich",Vingen 1+2,Political Narratives II,6,,1009
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,The Boys from Berlin: Decoding Nazi Party Recruitment with AI,"Focusing on early 20th-century Germany, this study examines how autobiographical narratives shed light on the formation of political affiliations, particularly through childhood experiences. Two principal corpora were compiled: (1) a set of autobiographical texts from Nazi supporters and (2) a comparison collection of writings by ordinary Germans from the same period. We employed large language models (LLMs) to extract childhood-related passages—while filtering out overt political content—thereby producing standardized “snippets” for analysis. These snippets were then evaluated using supervised machine learning models to classify each passage as either Nazi-supporting or non-Nazi. Our findings reveal that childhood narratives alone achieve over 70% classification accuracy, suggesting that references to educational setbacks, communal values, and work-related aspirations can reliably predict later political alignment. This outcome challenges long-standing theories that primarily link extremist support to authoritarian parenting and punitive childhood environments. While such themes do appear, many autobiographies from Nazi supporters instead underscore schooling deficits and collective obligations—rather than rigid discipline—as central influences. By framing corpus membership as a classification task, this study introduces a novel computational approach to text-based political analysis. Although centered on a specific historical context, these insights have broader implications for understanding how personal narratives may signal ideological commitments across diverse sociopolitical settings.","Hans-Joachim Voth, Vasiliki Fouka, Dominik Loibner",Vingen 1+2,Political Narratives II,7,,989
,,,,,,,,,,
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Measuring ideological polarization across the world on comparable political dimensions using social media and political survey data,"Polarization in society has enjoyed continued and growing interests from social scientists in the past couple of decades. This has yielded an extensive and diverse set of works addressing its conceptualization, causes, and measurement. Despite much effort, it is still difficult to quantify polarization both across national settings and between periods of time. Traditional difficulties in achieving such an objective include the costs of conducting large transnational surveys and designing them with meaningful dimensions for self-placement of respondents. While respondents from different countries can be prompted to position themselves on relevant dimensions, e.g., a Left-Right dimension, it remains difficult to compare self-positioning across countries. Furthermore, while individuals might display coherent spatial references (e.g., between self-positioning, how they perceive candidates and parties, and how they vote), the dimensions that yield coherent spatial positions might not always iden- tify clear policy positions (e.g., on immigration, environmental protection, or education, and on which individuals might be less knowledgeable). Prominent instruments that target these challenges are the European Social Survey (ESS), or the Eurobarometer, which are limited, however, to an European scope. To our knowledge, no global quantitative measurement of po- larization exists; either at the country level nor at the individual level. A prominent candidate solution for some of these ills is to use scaling of behavioral data to passively estimate position of individuals on relevant ideological and issue dimensions (Imai, Lo, and Olmsted 2016). A promising data source capturing relevant behavior are social media platforms, and in particular those entangled with political communication, and having a large user base in several countries, such as X/Twitter. While several proposals have performed ide- ology scaling of X/Twitter data (Barbera ́ 2015; Barbera ́ et al. 2015), they have mostly focused on a single country (and disproportionately the US), solving identification problems in the in- ference in a way that hinders comparability across countries, fixing the center of ideological scales inferred at the mean of the sample. Furthermore, most methods are designed to capture the main ideology dimension structuring national politics, which might vary across countries, and might not consist of the same structure of aligned issues (despite having a shared name, such as Left-Right, or Liberal-Conservative dimension). A more recent proposition by Ramaciotti Morales et al. 2023 combined multidimensional scaling of X/Twitter data with political survey data to calibrate ideology and issue dimen- sions, solving the identification problems of the inference of positions by fixing reference points present in surveys (e.g., positions of political parties) along comparable dimensions. Building on this approach, we propose a method to position individuals from tens of countries in nearly all continents in comparable ideology and issue dimensions, providing the first global atlas of polarization. Following the research design of Ramaciotti Morales et al. 2023 we collected the more than 100M followers of Members of Parliament (MPs) on X/Twitter in 2023 on 34 countries, and computed a multidimensional scaling producing a latent space for users, including MPs. We then created proxy positions for parties as the mean position of MPs grouped by party, and used party positions to map every user in the latent space onto the issue and ideology dimensions of the Global Party Survey (GPS; Norris 2020). This allowed us to position all X/Twitter users in our extensive multi-national sample on comparable dimensions, including relevant ones such as the GPS Left-Right dimension. Once the cross-national positioning of individuals was validated, we proceeded to measure Left-Right polarization on each country using the Duclos-Esteban-Ray (DER) measure on the distributions of the populations. The DER measure is an index that captures both the degree to which a distribution is concentrated around attractors, and the distance between the position of attractors or modes (Duclos, Esteban, and Ray 2006). We provide an atlas of the world colored according to the degree of polarization, as measured by the DER measure, on our pop- ulation of users connected to MPs in each country. Our results conform to the expectations set by previous research in the EU (Caravaca et al. 2022), but extends the comparability of coun- tries to provide in trans-continental perspective, including most of the Americas. Our results show that the US X/Twitter-sphere is far more polarized than that of other countries, more than doubling the value of the DER measure in comparison to almost all European countries.",Pedro Ramaciotti Morales,Troselli,Polarization I,1,,227
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Computational Measures of Mass Polarization: A Belief Network Approach for Global Comparison,"Despite growing concerns over mass polarization and its societal consequences, a critical methodological gap remains in how polarization is quantified and compared across different societies. This comparative study proposes standardized, network-based measures to capture three key dimensions of polarization—constraint, sorting, and disagreement. We introduce a belief network approach, which conceptualizes an individual’s belief system as a network of interconnected attitudes and identities. In such belief networks, the nodes represent specific political issues or identities, and the edges denote the regularized partial correlations between the distributions of opinions on these entities. Using data from the World Values Survey (WVS) and the European Values Study (EVS) from 2017–2023 in 78 countries, we found that constraint and sorting exhibit a high level of correlation, but disagreement shows different patterns. We further consider how various macro-level factors explain these dimensions of polarization. Our results reveal the multidimensional nature of mass polarization, highlighting this global phenomenon may have various substantiations and structural mechanisms.","Yufan Guo, Yilang Peng, Tian Yang",Troselli,Polarization I,2,,513
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,The emergence of polarised groups through source filtering,"Societies worldwide often display multi-dimensional ideological divides that extend across unrelated topics, from environmental policy to vaccine safety. Existing explanations for such polarisation sometimes hinge on strong assumptions (e.g., irrational learning, negative updating) or yield weaker forms of disagreement. In contrast, we develop a computational framework showing how *source filtering*, in which agents accept or reject new beliefs based on their trust in the information source, can drive beliefs to cluster into tightly correlated, opposing packages, even when those beliefs are intrinsically unrelated. By comparing this with *content filtering*, where agents focus on a belief’s intrinsic coherence, we find that source filtering more readily generates two dominant, polarised “camps”. Mathematical models and agent-based simulations confirm that random interactions can quickly yield stark polarisation, suggesting a mechanism akin to algorithmic bias on social media platforms (e.g., collaborative filtering) that may further reinforce these ideological bundlings. Crucially, the theory equips computational social science with a basis for interpreting large-scale social data, especially from social media, by clarifying how platform-driven interactions can systematically bundle otherwise unrelated viewpoints and exacerbate polarisation at scale.",Fredrik Jansson,Troselli,Polarization I,3,,567
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Pathways to Polarization: Online Information-Seeking Among Political Extremists,"Do extremists on all ends of the political spectrum exhibit similar patterns of political information seeking online? In recent years, social media and the Internet have been blamed for spreading toxic and extremist discourse. Previous research shows that strong partisans tend to be more politically interested, informed, and mobilized [Taber and Lodge, 2006]. However, we still know very little about the pathways and types of information sources accessed by individuals who position themselves on the far ends of the left-right scale. In this paper, we examine the information consumption habits of individuals with different ideological leanings. Using panel survey data and web-tracking data from 893 individuals in Spain, collected one month before and after the 2023 General Election, we analyze all political content individuals were exposed to in newspapers (N10,000) and social media (N20,000) using Large Language Models (LLMs). Second, we analyze information pathways resorting to Markov chains, thereby identifying differential patterns among far-right, far-left, and the remaining population. Previous research also shows that civil (rather than uncivil) political content and interactions via news media or social networks favor information seeking and tend to invigorate political participation [Papacharissi, 2002, Schudson, 2002]. However, online incivility increases certain forms of political engagement by reinforcing partisan identity [Coe et al., 2014], and a hostile opinion climate has been shown to increase participation among those who see themselves in a minority [Abts et al., 2024, Madriaza et al., 2025]. For those in like-minded social media environments, incivility can be mobilizing, acting as a signal that alerts in-group individuals that something important is at stake [Kosmidis and Theocharis, 2020]. Preliminary results indicate that far-right individuals consume less political content than the average respondent, consuming, in relative terms, a greater amount of extremist media and influencers, as shown in figure 1. The growing importance of influencers to far-right strategic communication has been highlighted by [Edgerly et al., 2017]. Moreover, far-right individuals are more likely than the average user to turn to social media after visiting legacy or political sites or searching for political content on search engines [Figure 3]. In contrast, far-left individuals tend to continue informing themselves through similar sources [Figure 4]. These findings reveal that individual ideological differences can lead to distinct information pathways, which not only shape the type of political content consumed but also have varying potential to fuel polarization, reinforce ideological echo chambers, and hinder meaningful debate across political divides, ultimately influencing both political engagement and polarization. Dependent variables: Average index political participation, measured by responses to how often individuals engaged in activities such as electoral campaigns, protests, civic engagement, online participation, and used sources like legacy media, extremist sites, and political influencers. Method II: Inclusion criteria for media outlets: Extremist media outlets are characterized by ideological bias and ethical violations, including failure to verify sources and anti-establishment positions, which compromise journalistic integrity. Legacy media outlets, on the other hand, adhere to journalistic standards, and avoid clear ideological bias.","Alejandro De la fuente Cuesta, Laia Castro Herrero, Yuan Zhang, Frank Esser, Jihye Park, Pamina Syed Al, Michael Amsler",Troselli,Polarization I,4,,523
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Affective Polarization and Deliberative Decision-Making: Evidence from a Visual Conjoint Experiment,"The rise of partisan antagonism and affective polarization among members of different political parties has become a significant concern in advanced democracies, posing challenges for political dialogue, social cohesion, and democratic governance. While research on deliberative decision-making highlights the potential of deliberation to foster mutual understanding, we still lack insights into how partisan identities function as social markers that influence citizen' opinion formation in deliberative contexts and shape their willingness to consider alternative perspectives. Drawing on social identity theory and the role of social norms, we hypothesize that citizens' support for policy proposals and their readiness to engage in deliberative discourse are influenced by the partisan identity of the policy proponent. To test this argument, we implement a large-scale, pre-registered visual conjoint experiment, leveraging computational text analysis to examine deliberative engagement. Our study, conducted in Germany—a country experiencing increasing affective polarization—emulates the online citizens' assembly Conference on the Future of the EU to provide an externally valid measure of partisan bias in deliberation. Our results show that when the out-partisan identity of a policy proponent is made salient, individuals are more likely to dismiss the policy proposal, even when they substantively agree with it. By integrating experimental and computational methods, this study sheds light on how affective polarization constrains citizens' willingness to engage with policy proposals from out-party members despite ideological alignment. These findings contribute to our understanding of the challenges to effective deliberation and inclusive democratic discourse in Western European societies while offering methodological insights for studying online deliberation in polarized contexts.","Julia Schulte-Cloos, Daniel Bischof, Roman Senninger",Troselli,Polarization I,5,,733
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,The Effects of Outgroup Agreement and Ingroup Dissent on Political Polarization,"Global polarization has intensified in recent years, driven in part by the growing influence of social media. Users’ preference to engage with like-minded online content creates echo chambers that segregate them into increasingly polarized groups. Content curation algorithms further reinforce this divide, deepening affective polarization. A key issue with these algorithms is content ranking based on predicted engagement. High-arousal posts, both positive and negative, tend to stimulate engagement. As a result, algorithms that focus on maximizing engagement prioritize these posts, inadvertently distorting political perceptions. On one hand, they amplify positive content from the ingroup, reinforcing a false sense of homogeneity. On the other hand, they highlight negative content from the outgroup, exaggerating the perceived extremism of opposing viewpoints. Given these dynamics, interventions that reshape how individuals perceive political divisions may help reduce polarization. Strategies that reshape perceptions of outgroups include introducing counter-stereotypical information, correcting false perceptions, recategorizing social identities, and facilitating intergroup contact. Research suggests these interventions can reduce partisan hostility, but their long-term impact on intergroup attitudes and whether they foster positive cross-partisan interactions remains uncertain, as they typically involve brief, one-time exposures within surveys. Polarization is shaped not only by passive exposure to information but also by social interactions that actively reinforce perceptions of “us” versus “them.” While field interventions that target intergroup interactions have shown lasting effects that promote cooperative behaviors, they are less scalable. We propose a study design utilizing Large Language Models (LLMs) to simulate real-time discussions, allowing us to test how political conversations can mitigate partisan divides. We hypothesize that encountering unexpected experiences, such as finding common ground with a political opponent (Outgroup Agreement) or disagreement with a political ingroup member (Ingroup Disagreement), can trigger cognitive dissonance and a reassessment of partisan boundaries, ultimately reducing political polarization. Unlike one-off informational exposure, which may produce short-term attitude shifts, engaging in dialogue—particularly when it involves ingroup disagreement or outgroup agreement—has the potential to challenge entrenched partisan perceptions, leading to enduring attitude changes. To test these hypotheses, we employ LLM-embedded survey experiments. Participants will be recruited via quota-based sampling and randomly assigned to one of four conditions in a 2×2 factorial design: (1) Ingroup Agreement (discussion with a like-minded ingroup member), (2) Ingroup Disagreement (discussion with an ingroup member who disagrees), (3) Outgroup Agreement (discussion with an outgroup member who agrees), or (4) Outgroup Disagreement (discussion with an outgroup member who disagrees). Participants will engage in real-time conversations with LLM personas, believing they are interacting with another randomly matched participant. These LLM personas are dynamically customized based on each participant’s pre-treatment responses (e.g., opinions on key political issues) and their assigned experimental condition. For instance, if a Democratic participant who opposes immigration restrictions is assigned to the Outgroup Agreement condition, the LLM persona will be given a Republican identity that also disagrees with immigration restrictions. This alignment is generated within the system prompt, where the persona’s partisan identity (ingroup vs. outgroup) and stance (agreement vs. disagreement) are inserted into predefined templates based on the participant’s responses and assigned experimental condition. After completing the discussion with the LLM persona, participants will answer post-treatment questionnaires measuring outcome variables. To assess whether the effects of political discussion persist over time, participants will be invited to a follow-up survey four weeks later. We provide empirical evidence on how political conversations—specifically, experiences of outgroup agreement and ingroup disagreement—can mitigate polarization. By leveraging LLM-driven dialogues within a survey framework, this research offers a scalable and controlled approach to studying depolarization strategies in digital environments. Beyond its experimental contribution, the findings have practical implications for social media interventions. If ingroup disagreement reduces the false perception of ingroup uniformity, this suggests that social media algorithms could be designed to prioritize diverse perspectives within the ingroup. Similarly, if cross-party agreement helps reduce polarization, emphasizing shared values and common ground in algorithmic content curation could help bridge partisan divides.","Do Won Kim, Bao Tran Truong, Ozgur Can Seckin, Saumya Bhadani",Troselli,Polarization I,6,,665
,,,,,,,,,,
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,How opinion variation among in-groups can skew perceptions of ideological polarisation,"There is a widespread perception that society has been polarising into groups with increasingly divergent opinions. Multiple studies have sought to quantify the degree of opinion divergence (or ideological polarisation), typically relying on differences between self-reported opinions, and have reached mixed conclusions. We propose this inconsistency can be explained by the way individuals' subjective perceptions are shaped by their social identities. We introduce a formal framework to analyse opinion data that accounts for such asymmetric, dynamic perceptions. When members of an in-group become increasingly homogeneous on a given topic (that is, when the variance of opinions in that group decreases), they perceive deviant opinions as increasingly distant from their own. Consequently, these individuals may perceive greater polarisation than an objective, neutral observer would. Applying the framework to data on the opinions of Germans about climate change, we show that perceived polarisation may depend as much on the dynamics of in-group variance as it does on actual opinion divergence in society. Moreover, we show that the direction of this effect may vary over time and across different partisan groups. Our framework offers an explanation why people might sometimes perceive higher levels of ideological polarisation than surveys indicate, independent of social segregation, polarisation-enforcing cognitive biases, or affect-driven attitudes towards out-groups.","Peter Steiglechner, Paul E. Smaldino, Agostino Merico",Troselli,Polarization II,1,,80
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Facing Common Threats in a Polarized Environment,"When facing a common threat, conventional wisdom suggests that members of a society will be able to set aside their differences and work together towards a collective solution. However, that this axiom is universal has been disproven by the disjointed and highly polarized responses to COVID-19 and the threat of climate change in the United States. Previous research has suggested that conditions are unfavorable for collective response, citing high levels of affective polarization, i.e., partisan dislike of members of the other party, low information and subsequent overreliance on social learning, and divisive influence by political elites. We synthesize these concepts into a mathematical model of opinion dynamics and evaluate different scenarios under which feedback between affective and ideological polarization may evolve. Under different specifications for social learning, initial polarization (representing, e.g., early influence by political elites), and inherent preferences between groups, the model predicts three behaviors. In a scenario with a high degree of social learning and high initial polarization, a common threat can deepen existing division, even when inherent preferences are equal between two groups. When initial polarization is lower, groups can reach consensus on the common threat, and when reliance on social learning is reduced and inherent preferences are more disparate, the consensus reached on the common threat can reduce polarization on pre-existing issues. This study helps solve the puzzle of why common, existential threats like COVID-19 and climate change are not guaranteed to unite polarized groups and suggests potential high-leverage intervention points to facilitate collective problem-solving.","Cathy DiGennaro, Vicky Chuqiao Yang",Troselli,Polarization II,2,,922
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Inference of multi-dimensional political positions of online users and web domains: methodology and validation on large-scale French Twitter data,"The study of phenomena related to public opinion online and especially political polarization garners significant interest in Computational social sciences. The undertaking of several studies of political phenomena in social media mandates the operationalization of the notion of political stance of users and contents involved. Relevant examples include the study of segregation and polarization online, or the study of political diversity in content diets in social media. While many research designs rely on operationalizations best suited for the US setting, few allow addressing more general design, in which users and content might take stances on multiple ideology and issue dimensions, going beyond traditional Liberal-Conservative or Left-Right scales. To advance the study of more general online ecosystems, we present a methodology for the computation of multidimensional political positions of social media users and web domains. We perform a case study on a large-scale X/Twitter population of users in the French political Twittersphere and web domains, embedded in a political space spanned by dimensions measuring attitudes towards immigration, the EU, liberal values, elites and institutions, nationalism and the environment. We provide several benchmarks validating the positions of these entities (based on both LLM and human annotations), as well as a discussion of the case studies in which they can be used, including, e.g., AI explainability, political polarization and segregation, and media diets. To encourage reproducibility and further studies on the topic, we publicly release our anonymized data.","Antoine Vendeville, Jimena Royo-Letelier, Duncan Cassells, Jean-Philippe Cointet, Maxime Crépel, Tim Faverjon, Théophile Lenoir, Béatrice Mazoyer, Benjamin Ooghe-Tabanou, Armin Pournaki, Hiroki Yamashita, Pedro Ramaciotti Morales",Troselli,Polarization II,3,,92
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Understanding Public Opinion in Times of Crises: Combining Survey and News Data Through Multimodal XAI,"How can the impact of events on public opinion be quantified? A key challenge in many liberal democracies is increasing polarization, as different social groups respond divergently to global events. Especially during polycrisis, vulnerable groups are often disproportionately affected. To address this, there is a growing need for robust tools that can analyze how polarization and fragmentation between groups occur and how different crises affect specific parts of society. In this study, we introduce a novel tool to the computational social sciences community and explore its potential to advance research on societal polarization and democratic resilience.","Amal Labbouz, David Borukhson, Jonas Fegert, Christof Weinhardt",Troselli,Polarization II,4,,328
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Neural Network Nominate: Mapping Mass Political Ideology via Revealed Preferences,"Political polarization poses a growing threat to democracies by weakening civic engagement, institutional trust, and effective governance (McCoy & Somer, 2019). Yet many studies on mass-level polarization rely on social media data (Del Vicario et al., 2016; Conover et al., 2021), which can be skewed by echo chambers and platform biases (Hargittai, 2015), or on survey-based self-reports (Tourangeau & Yan, 2007), which are vulnerable to social desirability and other response biases. To address these issues, we introduce Neural Network Nominate (NNN), a framework that infers political ideology from revealed preferences—direct policy choices—rather than solely from stated opinions. NNN builds on Thurstone’s (1927) method of paired comparisons and adapts the NOMINATE approach (Poole & Rosenthal, 2001) from legislative roll-call data to large-scale individual-level datasets. Our method simultaneously embeds both voters and policy proposals in a low-dimensional space, creating a shared ideological map. We tested this approach in three distinct contexts: Chile (2019) with three million pairwise comparisons submitted by 48,000 participants during a period of intense social unrest, France (2022) with two million comparisons from 1,488 participants in the lead-up to the presidential election and Brazil (2022) with around 277,000 comparisons from 790 participants during the presidential election. In each setting, participants saw pairs of policy proposals and indicated which proposal they preferred, after which they could optionally provide self-reported ideology (left–right) and basic demographics (Figure 1-a). We applied bot-detection criteria (Awad et al., 2018; Navarrete et al., 2023) and then trained a neural network classifier to predict which proposal would win in each pair—achieving predictive accuracies of about 68–70%. The network features two embedding matrices (one for users, another for proposals). By adjusting these embeddings to minimize prediction error, the model learns a latent ideological space in which each user and each proposal occupies coordinates in a two-dimensional space. After learning the embeddings (Figure1-b), we examined how well a user’s coordinates could predict self-reported left–right ideology. When combined with minimal demographic data, we classified left- vs. right-leaning users with 83% accuracy in Chile, 91% in France, and 86% in Brazil (Figure 1-d,e). Visualizing these coordinates revealed coherent clusters of users and proposals: left-leaning participants clustered near left-leaning proposals, right-leaning participants near right-leaning proposals, and so on (Figure 1-c). Sensitivity analyses showed that even after only 20 pairwise comparisons per user, NNN could still classify political leanings with about 77–82% accuracy. Generational patterns emerged across countries. In France and Brazil, younger cohorts (Millennials and Generation Z) formed more polarized “peaks,” aligning with research suggesting stronger ideological intensity among “digital natives” (Twenge et al., 2019). In contrast, in the Chilean sample—collected amid widespread protests—self-identified younger right-wing participants gravitated somewhat leftward on certain policy choices, pointing to a more fluid ideological landscape during a time of social upheaval. Methodologically, NNN overcomes key limitations of standard surveys and social media scraping by using direct policy choices instead of abstract scales or retrospective recall. This approach reduces the impact of social desirability bias, since participants choose between concrete policy proposals rather than rating their positions on sensitive topics. It also avoids platform-driven distortions, since no single social network or curated feed dictates exposure. Furthermore, NNN expands the traditional spatial-voting paradigm—which typically focuses on legislative elites—to broader populations. By systematically placing both people and proposals in the same ideological space, we gain clearer insights into which policies unite or divide voters at the mass level. This can illuminate not just how polarized a population is but also why it is polarized, by identifying the specific proposals that drive ideological cleavages. In sum, our findings demonstrate that pairing a neural network architecture with revealed preferences offers a scalable, transparent means of tracking polarization and understanding how specific policy choices shape ideological divides. By capturing actual decisions rather than stated views, this framework complements or, in some cases, outperforms conventional surveys and social media analyses. The results point toward promising avenues for “digital democracy,” where participants can discover consensus points, highlight entrenched fault lines, and surface emerging issues with fewer biases than in traditional data-collection methods.","Adolfo Fuentes-Jofre, Cristian E Candia, Cristian Jara-Figueroa",Troselli,Polarization II,5,,76
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Divergence Between Predicted and Actual Perception of Climate Information,"Despite strong scientific consensus on the severe risks posed by climate change, a substantial segment of the population remains unconvinced, limiting progress on effective climate action. Persuading climate skeptics is essential for building broader support for stronger climate policies and accelerating efforts to mitigate climate change. However, outreach efforts often depend on perceptions of skeptics' openness to climate communication: when persuasion is seen as unlikely, communication efforts tend to diminish. In this paper, we investigate the predicted versus actual impact of climate change information on skeptics. Using a series of surveys with U.S. respondents, we first gather predictions about the effectiveness of authentic news articles in changing skeptics' views. Our findings reveal a widespread pessimism: climate advocates expect no change in attitudes, while skeptics anticipate a backfire effect that reinforces their skepticism. Contrary to these predictions, our preregistered survey experiment finds that exposure to climate change articles significantly increases concern among skeptics. However, their responses vary in terms of willingness to adopt climate-friendly behaviors and support climate policies. These results reveal a significant disconnect between people's expectations and actual effects of climate communication on skeptics, emphasizing the need for sustained and strategic investments in climate communication to foster greater public engagement and support for climate action.","Amir Tohidi Kalorazi, Stefano Balietti, Samuel Fraiberger, Anca Balietti",Troselli,Polarization II,6,,912
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Modeling 2-Level Polarization in Signed Networks,"Polarization is often seen as a simple ``for or against"" dynamic, which we define as a 1-LEVEL view—where people align into opposing sides (e.g., left vs. right) with strong internal agreement and mutual dislike. However, this oversimplifies reality. Beyond this, a 2-LEVEL perspective emerges, where subgroups form not just by agreement but through shared animosities, shaping distinct structures of negativity. These hidden layers play a crucial role in polarization dynamics. To model polarization in signed networks, archetypal analysis has been used to identify extreme archetypes, while Graph Neural Network (GNN)-based autoencoders capture latent graph structures. However, explainable neural generative models for signed networks remain underexplored. We address this with the Signed Graph Archetypal Autoencoder (SGAAE), which extracts node representations by projecting the graph onto a learned polytope governing polarization. Combining the Skellam distribution, relational archetypal analysis, and GNNs, SGAAE uncovers latent structures and competing communities. We introduce the 2-LEVEL network polarization problem and demonstrate how SGAAE characterizes it. The model outperforms baselines in signed link prediction across four real-world datasets and provides interpretable polytope-space visualizations that reveal key network structures.","Nikolaos Nakis, Chrysoula Kosma, Giannis Nikolentzos, Michail Chatzianastasis, Iakovos Evdaimon, Michalis Vazirgiannis",Troselli,Polarization II,7,,450
,,,,,,,,,,
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Generation of Human Mobility Trajectories Using Map Information,"This study presents a novel approach to generating human mobility trajectories by leveraging map information. Our proposed model integrates Vision Transformer (ViT) for encoding map data as visual information and GPT-2 for generating realistic movement trajectories. Unlike conventional methods that rely solely on sequential positional data, our approach incorporates spatial structures and regional characteristics, enabling the generation of more natural and diverse trajectories. We trained our model using anonymized point-based population data from Ishikawa Prefecture, Japan, and applied data augmentation techniques to enhance robustness. Experimental results demonstrate that our model effectively captures population density patterns and regional characteristics, improving the applicability of mobility trajectory generation in urban planning and transportation network design. The proposed method enhances computational social science applications by offering more accurate simulations of human movement in diverse environments.","Shouji Fujimoto, Atushi Ishikawa, Takayuki Mizuno",Hemeryck,Mobility & Urban Science I,1,,386
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Extreme heat reshapes daily travel behaviour,"Extreme heat is a problem in European countries, with rising temperatures affecting ageing populations. While research has documented how high temperatures affect travel and mobility, less is known about how these decisions vary across social and economic groups. Furthermore, most work relies on data from sources with small samples like surveys, or limited contexts like city transport networks. We use open human mobility data from passive and active mobile network connections covering 13 million individuals in Spain (27\% of the population) to examine extreme heat's impact on mobility. We stratify by age, gender, social and economic status, and activity. Our findings show activity falls by as much as 10% on hot days generally and 20% on hot afternoons specifically, when temperatures peak. Individuals cut infrequent activities most, frequent ones less, and rarely skip work. Further differences emerge on hot days. Older adults are more likely to avoid work related travel and cut back on other activities, while those earning less are less able to reduce work related mobility. Our results suggest that extreme heat disrupts mobility and worsens intergroup differences, disproportionately affecting vulnerable groups.",Andrew Renninger,Hemeryck,Mobility & Urban Science I,2,,532
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,When Proximity Falls Short: Inequalities in Commuting and Accessibility in Santiago,"This study investigates commuting patterns and accessibility inequalities in Santiago, Chile, using eXtended Detail Records (XDR) from mobile phone data. Residential and key activity locations were identified, and commuting routes were modeled with the R5 routing engine, integrating public transport and walking. By combining mobility data with accessibility metrics, the analysis explores the relationship between commuting times, socioeconomic status, and access to opportunities like jobs and education. The findings reveal that high-opportunity areas are mainly inhabited by higher socioeconomic groups; however, these areas do not necessarily experience shorter commuting times, highlighting a disconnect between proximity to opportunities and travel times.","Cesar Marin-Flores, Leo Ferres, Henrikki Tenkanen",Hemeryck,Mobility & Urban Science I,3,,48
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Exploring Multidimensional Accessibility and Flow Patterns in Urban Commercial Areas,"In urban environments, commercial districts serve as hubs of economic activity, attracting consumers while supporting local businesses. Their growth and development are closely tied to urban population distribution and mobility. Changes in accessibility influence both the prosperity of existing commercial centers and the emergence of new ones. Thus, quantifying accessibility is essential for understanding the spatial structure of commercial districts and their transformation over time. Traditional accessibility indicators, such as network density or distance to transit stations, often emphasize physical distance rather than consumer experience~\cite{heroy2023neighbourhood}. However, to better understand the relationship between consumer distribution, mobility patterns, and commercial district development, accessibility must be measured as it is actually experienced. Furthermore, variations between distance-based and time-based accessibility, influenced by transport infrastructure, should be considered. This study develops a multidimensional accessibility index using real-time movement data from GPS-based navigation systems and mapping services. The proposed index integrates physical distance-based accessibility, travel time-based accessibility, and public transportation accessibility for a comprehensive assessment of commercial district accessibility. Additionally, population distribution data is incorporated to reflect consumer density, ensuring accessibility measures align with consumer demand and commercial district activity. Using floating population data, we empirically analyze the relationship between commercial district accessibility and the spatial distribution of potential consumers through regression analysis. The study focuses on commercial districts in Incheon, South Korea, a rapidly developing mid-sized Asian city. Incheon features both traditional commercial hubs and newly developed business districts, making it an ideal case for examining accessibility’s impact. The boundaries of Incheon’s commercial districts are defined using the methodology of~\cite{jun2022economic}. Within these boundaries, we collect travel time and distance data for approximately 2,000,000 optimal paths from Korean navigation platforms (Naver~\cite{naver_directions}, Kakao~\cite{kakao_directions}), covering both driving and public transportation. Additionally, floating population data and credit card transaction records are used to investigate the relationship between accessibility and visitor flow patterns. Building on spatial interaction theory~\cite{heroy2023neighbourhood,nyerges2011sage}, we propose a district-focused accessibility index that reflects \textit{accessibility-weighted catchment demand}: \[ A_{z}^{t} = \sum_{i} P_{i} e^{-\frac{c^{t}_{iz}}{\lambda_{t}}} \], where \( A_{z}^{t} \) represents the accessibility of commercial district \( z \) via transportation mode \( t \), \( P_{i} \) denotes the potential consumer population at origin \( i \) (reflecting the \textit{catchment demand}), \( c^{t}_{iz} \) refers to the travel cost from \( i \) to \( z \), and \( \lambda_{t} \) is a decay parameter that reflects sensitivity to travel costs. This approach captures the \textit{effective catchment demand} by incorporating both population size and spatial accessibility. As shown in Figure 1 [A], distance-based accessibility reflects geographical proximity, with higher values near district boundaries. However, time-based accessibility varies due to traffic conditions and infrastructure differences, showing distinct patterns in driving vs. public transportation accessibility. By integrating three accessibility scores, we obtain a comprehensive profile of each commercial district, highlighting differences between newly planned cities and older, organically developed urban centers. In recently developed areas (e.g., \textit{Songdo}), physical distance-based accessibility is low, while time-based accessibility remains high due to well-developed transport infrastructure, though limited public transit weakens external connectivity. Conversely, older urban centers (e.g., \textit{Bupyeong}) show high accessibility in both distance and time-based measures, with traditional commercial districts benefiting from strong public transit access. This study enhances understanding of commercial district accessibility, enabling a more precise quantification of its impact on spatial structure and consumer flow. Moreover, it provides insights into how accessibility attracts visitors, shapes urban mobility trends, and affects commercial revitalization strategies. By revealing the relationship between accessibility and mobility patterns, this research offers valuable implications for urban planning, transportation policy, and sustainable commercial development.","Minjin Lee, Hyoji Choi, Taesung Hwang, Jeong hwan Jeon",Hemeryck,Mobility & Urban Science I,4,,1013
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Urban highways are barriers to social ties,"Cities are hubs of concentrated social capital that can foster diversity and innovation [1]. However, this potential is threatened by spatial fragmentation through built infrastructure that can divide neighborhoods [2, 3], exacerbate inequalities [4, 5], and contribute to segregation [6]. Among various types of barriers fragmenting urban areas, roads designed for motorized traffic are the most ubiquitous, especially highways [7, 8]. Since the 1960s, urban planners have theorized that high-traffic roads reduce opportunities for creating and maintaining social ties across divided neighborhoods [9], thus undermining the social cohesion essential for the development of thriving communities. This premise lies at the core of contemporary urban planning research and interventions [10, 11] that strive to meet the UN’s sustainable development goal of “making cities and human settlements inclusive, safe, resilient and sustainable” [12]. Despite its significance in urban planning theories, the association between high-traffic roads and reduced social connectivity has never been measured empirically, with the notable exception of a few small-scale, survey-based studies [13, 14]. Previous quantitative research in this area, constrained by the scarcity of geo-referenced social network data [15, 16], has focused instead on measuring socio-economic segregation in cities. This goal has been achieved either by using static demographic data [17, 6] or, more recently, through mobility data [18, 19], with only sporadic attempts to link segregation to urban barriers [20]. While highly valuable, such previous research could not explicitly consider social ties. However, providing an explicit, quantitative estimation of the barrier effect of different roads in curbing social ties is crucial for guiding evidence-based plans of restorative urban interventions and for prioritizing them according to their estimated benefits [21]. To fill this gap, we introduce a method to systematically quantify the association between highways and social ties at multiple scales, ranging from individual highway segments to entire metropolitan areas. We focus on the network of urban highways in the US. This highway network offers a compelling subject for the study of barrier effects: with a cost of at least 1.4 trillion USD [22], US highways were built to bridge city centers and newly created suburbs; simultaneously, they displaced an estimated 1 million people from their neighborhoods and today pose hard-to-cross physical barriers to pedestrians and cyclists [3, 23]. Onto this network of urban highways within the 50 largest metropolitan areas in the US, we overlay a massive geolocated social network of ties between individuals who follow each other on Twitter [24]. We compute a Barrier Score which quantifies the reduction in the number of social ties crossing highways, comparing the empirical crossings with a null model that makes ties oblivious to highways. The distribution of Barrier Scores reveals that in all 50 cities, the presence of highways consistently correlates with reduced social connectivity compared to the null model, showing that urban highways are barriers to social ties. This reduction is stronger between people living closer to each other, peaking at distances below 5km in most cities and fading beyond 20km. Notoriously, urban highways in the US have been instrumentalized for government-backed racial segregation, creating social divides between communities that persist to this day [8, 25]. We therefore revisit several highways in US cities that are well-documented for their historic role in racial segregation, finding potential evidence for long-lasting effects several decades after their construction, by measuring high Barrier Scores in contemporary social networks.","Luca Maria Aiello, Anastassia Vybornova, Sandor Juhasz, Michael Szell, Eszter Bokanyi",Hemeryck,Mobility & Urban Science I,5,,118
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Decomposing geographical and universal aspects of human mobility,"Driven by access to large volumes of detailed movement data, the study of human mobility has grown rapidly over the past decade. This body of work has argued that human mobility is scale-free, it has proposed models to generate scale-free moving distance distributions, and explained how the scale-free distribution arises from aggregating displacements across scales. The field of human mobility, however, has not explicitly addressed how mobility is structured by the constraints set by geography – that mobility is shaped by the outlines of landmasses, lakes, and rivers; by the placement of buildings, roadways, and cities. Based on unique datasets capturing millions of moves between precise locations, we show how separating the effect of geography from mobility choices reveals a universal power law spanning five orders of magnitude (10 m to 1,000,000 m). To do so, we incorporate geography via the ‘pair distribution function,’ a fundamental quantity from condensed matter physics that encapsulates the structure of locations on which mobility occurs. We show that this distribution captures the constraints that geography places on human mobility across length scales. Our description conclusively addresses debates between distance-based and opportunity-based perspectives on human mobility: By showing how the spatial distribution of human settlements shapes human mobility, we provide a novel perspective that bridges the gap between these previously opposing ideas.","Louis Boucherie, Benjamin Frank Maier, Sune Lehmann",Hemeryck,Mobility & Urban Science I,6,,55
,,,,,,,,,,
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,The Effect of Trajectory Sparsity on Epidemic Modeling Outcomes,"Location datasets collected from smartphones are increasingly used in epidemic models [1]. These types of dataset are generally affected by presence of gaps in individual trajectories which can be due to mobile-phone usage and the data collection process. Sparsity can lead to under-estimate visits to locations and events of potential transmission. Despite the critical role of these datasets for epidemic modeling, the extent to which sparsity can impact the findings of epidemiological studies is not entirely clear [2]. In this study, we propose a data-driven framework in which we can fine-tune the sparsity level in users’ signals to evaluate its effect on descriptive statistics of epidemic modeling simulations. [1] H. Barbosa, M. Barthelemy, G. Ghoshal, C. R. James, M. Lenormand, T. Louail, R. Menezes, J. J. Ramasco, F. Simini, and M. Tomasini, “Human mobility: Models and applications,” Physics Reports, vol. 734, pp. 1–74, 2018. [2] F. Schlosser, V. Sekara, D. Brockmann, and M. Garcia-Herranz, “Biases in human mobility data impact epidemic modeling,” arXiv preprint arXiv:2112.12521, 2021.","Federico Delussu, Francisco Barreras, Yuan Liao, Laura Maria Alessandretti, Duncan J. Watts",Hemeryck,Mobility & Urban Science II,1,,827
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Technological Change Shapes the Geometry of Urban Evolution,"We present a topology-based approach to visualize cities’ technological positions and quantify their shift and differentiation using a shape graph. This approach is applied to over 9 million geocoded patents spanning 756 technological activities in Chinese and U.S. cities between 2003 and 2017. Our results show that while Chinese cities undergo significant positional shifts, over 80% experience reduced differentiation or remain undifferentiated. Nevertheless, topological data analysis identifies a subset of emerging tech hubs with markedly increased differentiation, driven by advancements in frontier technologies like telecommunications and semiconductors. Compared to their leading U.S. counterparts, these emerging Chinese tech hubs exhibit a faster diversification rate but remain less differentiated overall. This study offers a technology-sensitive framework for understanding the competition dynamics in urban systems and assessing cities’ development trajectories.",Ziyu Chen,Hemeryck,Mobility & Urban Science II,2,,28
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Urban scaling and network inequality,"Urban scaling research has documented striking and seemingly universal superlinear relationships between city size and their outputs, from economic productivity and innovation to crime (1-5). Larger cities, across time and space, systematically generate disproportionately more output per capita than smaller ones. Recent studies further show that not only do totals rise with city size, but inequality in these outputs also systematically increases (6-9). Explanations for urban scaling focus on increased social connectivity and economic complexity in dense cities. Simple models of cities as interconnected networks have provided predictions that map remarkably well onto empirical observations of city totals (4,5). However, these models are unable to account for the increases in inequality by city size and instead assume high homogeneity––where everyone is similarly more interconnected and productive in larger cities. Thus, our understanding of the network mechanisms responsible for jointly producing increased productivity and inequality by city size remains poor. To address this gap, we bring together ideas from sociology, network science, and urban economics to identify two network-based mechanisms through which increasing city size produces both higher aggregate output and higher inequality. These mechanisms build on classic sociological theories of social networks—Granovetter’s weak ties (10) and Blau’s social structure (11)—and on economic ideas of skill complementarity (12), embedding them in the context of urban scaling. The first mechanism draws on Blau's theory of social structure, which shows network segregation is governed by heterogeneity, complexity, and consolidation of attributes. When homophilous tie formation occurs alongside correlated social dimensions, networks fragment into clusters, inhibiting diffusion between groups (13-15). For urban scaling, this implies larger cities with greater heterogeneity and stronger consolidation develop more segregated networks. Research confirms bigger cities exhibit greater diversity (16), and our results show increasingly correlated social traits with city size. Consequently, big cities sort individuals into segregated interactions (17), concentrating opportunities among some groups while limiting access for others—simultaneously producing higher citywide output and greater inequality. The second mechanism builds on Granovetter’s insight that “the strength of weak ties” lies in their ability to act as bridges to novel information (10). Large cities are not only more internally diverse; they also provide more opportunities to connect disparate social circles. Prior research (12) shows that big cities facilitate more complementary (and therefore productive) interactions. However, these studies focus on ties defined by frequent interaction within social circles, neglecting the higher-order network connections between such circles. We posit that increased diversity in large cities amplifies benefits from indirect connections. As cities grow, potential weak ties multiply, creating bridges between specialized clusters. Unlike small towns where friends-of-friends resemble immediate circles, big city networks span broader ranges of expertise. This suggests complementarity through longer-range ties scales superlinearly with city size, allowing individuals to access specialized skills through few introductions—contributing to superlinear productivity. This mechanism also generates inequality because advantaged individuals (highly skilled, educated) better recognize and utilize distant network opportunities. They activate weak ties spanning clusters, gaining disproportionately from urban diversity. Less advantaged individuals often lack either the connections or capacity to benefit (12), creating cumulative advantage where network spillovers widen existing gaps. To study these mechanisms, we combine population-scale microdata analysis with agent-based simulations. For the first mechanism, we measure city-specific parameters of Blau’s theory to calibrate simulation models (13-15) for predicting network segregation and inequality, comparing results with empirical observations. For the second mechanism, we analyze skill complementarity across first and second-order ties by educational level. Our results confirm theoretical expectations. In conclusion, this study addresses a critical gap in urban scaling research by identifying network mechanisms that simultaneously produce increased output and inequality. Our preliminary results support these mechanisms, demonstrating how urban network structures differentially distribute opportunities across population segments, contributing to our understanding of cities as complex social systems and offering insights for more inclusive urban policies.","Martin Arvidsson, Marc Keuschnigg",Hemeryck,Mobility & Urban Science II,3,,1046
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Working behaviour and the spatial complexity of economic activity,"The COVID-19 pandemic has accelerated remote work adoption globally, revealing socio-economic disparities in access to remote work. This study investigates the determinants of remote work adoption in Budapest, Hungary, using mobile phone geolocation data and administrative records of Hungarian companies. By combining these data sources, we analyze how remote work prevalence varies across industries, income groups, and neighborhoods, focusing on spatial and temporal patterns of work activity. We identify three spatial clusters: industrial areas with low economic activity, institutional and commercial hubs with high remote work adoption, and mixed-use areas with diverse working patterns. Regression analyses reveal that higher-income individuals and those in finance-dominated areas are more likely to work remotely, while lower-income individuals, women and those in commerce sectors remain tied to physical workplaces. Proximity to the city center is negatively correlated with remote work, and company productivity measures are positively associated with remote work adoption. This study highlights the unequal distribution of remote work opportunities across socio-economic groups and urban locations, offering valuable insights for policymakers and urban planners in adapting cities to the post-pandemic work environment.","Zsófia Zádor, Balázs Lengyel, Riccardo Di Clemente",Hemeryck,Mobility & Urban Science II,4,,1022
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,The temporal dimension of experienced segregation in cities,"Cities have been traditionally viewed as a great equalizer of economic prosperity, the core mechanism of which is the interactions between people of different demographic characteristics (Jacobs [1984], Jacobs [1969], Florida [2003]). However, a long history of work shows that segregation in cities undercuts this possibility. Recent work has sought to demonstrate the (in)equality in cities using high-resolution mobility data, finding that experiences of segregation extend beyond residential configurations of cities to the everyday interactions between individuals (Moro et al. [2021]). However, these comprehensive studies overlook another dimension recognized to be an important aspect of experience inequality: time (Massey [1994], Netto et al. [2018]). Our study builds on this foundation by empirically measuring space-time inequality using high-resolution mobility data. We leverage anonymized mobility data from Cuebiq to quantify how inequality manifests dynamically across cities, within cities, and between points of interest (POIs). Unlike static segregation metrics, our approach captures fluctuations in socioeconomic integration at different times of day. For instance, POIs that appear integrated at one moment may become highly segregated at another due to shifting activity patterns. The COVID-19 pandemic highlighted the importance of these temporal dynamics, as changes in work schedules and public space usage fundamentally altered mobility-driven inequality (Santana et al. [2023]). Moreover, recent research suggests that large metropolitan areas, despite their diversity, often exhibit higher exposure segregation due to differentiated space usage across socioeconomic groups (Nilforoshan et al. [2023]). Our work extends these insights by integrating both spatial and temporal dimensions to offer a more comprehensive framework for understanding mobility-driven inequality. Across 11 major US CBSAs, we systematically map the structure of space-time inequality over a six-month period, capturing both weekdays and weekends—in doing so, we document a consistent shape of urban inequality throughout a day. In particular, our results confirm the existence of substantial variation in space-time inequality, beyond typical residential segregation (Fig. 1c). This variation exists on three geographic scales: (1) between cities, (2) within cities, and (3) across POI types. Within cities, we find that greater temporal variation in experienced inequality is negatively correlated with income and positively correlated with diversity—suggesting that neighborhoods with greater resources are insulated from fluctuations in access to amenities and economic activity, while more diverse neighborhoods experience greater shifts in inequality throughout the day. The temporal inequality cataloged in this work emerges from the interplay of where people live, work, and gather—offering valuable insight into how urban form and zoning shape segregation and access to resources. A more detailed understanding of the forces underlying experienced temporal inequality can offer policymakers and community leaders valuable insights about the placement and design of new, inclusive, multi-use spaces—urban POIs that actively counter experienced segregation and reduce disparities in amenity access. In sum, documenting this seemingly universal shape of space-time inequality invites a deeper commitment to reshaping our urban environments and guiding policymakers to design more equitable places to live, work, and connect.","Joshua Rosen, Brennan Klein, Erik Weis, Hamish Gibbs, Daniel O’Brien, Takahiro Yabe, Esteban Moro",Hemeryck,Mobility & Urban Science II,5,,340
,,,,,,,,,,
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Structural differences in gendered mobility networks,"Understanding gender differences in mobility is essential for equitable urban planning. While surveys suggest women have more complex travel behaviors, large-scale mobility studies often show greater predictability. This discrepancy arises from measurement limitations, particularly the reliance on visitation entropy. Using high-resolution smartphone data from over XX users across 10 countries, we introduce a multidimensional approach combining entropy-based and network-based metrics. Our findings reveal significant gender differences in mobility complexity—women have more interconnected mobility networks, higher trip-chaining tendencies, and more efficient spatial navigation. These insights underscore the importance of examining mobility complexity beyond entropy-based measures and adopting a gender-aware approach to mobility analysis.","Silvia De Sojo, Sune Lehmann, Laura Maria Alessandretti",Concert hall,Mobility & Urban Science III,1,,525
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Incorporating Social Influence in LLM-Agent Based Modeling Improves Predictability of Evacuation,"Predicting individual evacuation behavior during disasters and quantifying the effects of social influence are crucial to developing effective disaster response strategies and minimizing human casualties. Traditional agent-based models often rely on simplified assumptions that fail to account for how diverse populations make decisions under stress. Recently, LLM agent-based modeling has enabled the simulation of human-like decision-making processes, allowing for more realistic and dynamic scenarios. Using large-scale mobile phone GPS location data collected during the 2021 Colorado wildfire from 6,872 individuals, we analyzed personal mobility patterns to define agent characteristics. Each agent was assigned a persona generated by prompts to a large language model (LLM), integrating daily mobility patterns, activity frequencies, and residential attributes. We conducted evacuation simulations under two scenarios: one without social connections and another incorporating social networks derived from co-location data using the Louvain algorithm. Results show that including social connections better replicates actual evacuation patterns, with more gradual and sustained evacuation trends compared to abrupt increases in the model without social influence. Logistic regression analyses confirm that proximity to the fire, sociodemographic characteristics, mobility patterns, and social connections significantly affect evacuation decisions. These findings highlight the crucial role of social networks in capturing real-world evacuation behaviors.","DongHak Lee, Jiayi Weng, Vaidehi Raipat, Takahiro Yabe",Concert hall,Mobility & Urban Science III,2,,301
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Behavioral response to mobile phone evacuation alerts,"On the night of February 2-3, 2024, severe wildfires ravaged Valparaíso, Chile, marking the country's worst natural disaster since the 2010 earthquakes and the most devastating wildfire in 30 years, with 137 fatalities and over 16,000 people directly affected. While the emergency impacted many people in the region, its effects were expected to burden unequally different socio-demographic groups. This paper examines the stratified re-location behavior of individuals during the wildfire and its differential impacts based on socioeconomic status. SMS-based alerts during emergencies are a highly effective communication tool due to their broad reach, low cost, and immediacy. However, overly broad alerts can lead to over-evacuation, straining infrastructure, and eroding public trust. In this study, we analyzed the immediate and short/medium-term response (days/weeks) to the fires and SMS-based alerts issued during Chile's wildfire event, using spatio-temporal data from a national mobile network and census-based proxies for socioeconomic status (SES). Official alerts provided the timing and location of evacuation messages and affected locations. To understand the causal effects of the Valparaiso wildfires on the populations of interest, we employ difference-in-differences and regression discontinuity methods. The difference-in-differences approach compares changes in outcomes over time between affected and unaffected groups, while regression discontinuity exploits a threshold-based assignment to estimate local treatment effects around the cutoff, the fire in our case. We categorized telecommunication towers into lower, middle, and higher SES groups. We infer the socioeconomic status of antennas based on the educational indicator distributions obtained by the national census for the areas nearby the tower. Based on the associated socioeconomic indicator values, we split towers into three equally populated quantile groups representing the lower, middle, and higher socioeconomic strata. Additionally, we leverage XDR locational data to infer the home towers for each unique phone ID in the Valparaíso region based on the location of the most frequent overnight stay phone tower before the wildfire. Combining this information with the subsequent mobility pattern, we split the population into three groups: potentially affected, likely evacuated, and not affected people. Regarding the immediate response, our findings show that the first SMS alert prompted significant evacuation behavior across all SES groups, regardless of proximity to the wildfire (Figure 1a). Higher SES areas exhibited fewer connections (Figure 1b), suggesting greater capacity for proactive evacuation. Interrupted time-series analysis confirmed that the initial alert was the primary driver of evacuation, with higher SES evacuations influenced more by prudence than direct alert targeting (Figure 1c). Later messages had a diminished effect even for newly warned areas. In the longer term, our analyses show that the wildfire had a statistically significant effect on people spending several nights away from their homes, which hints at the suitability of the dataset to characterize the impacts of these types of fast but short-lived wildfires. Interestingly, we found that the re-location effect is stronger for the low socioeconomic group, who also end up spending more time away from their home towers, with some of them also needing more time to evacuate (Figure 2). We also measured that the affected people reduced their night-to-night travel distances after the wildfires began. In this case, however, no statistically significant differences were observed between the socioeconomic groups. To assess where people went after evacuation, we implemented a spatially informed socioeconomic assortativity analysis of segregation, which shows the mixing patterns in mobility of different socioeconomic groups. High levels of assortativity mean that people tend to travel more to places of the same socioeconomic level. We find a significant decrease in traveling assortativity immediately after the beginning of wildfires, with a subsequent significant increase lasting for 5 nights. This may suggest that people first moved to places like shelters or temporary camps but then relocated to places with more similar socioeconomic profiles than their own, leading to a temporary increase in assortativity (see Figure 3a). A similar conclusion can be drawn from the regression discontinuity and difference-in-differences analysis (see Figure 3b and c, respectively). Our findings show several interesting patterns; initial alerts elicit stronger responses, repeated alerts risk desensitization, and SES shapes evacuation patterns, with higher SES groups better positioned to act. These insights inform strategies to enhance emergency communication, ensuring precision and improved safety for all communities.","Timur Naushirvanov, Erick Elejalde, Kyriaki Kalimeri, Elisa Omodei, Marton Karsai, Leo Ferres",Concert hall,Mobility & Urban Science III,3,,711
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Social homophily predicts evacuation destination choice and long-term displacement,"Rapid urbanization and climate change have contributed to a significant rise in the frequency and intensity of disasters, which have resulted in three million adults being displaced from their homes in the United States during the past year, according to the Census Bureau. Using large-scale mobility data, it is now possible to observe and analyze post-disaster mobility dynamics across a longer time period, compared to household surveys which are often limited in scale. However, much of the mobility data-driven research on evacuation and displacement destination choice behavior has focused on analyzing the effects of physical and spatial factors, often underemphasizing the role of social factors, including individual preferences and social connections. Motivated by the recent literature showing strong associations between social homophily and mobility behavior, we use large-scale data of anonymized GPS traces and online social connections from the Marshall Fires in Colorado, USA, to unravel the associations between social and behavioral factors and evacuation destinations and long-term displacement decisions. We find that behavioral characteristics and social homophily play a significant role in post-disaster mobility decisions. First, incorporating pre-disaster behavior characteristics increases the predictability of evacuated distance by more than five-fold, which is critical for wildfire evacuation. Second, given the same evacuation distance, evacuees chose locations that have a high sociodemographic homophily with their home locations, and locations that have more friendship connections, compared to the level of homophily they are spatially exposed to. The social homophily effect is stronger among White and educated populations than low-income, Black, and Asian populations. This effect has significant implications for long-term disaster impacts and policymaking, as it is a significant predictor of displacement and return decisions. Our findings highlight the importance of incorporating the social, behavioral, and economic characteristics to better understand and predict evacuation and displacement dynamics after disasters.","Vaidehi Raipat, Takahiro Yabe",Concert hall,Mobility & Urban Science III,4,,155
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Urban Safety Perception Through the Lens of Large Multimodal Models: A Persona-based Approach,"Understanding how urban environments are perceived in terms of safety is crucial for urban planning and policymaking. Traditional methods like surveys are limited by high cost, required time, and scalability issues. To overcome these challenges, this study introduces Large Multimodal Models (LMMs), specifically Llava 1.6 7B, as a novel approach to assess safety perceptions of urban spaces using street-view images. In addition, the research investigated how this task is affected by different socio-demographic perspectives, simulated by the model through Persona-based prompts. Without additional fine-tuning, the model achieved an average F1-score of 59.21% in classifying urban scenarios as safe or unsafe, identifying three key drivers of perceived unsafety: isolation, physical decay, and urban infrastructural challenges. Moreover, incorporating Persona-based prompts revealed significant variations in safety perceptions across the socio-demographic groups of age, gender, and nationality. Elder and female Personas consistently perceive higher levels of unsafety than younger or male Personas. Similarly, nationality-specific differences were evident in the proportion of unsafe classifications ranging from 19.71% in Singapore to 40.15% in Botswana. Notably, the model’s default configuration aligned most closely with a middle-aged, male Persona. These findings highlight the potential of LMMs as a scalable and cost-effective alternative to traditional methods for urban safety perceptions. While the sensitivity of these models to socio-demographic factors underscores the need for thoughtful deployment, their ability to provide nuanced perspectives makes them a promising tool for AI-driven urban planning.","Ciro Beneduce, Massimiliano Luca, Bruno Lepri",Concert hall,Mobility & Urban Science III,5,,686
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Uncovering Urban Lifestyles Through Detailed Large-scale Purchase Records,"Lifestyle encompasses an individual's way of life, including various aspects such as values, social status, consumption habits, and cultural interests. Its multifaceted concept involves complex interactions among these dimensions, making it challenging to measure and capture comprehensively. Recently, there has been a growing consensus that a more direct approach to understanding people’s lifestyles is through the observation of their consumption patterns, which offer explicit insights into their choices, such as what they eat, how they spend their time, and the interests they prioritize. The availability of large-scale purchasing records such as credit card transaction records has enabled data-driven studies on consumption behavior, linked to consumer characteristics. However, while credit card transaction records provide advantages in inferring purchase locations, their lack of information about detailed categories of consumed goods and services limits the ability to comprehensively capture latent lifestyle, which can be represented as a complex composition of purchased items related to socioeconomic status as well as individual preference. Differentiating spending on, for instance, golf gloves versus boxing gloves --- which may signal distinct lifestyles and even socioeconomic statuses --- remains challenging. Here, we extract urban lifestyles using millions of detailed package delivery records from Seoul, Republic of Korea, which span four years. As a global metropolitan city with a diverse mix of social, cultural, and economic backgrounds, Seoul also stands as one of the world’s largest e-commerce markets, with around 80% of its population using online shopping. Our dataset provides granular information on both recipient locations and the specific types of products purchased, allowing us to analyze urban lifestyles in unprecedented detail. Utilizing the data, we capture lifestyle groups consisting of products that are significantly more co-purchased. We apply network analysis and community detection algorithms to generate a co-consumption network of products and identify meaningful lifestyle groups. Moreover, by iterating the community detecting algorithm on a more granular level, we find the hierarchical structure of lifestyles which includes both broad pictures and detailed trends. We further analyze variations in these lifestyle patterns across different urban areas, income levels, and age demographics, highlighting their complex relationships with socioeconomic attributes. In addition, we examine the spatial distribution of lifestyles to assess clustering tendencies. The results show significant spatial autocorrelation, as measured by Moran’s I, indicating that similar lifestyle patterns tend to cluster geographically. This spatial homophily effect has intensified over time, suggesting an increasing alignment of lifestyle behaviors within specific urban areas. This study offers a novel framework for analyzing urban lifestyles through large-scale package delivery data, allowing for a more detailed examination of consumption behavior than traditional methods. By identifying co-purchase patterns and revealing consumer baskets, we uncover distinct lifestyle trends across various socioeconomic groups and demographics, demonstrating the utility of consumption patterns as a proxy for understanding lifestyle choices. Our findings also reveal that lifestyle groups do not align with any single socioeconomic characteristic, underscoring the complex interplay between lifestyle and socioeconomic factors. These insights provide valuable guidance for policymakers, as understanding how urban residents navigate their consumption choices based on lifestyle can inform the development of inclusive, targeted public services and enhance the overall quality of urban life.","Minjin Lee, Hokyun Kim, Bogang Jun, Jaehyuk Park",Concert hall,Mobility & Urban Science III,6,,508
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Gender disparities in the dissemination and acquisition of scientific knowledge,"Recent research has challenged the widespread belief that gender inequities in academia would disappear simply by increasing the number of women. More complex causes might be at play, embodied in the networked structure of scientific collaborations. Here, we aim to understand the structural inequality between women and men in the dissemination of scientific knowledge. We use a large-scale dataset of academic publications from the American Physical Society (APS) to build a time-varying network of collaborations from 1970 to 2020. We model knowledge dissemination as a simple contagion process in which scientists become informed based on the propagation of knowledge through their collaborators. We quantify the fairness of the system in terms of how women acquire and diffuse knowledge compared to men. Our results indicate that knowledge acquisition and diffusion are slower for women than expected. We find that the main determinant of women's disadvantage is the gap in the cumulative number of collaborators, highlighting how time creates structural disadvantages that contribute to marginalizing women in physics. Our work sheds light on how the dynamics of scientific collaborations shape gender disparities in knowledge dissemination and calls for a deeper understanding of how to intervene to improve fairness and diversity in the scientific community.","Chiara Zappalà, Luca Gallo, Jan Bachmann, Federico Battiston, Fariba Karimi",Concert hall,Science of Science I,1,,769
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Bridging the Gender Divide: Leadership and Gender Dynamics in Economics Research,"Despite increased female participation in economics since the 1980s, gender disparities persist in leadership, authorship, citations, and recognition. This study analyzes 11,742 publications from top economics journals and 41 major awards to assess women's representation and influence in the field. Our findings reveal that men dominate authorship, citation impact, and prestigious awards, with women receiving fewer citations and lower financial compensation. While female-only research teams appear more frequently than expected, they struggle for equal recognition. Addressing these disparities is essential for fostering a more inclusive and equitable academic environment in economics.","Diego Fregolent Mendes de Oliveira, Qian Huang",Concert hall,Science of Science I,2,,62
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Parenthood Penalties in Academia: Gender Role Beliefs and Institutional Supports,"Despite progress toward gender parity in doctoral education, women remain underrepresented in academia, comprising only 28% of researchers globally and even fewer in senior positions (AAUP, 2023; Spoon et al., 2023; UNESCO, 2015). Parenthood is a key factor contributing to gender disparities, yet the specific role of childcare responsibilities remains understudied (Derrick et al., 2021). Moreover, it is essential to consider the evolving beliefs about gender roles and the uncertain influence of institutional parental support. Recent studies indicate a shift toward more egalitarian gender role beliefs among both men and women (Bleske-Rechek & Gunseor, 2022). Women are increasingly rejecting gender norms, while men are becoming more involved in family and child-rearing responsibilities. Are academics’ gender role beliefs evolving, and could these changes lead to a different distribution of caregiving responsibilities across genders? Besides, while institutional support is intended to mitigate these challenges, its effectiveness is uncertain, with some policies potentially reinforcing disparities. This study examines the interplay between gender, childcare responsibilities, gender role beliefs, and institutional support to better understand their impact on scientists’ careers. Specifically, we seek to address the following research questions: (1) How do childcare responsibilities help explain the gender gap in academic achievements as a mediator? (2) Do academics’ egalitarian gender role beliefs moderate the associations between gender and childcare responsibilities? (3) Can institutional parenting support policies moderate the association between childcare responsibilities and academics’ career outcomes? Our research leverages a large-scale survey data and bibliographic records from Clarivate’s Web of Science. Researchers affiliated with US and Canadian institutions were surveyed via Qualtrics between June and July 2019. From an initial pool of 396,674 scholars, a random sample of 99,168 was invited to participate, with 9,105 completing the survey. After refining the dataset to include only respondents with at least one child, the final analytical sample comprised 5,670 scholars (44.56% men, 55.44% women). This study employs several statistical analysis techniques, including Structural Equation Modeling (SEM) and moderated linear regressions. This research sheds light on the persistent gender disparities in academia, particularly in the division of childcare responsibilities and the impact of gender role beliefs and institutional support policies. The main theoretical contribution is as follows: 1. It reveals a misalignment between evolving gender role beliefs and the actual distribution of childcare responsibilities in academia. While both men and women increasingly endorse egalitarian beliefs, women continue to bear a disproportionate caregiving burden. This imbalance persists due to societal and workplace norms that reinforce traditional gender roles, limiting men’s involvement in parenting. However, the research highlights that as women’s egalitarian beliefs strengthen, their childcare responsibilities decrease—an effect not observed in men. This finding aligns with theories of maternal gatekeeping, suggesting that women’s beliefs play a crucial role in reshaping caregiving dynamics. The study underscores the need for policy reforms and cultural shifts to promote a more equitable balance between professional and family responsibilities in academia. 2. This study confirms that childcare responsibilities significantly mediate gender disparities in academic career achievements, impacting both objective and subjective outcomes. Women academics bear more childcare responsibilities, with the effect being particularly pronounced among those with an employed partner or those with partners in non-research-related jobs. While prior research has examined parenthood's impact on gender disparities, childcare as a distinct factor has been understudied. This study unravels the heightened stress women face in balancing professional and caregiving responsibilities, emphasizing the need for institutional support and cultural change. By identifying particularly vulnerable groups, the findings offer critical insights for policies aimed at fostering greater gender equity in academia. 3. This study highlights the complex impact of institutional parental support policies on gender disparities in academia. While flexible work schedules and childcare support help mitigate the adverse effects of caregiving on women’s careers, policies such as paused tenure clocks and paternity leave may unintentionally reinforce gender inequalities. To contextualize these findings, it is essential to consider that the ""parenting penalty"" is closely tied to the level of engagement in caregiving activities and the ways in which institutions enforce parental support policies.","Xi Hong, Xiang Zheng, Chaoqun Ni",Concert hall,Science of Science I,3,,677
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Large-scale randomized trials show no evidence of gender bias in evaluating scientific abstracts,"The gender gap in science is primarily documented through observational studies. Because such studies struggle to account for confounding factors like research quality, the underlying causes of the gender gap in scholarly recognition, as measured through citations, remain unclear. As citation-based metrics are increasingly used to evaluate scientists, calibrate recommendation systems, and allocate funding, understanding whether these disparities stem from gender bias is essential. Here, we address this knowledge gap with a randomized experiment surveying 169,765 researchers. In this experiment, participants evaluated abstracts generated by a Large Language Model (LLM) tailored to their field, attributed to either a fictional male or female author. The reported likelihood of citing research measures the Matilda effect, a recognition bias against female scientists. This procedure addresses two key limitations of prior studies: It is large-scale and it controls for quality. Surprisingly, our results reveal no significant gender difference in citation likelihood or reported credibility of the abstracts. These findings challenge prevailing hypotheses, underscoring the complexity of factors influencing gender disparities in science and calling for more large-scale controlled experiments in science. Our insights hold important implications for identifying the correct drivers of gender disparities documented in the literature, for improving evaluation practices, and for refining policies to address gender disparities in scientific recognition.","Sandro Ferreira Sousa, Roberta Sinatra, James Evans, Luca Maria Aiello, Zhilong Chen",Concert hall,Science of Science I,4,,683
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Unveiling Bias in Academic Peer Review,"The peer review process is often regarded as the gatekeeper of scientific integrity, yet mounting evidence suggests it is not immune to bias. While structural inequities in peer review have been widely debated, far less attention has been paid to the subtle ways in which language itself may reinforce disparities. This study undertakes one of the most comprehensive linguistic analyses of peer review to date, examining over 80,000 reviews across two major journals. Using natural language processing and large-scale statistical modeling, it uncovers how review tone, sentiment, and supportive language vary across author demographics—including gender, race, and institutional affiliation. By leveraging a dataset that includes both anonymous and signed reviews, this research also reveals how reviewer identity disclosure shapes the language of evaluation. The findings not only expose hidden biases in peer feedback but also challenge conventional assumptions about anonymity’s role in fairness. As academic publishing grapples with reform, these insights raise critical questions about how review policies shape career trajectories and scientific progress.","Maria Sahakyan, Bedoor AlShebli",Concert hall,Science of Science I,5,,578
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Dominating the Narrative: How Male Non-African Scholars Define African Politics,"Within political science, previous research has shown that our understanding of “African politics” is disproportionately shaped by non-African scholars far removed from Africa. In a novel contribution, we use a comprehensive dataset and a citation network approach to demonstrate that African and Africa-based scholars are even more underrepresented in the most influential research. Drawing on articles published from 1956 onward in the top 20 political science journals with “Africa” or an African country in their title, we computed the PageRank centrality of more than 16,000 nodes in the network to identify the most influential papers. We then disaggregated our analysis by author nationality, location, and gender, uncovering stark underrepresentation of African, Africa-based, and female scholars. Furthermore, we employ regression modeling to show robust negative associations between the share of African and women authors and an article’s PageRank centrality. These findings offer stronger quantitative evidence of the marginalization of African researchers in shaping the dominant academic scholarship on African politics.","Zack Zimbalist, Elisa Omodei",Concert hall,Science of Science I,6,,264
,,,,,,,,,,
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Interdisciplinary PhDs face barriers to top university placement within their discipline,"Interdisciplinary research has gained prominence in addressing complex challenges, yet its impact on early academic careers remains unclear. This study examines how interdisciplinarity during doctoral training influences faculty placement at top universities across diverse fields. Analyzing the career trajectories of 32,977 faculty members from 355 U.S. universities, we find that PhD graduates with higher interdisciplinarity are less likely to secure faculty positions at top-ranked institutions, particularly when remaining in their doctoral discipline. Instead, top universities tend to favor candidates with lower PhD interdisciplinarity, aligning with established research priorities. This preference disproportionately affects women, who exhibit higher interdisciplinarity on average. Furthermore, we show that faculty with greater interdisciplinarity achieve higher long-term research productivity, suggesting a potential loss in innovation when top institutions undervalue interdisciplinary scholars. These findings highlight structural barriers in faculty hiring and raise concerns about the long-term consequences of prioritizing disciplinary specialization over interdisciplinary expertise.","Xiang Zheng, Anli Peng, Xi Hong, Chaoqun Ni",Concert hall,Science of Science II,1,,656
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Linking Funding Landscapes: A Comparative Study of Global Science Funding,"Understanding global science funding requires accurate and comprehensive data, yet existing bibliometric databases provide fragmented and incomplete coverage, particularly for funders outside high-income countries. This study addresses these limitations by developing a heuristic-driven pipeline that integrates and disambiguates funding data across multiple sources, including Web of Science and OpenAlex. Our approach leverages text normalization, lexical similarity clustering, and acronym-based matching to improve funder attribution. We evaluate the effectiveness of this method using LLM-based assessments and direct dataset comparisons. Preliminary findings highlight significant disparities in funder representation, with existing databases underrepresenting funders from the Global South and smaller agencies. By enhancing the accuracy and scope of funding data, this work enables more equitable and data-driven science, technology, and innovation (STI) policies, fostering a more transparent global research funding ecosystem.","Jacob Aarup Dalsgaard, Jin Ai, Filipi Nascimento Silva",Concert hall,Science of Science II,2,,559
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Philanthropic Funding in Scientific Innovation,"The fluctuating funding landscape highlights the vulnerability of scientific research to political and economic shifts when reliant on government and corporate funding. Philanthropy has emerged as an essential alternative, funding high-risk and fundamental research with long-term impact. However, its role remains understudied primarily due to data limitations. This study bridges this gap by mapping philanthropic funding across scientific fields, analyzing its alignment with government and corporate funding, and identifying its distinctive characteristics. Using multi-source data integration and heuristic-driven funder disambiguation, we reveal that nearly 30% of funded publications receive philanthropic support from highly diverse sources, often supplementing government and corporate investments. Our preliminary findings highlight the unique and growing role of philanthropy in sustaining scientific progress. By providing evidence-based insights, this study informs funders, policymakers, and researchers on strategies to build a more resilient and diversified funding ecosystem that drives innovation.","Jin Ai, Filipi Nascimento Silva, Jacob Aarup Dalsgaard, Charlotte Ren",Concert hall,Science of Science II,3,,473
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Narrative License and the presence of inappropriate causal claims in Social Science articles,"The full abstract is attached as a PDF, here's a shortened version. Effective science communication relies on accurately conveying research findings, yet many social science articles use Narrative License (NL)—claims that overstate, misrepresent, or distort results. This study examines the prevalence of inappropriate causal language in cross-sectional studies, which inherently cannot establish causality due to their lack of temporal order, randomization, or experimental controls. Using a dataset of 8,258 cross-sectional articles from PsycINFO, we applied a Large Language Model (LLM)-assisted classification to assess the prevalences of causal claims. Manual verification confirmed high accuracy, and results revealed that 59% of abstracts contained some form of causal language, with direct and implied causal statements increasing over time. Articles using causal language were slightly more likely to appear in lower-impact journals and had fewer citations, but these differences were very small, reflecting statistical more than substantive differences. Similar findings emerge for different disciplines, where some fields had slightly higher and lower prevalence rates, all fields had a similarly high amount of inappropriate claims. These findings suggest that while methodological reforms have improved research rigor, rhetorical overstatement remains prevalent. We propose that LLMs can assist in detecting and mitigating NL, supporting both authors in refining claims and readers in critically assessing research. This study highlights the need for greater attention to linguistic precision in scientific writing.","Calvin Isch, Timothy Dörr, Neil Fasching",Concert hall,Science of Science II,4,,61
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Can Large Language Models Provide Useful Feedback on Research Preprints? A Large-Scale Randomized Field Experiment,"The transformative impact of Large Language Models (LLMs) across various sectors has demonstrated their potential to enhance productivity and facilitate complex decision-making processes, significantly altering innovation workflows. Despite their widespread adoption in commercial and consumer domains, the integration of LLMs into the unique processes of scientific discovery and innovation has been minimally explored. In the process of scientific discovery, feedback and revision are critical components of knowledge production, essential for refining and validating new scientific insights. Nonetheless, the effectiveness of existing feedback channels is currently under significant strain. On one hand, there is a critical shortage of high-quality feedback, which poses a substantial barrier to the sustained development of the scientific field. For instance, the traditional peer review system, a primary avenue for such feedback, is burdened by rapidly increasing submission volumes, escalating costs in terms of labor and resources, and the complexity of increasingly specialized tasks. On the other hand, the global academic research ecosystem is riddled with deep-seated inequities. Feedback channels within elite institutions in Western countries often exclude diverse geographical perspectives, perpetuating existing barriers and reinforcing systemic inequities within the scientific community. Against this backdrop, the question arises: Can LLMs help overcome these challenges by providing scalable and efficient feedback? Preliminary studies have suggested that LLMs can produce coherent and contextually relevant feedback that could supplement human reviews. In one of our foundational studies, we systematically compared feedback generated by LLMs with that provided by reviewers from top-tier journals and conferences. The results revealed a high degree of alignment between the two sources of feedback, and our follow-up use study revealed 82.4% of participants in the user study preferring the LLM-generated feedback over that from some human reviewers . Despite these promising results, there remains a significant gap in causal evidence regarding the real impact of LLMs in the context of scientific feedback, particularly concerning their utility, accuracy, and acceptance within the academic community. To address these gaps, we conducted a large-scale randomized field experiment to systematically evaluate the effectiveness of LLM-generated feedback on scientific papers. This experiment involves 34,340 recent arXiv preprints in 2024 by 50,454 scholars across 8 STEM domains and 136 regions globally (Figure 1). From these preprints, we extracted metadata including author, email, institution, and field of study. We then implemented a stratified random selection across 150 subfields to create a representative and balanced sample for our interventions. To enhance the precision of the feedback provided, we refined the prompts of our LLM by incorporating multi-agent systems that perform review analysis, title suggestions, and grammar checks. These were combined with in-context learning techniques to uniquely tailor the feedback for each individual preprint. Each participant in the treatment group accessed their feedback through a private link sent in targeted emails, personalizing the interaction and enabling detailed tracking of their engagement with the feedback, subsequent revision activities, and overall responses. Considering the logistical challenges in generating and distributing feedback on a large scale, with delays ranging from 1-5 months from initial arXiv submission, we excluded papers that were published or revised prior to our feedback dispatch. To quantify the effects of treatment on their likelihood of revision within one month, we employed logistic regression analysis. As illustrated in Figure 2, there was a notable increase of 11.7% in the likelihood of revisions among the treatment group within one month. Also, there was a marked difference in revision likelihood between non-English and English-speaking teams. Non-English speaking teams who received feedback were 19.4% more likely to revise their papers within a month, a statistically significant difference. In contrast, there was no significant effect observed among English-speaking teams. Our qualitative analysis on text corroborated these quantitative results, revealing that scholars from non-English speaking country or lower-prestige institutions perceived the feedback as more constructive and valuable compared to their counterparts from English-speaking countries or higher-prestige institutions. This disparity suggests that the benefits of using LLMs for scientific feedback are particularly significant for scholars from marginalized groups and those in resource-scarce environments, thus making scientific discourse more accessible to a wider and more diverse audience.","Binglu Wang, Weixin Liang, Jiahui Xue, Yuhui Zhang, Hancheng Cao, Dashun Wang, Yian Yin",Concert hall,Science of Science II,5,,1004
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Identifying Non-Replicable Social Science Studies with Language Models,"In this study, we investigate whether LLMs can be used to indicate if a study in the behavioural social sciences is replicable. Using a dataset of 14 previously replicated studies (9 successful, 5 unsuccessful), we evaluate the ability of both open-source (Llama 3 8B, Qwen 2 7B, Mistral 7B) and proprietary (GPT-4o) instruction-tuned LLMs to discriminate between replicable and non-replicable findings. We use LLMs to generate synthetic samples of responses to behavioural studies and estimate whether the measured effects support the original findings. When compared with human replication results for these studies, we achieve F1 values of up to $77\%$ with Mistral 7B, $67\%$ with GPT-4o and Llama 3 8B, and $55\%$ with Qwen 2 7B, suggesting their potential for this task. We also analyse how effect size calculations are affected by sampling temperature and find that low variance (due to temperature) leads to biased effect estimates.","Denitsa Saynova, Kajsa Hansson, Bastiaan Bruinsma, Annika Fredén, Moa Johansson",Concert hall,Science of Science II,6,,951
,,,,,,,,,,
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Structural Diversity and Network Versatility are Higher in Informal Structures of Collaboration,"Co-authorships offer one of the main collaboration mechanisms to integrate knowledge and expertise. Past research shows that co-authorship networks influence professional trajectories and facilitate breakthrough discoveries. At the same time, researchers often rely on other, more informal types of collaboration and exchange. These informal ties give shape to structures of support that are often referred to as the `invisible college'. In these networks, communication is not based on publications (via co-authorship or citations) but rather on more intangible exchanges that nonetheless also feed relevant information (e.g., guidance, feedback) into the exercise of scientific research. Here we aim to grant some visibility to this intangible structure by retrieving the `thank you' notes from the acknowledgment sections of published papers. To assess on whether the structural diversity leads to higher diversity in terms of topic domains, we combine these topological measures with structural topic modeling and analyze a corpus of 129,750 papers published in Political Science journals from 2003 to 2024 authored by 85,653 different authors. Our analyses reveal two things: (1) scientists have higher levels of structural diversity (topologically defined) in their acknowledgment networks, compared to the co-authorship counterpart; and (2) structural diversity is positively associated with topic diversity in both networks, but especially so in informal collaborations. Acknowledgment ties, in other words, create more versatile networks. These findings suggest that embeddedness in informal structures of communication is, potentially, an important source of variation in career trajectories and indicators of success that should, therefore, receive more empirical attention.","Lluis Danus, Guy Grossman, catba, wdinneen, Sandra Gonzalez-Bailon",Vingen 3+4,Science of Science III,1,,380
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,The Publication Preferences of Academics,"This paper presents Publish or Comparish, a novel survey-based approach to measuring academics' publication preferences through pairwise comparisons. Survey participants made 56,884 venue selections and completed 157,606 pairwise comparisons. Analyzing these rich data, we uncover field-specific patterns of coherence (shared venue preferences) and exclusiveness (researchers belonging primarily to one field), the role of institutional prestige in preferences and publication outcomes, and discrepancies between empirical preferences and Journal Impact Factor-based rankings. Our findings highlight the collective construction of prestige in academic publishing and the limitations of traditional metrics. This work contributes to a broader understanding of how scientific knowledge is organized and valued and how publication preferences interact with other hierarchies within the scientific ecosystem.","Ian van Buskirk, Ekaterina Landgren, Marilena Hohmann, Johan Ugander, Daniel Larremore, Aaron Clauset",Vingen 3+4,Science of Science III,2,,146
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,"Geography of Knowledge: Scientific Focus, Disease Burden, and Research Alignment","Impact. This work bridges bibliometric and health data to reveal a persistent misalignment between global research priorities and actual disease burden. By integrating clinical publication data with standardized health metrics, we demonstrate that diseases prevalent in high-income settings receive disproportionate attention, whereas conditions affecting low-income regions remain markedly under-studied. We observed doubling in research responsiveness over three decades which highlights a shifting yet still imbalanced agenda, with clear implications for reorienting funding, policy, and local research capacity toward a more needs-driven global health strategy. Theoretical contribution. Our study refines theories in global health equity \cite{ostlin2005priorities} and the science of science by integrating bibliometric mapping with public health metrics. Building on prior work on research misalignment, we introduce a novel measurement framework that distinguishes between research production and contextual evidence sourcing. By linking clinical publications to health measures through text embeddings and standardized disease codes, our approach quantifies “research responsiveness” and reveals how socioeconomic factors and market-driven incentives bias both public and private research agendas toward diseases prevalent in high-income settings. Data and Methods. This study analyzes 308,135 clinical medicine research articles sourced from OpenAlex. For each paper, we use large language models to extract structured information from titles and abstracts—including evidence source countries, relevant diseases, and key medical concepts—which are then mapped to Medical Subject Headings (MeSH) using neural text embeddings. These MeSH codes are subsequently linked to the International Classification of Diseases (ICD) through the Unified Medical Language System (UMLS) and further connected to corresponding disease burdens as quantified by Disability-Adjusted Life Years (DALYs) in the Global Disease Burden dataset. The resulting dataset covers 20 general disease burdens, capturing both research volumes and associated DALYs for various countries from 1990 to 2021. We begin with descriptive analyses to examine the distribution and evenness of disease research across countries at different development levels over time. To further explore the alignment between research output and health needs, we employ fixed-effects regressions structured around three research questions: (1) Which disease burdens receive disproportionate research attention relative to its health impact; (2) How responsive is a country's research output to its pressing disease burden; and (3) How has this responsiveness evolved over time. Findings. Global disease research exhibits a prominent segregation between research production and evidence sourcing. Lower-income countries contribute less than 1\% of authorship across all disease categories, yet they account for a disproportionate share of study context, especially for neglected tropical diseases, malaria, and HIV/AIDS, which illustrates a significant gap in local research participation. Promisingly, our analyses show increasing diversity in country engagement in both research production and evidence sourcing over time, indicating a broader, more inclusive global participation. Connecting disease research with disease burden statistics, our fixed-effects regressions reveal several key insights. First, after controlling for country- and disease-specific factors, research attention is disproportionately concentrated on neoplasms, cardiovascular diseases, and certain infectious diseases, while conditions such as respiratory infections, tuberculosis, skin and subcutaneous diseases, and nutritional deficiencies receive relatively less attention compared to their health impact. Second, countries with higher GDP per capita tend to align their research output more closely with their pressing health challenges, although considerable heterogeneity exists even among the wealthiest nations. Finally, over the past 30 years, the responsiveness of research output to disease burden has doubled, suggesting that research efforts are progressively more attuned to critical public health needs.","Prashant Garg, Hongyu Zhou, Thiemo Fetzer",Vingen 3+4,Science of Science III,3,,820
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Forming the idea evolution tree for tracing research trends in computer networks,"To track the development of research ideas, traditional methods relying on expert reviews and citation networks face limitations as many key ideas are not captured by citations. This study introduces a concept evolution tree model with BERTopic to identify key topics, then a keyword co-occurrence network for k-shell to extracts core ideas every 5 years. Applying this model to computer networks, the study links several topics to TCP/IP layers standard in this field. Take the topic Wireless Networking Optimization as an example, we further cluster the keywords on this tree for the second time and find out the research focus transfer transformation, from Network Performance Challenges to Wireless Networking Standards, then Network Optimization Frameworks. Meanwhile, a comparison with the citation-based method shows the citation alone do not fully capture idea evolution. This model offers a comprehensive and dynamic approach to analyzing large-scale academic datasets, providing a more continuous and refined view of idea evolution compared to citation-based methods.","Ziqing Yan, Ruiyao Liu, Jar-Der Luo, Xiaoming Fu",Vingen 3+4,Science of Science III,4,,285
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Belief Perseverance in Science: Who keeps citing retracted papers?,"Retractions are intended to correct the scientific record, but retracted papers continue to be cited years after retraction. We call this phenomenon of presence and use of flawed findings in the scientific literature belief perseverance in science. Using a dataset of 11,986 retracted papers and 153,511 citations, we analyze how intellectual distance between scientific disciplines influences the continued citation of retracted findings. Our findings suggest that citations to retracted papers decline over time but persist disproportionately in thematically distant fields, while closely related fields respond more immediately to retractions. These results highlight the challenges of scientific self-correction.","Maximilian Noichl, Samuli Reijula",Vingen 3+4,Science of Science III,5,,797
,,,,,,,,,,
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,STEM-Oriented Latent Communities Embedded in High-school Math/Science Course-Taking: Does it Matter for College STEM Pursuit?,"Adolescent peers of shared schooling activities are known to influence students’ current and future educational outcomes from past research on observed within-school course-taking patterns. Less is known, however, how school-boundary-transient STEM-oriented latent communities may be embedded in course-taking given the national math/science curriculum for secondary education. Individual choices of course-taking, STEM interest nurtured by the family and school, and tracking structures of school organizations jointly give rise to a national landscape of math/science course-taking that embeds STEM-oriented latent communities of unobserved STEM readiness and interest. These communities may exert a long-lasting effect beyond high school into postsecondary education and the labor market. In this study, using a nationally representative sample of high school students, we detected STEM-oriented latent communities from the network of students who took math and science courses of a nationally representative sample of high school students and examined the influence of such latent communities on college STEM pursuit. The implications of our novel view of early STEM-oriented latent communities go beyond high school to postsecondary education and future labor market outcomes.","Wenrui Huang, Lingxin Hao",Vingen 8,Education,1,,414
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,When and for how long? On the relevance of time in higher education investments,"This paper focuses on implications of time in higher education investments in Sweden. Prior research shed light on social and educational differences across institutions and fields of study, but less attention has been paid on how temporal dimensions –timing, sequencing and duration– produce differences in trajectories engaging at any point in the system. The aim is to understand the simultaneous unfolding of educationally- and occupationally-related trajectories by the identification of temporal patterns in which higher education is embedded in life courses. Using administrative data from Statistics Sweden, individual sequences in four domains were constructed for those leaving compulsory school in 2000 and enrolling tertiary education up to 2019: educational status, educational level, occupational status and income group. Multidomain sequence analysis was applied for quantifying pairwise distances and, after clustering, produce a typology of temporalities representing varied modalities of investment and accumulation at post-secondary level, and conversion of these assets into occupational and rewards structures. Findings show that trajectories mostly differ in timing of arrival and duration of permanence in higher education, but also in how this is paralleled –or not– with commitments in other spheres that might impact on such temporal dimensions. Furthermore, results suggest that degree completion leads to occupational and income upgrading according to the length of investment. In sum, earliness and lengthening in higher education seem to further the advantage into subsequent social arenas by reaching high-status and income occupations; contrary to belatedness and shortening that undermine the value of the investment and, in turn, restricts its conversion into less profitable positions.",Ricardo Cevallos,Vingen 8,Education,2,,381
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,When Teachers Speak with More Than Words: How Multimodal Cues Reveal Children’s L2 Narrative Comprehension,"Compared to traditional child oral language assessments that rely primarily on children's speech data, this study conducts a multimodal analysis to investigate how three predictive features contribute to assessing narrative comprehension in a second language (L2): (1) children's speech intelligibility, (2) teachers' acoustic features, and (3) teachers' head movements and key facial points. This study provides new insights into the effects of multimodal signals, particularly teacher-related cues, on L2 comprehension assessment. By integrating these features into an assessment framework, we aim to reduce reliance on children's speech data while leveraging interaction-based multimodal information for more comprehensive language evaluation.","Hiu Ching Hung, Thorsten Piske, Chang Liu, Paula Andrea Perez-Toro, Tomás Arias Vergara, Andreas Maier",Vingen 8,Education,3,,996
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,The Impact of Large Language Models in Academia: from Writing to Speaking,"Large language models (LLMs) are increasingly impacting human society, particularly in textual information. Based on more than 30,000 papers and 1,000 presentations from machine learning conferences, we examined and compared the words used in writing and speaking, representing the first large-scale study of how LLMs influence the two main modes of verbal communication and expression within the same group of people. Our empirical results show that LLM-style words such as ""significant"" have been used more frequently in abstracts and oral presentations. The implicit impact on human expression like writing and speaking is beginning to emerge and is likely to grow in the future. We take the first step in building an automated monitoring platform to record its longitudinal changes to call attention to the implicit influence and ripple effect of LLMs on human society.","Mingmeng Geng, Caixi Chen, Yanru Wu, Yao Wan, Pan Zhou, Dongping Chen",Vingen 8,Education,4,,1032
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Teacher-directed scientific change: The case of the English Scientific Revolution,"While economic factors in directed technical and scientific change have been widely studied, the role of teacher-directed scientific change has received less attention. This paper studies teacher-directed scientific change for one of the largest changes in the direction of research, the Scientific Revolution. Specifically, the paper considers the case of the English Scientific Revolution at the universities of Oxford and Cambridge. It argues that exposure to different teachers shaped students' direction of research and can partly account for the successful trajectory of English science. For this, the paper introduces a novel dataset on the universe of all 111,242 students at English universities in the seventeenth and early eighteenth century and matches them to their publications. Using machine learning, the paper is able to quantify personal interest in different research topics. To derive causal estimates of teacher-student effects, the paper uses an instrumental variable design that predicts students’ choice of college based on their home regions, a stacked differences-in-differences approach exploiting teachers leaving their college, and a natural experiment based on the expulsion of teachers following the English Civil War. The paper finds empirical evidence of teacher-directed change in the English Scientific Revolution. These results illustrate how teacher-directed change can contribute to paradigm change. (Extended abstract attached as pdf)",Julius Koschnick,Vingen 8,Education,5,,350
,,,,,,,,,,
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Global Editing Patterns on Wikipedia Platform Reveal Segmentations in Knowledge Production,"This study examines Wikipedia editing behaviors across over 100 language editions, analyzing cross-lingual coordination and editorial dynamics. By categorizing articles into four genres—Conspiracy Theory, Controversy, Cooking, and Science—the research identifies statistical patterns in editor contributions, revert rates, and semantic similarity. Using economic complexity analysis, the study reveals distinct language groupings, showing that Wikipedia editions align with cultural, geopolitical, and economic factors. Science articles exhibit universal consistency, while Conspiracy Theory articles display regional complexity. Findings suggest that collaborative norms and linguistic diversity shape knowledge production on Wikipedia, highlighting the influence of language and geography on online information ecosystems.","Akira Matsui, FUJIO TORIUMI, Mitsuo Yoshida, Taichi Murayama, Shiori Hironaka",Vingen 8,Wikipedia,1,,120
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Unpacking Local and Global Collective Memory,"The study of collective memory—information about the past that is shared by a group—is essential to understand how societies preserve, transmit, and interpret historical knowledge. Yet, recent quantitative work on collective memory often relies on indicators of online attention that do not distinguish between local and global forms of popularity. Here, we introduce a method to separate local and global collective memory starting from the online attention received by 50,000+ biographies across 300+ different language editions of Wikipedia and validate it using data from an online trivia game where 40,000+ players from around the world answered questions about local and foreign historical figures. We show that players were more likely to answer correctly questions about figures that were local to them and with higher scores in our globality measure. Finally, we explore how major life events, such as receiving a major award (Oscar or Nobel Prize) and death shape the dynamics of local and global attention. We find the impact of these events to be different. Awards and death are followed by large but short-lived spikes in local attention and milder but longer-lived increases in global attention. These findings advance our understanding of collective memory by unpacking local and global forms of remembrance.","Mariana Macedo, Melanie Oyarzun, Cristian E Candia, Cesar A Hidalgo",Vingen 8,Wikipedia,2,,817
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Wikipedia Edits Before Elections: Analysing Strategic Changes in Political Representation,"Wikipedia is one of the most frequently accessed websites and a widely used source of structured, user-generated political information. Its perceived neutrality and accuracy make it an influential resource for voters, researchers, and machine learning applications (Neuberger, 2014; Messner & South, 2011). Platforms like Google use Wikipedia content for knowledge boxes and verification tags, while political scientists and AI developers rely on it for datasets (Göbel & Munzert, 2018; Salem & Stephany, 2023). Given this central role, Wikipedia’s coverage of political figures can have real effects, influencing public perception and even electoral outcomes, particularly for lesser-known candidates (Haman et al., 2021). However, Wikipedia’s open editing model raises concerns about strategic modifications to political articles, especially before elections. Prior studies have documented cases of political staffers editing pages to present candidates favorably (Agarwal et al., 2020), yet the timing, scale, and nature of these edits—especially across different language editions—remain underexplored. This study examines Wikipedia edits to U.S. politicians’ pages in the English and Spanish editions to assess whether strategic changes occur in the lead-up to elections. To do so, it compiles a large-scale dataset of Wikipedia revisions, election timelines, and congressional demographics. The dataset includes: 94,918 revisions to U.S. legislators' Wikipedia pages (English and Spanish) since 2002, with timestamps, editor metadata, and edit summaries. 21,445 full article snapshots from two weeks before major U.S. elections across 10 election cycles. 2,672,537 daily traffic observations from English and Spanish Wikipedia. Supplementary data on congressional districts (U.S. Census) and election results (MIT Election Data and Science Lab, 2017). The analysis proceeds in three steps: (1) classifying edits and editors, (2) examining temporal patterns, and (3) assessing political correlates. First, edits are categorized using a pre-existing classifier (Yang, Halfaker, Kraut, & Hovy, 2018) that distinguishes between 14 types of changes (e.g., counter-vandalism, point-of-view edits). To assess and improve its accuracy, newer-generation models (transformers, large language models) will be trained using this classifier’s dataset alongside newly annotated examples, particularly to enhance performance beyond the English-language context. Editors are identified through heuristic classification (edit speed, metadata patterns, bot flags/names), ORES bot scores, and network analysis to detect coordinated or polarized editing. Anonymous users’ IP addresses are analyzed for geographic patterns, given that 20% of edits are often made anonymously, some of which have been linked to political actors (Agarwal et al., 2020). Next, time series models explore whether editing spikes before elections and whether content changes align with shifts in public interest, inferred from daily page traffic data. This analysis helps determine whether Wikipedia is actively shaped by political events, scandals, or campaign strategies. Finally, the study investigates whether factors like race competitiveness and constituency demographics influence editing patterns. By integrating election results and census data, it assesses whether strategic editing varies by political context (e.g., volume of edits, types of editors). The findings will provide insight into Wikipedia’s role in shaping political narratives and election-related information. Given its impact on AI training data, search results, and misinformation detection, understanding strategic editing is critical for maintaining the integrity of political information online. This study contributes to broader discussions on digital governance, platform accountability, and the political manipulation of knowledge platforms.",Felicia Loecherbach,Vingen 8,Wikipedia,3,,736
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Measuring Cross-Lingual Information Gaps in English Wikipedia: A Case Study of LGBT People Portrayals,"To explain social phenomena and identify systematic biases, much research in computational social science focuses on comparative text analyses. These studies often rely on coarse corpus-level statistics or local word-level analyses, mainly in English. We introduce the InfoGap method -- an efficient and reliable approach to locating information gaps and inconsistencies in articles at the fact level, across languages. We evaluate InfoGap by analyzing LGBT people's portrayals, across 2.7K biography pages on English, Russian, and French Wikipedias. We find considerable discrepancies in factual coverage across the languages. Crucially, InfoGap both facilitates large scale analyses, and pinpoints local document- and fact-level information gaps, laying a new foundation for targeted and nuanced comparative language analysis at scale.","Farhan Samir, Chan Young Park, Anjalie Field, Zining Wang, Vered Shwartz, Yulia Tsvetkov",Vingen 8,Wikipedia,4,,882
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,The Dissemination and Treatment of Retracted Papers on Wikipedia,"Retractions of scientific papers serve to correct the academic record. Yet, retracted papers continue to be cited in widely accessed platforms like Wikipedia, potentially disseminating misinformation. This study investigates the prevalence, persistence, and treatment of retracted paper citations on Wikipedia, leveraging a novel dataset that integrates Retraction Watch, Crossref Event Data, Altmetric LLC, OpenAlex, and Wikipedia’s revision histories. Among 1,189 citations of retracted research on Wikipedia, 71.8\% are problematic in the sense that retracted papers are either cited uncritically before their retraction or without proper in-text warnings after retraction. We also examine citation patterns across academic domains, finding that retracted papers in health sciences are disproportionately susceptible to problematic citations. Furthermore, we analyze factors influencing citation correction, focusing on the roles of retraction reasons, open access, online mentions, and Wikipedia-specific editorial activity. This work provides critical insights into the systemic challenges of addressing retracted paper citations on Wikipedia and offers actionable recommendations to enhance the credibility and accuracy of widely accessed information.","Haohan Shi, Yulin Yu, Daniel Romero, Emoke-Agnes Horvat",Vingen 8,Wikipedia,5,,762
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Coordination mechanism in collective intelligence: costs for I's to become We,"We investigate coordination mechanisms in self-organized systems by analyzing a large-scale dataset from Wikipedia’s Vital Articles. Our study aims to understand how coordination costs evolve as projects grow, focusing on the interplay between interactive (personal) and formal (impersonal) coordination. This research is motivated by longstanding theories, including Weber’s observations on the emergence of bureaucratic organization in maturing systems. Using a scaling framework, we quantify coordination costs with power-law relationships between the number of unique contributors and various measures of coordination effort, such as talk-page discussion length, revert frequency, administrator edits, and bot interventions. Our analysis of over 26,000 projects reveals that interactive activities scale superlinearly with contributor count, while formal actions show sublinear scaling, reflecting an economy of scale in administrative and rule-enforcing functions. Employing principal component analysis, we identify two key dimensions—termed the “controversy” and “compensation” axes—that capture distinct aspects of coordination. The controversy axis aggregates measures of personal interactions, such as discussions and conflicts, whereas the compensation axis highlights the role of formal, impersonal coordination mechanisms. These findings indicate that as projects mature, there is a natural emergence of impersonal coordination, a transition that echoes Weber’s theoretical perspective on the evolution from personalized collaboration to bureaucratic organization. Overall, our study provides a comprehensive framework for understanding the dynamics of coordination in collective intelligence systems. By elucidating the scaling laws and dual-dimensional structure of coordination costs, we offer new insights into how self-organized communities can balance the increasing demands of collaboration with the efficiencies of formalized control, thereby advancing our understanding of both digital and traditional organizational systems.","Jisung Yoon, Vicky Chuqiao Yang, Chris Kempes, Seoul Lee, gbw, Hyejin Youn",Vingen 8,Wikipedia,6,,728
,,,,,,,,,,
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Impact frequency shuffling on synchronization in a ring network,"Synchronization is a universal phenomenon observed in various real-world systems including power grids, neural networks, and coupled oscillators [1,2,3]. It has been considered as one of important research topics in nonlinear dynamics because the synchronous state ensures stable and efficient operation of a system. Previous research has shown that applying frequency shuffling, in which oscillators exchange their natural frequencies over time, can facilitate synchronization and reduce the time required to achieve it [4]. This study has focused on all-to-all coupled networks. However, since many real-world systems operate under more constrained connectivity such as sparse or irregular interaction, it still leaves the question of how frequency shuffling affects structured oscillator networks with local interactions. In this work, we investigate the influence of frequency shuffling on the synchronization dynamics in a 1D ring structure (Fig. 1). Specifically, we consider a 1D ring network of coupled phase oscillators governed by the first-order Kuramoto model [5] \begin{equation} \frac{d\theta_i}{dt} = \omega_i + \frac{K}{2} \left[ \sin(\theta_{i+1} - \theta_i) + \sin(\theta_{i-1} - \theta_i) \right], \end{equation} where $\theta_i$ represents the phase of the $i$th oscillator, $\omega_i$ is the natural frequency of $i$ and $K$ is the coupling strength. The system follows periodic boundary conditions, ensuring $\theta_{N+1} = \theta_1$ and $\theta_0 = \theta_N$. In this framework, frequency shuffling modifies the temporal evolution of $\omega_i$, effectively altering the interaction dynamics over time. Unlike all-to-all coupled networks, where shuffling consistently improved synchronization, our results demonstrate a nonmonotonic behavior in the order parameter as the shuffling rate increases (Fig. 2). In particular, increasing the shuffling rate $\lambda$ leads to an initial increase in the order parameter, attributed to a reduction in the overall frequency variance (Fig. 3A). However, beyond an optimal value of $\lambda$, the order parameter decreases and the oscillators become phase-locked in twisted states, similar to those observed in identical oscillators on lattice structure [6, 7]. To investigate whether this decrease in the order parameter is due to the stabilization of twisted states, we conduct simulations in which the system is initialized as a twisted state with the winding number $q=1$ and observe the probability that the system remains in that state as $\lambda$ increases. Our results confirm that at low $\lambda$, the system transitions away from the initial twisted state, whereas at higher $\lambda$ the system remains locked in the initial configuration, thereby reducing the overall synchronization level (Fig. 3B). Furthermore, in the large-$\lambda$ limit, the system effectively converges to the case where all oscillators share an identical frequency ($\omega=0$), as demonstrated by the similarity between the shuffled system and the identical-frequency system (Fig. 3C). Our findings reveal that, while moderate frequency shuffling enhances global synchronization, excessive shuffling stabilizes incoherent states suppressing global order when oscillators are coupled through regular structure.","Juseong Kim, Cook Hyun Kim, Jong-Min Park, Heetae Kim",Troselli,Network Science,1,,678
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Explosive cooperation in social dilemmas on higher-order networks,"Understanding how cooperative behaviors can emerge from competitive interactions is an open problem in biology and social sciences. While interactions are usually modeled as pairwise networks, the units of many real-world systems can also interact in groups of three or more. Here, we introduce a general framework to extend pairwise games to higher-order networks. By studying social dilemmas on hypergraphs with a tunable structure, we find an explosive transition to cooperation triggered by a critical number of higher-order games. The associated bistable regime implies that an initial critical mass of cooperators is also required for the emergence of prosocial behavior. Our results show that higher-order interactions provide a novel explanation for the survival of cooperation.","Andrea Civilini, Onkar Sadekar, Federico Battiston, Jesus Gomez-Gardeñes, Vito Latora",Troselli,Network Science,2,,990
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Holey diamonds: Embeddedness of structural holes in signed networks,"The concept of brokerage and structural holes has inspired extensive research on social networks; however, most analyses focus on positive ties and neglect the roles of actors bridged by a broker. We address these gaps by integrating the literature on signed networks and structural balance theory with brokerage theory, focusing on network ties around a dyad featuring a structural hole. We propose that the presence of a common neighbours between the bridged nodes, along with the valence of those ties, may explain the absence of a direct tie. To test this, we conduct descriptive, bivariate, and multivariate analyses using MRQAP models on secondary data from 24 cross-sectional signed networks of varying sizes and contexts. Our meta-analyses provide empirical support for our hypothesis: a dyad surrounded by three positive ties and one negative tie—a configuration we term the 3PN diamond—is associated with a higher likelihood of constituting a structural hole. We discuss the implications of our findings for theory and research, highlighting the potential of our framework to advance the study of brokerage in networks.(For the extended abstract, please see the uploaded pdf document)","Paul Schuler, Srebrenka Letina, Károly Takács",Troselli,Network Science,3,,622
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Advancing social sensing to enable network interventions in the field,"Many policy relevant behaviors, ranging from the adoption of new technologies to changes in social norms, the growth of social movements and the emergence of political protests, can be described as a diffusion process on the relevant social network emerging from individual relationships and interactions. A core theme in diffusion research is the design of interventions that facilitate the large-scale adoption of a target behavioral change. In the diffusion literature, there is general agreement that the structure of social networks significantly affects the adoption of a new product or behaviour, and effective seeds can be identified through their position in the relevant social network. Various studies have proposed seeding central nodes identified through various centrality measures and have shown the structural properties of the underlying social network can alter dramatically the relative effectiveness of different seeding interventions. However, despite the theoretical richness and relevance of the obtained insights, their precise real-world application remains limited. Conducting network interventions in the field requires detailed social network data, whose collection is either resource and time-intensive and, for this reason, it typically cannot be carried out at large scale, or, in some contexts, is accessible to only a handful of organizations. In this study, we develop new techniques to estimate individual and network-level variables relevant for seeding interventions from a small yet strategically selected sample that acts as social sensors, circumventing the need to map in detail the entire social network in a population. We estimate in the field the accuracy of the developed methods and identify the characteristics of people who are accurate in their estimations. Furthermore, we assess the robustness of network interventions based on the proposed techniques to the accuracy of the estimations. This enables both the application of social network interventions to previously inaccessible contexts — i.e., contexts where social network data is inaccessible or severely limited — as well as the development and implementation of new interventions.","Luca Lazzaro, Mingmin Feng, Norina Anna Furrer, Manon Delvaux, Federico Cammelli, Manuel S. Mariani, Rene Algesheimer, Radu Tanase",Troselli,Network Science,4,,359
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Analysis of Engineer-Skill Bipartite Network from Employment History Data of Japanese Engineers,"This study models engineer-skill relationships using bipartite networks derived from Japanese employment history data. Our analysis reveals a statistically significant nested structure, where generalists acquire both core and specialized skills, while specialists develop expertise within a subset of core skills shared with generalists. This hierarchical organization of skill acquisition is evident across domains such as AI/Data Analysis and Microcontroller Embedded Control. Our findings provide a quantitative framework for understanding skill specialization, offering insights for workforce development and policy-making.","Masaki Chujyo, FUJIO TORIUMI",Troselli,Network Science,5,,220
,,,,,,,,,,
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Social network communities and income convergence in the largest US cities,"Social ties are essential for upward economic mobility and for economic development. Since the formation of social connections is largely driven by mechanisms of homophily and triadic closure, emergent network communities often reinforce socio-economic homogeneity that can lead to inequalities in local economies. Although communities can facilitate information exchange and peer effects, large-scale evidence regarding the dynamics of economic progress within network communities remains scarce. Here, we show that social network communities within the 50 largest U.S. metropolitan areas support income convergence over time. We use a unique geolocated social network data from Twitter, which contains 982,459 users and 2,711,185 social ties between them as of 2012--2013. By locating the home census tracts of frequently messaging users, we construct weighted social networks at the census tract level within the 50 largest US metropolitan areas from mutual follower relationships. We identify urban network communities with a spatially sensitive Louvain algorithm of Expert et al. (2011), which accounts for nearby nodes being more likely to connect. Yearly household income of tracts and socio-demographic variables are retrieved from the American Community Survey. Using multivariate regression models, our findings reveal that (1) there is sigma convergence within social network communities between 2012 and 2019. Income disparities within these communities are becoming significantly smaller over the period. Moreover, these communities predict income convergence more strongly than conventional administrative units within the metropolitan area (e.g., counties, school districts). (2) Even after controlling for socio-economic factors, we observe beta-convergence, indicating that lower-income tracts within a community tend to catch up economically. Our approach enables us to reveal heterogeneity across US metropolitan areas, across ethnic groups, and to identify the role of residential mixing in the aggregate economic outcome in neighborhoods. These results underscore the importance of local social networks in shaping economic outcomes and suggest that policies aiming to reduce inequalities and foster urban transformation should consider network-based boundaries.","Imre Gémes, Eszter Bokanyi, Sandor Juhasz, Balázs Lengyel, Gergo Toth",Hemeryck,Social Networks I,1,,643
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Anatomy of a Swedish population-scale network,"We construct a multilayer population-scale network for Sweden using pseudonymised registry data from 2000-2017, covering roughly 8.3 million individuals. We analyse the structure and connectivity patterns across six layers: close family, extended family, household, neighbourhood, school and work. Comparisons with a population-scale network for the Netherlands reveal similar degree distributions and small-world characteristics, with most individuals forming a single connected component when merging multiple layers.","Georgios Panayiotou, Inga K. Wohlert, Miia Bask, Mikael Bask, Matteo Magnani, Ilkka Henrik Mäkinen",Hemeryck,Social Networks I,2,,646
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,From hubs to natural early adopters: Understanding the homophily transition behind the effectiveness of social change interventions,"Understanding diffusion processes is fundamental to explaining how ideas, behaviors, and innovations spread through social networks. Complex contagion theory serves as a pivotal framework for modeling such diffusion where individuals need reinforcement from multiple social contacts before adopting a new product or behavior and adopt only when a specific fraction of their social contacts (i.e., their threshold) have already adopted it. While existing research debates whether targeting social hubs or early adopters is more effective, the role of homophily—the tendency of individuals to associate with similar others—remains underexplored in complex contagion. In this study, we leverage a recent framework to empirically estimate adoption thresholds using choice experiments in two contexts: political decision-making and social technology adoption. We integrate these real-world threshold distributions into simulations of complex contagion on synthetic networks with varying levels of homophily to systematically compare the performance of seeding strategies. Our results indicate that individual adoption thresholds in reality do not follow a uniform distribution but instead exhibit a bimodal pattern. By integrating empirically estimated individual behavior measures into simulations, we find that the effectiveness of seeding strategies in driving large-scale diffusion may be overestimated if homophily is not accounted for. These findings offer valuable insights into the conditions under which interventions can effectively scale behavioral change, contributing to research in marketing, public policy, and social movement strategies.","Mingmin Feng, Manuel S. Mariani, René Algesheimer, Radu Tanase",Hemeryck,Social Networks I,3,,332
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Bound by Ties: How religious embeddedness mitigates fee-induced religious disaffiliation,"Membership fees are known to influence individual decisions to leave religious organizations. In this study, I argue that religious embeddedness—the degree to which individuals share social ties with other members in the same organization—mitigates this effect through commitment mechanisms. Using longitudinal data for the years 2000 to 2022, with information on Church of Sweden memberships, fees, and network ties for the entire Swedish population, I estimate how membership fees impact disaffiliation likelihood and how religious embeddedness moderates this relationship. My analyses confirm that higher church fees increase disaffiliation probability, but this effect is weaker among individuals with many social ties to other church members. Using these estimates and the observed social network, I calibrate an agent-based simulation model to examine macro-level implications. The simulations reveal that religious embeddedness serves as a protective force against membership decline. However, as disaffiliation progresses and religious network density wanes, this protective buffer gradually erodes, potentially creating tipping points that can accelerate disaffiliation rates dramatically. These findings demonstrate how social networks provide resilience against economic costs while also creating conditions for nonlinear membership decline patterns in membership-based organizations.",Elis Carlberg Larsson,Hemeryck,Social Networks I,4,,872
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,The structure and function of antagonistic ties in village social networks,"Negative or antagonistic relationships are common in human social networks, but they are less often studied than positive or friendly relationships. The existence of a capacity to have and to track antagonistic ties raises the possibility that they may serve a useful function in human groups. Here, we analyze empirical data gathered from 24,770 and 22,513 individuals in 176 rural villages in Honduras in two survey waves 2.5 y apart in order to evaluate the possible relevance of antagonistic relationships for broader network phenomena. We find that the small-world effect is more significant in a positive world with negative ties compared to an otherwise similar hypothetical positive world without them. Additionally, we observe that nodes with more negative ties tend to be located near network bridges, with lower clustering coefficients, higher betweenness centralities, and shorter average distances to other nodes in the network. Positive connections tend to have a more localized distribution, while negative connections are more globally dispersed within the networks. Analysis of the possible impact of such negative ties on dynamic processes reveals that, remarkably, negative connections can facilitate the dissemination of information (including novel information experimentally introduced into these villages) to the same degree as positive connections, and that they can also play a role in mitigating idea polarization within village networks. Antagonistic ties hold considerable importance in shaping the structure and function of social networks.","Amir Ghasemian, Nicholas A. Christakis",Hemeryck,Social Networks I,5,,648
,,,,,,,,,,
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,A Network of Warring States: Antagonism and the Emergence of Stability in Medieval Japan,"Negative relationships significantly influence the structure and dynamics of social networks, even possibly serving a role in stabilizing an otherwise unstable system across time. We explore this idea by analyzing unique historical data from the Warring States period of medieval Japan, where 2,222 clans engaged in 2,889 battles over 133 years. Our network analysis reveals a temporal shift in the topological location of battles and warring actors. Specifically, we delineate a fragmentation phase (1467–1566), characterized by instability and decentralized conflict, followed by a unification phase (1566–1600), distinguished by centralized conflict. By extending classical balance theory to state-like actors, these findings provide insights into the role of negative ties in long-term social destabilization and stabilization cycles. Finally, we examine how Japan's distinctive geography—defined by its long, arc-shaped archipelago—has influenced the dynamics of unification, suggesting that geographical constraints, alongside collective networks and historical trajectories, may shape political systems and determine whether a region unifies under a centralized structure or remains polarized into rival factions.","Amir Ghasemian, Hirokazu Shirado, Nicholas D. Anderson, Nicholas A. Christakis",Hemeryck,Social Networks II,1,,661
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,The illusion of households as entities in social networks,"Data recording connections between people in communities and villages are collected and analyzed in various ways, most often as either networks of individuals or as networks of households. These two networks can differ in substantial ways. The methodological choice of which network to study, therefore, is an important aspect in both study design and data analysis. In this work, we consider various key differences between household and individual social network structure, and ways in which the networks cannot be used interchangeably. In addition to formalizing the choices for representing each network, we explore the consequences of how the results of social network analysis change depending on the choice between studying the individual and household network---from determining whether networks are assortative or disassortative to the ranking of influence-maximizing nodes. As our main contribution, we draw upon related work to propose a set of systematic recommendations for determining the relevant network representation to study. Our recommendations include assessing a series of entitativity criteria and relating these criteria to theories and observations about patterns and norms in social dynamics at the household level: notably, how information spreads within households and how power structures and gender roles affect this spread. We draw upon the definition of an illusion of entitativity to identify cases wherein grouping people into households does not satisfy these criteria or adequately represent given cultural or experimental contexts. Given the widespread use of social network data for studying communities, there is broad impact in understanding which network to study and the consequences of that decision. We hope that this work gives guidance to practitioners and researchers collecting and studying social network data.","Izabel Pirimai Aguiar, Philip S. Chodrow, Johan Ugander",Hemeryck,Social Networks II,2,,603
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Estimating occupational clustering based on complete kinship networks,"Researchers can construct complete population networks based on biological descent and other links when appropriate register data are available [8, 5, 1]. We show how such networks can be used to analyse occupational clustering. We recover known results such as the manual/non-manual distinction and micro-class reproduction based the distribution of occupations within the kinship network. We also show that occupational reproduction happens far beyond the extended family. Using the entire population networks avoids having to privilege some relationships over others (parent-child, partner, siblings etc.) and contributes to moving analyses of social stratification and mobility beyond the nuclear family [6, 7, 3]. Jonsson et al [4] argued that “much of what shows up as big-class reproduction in conventional mobility analyses is in fact occupational reproduction in disguise.” They show that most of the “big class” reproduction (between fathers and children) takes place at a very fine occupational level: if children of lawyers are over-represented among high-prestige occupations, it is because they disproportionately often become lawyers. [2] replied that “the microclass approach does not deal in a theoretically consistent way with the remaining associational underlying patterns of occupational mobility,” highlighting that occupational reproduction was weaker for females, and that Jonsson et al.’s “micro- class” reproduction accounts for only half of overall class reproduction. We argue that apprehending social class via a dyadic perspective, i.e. focusing on parent-child measures, fundamentally restricts our analyses. Extending our view to an entire societal segment linked via descent gives us a more comprehensive picture of the distance between and cohesion within occupations. Figure 1 (p. 3) illustrates how we derive distances between occupations based on the kinship relations of individuals. We calculate all pairwise distances in the network. We then summarize each distribution of distances from individuals of one occupation to individuals of another, e.g. from bakers to bus drivers, by calculating the normalized area under the empirical cumulative distribution function $\hat{F}(d)$, $nAUC$. It is equal to 0 when all observed distances are equal to the maximum distance. It is equal to 1 when all observed distances are equal to the minimum possible distance. $$\hat{F}(d) = \frac{1}{d_{max}}\sum_{i=1}^{d_{max}} 1_{x_i\leq d}, \quad AUC = \sum_{d=1}^{d_{max}} \hat{F}(d),\quad nAUC = \frac{AUC - d_{min}}{d_{max} - d_{min}}$$ This study uses individual-level microdata from Statistics Sweden: We use the total population register (1968-2019) to link parents and children and the longitudinal integra- tion database for health insurance and labour market studies (2001–2019) for information on occupations. We restrict our sample to individuals born in 1968 or later and having an occupation between 2001 and 2018, for computational tractability. Individuals are linked by biological descent, but we consider the edges undirected. The resulting largest connected component, i.e. every individual can be reached from every other individual, comprises 502 500 individuals and 621 471 edges, having 355 unique occupations (at the 4-digit level). The distribution of distances among individuals of the same occupation is left-shifted compared to the distribution of distances between individuals of different occupations (figure 2). In other words, individuals of the same occupation are more likely to be genealogically close. This is true far beyond distances characterizing the extended family (e.g. cousins are distance 4). Occupations cluster at all levels of granularity, clustering is consistent across levels, and clusters have high face validity. Figure 3 shows the clustering of occupations at the 2- and 1-digit level (more interpretable than the more granular levels), based on Ward D2 linkeage of euclidean-distance transformed $nAUC$. One can clearly see the split between manual and non-manual occupations, and, within the latter, between office and service workers, on the one hand, and professionals and associated occupations on the other. We show a new way to quantify social structure based on complete population net- works. We recover known patterns of occupational reproduction and clustering based solely on kinship links. Occupational reproduction beyond the extended family could be dynastic, by descent, or homophilic, by marriage. This approach is straightforward to extend to education, income, and other dimensions of interest. (This abstract, including references and figures, is in the attached pdf-file)","Ole Hexel, Yann Renisio, Tobias Dalberg",Hemeryck,Social Networks II,3,,348
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Assessing Mobile Instant Messenger Networks with Donated Data,"Despite the increasing popularity and importance of mobile instant messenger services (MIMSs) such as WhatsApp, Telegram and Signal, the vast majority of the research on social media is focused on the “traditional” social media platforms such as Twitter (X) and Facebook, mostly due to the difficulty of accessing MIMSs data. Consequently, we lack knowledge about even the most basic topological features of the societal-scale instant messenger network. To overcome this knowledge gap, we employ the innovative approach of data donation by respondents of a high-quality probability-based panel in the Netherlands (the LISS panel) to collect user data while preserving their privacy. Focusing on WhatsApp as the most popular MIMS, this study collects the first measurement of MIMS usage on a national probability sample. We find that the degree distribution of contacts is best approximated by a log-normal distribution, while the distribution of group membership is best approximated by the exponential distribution. At the individual level, we find that predictors of degree derived from the literature on extended networks mostly replicate.","Rense Corten, Laura Boeschoten, Thijs Carrière, Stein Jongerius, Bella Struminskaya, Joris Mulder, Parisa Zahedi, Shiva Nadi Najafabadi, Adriënne Mendrik",Hemeryck,Social Networks II,4,,140
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Quotegraph: A Social Network Derived from Millions of News Quotations,"We introduce Quotegraph, a novel large-scale social network derived from speaker-attributed quotations in English news articles published between 2008 and 2020. Quotegraph consists of 528 thousand unique nodes and 8.63 million directed edges, pointing from speakers to persons they mention. The nodes are linked to their corresponding items in Wikidata, enriching the dataset with detailed biographic entity information such as nationality, gender, and political affiliation. Each part of the network construction pipeline is language agnostic, enabling the construction of similar datasets based on non-English news corpora.","Marko Čuljak, Robert West, Andreas Spitz, Akhil Arora",Hemeryck,Social Networks II,5,,965
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,A temporal-network perspective on the analysis of online coordinated behaviour,"One social data analysis task in the emerging field of social cybersecurity that has received considerable attention concerns the identification of coordinated efforts to amplify political messages on social media. Network-based methods have proven successful in detecting coordination in social media, for example to identify deceptive attempts to increase the visibility of social media posts and websites. While time is fundamental in these methods, to define when two actors are coordinated, little attention has been dedicated to the longitudinal dynamics of coordination. In this work we examine the suitability of different temporal network analysis methods for the longitudinal study of online coordination, where the network is split into temporal slices and communities are traced over time. Our results confirm early evidence that a longitudinal approach can find more traces of coordination and reveal dynamic patterns that are otherwise lost in a static analysis. At the same time, we raise questions about the validity of existing design choices, their consequences, and suggest associated guidelines.","Luca Rossi, Matteo Magnani",Hemeryck,Social Networks II,6,,727
,,,,,,,,,,
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Imitation and Differentiation in News Production among American Media Outlets on Facebook,"In a crowded digital landscape characterized by decreasing levels of media trust and increasing news avoidance, where audience attention is scarce, media outlets must strategically balance imitation and differentiation to remain competitive. This study investigates how media outlets in the U.S. navigated this dynamic on Facebook between 2015 and 2019. Using a publicly available dataset of over 2.2 million posts from 29 media outlets, we analyze the extent to which ideological alignment or distance dictates these strategies. First, we use topic modelling and causal inference techniques to estimate the flow of influence between every pair of outlets. Then, we use these estimated influence scores to construct imitation and differentiation networks, and use graph regression techniques -- specifically, Quadratic Assignment Procedure (QAP) approaches -- to find strong evidence for differentiation. Differentiation, however, is notable only in the coverage of partisan political topics -- where ideologically distant outlets deliberately diverge from each other in choosing what news topics to cover. In contrast, imitation dynamics, where outlets replicate others' content, are not significant for either partisan political or entertainment topics. We also observe a partisan asymmetry in differentiation: left-leaning outlets exhibit a stronger tendency to differentiate from right-leaning competitors. Our work offers novel insights into the complex interplay of media strategies in a digital landscape, and has implications for the future of online news and its relationship with political processes.","Subhayan Mukerjee, Tian Yang, Yilang Peng",Vingen 3+4,Social Media & Networks,1,,122
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Scaling of Community Rules Across Mastodon Servers,"The rise of decentralized social media platforms like Mastodon and Bluesky has renewed interest in self-governance. A key challenge in moderation is scalability, particularly in systems that rely on volunteer efforts. Understanding how moderation functions and scales in decentralized communities is crucial for their sustainability. This study examines Mastodon’s moderation practices by analyzing community rules across servers of different sizes. We categorize these rules to identify key governance priorities, finding that smaller communities focus disproportionately on a few topics, while larger instances maintain a more balanced emphasis. We also explore the relationship between rule lexical features and instance size, showing that as communities grow, rule scope expands while linguistic diversity declines. Finally, we find that instance size strongly predicts all aspects of rule lexical features. Federation connections, while playing a role, can only explain the expansion of rule scope.","Rasika Muralidharan, Bao Tran Truong, Yong-Yeol Ahn",Vingen 3+4,Social Media & Networks,2,,752
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Quantifying the Spread of Online Incivility in Brazilian Politics,"Incivility refers to behaviors that violate collective norms and disrupt cooperation within the political process. Although large-scale online data and automated techniques have enabled the quantitative analysis of uncivil discourse, prior research has predominantly focused on impoliteness or toxicity, often overlooking other behaviors that undermine democratic values. To address this gap, we propose a multidimensional conceptual framework encompassing violations of etiquette, legibility, pluralism, and democratic freedom norms. Using this framework, we measure the spread of online political incivility in Brazil using approximately 5 million tweets posted by 2,307 political influencers during the 2022 Brazilian general election. Through statistical modeling and network analysis, we examine the dynamics of uncivil posts at different election stages, identify key disseminators and audiences, and explore the mechanisms driving the spread of uncivil information online. Our findings indicate that impoliteness is more likely to surge during election campaigns. In contrast, the other dimensions of incivility are often triggered by specific violent events. Moreover, we find that left-aligned individual influencers are the primary disseminators of online incivility. They create uncivil content and amplify uncivil content from politicians, media agents, and individuals to reach broader audiences, revealing a diffusion pattern mixing the direct and two-step flows of communication theory. Consequently, a feedback loop may exist between right-wing offline violent actions and left-wing uncivil online responses, potentially harming democracy. This study offers new insights into the multidimensional nature of incivility in Brazilian politics and provides a conceptual framework that can be extended to other political contexts.","Yuan Zhang, Alexandre Bovet, Laia Castro Herrero, Michael Amsler, Frank Esser",Vingen 3+4,Social Media & Networks,3,,183
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Causal Modeling of Climate Activism on Reddit,"Climate activism is crucial in stimulating collective societal and behavioral change towards sustainable practices through political pressure. Although multiple factors contribute to the participation in activism, their complex relationships and the scarcity of data on their interactions have restricted most prior research to studying them in isolation, thus preventing the development of a quantitative, causal understanding of why people approach activism. In this work, we develop a comprehensive causal model of how and why Reddit users engage with activist communities driving mass climate protests (mainly the 2019 Earth Strike, Fridays for Future, and Extinction Rebellion). Our framework, based on Stochastic Variational Inference applied to Bayesian Networks, learns the causal pathways over multiple time periods. Distinct from previous studies, our approach uses large-scale and fine-grained longitudinal data (2016 to 2022) to jointly model the roles of sociodemographic makeup, experience of extreme weather events, exposure to climate-related news, and social influence through online interactions. We find that among users interested in climate change, participation in online activist communities is indeed influenced by direct interactions with activists and largely by recent exposure to media coverage of climate protests. Among people aware of climate change, left-leaning people from lower socioeconomic backgrounds are particularly represented in online activist groups. Our findings offer empirical validation for theories of media influence and critical mass, and lay the foundations to inform interventions and future studies to foster public participation in collective action.","Jacopo Lenti, Corrado Monti, Luca Maria Aiello, Gianmarco De Francisci Morales",Vingen 3+4,Social Media & Networks,4,,519
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Characterizing controversial far-right communications on Telegram,"Fringe political communities have increasingly migrated to alternative social media platforms such as Telegram, where content moderation is minimal, enabling the rapid spread of extremist narratives. This study provides a quantitative analysis of discourse, harmful content, and message propagation across five far-right Telegram communities: MAGA Trumpists, QAnon, COVID-19 misinformation, White Supremacists, and Proud Boys. We find a significant variation in harassment, hate speech, and violence-related messages across the five groups. Analyzing forwarded messages as a weighted directed network, we identify the core ""propagators""—channels central to content amplification. A two-sample test of proportions shows that in some of the far-right communities, hub channels disproportionately spread harmful content, while in others, harmful discourse is more decentralized. Our findings underscore the structural role of key amplifiers in shaping extremist narratives on Telegram. Our work also paves the path for future work to examine cross-community message passing and temporal trends, particularly leading up to the 2024 U.S. elections, to assess how network shifts influence harmful content dissemination in far-right online spaces.","Upasana Dutta, Yasmine Houri",Vingen 3+4,Social Media & Networks,5,,904
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,The Reddit Network of Mental Health Support,"Over the past few decades, research has documented a significant rise in mental health issues [1], highlighting a growing disconnect between advancements in health sciences and the psychological challenges individuals face. Simultaneously, social media has reshaped mental health support, enabling peer-driven interactions that help us look into mental health through lived experiences [2, 3]. Platforms like Reddit have become valuable spaces for individuals seeking guidance, sharing personal stories, and navigating mental health difficulties—often filling gaps left by the formal healthcare system. Unlike traditional forms of support, Reddit’s decentralized and anonymous nature encourages open expression and a sense of safety, making it particularly useful for studying stigmatized conditions. In this work, by examining Reddit as a system of disorder associations, we aim to uncover the implicit structures that shape mental health discourse, connecting clinical knowledge with peer-to-peer support. We present a network of mental disorders, symptoms, and addiction associations extracted from mental health support discussions on Reddit spanning five years (from 2019 to 2024). By conducting an expert review of the 20,000 most popular subreddits, we curated a list of 113 mental health support communities dedicated to a specific condition. Each subreddit was then categorized into 63 conditions and 15 disorder categories as delineated in the DSM‐V‐TR [4]. The final dataset comprises 4.1M public posts from 1.62 million users, offering a comprehensive view of the digital landscape of mental health discourse. The network is constructed by linking conditions based on statistically significant overlaps (Bonferroni-corrected $p<0.05$) in user participation across their respective subreddits. The resulting network is sparse (graph density of 0.071), yet it forms a single giant component comprising 104 out of 113 subreddits—a strong indication of the interconnectedness of mental health conditions (Figure 1). This giant component follows a modular structure (weighted betweenness Girvan-Newman modularity $Q_{max} = 0.668$ [5]), with groups of subreddits that are more strongly connected within than between groups. Here, we examine two types of edges in the network: - Intra-category (56.44\% of edges) -- linking two subreddits that provide support focused on a single condition category (e.g., BingeEatingDisorder and r/AnorexiaNervosa, both in the category of Feeding and Eating Disorders). - Inter-category (43.56\% of edges) -- linking two subreddits that provide support for different conditions (e.g., r/bipolar and r/BorderlinePDisorder, the first belonging to Bipolar Disorders and the latter to Personality Disorders). The inter-category edges reveal the non-trivial modular structure of the network, linking pairs of conditions either comorbid or similar in their symptomatology. The most central inter-category subreddits, r/C-PTSD (complex PTSD) and r/dpdr (depersonalization-derealization disorder), focus on conditions tied to prolonged trauma—-well-documented risk factors for other mental health disorders [6,7]. Our analysis of the hierarchical modular structure of the network shows that it does not fully match the diagnostic categorization defined in the DSM‐V‐TR (Figure 2). This demonstrates that user behavior on social media reveals patterns of similarity between diagnoses that differ from clinical categorizations. Specifically, we observe several cross-category clusters, such as Dissociations and Trauma, Personality Disorders and Psychotic Disorders, and Anxiety and Panic Disorders. In the clustering with the highest modularity in the hierarchy ($Q_{max}$), only two major clusters emerge: a smaller one comprising substance abuse and sleep disorders, and a larger cluster including the remaining conditions. These findings add to the growing evidence that clinical taxonomies do not fully capture the complexities of lived mental health experiences, reinforcing the need for alternative classifications grounded in broader behavioral data [8, 9]. Our findings reveal that the mental health support discourse on Reddit is strongly interconnected, with trauma and depersonalization conditions at the core of our network. Although the network is highly modular, the groups emerging from user behavior do not fully align with the clinical taxonomy of disorders, with users experiencing similarities between diagnoses in ways that differ from traditional clinical categorizations. Overall, the study offers a unique perspective on the co‐occurrence of mental health conditions as discussed in digital social spaces. By broadening the research focus beyond individuals actively seeking medical care, this work highlights the experiences of those who self-manage their symptoms, encounter barriers to healthcare, or find traditional support insufficient.","Bojan Evkoski, Srebrenka Letina, Petra Kralj Novak",Vingen 3+4,Social Media & Networks,6,,703
,,,,,,,,,,
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Measuring political activity on Facebook using donated data,"Introduction. In recent years, contrasting and integrating survey and digital trace data has emerged as a promising approach to enhance our understanding of human behavior in the digital age. Research that has so far aimed at comparing the two data sources has shown mixed results, with only weak/moderate correlations between the data collected by the two methods. These results highlight the validity problems of survey data but also point out that it is not always possible to match digital data with theoretical concepts well and that different validity issues may arise with digital data, too. In this study, we compare self-reported social media usage with data from digital footprints. As political content consumption is a key topic in many studies using digital data, our primary focus is on how we can measure it in donated Facebook (FB) data and how these measures align with survey self-reports. Data and Methods. Between February and June 2023, we conducted a complex data collection in Hungary, in which we asked participants to fill out a questionnaire and share their social media data with us alongside the survey. For data sharing, we used a data donation approach. We asked respondents for access to FB and Google data. In this study, we use the donated FB data and contrast it with survey questions about FB usage. We use the same questions to measure the frequency of different activities on FB (posting, sharing, reacting, commenting) on different topics (in general and about politics) In the survey, we used a seven-grade scale to measure activity frequency. We used three data types from the FB data packages: comments, reactions, and posts. The basis of all our digital measures was the number of specified activities within a given timeframe. To measure political activity, we had to take an additional step: We needed to identify the political content within the donated FB data. For this, we used three different approaches: text classification, manual page classification, and page classification by FB. Besides varying the different approaches to measuring political activity, we also varied the timeframe of the digital data. Results. In the first step of the analysis, we compare the correlation of general activity frequencies measured by the survey and measured by digital data. Correlations were between 0.3 and 0.6. We found the lowest correlation for post-activity and the highest for sharing. The correlations also differ regarding the time frame used in the analysis. When we used the last 30 days of the respondents' digital data to measure the activity frequencies, we found weaker correlations than when we used longer periods. Measuring the political activity with FB data is even more challenging based on the correlations. Regarding post and share data, the correlations were below 0.2. The results for reactions and comments were more promising. The correlations were just slightly weaker for political content than for general activities. We did not find huge differences between the manual and automatic page classification approaches, but narrower categories worked better than strict ones in most cases. For comments, we could compare all approaches. Text classification produces the same level of correlation with survey data as the page classification methods. Even if there are no differences in correlations, there might be differences between the frequencies derived with different approaches. We categorized the continuous political comment estimates into the 7 ordinal categories used in the survey. Based on the raw distributions, the narrower automatic classification yielded the most similar result to the survey result. The other approaches underestimate the frequency of political commenting. Discussion. In this paper, we used donated digital data to measure general and political activities and contrasted these results with survey data. The average correlation level between digital and survey data was around 0.4, corroborating the findings of previous studies. However, some activity types (e.g., posts) were difficult to estimate through the DDPs. Using too short periods could lead to biased estimations if surveys are treated as reference measures. Estimating political content is even more challenging for certain activities.","Zoltan Kmetty, Adam Stefkovics",Vingen 3+4,Social Media I,1,,801
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Sampled datasets risk substantial bias in the identification of political polarization on social media,"Following recent policy changes by X (Twitter) and other social media platforms, user interaction data has become increasingly difficult to access. These restrictions are impeding robust research pertaining to social and political phenomena online, which is critical due to the profound impact social media platforms may have on our societies. Here, we investigate the reliability of polarization measures obtained from different samples of social media data by studying the structural polarization of the Polish political debate on Twitter over a 24-hour period. First, we show that the political discussion on Twitter is only a small subset of the wider Twitter discussion. Second, we find that large samples can be representative of the whole political discussion on a platform, but small samples consistently fail to accurately reflect the true structure of polarization online. Finally, we demonstrate that keyword-based samples can be representative if keywords are selected with great care, but that poorly selected keywords can result in substantial political bias in the sampled data. Our findings demonstrate that it is not possible to measure polarization in a reliable way with small, sampled datasets, highlighting why the current lack of research data is so problematic, and providing insight into the practical implementation of the European Union's Digital Service Act which aims to improve researchers' access to social media data.","Gabriele Di Bona, Emma Fraxanet, Björn Komander, Andrea Lo Sasso, Virginia Morini, Antoine Vendeville, Max Falkenberg, Alessandro Galeazzi",Vingen 3+4,Social Media I,2,,93
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Not so bad after all: cross-country estimates of prevalence of and engagement with negative content in political and non-political news on Facebook,"Negativity is a core characteristic of news and so the saying “if it bleeds, it leads” has described journalistic decisions about what to cover for decades. As a result, news outlets tend to produce and share negative content online and on platforms, and this tendency has been increasing in recent years. This is in part because negativity generates more attention, stimulates information seeking and—among some citizens—promotes engagement with news, and greater news sharing on platforms. Here, we advance extant work on negativity in news in the following key ways. First, we offer large-scale comparative evidence on the prevalence of and engagement with negative news on social media. Because most research comes from the U.S., it is not clear whether the findings generalize to other countries. Second, most past work examines user engagement with all negative articles produced by a news organization without differentiating between news about politics versus non-political topics or focuses on strictly political contexts without direct comparisons against a non-political baseline. Despite the importance of negativity in news coverage of candidates, elections, social groups, among other political issues, missing are at-scale estimates of the differential prevalence of and engagement with negativity in political vs. non-political news across countries. Third, we integrate three distinct engagement behaviors studied separately in past work. We examine the liking and sharing of negative news and also commenting on such news content. These behaviors reflect distinct affordances of platforms and have different implications for users themselves and online discourse at large. Furthermore, we put in perspective extant concerns about negativity in online communication by examining the relative volume of engagement with negative and positive news on platforms. We account for the differential prevalence of negative and non-negative news, aiming to provide more accurate conclusions regarding the actual volume of user engagement with negativity in political and non-political news. Lastly, methodologically, we offer a comprehensive approach to negativity and provide a validated multilingual classifier to capture—at scale, automatically, and in a reliable way—the presence of negativity in news. Following past conceptual work, we combine “the mere dissemination of negative news” (exogenous negativity coming into the news from outside, that is, from the topic itself) and media-initiated negativity (“endogenous negativity imposed on news by journalists through their use of language”). We use 6,081,134 Facebook posts published between January 1, 2020, and April 1, 2024, by 97 news media organizations in six countries. In particular, we use data on posts published by 37 major U.S.-based news outlets (2,274,210 posts), 12 outlets from the United Kingdom (959,141 posts), 11 from Ireland (451,783), 17 from Poland (842,321 posts), 8 from France (355,697 posts), and 12 news outlets from Spain (1,197,982 posts). For each post published by each news outlet, we obtained the text content, posting time, and the core interaction metrics — numbers of likes, comments, and shares. To identify political and negative news content, we develop two multilingual binary classifiers for automated labeling, both based on a moderately large transformer model known as XLM-RoBERTa-Large, and use them to label all posts as political/other and negative/other. This allows us to estimate the prevalence of negativity in political and non-political posts published by all analyzed news outlets as well as the users’ engagement with such news posts. We use those data to systematically and comparatively test four questions: (1) Is news about politics more negative overall than non-political news?; (2) What are the differences in the levels of negativity in political and non-political news across the tested countries? (3) What are the relative levels of users’ engagement — in terms of likes, comments, and shares — with negative news in general and also negative political and negative non-political news in particular? Lastly, (4) what are the relative levels of user engagement with negative news and with political versus non-political news when accounting for the prevalence of negative versus non-negative news?","Szymon Talaga, Magdalena Wojcieszak, Dominik Batorski",Vingen 3+4,Social Media I,3,,321
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Divergent patterns of engagement with partisan and low-quality news across seven social media platforms,"In recent years, social media has become increasingly fragmented, as platforms evolve and new alternatives emerge. Yet most research studies a single platform—typically Twitter/X, or occasionally Facebook—leaving little known about the broader social media landscape. Here we shed new light on patterns of cross-platform variation in the high-stakes context of news sharing. We examine the relationship between user engagement and news domains’ political orientation and quality across seven platforms: Twitter/X, BlueSky, TruthSocial, Gab, GETTR, Mastodon, and LinkedIn. Using an exhaustive sampling strategy, we analyze all (over 10 million) posts containing links to news domains shared on these platforms during January 2024. We find that the news shared on platforms with more conservative user bases is significantly lower quality on average. Turning to patterns of engagement, we find—contrary to hypotheses of a consistent “right wing advantage” on social media—that the relationship between political lean and engagement is strongly heterogeneous across platforms. Conservative new posts receive more engagement on platforms where most content is conservative, and vice versa for liberal news posts, consistent with an “echo platform” perspective. In contrast, the relationship between news quality and engagement is strikingly consistent: across all platforms examined, lower-quality news posts received higher average engagement even though higher quality news is substantially more prevalent and garners far more total engagement across posts. This pattern holds despite accounting for poster-level variation, and is observed even in the absence of ranking algorithms, suggesting user preferences – not algorithmic – bias may underlie the underperformance of higher-quality news.","Mohsen Mosleh, Jennifer Allen, David Rand",Vingen 3+4,Social Media I,4,,77
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Why Social Media Communities Become Negative Over Time,"Negative expressions are among the most hotly debated phenomena in contemporary society. Here we present a new theory of motivation to be unique as a driver of social media negativity. The premise of our theory is Tolstoy’s old adage that “all happy families are alike; each unhappy family is unhappy in its own way.” Tolstoy’s suggestion, which has now been validated in psychological studies, is that negativity is more heterogeneous than positivity (Alves et al., 2017). A pursuit of uniqueness can therefore lead to a descent into negativity. The main prediction from this account is a decline in affective valence over time on social media at multiple levels of analysis. Threads should become more negative over time as users find it more difficult to offer unique comments. Social media communities devoted to a topic should become more negative over time as it becomes more difficult to offer a unique perspective on the topic. We also hypothesize that there should be two crucial moderators of the trend towards negativity. The first moderator is initial valence: the effect should be most prominent when content starts off as positive. When initial posts or comments are positive, it is easier to differentiate oneself through negativity. The second moderator is group size: the effect should be most pronounced in larger groups. In a sufficiently small community, it should be less challenging to differentiate oneself than in a very large community, and the pull towards negativity therefore should not be so great. Methods and Results We tested these hypotheses using a combination of naturalistic data and controlled experiments to balance internal and external validity. Naturalistic Data. We retrieved naturalistic data from 2,150 “subreddit” communities on Reddit (2.05 billion comments) from 2010 – 2022 (see Figure 1). As predicted, we found that affective valence became more negative over time in comment threads, b = -0.001, SE = 0.0002, t = -7.57, p < 0.001, and in subreddits, b = 0.02, SE = 0.004, t = -5.37, p < 0.001. In subsequent analyses, we stress-tested our mechanism through mediation and moderation. If people are expressing negativity out of a motivation to be unique, then the rise of negativity over time should be mediated by increases in semantic uniqueness. Using an established measure of semantic uniqueness (Hoffman et al., 2013; Shi et al., 2019), we found this mediation in our thread, 95% CIs [-0.287, -0.140] (see Figure 2.). In terms of moderation, we predicted that the rise of negativity should be largest when discussions were initially positive, and when threads and communities contained many different users. We found support for both of these moderators. Initial positivity, b = -0.05, SE = 0.002, t = -31.17, p < 0.001, and number of unique users, b = -0.01, SE = 0.001, t = -9.05, p < 0.001, both moderated the trend towards negativity over time. Experimental Data. We next conducted two pre-registered experiments in which participants (n = 5,000) contributed posts to an evolving social media feed over five generations. In both experiments, participants saw news stories that were pre-tested to vary in their affective valence. The first generation of participants were instructed to write a post reflecting on the news story. Then the next generation saw the news story followed by a random subset (n =20) of posts from the previous generation. In Experiment 1, we test whether participants’ posts become more negative over subsequent generations, and whether this effect is greatest when people comment on positive articles (high initial positivity) versus negative articles (low initial positivity). In Experiment 2, we replicate the effect and further showed that the effect was stronger when people sought to be unique (via a monetary bonus awarded to the person who contributed the most unique perspective on the news topic), vs. conformist (via a monetary bonus for the person who mirrored previous perspectives). In both studies, we found the hypothesized generation * initial positivity interaction, p < 0.001, confirming that discussions have a higher valance decline overtime when they start off positively. In Experiment 2, we also found our hypothesized interaction with uniqueness condition. When participants were incentivized to contribute unique perspectives, we observed the expected interaction between generation and time, b = -0.04, SE = 0.01, t = -3.42, p < 0.001. However, when they were incentivized to contribute conformist perspectives, the interaction was in the opposite direction, b = 0.03, SE = 0.01, t = 3.28, p < 0.001, suggesting that initial positivity encouraged more positivity—the reverse of what we observed in naturalistic data.","Hongkai Mao, Joshua Conrad Jackson, Yutong Jiang, Alex Koch, Yuan Chang Leong, William J Brady",Vingen 3+4,Social Media I,5,,918
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Rules and Rulemakers: The Evolution of User-Defined Community Rules,"The Internet, despite its reputation as a ""Wild West,"" demonstrates that even in decentralized spaces, rules naturally emerge. Online platforms require order despite lacking centralized control, reflecting how human communities develop governance systems even without formal authority. While rules have traditionally been studied as static entities, their evolution—especially in online communities—remains poorly understood. We address this gap by analyzing rule changes across 13,000 Reddit communities over a decade, identifying four key evolutionary pathways: institutional diffusion (communities adopting successful rules from elsewhere), boundary spanning (moderators transferring rules between communities), exogenous shocks (external events prompting rule changes), and organizational scaling (communities developing more formal structures as they grow). Reddit's decentralized structure provides a natural experiment for observing governance evolution across thousands of semi-independent communities operating within the same framework. Using temporal data that captures both rule changes and moderator activity, we move beyond static analyses to examine the dynamics of rule creation and adaptation. Our initial findings suggest that ""low effort"" rules gained traction rapidly after 2013, civility rules transitioned from prohibitive restrictions to constructive guidance, and hate speech regulations were adopted in synchronized patterns across subreddits. These trends indicate that governance on Reddit is influenced by both internal community behaviors and external societal pressures. Understanding these mechanisms informs broader discussions on governance and institutional design while offering practical insights for platform policy development. By examining how rules evolve and persist, our research sheds light on the mechanisms that drive self-regulation in online communities and how digital governance structures adapt over time","Katherine Van Koevering, Shambhobi Bhattacharya, Hyejin Youn, Jon Kleinberg",Vingen 3+4,Social Media I,6,,871
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,"Intimacy with limits: How short-form video propaganda embraces platform norms, but not for leaders","How does authoritarian propaganda adapt to digital platforms, and how can we measure it across modalities? In this paper, we expand the literature on digital propaganda by introducing the concept of ""intimate propaganda"", which captures how governments craft narratives that foster a psychologically close relationship between audiences and the state. To test whether governments create more intimate propaganda on social media than traditional media, we focus on Xinwen Lianbo, China’s flagship television broadcaster, and compare propaganda videos from its flagship TV broadcast to its social media channel (Douyin, or Chinese TikTok) over twelve months from June 2020 to June 2021. We construct variables measuring intimacy across video (face proportion, happiness), audio (tempo, pitch), and text (informality, pronoun usage, slang), and find that Douyin is more intimate across most of them. Furthermore, we find that depictions of political leaders are the exception to this intimacy -- despite literature in democratic contexts showing the importance of message personalization, we find that in an authoritarian context leaders are held aloof. Our research contributes to the literature on digital propaganda, political message personalization, and multimodal content analysis.","Matt DeButts, Yingdan Lu",Vingen 3+4,Social Media II,1,,492
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,The Musk Effect: Declining Information Quality Under New Platform Governance,"Social media platforms play a central role in shaping public discourse, facilitating political engagement, and influencing information consumption (Gillespie, 2018; Napoli, 2019). Among these platforms, Twitter has served as a critical space for real-time news dissemination and political discussion (Zhang et al., 2021). However, major shifts in platform governance can have profound effects on information ecosystems. In October 2022, Elon Musk acquired Twitter and implemented sweeping policy changes, including reduced content moderation, reinstatement of previously banned accounts, and algorithmic adjustments that influenced content visibility (Frenkel & Conger, 2022). These transformations raised concerns about their potential impact on information quality, misinformation dynamics, and the broader health of digital public spheres (Wojcieszak et al., 2022). This study investigates whether these concerns are empirically reflected in shifts in Twitter’s information quality. Specifically, it examines how information credibility changed before and after Musk’s acquisition, contributing to ongoing debates on platform governance, misinformation regulation, and content moderation (Vaidhyanathan, 2018; Zhuravskaya et al., 2020). While previous research has analyzed the effects of algorithmic curation on misinformation exposure (Guess et al., 2020; Pennycook & Rand, 2019), the role of sudden leadership-driven policy changes remains underexplored. Addressing this gap, this study assesses how corporate governance decisions can reshape digital information environments. To analyze these dynamics, two large-scale datasets are used: the Twitter Panel, a representative sample of U.S. users, and the Decahose, a 10% random sample of all global tweets. Information quality is measured using established domain credibility scores, capturing engagement patterns with high- and low-credibility sources. Interrupted time series (ITS) analysis is employed to assess whether observable shifts in information quality coincide with Musk’s takeover (Grinberg et al., 2019; Guess et al., 2020). Findings reveal a statistically significant decline in information quality following the acquisition. Prior to the takeover, engagement with high-credibility sources exhibited an increasing trend, suggesting gradual improvements in information quality. However, after Musk assumed control, this trajectory reversed, showing a measurable increase in interactions with low-credibility domains and a reduction in exposure to reliable sources. These shifts are consistent across both datasets and remain robust across multiple operationalizations of information quality. These results highlight the influence of platform governance on information integrity. As social media platforms continue to shape political discourse, ownership-driven policy shifts—particularly those that relax content moderation—can have immediate and measurable effects on digital information ecosystems. The study’s findings contribute to discussions on platform regulation, misinformation control, and the role of private entities in governing public discourse (Napoli, 2019; Vaidhyanathan, 2018). Given the growing reliance on digital platforms for news consumption, understanding how governance decisions shape information quality is critical for researchers, policymakers, and platform designers.","Burak Ozturan, David Lazer, Nir Grinberg, Alexi Quintana Mathé",Vingen 3+4,Social Media II,2,,881
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Characterizing Deepfakes on X,"Deepfakes pose a growing threat to information integrity on social media. However, previous research has largely focused on their potential societal consequences rather than their real-world prevalence. In this study, we conduct a large-scale empirical analysis of deepfakes on the social media platform X. Specifically, we analyze a dataset of more than 5000 deepfakes identified through X’s Community Notes platform, which have been reposted over 137 million times. Our findings highlight that deepfakes are, compared to other forms of misinformation, disproportionately more likely to go viral, despite often originating from smaller accounts. These findings highlight the unique characteristics of deepfakes and their role in the misinformation ecosystem.","Chiara Drolsbach, Nicolas Pröllochs",Vingen 3+4,Social Media II,3,,985
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,WikiReddit: Tracing Information and Attention Flows Between Online Platforms,"The World Wide Web is a complex interconnected digital ecosystem, where information and attention flow between platforms and communities throughout the globe. These interactions co-construct how we understand the world, reflecting and shaping public discourse. Unfortunately, researchers often struggle to understand how information circulates and evolves across the web because platform-specific data is often siloed and restricted by linguistic barriers. To address this gap, we present a comprehensive, multilingual dataset capturing all Wikipedia links shared in posts and comments on Reddit from 2020 to 2023, excluding those from private and NSFW subreddits. Each linked Wikipedia article is enriched with revision history, page view data, article ID, redirects, and Wikidata identifiers. Through a research agreement with Reddit, our dataset ensures user privacy while providing a query and ID mechanism that integrates with the Reddit and Wikipedia APIs. This enables extended analyses for researchers studying how information flows across platforms. For example, Reddit discussions use Wikipedia for deliberation and fact-checking which subsequently influences Wikipedia content, by driving traffic to articles or inspiring edits. By analyzing the relationship between information shared and discussed on these platforms, our dataset provides a foundation for examining the interplay between social media discourse and collaborative knowledge consumption and production.","Patrick Gildersleve, Anna Beers, Viviane Ito, Agustin Orozco, Francesca Bolla Tripodi",Vingen 3+4,Social Media II,4,,766
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,"Understanding Diffusion in Social Media: Non-Exponential Growth, Topic Locality, and Infection Dynamics","Quantitative research on diffusion phenomena in society began in the early 20th century with the work of Chapin and is best known for Rogers' theory of the diffusion of innovation [1,2]. The field has been studied for over a century and diffusion processes are classically described by an S-curve, which can be approximated by the logistic equation. The S-curve initially exhibits exponential growth before converging to a constant value determined by the carrying capacity of the environment. This characteristic has led to its application in various fields, including linguistics, where it describes the diffusion of new words, and marketing, where the logistic equation forms the basis of the Bass model. Other phenomena similar to these diffusion phenomena are infection dynamics such as diseases and rumors often described by Susceptible-Infectious-Recovered (SIR) model etc. These also have in common with the diffusion phenomena that the initial phase is modelled by an exponential increase. The purpose of this study is to provide a comprehensive understanding of the growth curve of diffusion in social media. Specifically, we clarify the patterns of the growth curves and understand the mechanisms behind. Compared to previous studies, which often focused on individual word cases, this study aims to more systematically clarify the overall picture of growth curves by analyzing large-scale, long-term data.  Firstly, we systematically analyzed the growth curves of the diffusion of new words extracted from 10 billion blog posts in Japanese over a ten-year period from 2007 to 2019. We found that a non-exponential growth curve is the most common type (Figure 1). This typical curve is described by the following power-law type equation: $dx(t)/dt= rx(t)^α $ (1). The most common value of the exponent α is 0.5 (Figure 3), which is between the exponential growth (α = 1) and linear growth (α = 0). In general, we showed that more complex growth curves can be approximated using the equation: $\frac{dx(t)}{dt}= r x(t) (1+x(t)/X)^{α-1}$, where this equation corresponds to Eq. 1 for $X \to \infty$. Furthermore, we showed that these properties hold not only for Japanese blog data, but also for French, English, and Spanish [3]. Secondly, we investigated the relationship between the dominant parameter α in Eq. 1 and word meaning using two methods: word classification by LLM and the explanatory power of prediction by random forests. The results suggested that α was related to the ""locality of the topic"" (Table 1). Specifically, α was closer to 1 (i.e., exponential growth) for informative topics that are common both globally and across the entire country. In contrast, local and specialized experiential topics showed an α closer to 0 (i.e., linear growth). Thirdly, we introduced a simple agent-based infection model that takes into account the effect of the locality of the topic (Figure 2). In the model, the probability that the $i$-th infected person will infect a non-infected person is with probability p_i given by $p_i=1/(1+γk_i )$, where this probability decreases as the number of infected individuals $k_i$ around the $i$-th infected person increases. Here, γ is a parameter representing the locality of the topic, i.e., the ratio between the locality and globality of the topic. This agent-based model is connected to the typical power-law growth curve given by Eq. 1, and γ is directly linked to the power exponent $α = 1-γ$. The main contribution of this study is to systematically and clearly present the overall picture of continuous diffusion curves, based on the time series of one million words from a large, decade-long, nationwide blog dataset. These results are expected to provide a new perspective on the commonly used approach of observing long-term social changes through social media. References\ [1] Chapin F S 1928 Cultural Change (New York, NY: The Century Company) \ [2] Rogers E M 2003 Diffusion of Innovations (New York: Free Press) \ [3] Watanabe H 2023 J. Phys. Complex. 4 025018",Hayafumi Watanabe,Vingen 3+4,Social Media II,5,,249
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Multi Time-Scale Analysis of Information Spread on Telegram Reveals Critical State of Dynamics,"Online social media clearly shape the public discourse, yet our understanding of the information spreading process on online platforms is still limited. We study these spreading dynamics on the messenger app Telegram by analyzing a large data-set we collected. We find critical behavior, known from second order phase transitions in physical systems, and further show that a mean-field Random Field Ising Model in the vicinity of its critical point can accurately describe the statistics of observed information spreading phenomena on time-scales ranging from a few minutes to several months.","Roman David Ventzke, Anastasia Golovin, Andreas Christian Schneider, Viola Priesemann",Vingen 3+4,Social Media II,6,,325
,,,,,,,,,,
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Dynamics of collective mind in online news communities,"Collective understanding and public discourse in online news communities are shaped by the semantic representations of knowledge and beliefs shared by community members. This study introduces a computational model of this collective mind, calibrated with data from 400 million comments across five news platforms to examine how collective semantic networks evolve and differ from societal-level semantic representations. The model captures the influence of editorial agenda-setting, including alignment, amplification, and reframing, as well as community dynamics such as membership turnover, troll activity, and counterspeech. Our findings show how editorial practices can sustain echo chambers or challenge them through diversified narratives, and how community responses either reinforce or resist these influences. The results demonstrate that collective semantic networks are sensitive to external shocks, editorial policies, and community interactions, offering insights into mechanisms shaping public discourse.","Seungwoong Ha, Henrik Olsson, Mirta Galesic",Vingen 1+2,Media and Online Discourse I,1,,408
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,A Decade of DerStandard Data,"Social media have become a defining aspect of the first quarter of the 21st century. Their active use provides opportunity to collect large-scale longitudinal data. We release a dataset for the DerStandard newspaper platform covering an entire decade. DerStandard, an Austrian newspaper founded in 1988, pioneered online presence in 1995 with chat rooms that evolved into forums where registered users post comments on articles. These forums are highly active with 247,864 users posting 75,644,850 comments between 2013-2022. The dataset includes extensive text data in user comments and behavioral measures such as up/down-votes (412,511,165 votes total). We include information on which user voted positively or negatively on which posts, enabling reconstruction of signed networks of online interaction. We provide publicly available information on articles that serve as the basis for user postings, including content tags by DerStandard staff. To facilitate use of textual data and preserve privacy, we provide pre-computed vector representations of all texts, created using the state-of-the-art ""KaLM-embedding-multilingual-mini-v1"" model from Hugging Face. DerStandard is a source of high-quality text as the platform uses semi-automatic moderation to remove automated accounts and unwanted content. Our release enables researchers to move beyond typical English-centric contributions by providing large-scale textual data in German, a medium-resourced language spoken by approximately 100 million people worldwide. The data should interest social scientists, as it covers many contentious political events in Austria. Despite being a smaller European nation, Austria is often viewed as a model for later developments in Germany and other Western European countries. Its central location makes it share features with bordering countries and presents an interesting case for social scientific research. This data was previously used in three studies: monitoring affective expressions of the DerStandard community during COVID-19; showing sentiment analysis of user comments tracks mood dynamics expressed in platform surveys; and extracting signed networks of user interactions to identify divisions between users, pinpointing issues that reinforce societal fault lines and contribute to polarization. Our technical validations confirm the quality of the provided embeddings. Vector similarity analyses show expected patterns: highest similarity scores occur between direct reply pairs, followed by comments in the same thread, with lowest similarity between any comment pairs under the same article. We also examined similarity distributions for comments under articles with different topic labels versus the same topic, finding cross-topic pairs generally have lower similarity scores. Among same-topic pairs, specific labels like ""football"" or ""Middle East"" exhibit higher similarities than broader categories like ""policy issues."" This dataset enables future research in several domains. It provides a unique resource for network science with large-scale, longitudinal, real-world ""found"" data that directly allows building networks of signed interactions between thousands of users. Previous work in signed networks either used small-scale data or proxy measures to assume interaction positivity/negativity. On the article level, content tags can serve as valuable gold standard labels for validating clustering approaches. For additional flexibility, we provide linkage to the ""One Million Post Corpus"" of DerStandard previously released by the Austrian Research Institute for Artificial Intelligence, containing full text and manually annotated labels for a data subset.","Emma Fraxanet, Vicenç Gomez, Andreas Kaltenbrunner, David Garcia, Max Pellert",Vingen 1+2,Media and Online Discourse I,2,,426
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Giving the Far-Right a Voice. An NLP approach to the mainstreaming of far-right discourse in legacy media.,"The rise of far-right parties across Western democracies has prompted scholars to interrogate the media’s role in disseminating far-right messages, eventually consolidating their political stand (Moffitt 2018). While much focus has been placed on social media’s facilitation of far-right mobilization (Schradie 2019) and alternative conservative media (Della Vigna and Kaplan 2007), legacy media have also been largely studied. There are good reasons for this. Despite pervasive transformations of media ecosystems, they remain authoritative voices in the public sphere (Langer and Gruber 2021). Specifically, they play a key role in defining the boundaries of acceptable political discourse (Hallin 1989). Existing studies have examined their representation of far-right politics focusing on indicators such as the presence of far-right speakers in televised political shows (Cagé et al. 2022) or of far-right frames in journalistic writings (Wettstein et al. 2018). However, these now classic approaches only partially account for the process through which journalists give far-right actors a voice - both granting their visibility and shaping the conditions of their reception. Capturing this entails interrogating the extent to which far-right politicians are allowed to speak, and in which context. It also entails capturing how their discourse is framed and qualified through the work of journalists. One pathway to do so is to look at quotes. Quotes are a prime object of journalistic work. The place and form they take in journalistic content speaks of the deontological standards applied by journalists in the coverage of politics (Tuchman 1972). Most importantly, quotes reflect relationships of proximity or distance and of epistemic authority between journalists and politicians, over specific subjects and at specific points in time (Carlson 2009; Ekström et al. 2020). Yet, they are understudied sociological objects, partly because they are hard to apprehend at scale. To address this issue, we leverage recent advances in NLP to analyze how French legacy newspapers not only mention, but also quote politicians of different political orientations, including far-right, from the 1990s to the present. We set out to analyze quotes developing a novel methodology that combines: a) A sequence labeling algorithm, built on SpERT (Eberts and Ulges 2020) and FRACAS (Richard et al. 2023), which extracts from newspaper content “reported speech triplets” (quoted statement, source, reporting verb/phrase). b) A sequence-to-sequence algorithm on the model of BARThez (Eddine et al. 2020), which extracts the proper name of every quote’s source when possible, allowing to cluster quotes by individual. c) A database containing biographical information for French politicians to add relevant metadata to quoted political personalities. We applied this methodology on a large-scale corpus of political service articles from leading French newspapers, encompassing diverse editorial perspectives (Le Monde, Le Figaro, Libération). Using this data, we first quantify the voice given to far-right politicians vs. affiliated to other parties. We do so across outlets and over time. Our preliminary findings reveal correlations between the volume of quotes attributed to political factions, outlets’ political leaning, and national political events (elections, also terror attacks). Since the early 2010s, we also observe an upwards trend for quotes from far-right politicians in our corpus, with peaks corresponding to years when far-right candidates reached the second round of presidential elections (e.g. 2017). In parallel, we register a downward trend for center-left quotes. The strength of our method is that we can also qualify the voice given to the far-right. We can focus on the phrases used to introduce quoted statements. By computing odds ratios, we analyze the terms specifically used to introduce far-right discourse, and find clear tendencies over time. While the terms used in the early 2000s often denote an aggressive and adversarial attitude, detachment from reality, emotions generally considered unconventional in the political sphere, this is not the case two decades later. These verbs are often substituted by more neutral expressions, pointing to a clear normalization of far-right discourse in general media outlets. We also observe important inter-media differences. Verbs denoting uncontrolled anger or an adversarial attitude are more common in left-leaning outlets, while right-leaning papers delineate a more moderated portrayal of far-right statements. Building on these results, the presentation will i) introduce a novel methodology to analyze quoted statements in media content, ii) provide critical insights into the dynamics of media representation and normalization of far-right voices, iii) analyze the determinants of the voice given to the far-right over time, thus elucidating the factors that lead to the legitimation of these parties.","Emma Bonutti D'Agostini, Etienne Ollion",Vingen 1+2,Media and Online Discourse I,3,,240
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Converging or Diverging? Event-Driven Shifts in Meaning Networks across Newspaper and Online Discourses,"Sociological theorizing on meaning-making relies on network metaphors, yet empirical research has lagged behind in measuring relational meanings at scale. We conceptualize cultural meanings as networks of related interpretations in big text data from vastly different contributors. We use semi-supervised seeded topic modeling to identify meaning structures comparably across differences in language and text formats. As a case study, we investigate the convergence and divergence of immigration discourses between newspapers and online discussions in Sweden during a transformative period from 2008 to 2020. A longstanding question is whether crises disrupt meaning-making in ways that lead to divergence between discursive spheres, or foster interpretative convergence. In the short term, our results support the convergence story, as meaning networks in the newspapers and online become more aligned during the 2015--16 European `refugee crisis.' Convergence is driven by peripheral interpretations aligning bidirectionally, where both journalists and social media users move closer to each other’s perspectives. However, as the crisis subsides, meanings diverge, exceeding pre-crisis levels. Our methodology and results provide new insights into how crises synchronize and fragment public discourses across societal spheres.","Anastasia Menshikova, Miriam Hurtado Bodell, Måns Magnusson, Marc Keuschnigg",Vingen 1+2,Media and Online Discourse I,4,,148
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Disentangling Participation in Online Political Discussions: A Collective Field Experiment on Reddit,"Online discussions are far from representative–most people passively consume political content and only a small group produces most posts and comments. This phenomenon can evoke distorted perceptions of opinion prevalence and discourse norms, potentially creating feedback loops of public opinion formation driven by opinions of a loud minority (Robertson et al., 2024). While previous studies describe characteristics of those who post actively (Kim et al., 2021; Bor & Petersen, 2022; Bright et al., 2019), we still know very little about the other side: What distinguishes the silent from those who do enter the arena (Matthes et al., 2018)? What leads users to drop out of discussions? Is there a way to mitigate the resulting participation inequality? In this field experiment, we created large customized discussion groups on Reddit that allow us to test these questions in a controlled but ecological environment and to obtain detailed information about passive users and their perceptions. We recruit social media users via Reddit Ads in the United States and randomly allocate them (N = 520) to one of six experimentally controlled private online communities on Reddit. In all six communities, participants discussed political issues over a period of four weeks, accompanied by weekly diary surveys and concluded by a post-survey (see Figure 1). We find that even in this controlled lab-in-the-field environment, the number of comments written is predicted by male gender and high political interest. Furthermore, those who write many comments appear to get encouraged by disagreement, perceived polarization and even toxicity in a discussion. An almost completely opposite picture emerges for whether someone decides to enter the discussion at all. Perceptions of a toxic and polarized environment characterize those who remain silent, while on the other hand, writing the first comment is predicted by the group being respectful, knowledgeable and constructive (Figure not displayed for brevity.). Over time, we find evidence for positive reinforcement of behavior through social feedback (see Figure 3). Incentivizing participants to consistently write comments decreased participation inequality whereas making participants aware of moderation norms backfired and increased comment toxicity (see Figure 2). Discussion roles, in the sense that few individuals lead discussions while most others take a backseat, appears to be a robust feature of political discussions, as the two experimental treatments did not fundamentally alter discussion behavior and downstream political opinion formation. However, the experimental treatments successfully changed the constellations of who was most active and buffered early drop-out from commenting. Our setup allows for comparing how passive and active participants perceive a discussion, and how they react to toxicity differently. These divergent predictive patterns of environmental factors for (or against) online participation have important implications for future understandings of participation inequality and dynamics of online public discourse.","Lisa Oswald, William Small Schulz, Philipp Lorenz-Spreen",Vingen 1+2,Media and Online Discourse I,5,,130
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,The Impact of the George Floyd Killing on Public Sentiment Towards the Police and Black Lives Matter in YouTube Comments,"This study analyzed large-scale YouTube comments to examine how George Floyd's killing affected public sentiment toward police and Black Lives Matter. Using a RDiT design, we found decreased sentiment toward police and increased sentiment toward BLM. Our findings highlight the opportunities and limitations of using digital trace data in understanding public reactions in the aftermath of police violence.","Maximilian Pickartz, Christof Nägel",Vingen 1+2,Media and Online Discourse I,6,,137
,,,,,,,,,,
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Exploring the Impact of Online Environments on the Willingness to Express Opinions: A Spiral of Silence Perspective,"This research explores the relationship between human interaction and the processes of opinion formation and expression. While opinion dynamic models focus on interactions among individuals with differing viewpoints as drivers of opinion change, they often overlook how these interactions influence behavior without altering core beliefs. Understanding how individuals respond to feedback and how their choices impact others' behavior is increasingly important as more people engage with political content online. This study investigates how our need for connection influences our decisions to share opinions on contentious topics in online discussions. We propose an online experiment to examine whether online environments with a high incentive for connection give way to fear of isolation, thereby lowering willingness to express true opinions publicly. In our experiment, participants used an online interface to share opinions on controversial topics, with the option to conceal their views. They were encouraged to form connections and faced negative interactions if others disconnected or rejected them. Our study found that a high predisposition to share opinions, a strong belief in alignment with the majority, high attitude certainty, and issue importance all increase the likelihood of expressing opinions publicly. These findings support key aspects of the Spiral of Silence theory, which suggests that individuals are more likely to share their views when they believe their opinions align with the majority, have strong attitude certainty, and view the issue as important.","Gabriela Juncosa, Angel Sánchez, Julia Koltai, Taha Yasseri, Gerardo Iñiguez",Vingen 1+2,Media and Online Discourse II,1,,805
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Empathy from the Start: How Early Engagement Drives Long-Term Online User Retention,"In this paper, we investigate how early empathetic exchanges influence long-term user retention in online communities. We fine-tuned language models to detect multiple dimensions of empathy, such as requests, self-disclosures, and various forms of empathetic responses. Subsequently, we applied the model to examine the effects of early empathetic requests and replies on predicting sustained user engagement on Reddit and Stack Exchange. Our Weibull survival analysis reveals that early posting and replying behaviours related to empathy significantly affect user dropout rate. These findings offer practical insights for designing online platforms that foster supportive and lasting communities.",Yixin Chen,Vingen 1+2,Media and Online Discourse II,2,,197
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Masculine Defaults via Gendered Discourse in Podcasts and Large Language Models,"Masculine defaults are widely recognized as a significant type of gender bias, but they are often unseen as they are under-researched (Cheryan and Markus 2020). Masculine defaults involve three key parts: (i) the cultural context, (ii) the masculine characteristics or behaviors, and (iii) the reward for, or simply acceptance of, those masculine characteristics or behaviors. In this work, we study discourse-based masculine defaults, and propose a twofold framework for (i) the large-scale discovery and analysis of gendered discourse words in spoken content via our Gendered Discourse Correlation Framework (GDCF); and (ii) the measurement of the gender bias associated with these gendered discourse words in LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus our study on podcasts, a popular and growing form of social media, analyzing 15,117 podcast episodes. We analyze correlations between gender and discourse words -- discovered via LDA and BERTopic -- to automatically form gendered discourse word lists. We then study the prevalence of these gendered discourse words in domain-specific contexts, and find that gendered discourse-based masculine defaults exist in the domains of business, technology/politics, and video games. Next, we study the representation of these gendered discourse words from a state-of-the-art LLM embedding model from OpenAI, and find that the masculine discourse words have a more stable and robust representation than the feminine discourse words, which may result in better system performance on downstream tasks for men. Hence, men are rewarded for their discourse patterns with better system performance by one of the state-of-the-art language models -- and this embedding disparity constitutes a representational harm and a masculine default.","Maria Teleki, Xiangjue Dong, Haoran Liu, James Caverlee",Vingen 1+2,Media and Online Discourse II,3,,417
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Computational Analysis of Discourse Facets in Visual Communication around Climate Action,"In recent years, visual communication has become increasingly important in highly polarised social media debates, such as the one around climate change. Despite growing research on visual imagery in climate discussions, there is a gap in integrating advanced computational technologies like Vision-Language Models (VLLMs) to analyse these visuals. In this study, to fill this gap, we resorted to a dataset of 16,130 Facebook posts featuring images from both pro- and anti-climate action stakeholders. To analyze the visual discourse around the topic from both sides of the debate, we used LLM-enhanced visual clustering, employing GPT-4 for text labels and BERT embeddings for clustering. Six key visual facets of the climate discourse emerged, with two highly associated with right-wing political propaganda, and others focusing on sustainable practices and policies. We further explored the ideological dimensions by examining the presence of pro- and counter-actors in each visual cluster, finding that certain visual topics, such as wind turbines, triggered balanced engagement from both sides. Emotional polarization scores of posts revealed that anti-climate reactions were more negative, especially regarding sustainable practices. Overall, the study employed an innovative LLM-enhanced approach to the analysis of the image-based communication practices around climate change, detecting the heterogeneity of visual discourse in climate change, with ideological dominance shaping the framing of the debate.","Luigi Arminio, Luca Rossi",Vingen 1+2,Media and Online Discourse II,4,,195
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Beyond Stereotypes: Exploring How Minority College Students Experience Stigma on Reddit,"Minority college students face unique challenges shaped by their identities based on their gender/sexual orientation, race, religion, and academic institutions, which influence their academic and social experiences. Although research has highlighted the challenges faced by individual minority groups, the stigma process—labeling, stereotyping, separation, status loss, and discrimination—that underpin these experiences remains underexamined, particularly in the online spaces where college students are highly active. We address these gaps by examining posts on subreddit, r/college, as indicators for stigma processes, our approach applies a Stereotype-BERT model, including stance toward each stereotype. We extend the stereotype model to encompass status loss and discrimination by using semantic distance with their reference sentences. Our analyses show that professional indicated posts are primarily labeled under the stereotyping stage, whereas posts indicating racial are highly represented in status loss and discrimination. Intersectional identified posts are more frequently associated with status loss and discrimination. The findings of this study highlight the need for multifaceted intersectional approaches to identifying stigma, which subsequently serve as indicators to promote equity for minority groups, especially racial minorities and those experiencing compounded vulnerabilities due to intersecting identities.","Chaeeun Han, Sangpil Youm, Hojeong Yoo, Sou Hyun Jang",Vingen 1+2,Media and Online Discourse II,5,,160
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,News-like Information Ecosystem on YouTube,"Traditionally, news content was predominantly generated by established news organizations, where objectivity was a cornerstone valued by professional journalists. However, the advent of digital platforms has shifted the emphasis toward engagement and shareability. This evolution in focus has not only transformed consumption patterns but has also significantly influenced the methods of content production. In response to the evolving media landscape, news organizations have implemented various adaptations to sustain their visibility and relevance in the digital realm. Nonetheless, news content creation is no longer confined to traditional outlets, highlighting the importance of adopting more audience-centered approaches in measuring news impact. Here, we employ large language models to examine the contributions of ""Individual Content Creators"" in the information ecosystem. Our objective is to assess whether the decline in national television news consumption represents a genuine trend or if it is merely an artifact resulting from measuring news within the constraints of ""Traditional Media Organizations."" Furthermore, we employ large language models to analyze how content creators source their information and how these sources are represented by both traditional news organizations and individual creators. This analysis highlights the pivotal role that digital platforms play in shaping the contemporary definition of news in today’s hybrid media landscape. Finally, we conclude with a discussion of the limitations of our study and explore potential opportunities for future improvements.","Amir Ghasemian, Homa Hosseinmardi, Upasana Dutta, Jennifer Allen, David Rothschild, Duncan J. Watts",Vingen 1+2,Media and Online Discourse II,6,,650
2025-07-24 14:30:00,2025-07-24 16:15:00,session_presentation,Measuring the effect of Ownership Concentration on News Publication Practices,"The concentration of news media ownership is increasing globally. Through complex legal agreements between broadcasting companies, publishers may give up varying levels of editorial control in order to offset the costs of production involved in less profitable markets. On the other hand, they may gain control of additional news outlets in order to increase their effective market share in areas where FCC regulations on audience reach limits are not enforceable. This is done through a mixture of mergers, acquisitions, affiliations, sister channels, and shared-services agreements. In many cases, it has been found that news domains converge to the content of the broadcasting company that acquires them. Despite this, little can be said about the measurable effects of ownership concentration on news publication practices. We hypothesize that increased ownership concentration of news media leads to a decline in pluralism and a concentration of news content. To test this hypothesis, we propose a novel network method that allows us to correlate ownership concentration at the organizational level with changes in news content production. Our network method defines a distance measure over empirically observed event co-coverage and citation networks between US news domains. We then determine how far the observed networks are from a worst case scenario (complete concentration). To support the feasibility of this approach, we present preliminary analysis on GDELT and CommonCrawl datasets, and propose the use of our metric as a longitudinal measure of news content concentration.","Peter Carragher, Kathleen M. Carley",Vingen 1+2,Media and Online Discourse II,7,,804
,,,,,,,,,,
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Trapped by Personalization: LLM-Assisted Recommendations and Their Hidden Impact on Human-AI Ecosystems,"Recommender systems (RecSys) shape daily life and influence content selection on social media. While enhancing user experience, they also drive filter bubbles, radicalization, polarization, and social inequality. With the rapid advancement of technologies such as large language models (LLMs), these effects may become increasingly pronounced. Consequently, it is imperative to examine AI-powered RecSys within the broader context of human-AI ecosystems. In this study, by auditing an LLM-assisted YouTube recommender system, we analyze how LLM-assisted RecSys can enhance user experience by providing more personalized recommendations and examine their potential to amplify societal polarization. In our methodology, first, the YouTube algorithm initiates the process of personalization using actual historical data. Next, the candidate videos curated by YouTube undergo a re-ranking process employing LLMs that have been meticulously fine-tuned through various prompting strategies to enhance personalization. We show that the integration of LLMs into personalization strategies may unintentionally promote exposure to problematic content. Lastly, we present results on refining prompts to reduce the risk of producing extreme content while also diversifying the recommended videos.","Amir Ghasemian, Homa Hosseinmardi, Upasana Dutta, Ziying Chen, Duncan J. Watts",Vingen 3+4,Online Platforms & Algorithms I,1,,938
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Elections in the age of algorithms: assessing political bias in Search Engines and LLMs,"Search Engines (SEs), and more recently Large Language Models (LLMs), have established themselves as primary gateways to information. Despite their widespread use, these tools curate information under opaque algorithms, raising concerns about transparency, fairness, and potential bias. This study investigates whether SEs and LLMs display political bias in response to neutral election-related queries and examines whether such bias reflects external factors (e.g., media coverage or public polling) or is amplified by the platforms themselves. Using a web crawler-based methodology, we simulated user interactions with SEs (Google, Bing, DuckDuckGo, Yahoo) and LLMs (Copilot, ChatGPT) during the 2024 European Parliament and U.S. Presidential Elections. Crawlers performed identical queries across locations with varying political leanings, collecting results for analysis. Our findings reveal that SEs and LLMs disproportionately prioritize right-leaning political entities and issues. Ongoing analysis seeks to determine whether this bias reflects external factors or is exacerbated by the platforms themselves. This work highlights the need for greater transparency and accountability in algorithmic systems that shape access to information.","Íris Damião, Paulo David Dias Almeida, José M. Reis, Joana G Sa",Vingen 3+4,Online Platforms & Algorithms I,2,,1033
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Algorithmic Influence in Online Political Discourse,"Social media ranking algorithms determine what kinds of content users see in their feeds, and thus play an important role in shaping online discourse. Algorithms can influence individual users’ attitudes by curating their online media diet, but they also play an important role in incentivizing the creation of content in the first place, by giving certain kinds of content an advantage in gaining popularity in the online attention economy. The present research aims to disentangle these mechanisms of algorithmic influence, through a unique experimental paradigm that uses an open-source social media platform, Mastodon, as a “lab in the cloud.” Specifically, we run multiple Mastodon servers in parallel, populate these servers with research participants, and experimentally intervene in server-level algorithmic ranking weights, to estimate effects on server-level discourse outcomes. Using a novel algorithmic ranking system that we built for this experimental infrastructure, we conduct a large-scale online field experiment to investigate how algorithms shape the popularity and production of political content online, as well as users’ political attitudes, affective polarization, offline mobilization, and current events knowledge. Our analyses have important implications both for pro-democratic depolarization efforts, and also for online discourse in authoritarian contexts.","William Small Schulz, Tiziano Piccardi, Farnaz Jahanbakhsh, Michael S. Bernstein",Vingen 3+4,Online Platforms & Algorithms I,3,,901
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Navigating the Evolving Web: Are Large Language Modeling-based Chatbots Gatekeepers or Gateways?,"While traditional search engines (before LLMs) have acted as gateways to the broader internet, directing users to external websites based on their queries, social media has increasingly shifted towards prioritizing user retention (becoming more `selfish'), often discouraging external links to keep engagement within the platform. Chatbots utilizing Large Language Models (LLMs), such as ChatGPT, with their rapid adoption, introduce a new paradigm — serving as both information providers and potential gateways. Therefore, the health of the open web today depends on one open question: Are LLM-based chatbots ‘selfish’ in terms of user retention or ‘giving’ (referring users to external websites)? We posit that, as opposed to traditional search engines (before the introduction of LLMs), chatbots follow social media platforms in ‘selfishness’, discouraging engagement with external links to retain user engagement within the interaction with the chatbot, since the value proposition of LLM-based chatbots is to distill the open web, not point people to it. In this sense, chatbots might be ‘parasitic’ — reliant on the open web for their training and abilities to generate content, but gatekeeping and limiting access to the same open web. To this end, the primary research question we investigate in this work is RQ: How do these chatbots influence users' propensity to explore external websites? We will evaluate how chatbots compare to traditional search engines and social media platforms in terms of retention of users and duration of engagement. We will also analyze the content generated by chatbots to understand the contexts in which users are exposed to external websites. Further, we will compare search pages with and without LLM-generated summaries on Google to study if the propensity of search engines to direct users to external websites is also being affected. Since different users might interact with chatbots differently, we will also study the role of demographic factors such as age, gender, partisanship, and education in external website referrals (for example, do users with higher formal education levels click on external links generated by chatbots at a higher rate?). Our study will involve comprehensive analyses of how different user groups seek information and get exposed to information through LLM-based chatbots.","Pranav Goel, Kai-Cheng Yang, David Lazer",Vingen 3+4,Online Platforms & Algorithms I,4,,343
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Recommender Systems for Democracy: Toward Adversarial Robustness in Voting Advice Applications,"Voting advice applications (VAAs) help millions of voters understand which political parties or candidates best align with their views. This paper explores the potential risks these applications pose to the democratic process when targeted by adversarial entities. In particular, we expose 11 manipulation strategies and measure their impact using data from Switzerland’s primary VAA, Smartvote, collected during the last two national elections. We find that altering application parameters - such as the matching method - can shift a party’s recommendation frequency by up to 105\%. Cherry-picking questionnaire items can increase party recommendation frequency by over 261\%, while subtle changes to parties’ or candidates’ responses can lead to a 248\% increase. To address these vulnerabilities, we propose adversarial robustness properties VAAs should satisfy, introduce empirical metrics for assessing the resilience of various matching methods, and suggest possible avenues for research toward mitigating the effect of manipulation. Our framework is key to ensuring secure and reliable AI-based VAAs poised to emerge in the near future.","Frédéric Berdoz, Dustin Brunner, Yann Vonlanthen, Roger Wattenhofer",Vingen 3+4,Online Platforms & Algorithms I,5,,222
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Modeling Link Recommendations as a Network Growth Mechanism and their Impact on Social Contagion,"Link recommendation algorithms significantly shape online social networks, influencing both their structural evolution and critical processes such as information and behavior spread. This paper investigates how these algorithms affect simple and complex contagion processes by modeling recommendations as addi- tional network growth mechanisms. We introduce a synthetic network model that integrates preferential attachment, triadic closure, and choice homophily, then extend it with various link recommenders, including heuristics and graph neural networks (GNNs). Our findings show that while simple contagions exhibit relatively modest shifts under most recommenders, complex contagions are highly sensitive to clustering- and homophily-based recommendations, thriving at moderate recommendation strengths but sharply diminishing under excessive recommendation strength. These results underscore the nuanced interplay between network structure, recommendation strength, and contagion dynamics, highlighting the importance of incorporating social contagions into the design of link recommendation algorithms","Björn Komander, Jesus Cerquides, Jeffrey Chan, Azadeh Alavi",Vingen 3+4,Online Platforms & Algorithms I,6,,987
,,,,,,,,,,
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,In-group Favoritism or Out-group Hostility? Exploring Political Bias in YouTube Recommendation System,"YouTube is the most widely used social media platform globally, with 83% of Americans (Gottfried, 2024) and 868.4 million users worldwide (Statista, 2024). With its rapid rise in popularity, there is growing concern about the platform's potential to radicalize users through algorithmic recommendations. For example, its algorithmic system recommends ideologically like-minded or extreme content to users, potentially leading them down to rabbit holes (Bryant, 2020; Haroon et al., 2023). While extensive research has examined the ideological congeniality (pro- or counter-attitudinal) of recommended YouTube videos, little is known about the specific types of content within these recommendations. To address this gap, this study explores the types of pro-attitudinal content recommended by YouTube based on the framework of group identity. Specifically, we differentiate pro-attitudinal content into two types: in-group favoritism and out-group hostility. We rely on YouTube audit data from simulated user profiles, referred to as 'sock puppets' developed by Haroon et al. (2023). A total of 100,000 sock puppets were classified into five ideological groups: Far Left, Left, Center, Right, and Far Right. From October 2021 to May 2022, these sock puppets retrieved 5,411,122 videos from homepage recommendations and 16,632,184 videos from up-next recommendations. To capture political content, we filtered videos that mentioned political elites by name or included specific political keywords such as 'GOP,' 'Dem,' and 'Rep.' Additionally, we restricted the analysis to recommended videos from news channels, excluding those from non-news sources. We then identify whether each sock puppet was recommended videos favorable to its in-group or out-group, based on the alignment between its political ideology and the content of the videos. Specifically, we categorized recommended video content as positive, negative, or neutral toward Republicans or Democrats. For the video content classification, we leverage a large language model, OpenAI’s GPT-4o. Our preliminary analysis using a small sample of 5,026 recommendation videos for Far Left sock puppets and 4,974 for Far Right sock puppets shows that out-group hostility in YouTube recommendations is approximately four times greater than in-group favoritism. We also observed significant differences in recommendation patterns within pro-attitudinal content. Far Right users were recommended twice as many out-group hostile videos as Far Left users, whereas Far Left users received more videos favoring their in-group. These findings suggest that YouTube's recommendation algorithm may employ different strategies for engaging users based on group identity, favoring in-group dynamics for Far Left users while attacking out-group dynamics for Far Right users. In our main analysis, we will extend the dataset to include the full sample of recommended videos. Furthermore, we will explore whether this pattern is influenced by YouTube news channels as the supply side. We will systematically examine whether the news channels produce a bias toward one political stance over another. To conclude, this study has the potential to demonstrate how artificial intelligence shapes information consumption through social media algorithms.","Claire Wonjeong jo, Xudong Yu, Magdalena Wojcieszak",Vingen 3+4,Online Platforms & Algorithms II,1,,345
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Systematic Bias or Congeniality? Auditing YouTube Recommendation Algorithms from a Longitudinal Perspective,"Background and Previous Research: As a primary news source for over 200 million U.S. users (Statista, 2024), YouTube’s recommendation system drives 70% of content exposure (Pew Research Center, 2020). Concerns persist that its algorithm reduces information diversity (Roth et al., 2020), amplifies polarization (Roose, 2019), or exhibits systematic biases. Scholars debate whether YouTube’s algorithm reflects systematic biases (e.g., favoring specific partisan content) or congeniality (reinforcing users’ preferences). Systematic bias arguments are based on the supply-demand perspective of platform design (Munger & Phillips, 2022), and empirical studies showing disproportionate amplification of either left-wing (e.g. Ibrahim et al., 2023) or right-wing channels (e.g. Kaiser & Rauchfleisch, 2020). Conversely, congeniality theories emphasize “filter bubbles,” where conservatives receive right-leaning content and liberals left-leaning content (e.g. Haroon et al., 2023). However, longitudinal analyses are scarce, and prior work overlooks event-driven algorithmic shifts. Our study aims to bridge these gaps . Based on discussions above, this paper aims to address the following research questions: RQ1: Does the YouTube recommendation algorithm exhibit systematic ideological bias by consistently promoting left- or right-leaning content regardless of users’ own ideological orientations, or does it provide recommendations that align with users’ political preferences? RQ2: Does the YouTube recommendation algorithm adapt its recommendation patterns over time, particularly in response to significant socio-political events? Dataset and Methods: Based on previous research by Haroon et al. (2023), our dataset includes 229,982 sock puppets across five ideologies, simulating users with distinct ideological leanings. Each puppet watched 100 ideologically labeled videos (30 seconds each) to establish viewing histories. Recommendations from YouTube’s homepage and up-next page were collected on a daily basis, in two separated phases due to computing resource limitations (see the descriptive statistics of the dataset in Table 1). We quantify the political leanings of recommendation results on video level and channel level by referring to existing datasets (Haroon et al., 2023, Wojcieszak et al., 2024). We calculate the daily average slant scores across different sock puppet groups to track the variation of algorithms. Then we conducted the Interrupted Time Series Analysis to test the changes over pre-identified major social political events statistically. Results: Preliminary findings demonstrate algorithmic congeniality: YouTube’s recommendations align with users’ ideological preferences, particularly on the homepage. Aggregated ideological scores across sock puppet groups (Figures 1a and 1b) reveal that far-right puppets received predominantly right-leaning content, while far-left puppets saw left-leaning suggestions, with statistically significant differences among all five ideological groups. Systematic fluctuations emerged in temporal analyses at both video and channel levels (Figures 2a and 2b), showing shifts in recommendation patterns independent of puppet ideologies. To further investigate whether the algorithm would change the mechanism as responses to major socio political news, we are conducting Interrupted Time Series Analyses on 10 major socio political events, with a 7 day window size. While analysis is ongoing, initial results suggest measurable algorithmic responsiveness to events with broad societal impact, underscoring the interplay between external contexts and recommendation mechanics.","Miner Ye, Magdalena Wojcieszak, Muhammad Haroon",Vingen 3+4,Online Platforms & Algorithms II,2,,406
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Gender and Dialect Bias in YouTube Spanish's Captioning System,"Spanish is the official language of twenty-one countries and is spoken by over 441 million people. Naturally, there are many variations in how Spanish is spoken across these countries. However, YouTube offers only one option for automatically generating captions in Spanish. This raises the question: could this captioning system be biased against certain Spanish dialects? This study examines the potential biases in YouTube’s automatic captioning system by analyzing its performance across various Spanish dialects. By comparing the quality of captions for female and male speakers from different regions, we identify systematic disparities which can be attributed to specific dialects while observing limited differences with respect to gender.","Iris Dania Jimenez, Christoph Kern",Vingen 3+4,Online Platforms & Algorithms II,3,,108
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Subscribers Count! Modeling Content Creation through Archival Exhaustion,"In this work, we contribute a methodology for studying content creation on the platform over time. We utilize archival resources (Wayback Machine, Common Crawl) to construct a dataset of over 100 million channels, as well as high-resolution time series captures of their channels over time. We end with a case study, showing the ability to study how changes in the platform's recommendation system impacted the content created on the platform.","Chloe Eggleston, Maria Leonor Pacheco",Vingen 3+4,Online Platforms & Algorithms II,4,,1044
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Understanding the Role of Platform Curation and User Agency in Partisan and Unreliable News Consumption,"Across search engine results or social media feeds, the news content to which users are exposed is algorithmically determined. These algorithms, while proprietary and opaque, tend to include user-specific and platform-specifc components. Beyond initial exposure, users exercise their agency in choosing a particular news article to engage with by clicking on the link seen in search results or on a particular social media feed. Across many different platforms such as Google search, Bing search, Google news, Facebook, Reddit, Twitter/X, and ChatGPT, our work studies two important dimensions of online news consumption patterns: the gap between exposure to and engagement with news sites (within specific platforms), and differences across platforms that mediate news exposure and engagement. Specifically, we study three research questions. First, within each specific platform, RQ1: What is the difference in the partisan lean of news sources and the proportion of unreliable news that partisan users get exposed to versus choose to engage with on or through a specific platform? To understand the role of specific platforms in exposing users to certain types of news environment, we study RQ2: Across search engine and different social media platforms, which platform or platforms tend to expose users to higher amounts of partisan news segregation and unreliable news? Finally, we examine news visits rooted in different platforms as the source (engagement) to study: RQ3: Across different platforms, which platform or platforms tend to be the source of higher user engagement with partisan and unreliable news (after controlling for exposure)? All browsing activity and news visits (regardless of source) help serve as a baseline. Our study offers a comprehensive examination of how partisan segregation and unreliable news consumption vary for both user exposure and engagement across different major platforms.","Pranav Goel, Christo Wilson, David Lazer",Vingen 3+4,Online Platforms & Algorithms II,5,,211
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Beyond Time Delays: How Ex-Situ Web Scraping Distorts Measures of Online News Consumption,"As the exploration of digital behavioral data revolutionizes communication research, understanding the nuances of data collection methodologies becomes increasingly pertinent. This study focuses on one prominent data collection approach, web scraping, and more specifically, its application in the growing field of research relying on web browsing data. We investigate discrepancies between content obtained directly during user interaction with a website (in-situ) and content scraped using the URLs of participants’ logged visits (ex-situ) with various time delays (0, 30, 60, and 90 days). We find substantial disparities between the methodologies, uncovering that errors are not uniformly distributed across news categories regardless of classification method (domain, URL, or content analysis). These biases compromise the precision of measurements used in existing literature. The ex-situ collection environment is the primary source of the discrepancies (~33.8%), while the time delays in the scraping process play a smaller role (adding ~6.5 percentage points in 90 days). Our research emphasizes the need for data collection methods that capture web content directly in the user's environment. However, acknowledging its complexities, we further explore strategies to mitigate biases in web-scraped browsing histories, offering recommendations for researchers who rely on this method and laying the groundwork for developing error-correction frameworks.","Roberto Ulloa, Frank Mangold, Felix Schmidt, Judith Gilsbach, Sebastian Stier",Vingen 3+4,Online Platforms & Algorithms II,6,,151
,,,,,,,,,,
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Analyzing News Engagement on Facebook: Tracking Ideological Segregation and News Quality in the Facebook URL Dataset,"The Facebook Privacy-Protected Full URLs Dataset was released to enable independent, academic research on the impact of Facebook’s platform on society while ensuring user privacy. The dataset has been used in several studies to analyze the relationship between social media engagement and societal issues such as misinformation, polarization, and the quality of consumed news. In this paper, we conduct a comprehensive analysis of the engagement with popular news domains, covering four years from January 2017 to December 2020, with a focus on user engagement metrics related to news URLs in the U.S. By incorporating the ideological alignment and quality of news sources, along with users' political preferences, we construct weighted averages of ideology and quality of news consumption for liberal, conservative, and moderate audiences. This allows us to track the evolution of (i) the ideological gap in news consumption between liberals and conservatives and (ii) the average quality of each group's news consumption. We identify two major shifts in trends, each tied to engagement changes. In both, the ideological gap widens and news quality declines. However, engagement rises in the first shift but falls in the second. Finally, we contextualize these trends by linking them to two major Facebook News Feed updates. Our findings provide empirical evidence to better understand user behavior, polarization, and misinformation during the period covered by the dataset.","Emma Fraxanet, Andreas Kaltenbrunner, Fabrizio Germano, Vicenç Gomez",Concert hall,Misinformation,1,,439
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Limiting Exposure to Elites and Political Content on Social Media Can Reduce Polarization and Susceptibility to Misinformation,"Social media platforms are increasingly scrutinized for their role in political polarization and the spread of misinformation. Although past research has focused on echo chambers, emerging evidence suggests that exposure to elites and general political content may be more consequential. In this study, we conducted a pre-registered field experiment following the 2024 U.S. Presidential election. A total of 1,595 participants were recruited via Cloud Research to use a custom client for X (formerly Twitter), which maintained core functionalities while allowing experimental manipulation of timelines. Participants were randomly assigned to one of four conditions: elite-muting, keyword-and-elite muting, a demetricated placebo (with engagement metrics hidden), or an unaltered control. Over four weeks, we measured affective polarization, social identity, and misinformation susceptibility through pre- and post-surveys, while tracking app usage for compliance. Results reveal that reducing exposure to political elites and broader political content significantly decreases affective polarization and misinformation vulnerability. In particular, the keyword-and-elite muting condition yielded the most pronounced effects, suggesting that limiting elite-driven messaging can reduce the reinforcement of partisan identities and mitigate the spread of misinformation. Unlike strategies focused solely on dismantling echo chambers, our findings emphasize that the broader exposure to political information—especially from influential elites—is a critical driver of both polarization and misinformation susceptibility. This work highlights the need for social media platforms to address the pervasive influence of elite messaging in order to foster healthier political discourse.","Kokil Jaidka, Subhayan Mukerjee, Yphtach Lelkes",Concert hall,Misinformation,2,,284
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,"Social media algorithms can curb misinformation, but do they?","A recent article in Science by Guess et al. estimated the effect of Facebook’s news feed algorithm on exposure to misinformation and political information among Facebook users. However, its reporting and conclusions did not account for a series of temporary emergency changes to Facebook’s news feed algorithm in the wake of the 2020 U.S. presidential election that were designed to diminish the spread of voter-fraud misinformation. This issue may have led readers to misinterpret the results of that study and to conclude that the Facebook news feed algorithm used outside of the study period mitigates political misinformation as compared to reverse chronological feed. In this paper, we demonstrate that during the period of these emergency measures, which significantly overlapped with the Guess et al. experiment, the fraction of untrustworthy news views on Facebook dropped by 24%. We further discuss the broader research and societal implications of these findings.","Chhandak Bagchi, Filippo Menczer, Jennifer Lundquist, Monideepa Tarafdar, Anthony Paik, Przemyslaw A. Grabowicz",Concert hall,Misinformation,3,,866
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,"Distracting, Reinforcing, or Debunking: Auditing Google’s Reverse Image Search in Fact-Checking Visual Misinformation","As visual misinformation spreads online, reverse image search (RIS) has been proposed as a fact-checking tool for tracing an image’s contextual metadata, yet its practical effectiveness remains unclear. This study audits Google RIS to examine the types of content it retrieves when verifying visual misinformation and how these results change over time. Using a dataset of 95 misleading images sourced from fact-checking websites, we submitted them to Google RIS and collected 34,486 links and metadata. Content analysis reveals that a substantial portion of retrieved content is distracting information irrelevant to the searched images and events. Misinformation is frequently repeated, while debunking content appears less often. The effectiveness of Google RIS varies by misinformation type and topic: out-of-context misinformation yields the least debunking content compared to others, and political misinformation receives more debunking content than non-political misinformation. Mixed-effects logistic regression confirms these patterns. Additionally, google RIS has also shown a decline in distracting content and an increase in debunking results over time. This study expands research on search engines as fact-checking tools by examining their effectiveness in addressing visual misinformation. It challenges prior assumptions about RIS’s ability to reliably trace original image context and offers insights into how its performance evolves over time.","Cong LIN, YIFEI CHEN, Jiangyue Chen, Cuihua Shen, Yilang Peng, Yingdan Lu",Concert hall,Misinformation,4,,502
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Truth Warrants Reduce Misleading Claims on Digital Platforms,"Misleading online advertisements in digital marketplaces deceive buyers of online goods, posing significant challenges to platform integrity and buyer protection. Existing content moderation and reputation systems have proven insufficient in addressing the root incentives that drive false advertising. This paper introduces a novel market-based mechanism, “truth warrants” that allows online advertisers to guarantee the accuracy of their claims, and presents buyers with the ability to seek recourse when they are misled. Through a series of controlled online experiments in a two-sided digital marketplace, we demonstrate that introducing self-certification for advertisements reduces the prevalence of misleading ads by penalizing cheating advertisers that make false claims, and promotes accountability among online advertisers, without affecting the profits or sales of honest advertisers. This research contributes to market design, human-computer interaction, and social computing, offering an empirically validated intervention with implications for platform governance and commercial misinformation.","Swapneel S Mehta, Aaron D Nichols, Nina. Mazar, Marshall Van Alstyne",Concert hall,Misinformation,5,,950
,,,,,,,,,,
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Who's Heard and Who Decides?: Strategic Incentives in Model-Driven Social Evaluation,"We examine a model-driven, community-based algorithm that aggregates user reports to evaluate content quality—the core mechanism behind Birdwatch/Community Notes on the platform X. Bridging social choice and machine learning literature, we assess this algorithm’s impact on minority viewpoints and the incentives it creates for users to misrepresent their perspectives. We develop a theoretical and simulation-based framework to analyze how Birdwatch’s matrix-factorization-based aggregation mechanism interacts with different population structures. Our results indicate that population shifts and model choices significantly influence quality estimation from community feedback. Minority perspectives can be systematically disadvantaged, potentially exacerbating viewpoint imbalances. Moreover, users have strategic incentives to feign extreme ideological positions, amplifying polarization rather than mitigating it. Model selection, particularly regularization, plays a critical role in moderating these effects—switching from $L_2$ to $L_1$ regularization can mitigate the effects above. These findings highlight the importance of an interdisciplinary perspective at the intersection of computational social choice, mechanism design, and ML fairness to understand how model-driven community-based mechanisms create both estimates and strategic incentives.","David Gamba, Seura Ha, Daniel Romero, Grant Schoenebeck",Vingen 8,Communication & Cooperation I,1,,825
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Rich Talk: How Communication Predicts Cooperative Behavior,"Communication is a powerful antidote to defection in social dilemmas. But while the effects of communication have been known for decades, the mechanisms for this effect are less well understood. In this work, we use natural language processing to disambiguate “cheap talk” from “rich talk” — identifying meaningful signals of cooperative behavior from conversational data. We study a large corpus of online multiplayer public goods games, and we measure 63 features capturing various theories about the role of communication in economic games. We find that the mere existence of a communication channel facilitates higher rates of contribution, even when it is not in use. Among groups that did communicate, we find that norm statements emerge as a strong predictor of cooperation.","Xinlan Emily Hu, Mohammed Alsobay, Jared R. Curhan, Abdullah Almaatouq",Vingen 8,Communication & Cooperation I,2,,617
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,“I understand your perspective”: LLM Persuasion through the Lens of Communicative Action Theory,"Public discourse is essential for shaping opinions, exposing individuals to diverse perspectives, and challenging existing beliefs. In today’s digital landscape, this discourse is no longer limited to content produced by humans—AI-generated content, particularly those produced by Large Language Models (LLMs), is becoming increasingly prevalent. Despite their growing presence, the impact of LLMs on opinion formation and change remains largely unknown. *What role do LLMs play in public discourse, particularly in shaping and changing opinions?* We investigate the persuasive capabilities of LLMs through the lens of Jürgen Habermas’ Communicative Action Theory, examining whether these models express illocutionary intents (i.e., pragmatic meanings of language such as conveying knowledge, trust, or similarity) comparably to humans. In particular, we simulate an online discussion between an opinion holder and an LLM using conversations from the persuasive subreddit ChangeMyView. We then compare the odds of illocutionary intents in human-written opinion-changing counter-arguments and LLM-generated ones. Our findings show that LLMs are capable of engaging in *nuanced communicative actions*, potentially shaping human opinions in ways not yet fully understood. Potentially, LLM alignment training not only reinforces existing human biases but also makes individuals more susceptible to AI-driven influence on critical issues such as politics, social justice, and the environment. Given these concerns, we call for further research into the impact of alignment training on public discourse and opinion formation.","Esra Dönmez, Agnieszka Falenska",Vingen 8,Communication & Cooperation I,3,,353
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Increasing Effective Charitable Giving with Personalized LLM Conversations,"Despite substantial charitable giving, donations often fail to maximize impact. While a variety of persuasive strategies have been shown to increase charitable donations to effective charities, their success depends heavily on individual differences. Large Language Models (LLMs) offer a powerful solution to this problem by dynamically personalizing persuasive strategies to each individual. In a large-scale, pre-registered experiment, we tested whether personalized LLM conversations could increase donations to the Against Malaria Foundation (AMF), rated one of the world’s most effective charities. Participants allocated $1 between their favorite charity and AMF after being assigned to one of three conditions: (1) a personalized persuasive LLM conversation, (2) a static LLM-generated persuasive message, and (3) a control conversation. Personalized LLM conversations significantly increased donations to AMF by 46.6%, outperforming the static message condition (28.7% increase), while the control condition showed no significant change. Personalized LLMs also shifted moral attitudes about charitable giving. Our findings highlight the potential of AI-driven personalization to enhance effective giving and provide new insights into the psychology of charitable persuasion. (Extended abstract in PDF)","Joshua P. White, Carten Allen, Lucius Caviola, Thomas Costello, David Rand",Vingen 8,Communication & Cooperation I,4,,504
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Conversational receptiveness is contagious and reduces affective polarization,"Constructive disagreement is crucial to solving pressing societal problems, yet often devolves into destructive interpersonal conflict. What shapes the trajectory of conflictual conversations? Here, we focus on conversational receptiveness—the use of language to behaviorally demonstrate one’s thoughtful engagement with opposing views—and its transmission between disagreeing parties in dialogue. We use a multidisciplinary and multimethod approach (collective N = 17,184) to test whether and how conversational receptiveness shapes disagreeing counterpart behavior and evaluations of each other, thereby improving conflict outcomes. We first report the development of an updated algorithm for measuring receptiveness in text. Using the updated algorithm, we find that conversational receptiveness enacted by one party predicts receptiveness by the other among students in online class forums (Study 1) and government leaders in the laboratory (Study 2). In pre-registered, well-powered, and replicated experiments, we find that training one individual in this technique also increased its use by a political opponent (Study 3) and that a single use of receptiveness improved interpersonal (and intergroup) evaluations. This transmission is distinct from mimicry or emotion contagion and is driven by a deeper shift in linguistic style, which we term indirect accommodation. Together, we find that conversational receptiveness is effective not only for shifting behavior during a focal disagreement, but also for shifting subsequent interpersonal and intergroup evaluations, providing disagreeing parties with a path around destructive conflict spirals. Broadly, our research emphasizes the importance of studying how linguistic behavior shapes conflict dynamics.","Michael Yeomans, Julia Minson, Hanne Collins, Charles Dorison",Vingen 8,Communication & Cooperation I,5,,649
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Patterns of Consistency in Large Language Model Outputs for Social Media Conversations,"Large language models (LLMs) have the potential to influence social media discourse, yet their emotional consistency and semantic alignment with human-generated content are not well understood. This paper evaluates the emotional intensity and semantic similarity between LLM-generated and human-generated texts in climate change discussions across two types of tasks: responses and continuations. Using two LLMs, Gemma and Llama, we analyze emotional patterns and emotional intensity using Twitter and Reddit data. Our findings reveal that LLMs exhibit a bias toward positive emotions in response tasks and a systematic transformation of negative emotions into positive ones. Additionally, LLMs show moderate emotional intensity compared to human texts, highlighting challenges in conveying deep emotional nuance. This research contributes to understanding the role of LLMs in shaping online interactions, particularly in emotionally charged contexts like climate change discussions.","Fan Wenlu, Yuqi Zhu, Wentao Xu",Vingen 8,Communication & Cooperation I,6,,494
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Understanding the Time-to-Persuasion in Multi-Round Discussions,"Persuasion is a fundamental aspect of communication, shaping opinions, decision-making, and behavior across various domains, including politics, marketing, and online discourse. Prior research has extensively explored persuasive strategies such as counterarguments, rhetorical questions, and concessions, demonstrating their effectiveness in influencing attitudes (Selicka, 2024; Musi et al., 2018). Additionally, studies on the cumulative exposure effect suggest that repeated exposure to persuasive messages enhances persuasion but with diminishing returns (Cacioppo & Petty, 1979; Koch & Arendt, 2017). However, while these studies offer valuable insights into persuasion mechanisms, they primarily focus on single-exposure effects or static argument structures rather than the dynamic, interactive nature of persuasion. In online discussions, persuasion is rarely a one-time event; instead, it unfolds over multiple conversational rounds, with participants engaging in iterative exchanges before reaching a conclusion. Despite this, little is known about how the number of conversational rounds affects persuasion success. This study investigated the relationship between the number of conversational rounds and persuasion success in online discussions. While prior research has categorized persuasive argumentation techniques (Egawa et al., 2020) and examined their effectiveness in various contexts, it has not explicitly addressed how the length of a persuasive exchange influences the probability of success. We hypothesize that the likelihood of persuasion success follows a time-dependent pattern influenced by the number of conversational rounds, engagement levels, conversation topic, and argumentative strategies. To test these hypotheses, we employed Cox proportional hazards survival analysis to model the probability of persuasion success over multiple conversational rounds. Survival analysis is well-suited for this task, as it allows us to estimate the likelihood of persuasion occurring at each conversational round while accounting for censoring (cases where persuasion may not have been achieved within the observed interaction window). Our study analyzed a large corpus of online persuasive discussions from subreddit /r/ChangeMyView, estimating conversation topics and key argumentative strategies along with the engagement metrics to determine their effects on persuasion success. Model 1 showed that higher engagement (operationalized as the number of delta threads and engaged threads) significantly increases the hazard of persuasion occurring sooner, meaning persuasion is more likely to happen earlier in a conversation. In contrast, a greater maximum number of turns in engaged threads is associated with a lower hazard, suggesting that longer discussions delay or reduce the probability of persuasion success at any given round. Model 2 included topics, and we found that topic effects on persuasion timing are weak overall. While discussions on foreign policies and gun control issues show a lower hazard, indicating that persuasion takes longer or is less likely to occur in these discussions, most other topics do not exhibit significant effects. This suggests that the difficulty of persuading someone may be topic-dependent, but topic effects alone do not strongly dictate the timing of persuasion success. Model 3 examined the effect of argumentative strategies. Specific techniques significantly impact how quickly persuasion occurs. The use of concessions, rebuttals, and emotional appeals (both positive and negative) increases the hazard of persuasion, meaning that these strategies accelerate the likelihood of persuasion success within fewer conversational rounds. Concessions have the strongest effect, suggesting that acknowledging opposing viewpoints can expedite persuasion by building credibility and fostering agreement. The improvement in model concordance from 0.782 in Model 1 to 0.824 in Model 3 indicates that incorporating argumentative strategies enhances the model’s predictive accuracy in estimating when persuasion is likely to occur. These results highlight the dynamic nature of persuasion, demonstrating that engagement, argumentation strategies, and discussion topics collectively shape when persuasion is achieved in an ongoing conversation.","Wanting Wang, Haoran Shi",Vingen 8,Communication & Cooperation II,1,,1050
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,"Learn, Explore and Reflect by Chatting: Understanding the Value of an LLM-Based Voting Advice Application","Voting Advice Applications (VAAs) have become widely used digital tools in Europe, particularly in multiparty systems like Germany, to help voters identify the political parties that align with their policy preferences. Studies have shown that VAAs enhance political knowledge [6, 13], increase political engagement, and boost voting intention [13, 8]. However, despite their popularity, traditional VAAs face significant challenges that limit their effectiveness in fostering informed democratic participation. These challenges include comprehension problems [3] due to the use of complex terminology, a skewed adoption towards young, educated, and politically engaged users [10, 1, 7, 12], and a rigid presentation of policy statements that does not cater to individual voters’ curiosity and informational needs. To address these limitations, prior research has suggested integrating explainer chatbots into VAAs to address comprehension challenges [4, 11]. Yet an LLM-based conversational chatbot’s potential as a tool for tailored discussion and deliberate decision-making [9, 2] remains untapped. In this study, we investigate (1) how an LLM-based chatbot can address the limitations of traditional VAAs, (2) what additional value a conversational interface can bring to voters, and (3) what obstacles to trusted utilization of VAA chatbots need to be overcome. We deployed a prototype VAA chatbot (Figure 1) that allowed users to engage in two ways with electoral information: a ChatGPT-like interaction involving freeform questions and responses, and a structured survey format mimicking traditional VAAs with policy statements and stance selection. A total of 331 participants interacted with the chatbot in our user study prior to the 2024 European Parliament Election in Germany and completed a survey. We followed up with 10 participants with in-depth interviews to gather qualitative insights. Our exploratory mixed-methods approach prioritized understanding users’ informational needs and value of such tools over refining specific UI elements or model parameters, ensuring that findings contribute broadly to future chatbot design for civic education. Our study revealed several key findings: First, participants found the chatbot notably more accessible than traditional VAAs. The ability to clarify complex political terms on demand and provide tailored explanations lowered barriers to engagement, making political information more digestible. The chatbot’s flexibility in responding to individuals’ curiosity was frequently cited as a strength, as it allowed users to navigate political topics at their own pace and according to their interests. Secondly, beyond merely providing voting advice, the conversational format of the chatbot facilitated curiosity-driven exploration and self-reflection. Users reported that the chatbot encouraged them to think critically about their own opinions, explore different political perspectives, and engage more deeply with policy discussions. The chatbot’s ability to simulate dialogue and present counterarguments contributed to a richer, more deliberative form of voter education compared to traditional VAAs, which often reduce political alignment to a numerical ranking. Thirdly, concerns about trustworthiness and transparency emerged as clear obstacles to user trust. Participants expressed skepticism due to LLMs’ known limitations, particularly their susceptibility to generating incorrect or biased information. While users appreciated the chatbot’s informative nature, many emphasized the importance of verifiable sources and transparency in how responses were generated. The majority of interviewees explicitly stated that they would like to see references accompanying the chatbot’s claims to enhance credibility. Additionally, some users worried that the chatbot might only reinforce their personal pre-existing opinions rather than challenge perspectives, raising questions about how such tools should be designed to promote balanced and objective discourse. Our findings suggest that LLM-based VAA chatbots hold significant potential for expanding the reach and effectiveness of digital civic education by making political information more accessible, engaging, and interactive. However, to build justified user trust [5], future designs must prioritize transparency, accountability, and neutrality. We propose several design recommendations, including the integration of source traceability, third-party audits, and mechanisms that actively encourage critical thinking rather than passive agreement. We hope our work inspires further exploration in designing trusted LLM-based systems that empower citizens to better understand their political landscape, critically reflect on their opinions, and actively engage as an informed stakeholder in democratic processes.","Jianlong Zhu, Manon Lilott Kempermann, Vikram Kamath Cannanure, Alexander Hartland, Giuseppe Carteny, Rosa M. Navarrete, Daniela Braun, Ingmar Weber",Vingen 8,Communication & Cooperation II,2,,1029
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Manager or Interlocutor: How Facilitator Styles Shape Public Deliberation,"Facilitated dialogue - the art of hosting meaningful conversations - remains underexplored from a computational perspective. In this study, we leverage embeddings, large language models, and lexicon-based methods to quantify and categorize facilitator styles and participant roles in small-group conversations. Using the Fora Corpus, which comprises 262 facilitated conversations (39,911 speaker turns, with 25% manually annotated for personal storytelling and experiences), we extend existing annotations via few-shot prompting and incorporate phatic speech as a distinguishing feature between social talk and substantive contributions. Our approach establishes a taxonomy of facilitator styles by integrating psycholinguistic traits, constructive communication metrics, and speech act analysis. We identify two distinct styles: a managerial approach - characterized by a focus on balancing turn-taking - and an interlocutor approach that emphasizes direct engagement with participants. Notably, the managerial style correlates with a statistically significant increase in turn-taking equity and a higher personal sharing ratio. Further analysis reveals emergent participant roles, including Storytellers, Socializers, and Debaters, each contributing uniquely to the dynamics of dialogue. These findings offer new insights into the interplay between facilitator style, conversational structure, and participant behavior, advancing the computational study of facilitated dialogue and providing a robust basis for future research.","Paul Fromm, Michael A. Hedderich, Brandon Roy",Vingen 8,Communication & Cooperation II,3,,372
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,A Framework for Auditing Chatbots for Dialect-Based Quality-of-Service Harms,"Increasingly, individuals who engage in online activities – including everyday ones like web searching and high-stakes ones like e-filing taxes – are expected to interact with large language model (LLM)-based chatbots. Prior work has shown that LLMs can display dialect bias, which occurs when they produce harmful responses when prompted with text written in minoritized dialects. However, whether and how this bias propagates to systems built on top of LLMs, such as chatbots, is still unclear. To address this, we present a framework for auditing LLM-based chatbots for dialect bias by measuring the extent to which they produce quality-of-service harms, which occur when systems do not work equally well for different people. The framework consists of five steps: target identification, prompt collection, prompt perturbation, response collection, and disaggregated evaluation. The framework has several key characteristics that make it useful in practice. First, by leveraging dynamically generated instead of pre-existing text, our framework enables testing over any dialect, facilitates multi-turn conversations, and represents how users are likely to interact with chatbots in the real world. Second, by measuring quality-of-service harms, our framework aligns audit results with the real-world outcomes of chatbot use and also calls attention to the often under-measured quality of AI functionality. Third, our framework requires only query access to an LLM-based chatbot, meaning that it can be leveraged equally effectively by internal auditors, external auditors, and even individual users in order to promote accountability. We present a case study of our framework applied to Amazon Rufus, a widely-used LLM-based chatbot in the customer service domain. We find that Rufus is more likely to produce low-quality responses when prompted in minoritized dialects, and that this effect is exacerbated by the presence of typos in the prompt.","Emma Harvey, Rene F Kizilcec, Allison Koenecke",Vingen 8,Communication & Cooperation II,4,,115
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Spoken Conversation Facilitates Constructive Disagreement,"With rising political and social dissent across the world, finding ways to constructively disagree is a global imperative. The current paper examines whether a structural aspect of disagreement–the communication medium by which it occurs–can enhance constructive outcomes. Across nine randomized experiments (n=1,576 conversation partners and 1,432 observers who rated the conversations) we show that spoken conversations elicit higher understanding, lower experienced conflict, more favorable impressions of one’s counterpart, and more attitude alignment compared to written conversations. At least one reason for this result is that, in speech, people communicate with greater receptiveness (i.e., linguistic cues that demonstrate listening and intellectual humility), which mediates the effect of medium on constructive outcomes. However, conversation medium also moderates the effect of receptiveness: linguistic receptiveness is a significantly better predictor of constructive disagreement for written than spoken conversations, suggesting people use receptive language less often in the very context (i.e., writing) when it is most effective. Furthermore, people mis-estimate how the medium affects their conversations, incorrectly predicting that spoken conversations will be less constructive than written ones. If people are willing to engage in it, spoken conversation is a promising means for facilitating constructive disagreement.","Burint Bevis, Juliana Schroeder, Michael Yeomans",Vingen 8,Communication & Cooperation II,5,,633
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,AI-Driven Conflict Detection in Teams,"In organizational and social settings, people often work in teams, where conflicts are inevitable. Such conflicts can have a significant impact on team performance and cohesion. Identifying and mitigating conflicts in team interactions is crucial to fostering productive activities and relationships. Prior conflict detection methods have relied mainly on classical machine learning models, focusing primarily on interpersonal (i.e., relationship) conflicts alone. However, conflicts are more varied, including not only interpersonal issues but also task conflicts that stem from differing perspectives or approaches towards the work itself. Detecting the distinct conflict types is crucial since they have differential impacts on team performance. In this research, we first develop a novel, synthetic team conflict dataset (SWD) designed to distinguish between these conflict types and their varying levels. We propose a team conflict detection approach that utilizes multi-feature embeddings (MFemb), incorporating structural (dialogue acts and entrainment) and affective (sentiment and emotion) features to capture nuanced states in conversations. A range of computational models are proposed, including MFemb-enhanced classical models (Logistic Regression, SVM and Random Forest), MFemb-enhanced language models (BERT and RoBERTa) and large language models (GPT-4o and Gemini 1.0 Pro). Experiments on four datasets (including ours) demonstrate the superior performance of our approach, with F1 scores of up to 0.95 for conflict type and 0.86 for conflict intensity, significantly improving upon the baselines. This sets a new benchmark in the field and offers novel insights into the detection and mitigation of team conflicts.","Astha Verma, Pratyush Yadav, atreyi",Vingen 8,Communication & Cooperation II,6,,135
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,"Love at First Swipe: Online Dating, Assortative Mating, and Marriage Outcomes in Europe Using Machine Learning-Based Causal Inference","This study investigates the impact of online dating on marital and fertility outcomes and partnership heterogamy (education, age, and nativity), as well as the moderating role of heterogamy across nine European countries using data from the second round of the Generations and Gender Survey (GGS-II). Using Augmented Inverse Probability Weighting (AIPW) to estimate the average treatment effect, results indicate that meeting a partner online consistently leads to a 10-30% lower likelihood of marriage and having biological children across sampled countries. However, online dating does not significantly impact relationship satisfaction or the likelihood of considering a breakup. AIPW and multinomial models further reveal that meeting the partner through online dating increases both education hypergyny and hypogyny, and that the effect on nativity heterogamy is mostly driven by hypergyny rather than hypogyny. In contrast, its effect on age heterogamy remains limited. To explore treatment effect heterogeneity, Causal Forests are applied, estimating individual treatment effects (ITE) across demographic groups. Results provide evidence for all three key gradients, namely an education gradient, nativity gradient, and cohort gradient. The varying characteristics of the education and nativity gradients in online dating’s effects likely reflect how strongly education and nativity structure social and romantic opportunities in different countries. The cohort gradient reveals that later-born cohorts experience weaker negative effects on marriage and fertility, reflecting shifting social norms and life course expectations. These findings highlight how online dating reshapes relationship trajectories in stratified ways, reinforcing existing social structures while expanding opportunities for diverse partnerships. Methodologically, this study advances causal inference in partner selection research by leveraging AIPW and Causal Forests, offering a fine-grained, cross-national perspective on contemporary dating and family formation.",Zerui Tian,Vingen 1+2,Digital Behavior,1,,189
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Expressing One’s Identity Online: Left–Right and cross EU-country variation in self-representation in social media,"We examine how social media users from eight European Union (EU) member states express their socio-political identities, focusing on users' online self-presentation and group identity cues conveyed through bios. Our goal is to explore commonalities and differences in topics discussed in social media profiles, across Left- and Right-wing user groups, within and across EU countries. Through a novel approach we map how identity-related discourse varies by country and political orientation, revealing how group identity is expressed within the EU. We find that topics related to democracy, national way of life, and decentralization emerge as particularly divisive, showing considerable variation both within and between EU countries. A subset of topics, which includes education, environmentalism, sustainability, equality, freedom & human rights, and traditional morality, among others, clearly differentiate Left- from Right-leaning user groups. These partisan topics are relevant as they could be leveraged for mobilizing ideological groups and highlight Left-Right identitarian differences at the EU level. Finally, we show that our Left-Right identity similarity metrics reflect aspects of real-world political fragmentation, which are closely aligned to the perceptions of political conflict intensity by country, as measured by the 2022 PEW survey.","Carlo Romano Marcello Alessandro Santagiustina, Jean-Philippe Cointet, Pedro Ramaciotti Morales",Vingen 1+2,Digital Behavior,2,,710
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Political learning during election campaigns: evidence from web tracking data,"To what extent citizens gain political knowledge during election campaigns has been a repeatedly investigated question in political science. Researchers take the assumption that citizens engage with the campaign, especially via news coverage, and learn about the most important events and issues. However, due to a lack of content data and imprecise self-reported measures of media use, it has so far been difficult to directly link exposure with measures of political learning. In this paper, we use linked panel surveys and web tracking data collected from more than 700 study participants during the 2021 German federal election. In two survey waves, we implemented a series of political statements that participants had to rate as true or false. Results from a multiverse analysis that varies different online news content measures and other regression specifications show that online political news exposure is a consistently positive predictor of political learning, in contrast to more generic exposure measures. The substantive results demonstrate the value of moving beyond static political knowledge questions when aiming to measure political learning in dynamic media environments. Methodologically, the paper shows that linking fine-grained measures of digital behavior with surveys can provide new answers to established social science research questions.","Sebastian Stier, Felix Schmidt",Vingen 1+2,Digital Behavior,3,,845
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Exploring the Relationship Between Internet Users’ Search and News in Social Events Through Topic Extraction With Semantic and Trend Features,"In the era of big data, a large number of documents on the Internet have been produced. It is difficult to grasp an overview of information in these documents by reading each document. Thus, a method for topic extraction, that is, clustering many documents into topics, is needed. Previous studies only utilize natural language processing for topic extraction; therefore, they cannot detect the trends of topics and distinguish the direct correlation between keywords among topics. To overcome this difficulty, this paper proposes a novel method for topic extraction utilizing both semantic and trend features to explore the relationship between Internet users’ search and news in social events. Specifically, we use graphical lasso-guided iterative principal component analysis (GLIPCA) for trend clustering and use Affinity Propagation to semantically cluster word embedding of keywords (Word2Vec/ SentenceBERT) into topics. Our method can detect trends by time-series signal processing and remove the indirect correlation between keywords that support in clarifying the actual relationship between topics. To validate the effectiveness of proposed methods, we compare our method with other methods by F-score, ARI, and AMI. As a result, our method outperforms with other methods. The proposed method provides insights into exploring information from a keyword perspective, which is especially useful for detecting important trends in information on the Internet.","Hoan Huu Le, Ryosuke Harakawa, iwahashi",Vingen 1+2,Digital Behavior,4,,259
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Understanding the Digital Divide in AI Adoption: Predictors of ChatGPT Usage from German Web Tracking Data,"A major challenge of our time is reducing disparities in access to and effective use of digital technologies, with recent discussions highlighting the role of AI in exacerbating the digital divide. We examine user characteristics that predict usage of the AI-powered conversational agent ChatGPT. We combine behavioral and survey data in a web tracked sample of N = 1376 German citizens to investigate differences in ChatGPT activity (usage, visits, and adoption) during the first 11 months from the launch of the service (November 30, 2022). Guided by a model of technology acceptance (UTAUT-2), we examine the role of socio-demographics commonly associated with the digital divide in ChatGPT activity and explore further socio-political attributes identified via stability selection in Lasso regressions. We confirm that lower age and higher education affect ChatGPT usage, but do not find that gender or income do. We find full-time employment and more children to be barriers to ChatGPT activity. Using a variety of social media was positively associated with ChatGPT activity. In terms of political variables, political knowledge and political self-efficacy as well as some political behaviors such as voting, debating political issues online and offline and political action online were all associated with ChatGPT activity, with online political debating and political self-efficacy negatively so. Finally, need for cognition and communication skills such as writing, attending meetings, or giving presentations, were also associated with ChatGPT engagement, though chairing/organizing meetings was negatively associated. Our research informs efforts to address digital disparities and promote digital literacy among underserved populations by presenting implications, recommendations, and discussions on ethical and social issues of our findings.","Roberto Ulloa, Celina Kacperski, Denis Bonnay, Juhi Kulshrestha, Peter Selb, Andreas Spitz",Vingen 1+2,Digital Behavior,5,,158
,,,,,,,,,,
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Collective Moral Reasoning in Multi-Agent LLMs,"What happens when artificial agents debate moral dilemmas together? As AI ensembles increasingly assist in ethically complex political and health domains, understanding how large language models (LLMs) reach moral consensus is critical. This study investigates how multi-agent LLMs negotiate moral decisions and explores their potential alignment—or misalignment—with human collective moral reasoning. Understanding collective moral deliberations in LLMs is particularly important in light of recent research identifying trends in LLMs’ judgments. Proprietary LLMs, for example, appear more utilitarian than their open-weight counterparts (Tlaie, 2024): They try to maximize the concrete benefits for the greatest number of people rather than rely on rules for behavior. LLMs frequently favor utilitarian outcomes in ways that might misalign with human medical ethics (Sorin et al., 2024). But the tendencies depend on context, as LLMs tend to respond in a less utilitarian manner to personal (direct) versus impersonal (indirect) harms (Garcia et al., 2024). While these findings provide insights into individual LLM behavior, research has shown that the dynamics of multi-agent discussions can significantly alter AI judgments (Xu et al., 2024). Collective decision-making in humans results in more utilitarian judgments (Keshmirian et al., 2022). It is unclear if the same happens with multi-agent LLM systems. Our experiments address this gap. Building on prior moral (Greene et al., 2014; Keshmirian et al., 2022; Körner et al., 2022) and group decision-making research (Keshmirian et al., 2023; Rokosz et al., 2025; Curşeu et al., 2020), we presented LLM agents with personal dilemmas, impersonal dilemmas, and non-moral controls. We formed groups of 2, 3, or 4 GPT-3.5-Turbo agents, each initialized with an onboarding opinion (1–10 scale) randomized across the agents, with 10 representing complete moral acceptability of a proposed utilitarian action or inaction. To ensure a moderate range of viewpoints without excessive initial polarization, each group’s maximum difference among initial ratings was capped at 5 points. Agents participated in at least three sequential rounds of discussion, where agents could defend their positions and reference or challenge prior arguments. The debate ended when final opinions converged to a separating distance of 1. We tracked changes in utilitarian vs. non-utilitarian moral judgments, as well as the polarization of agent positions. By systematically adjusting group size, interaction rounds, and consensus criteria, we aimed to mimic real-world collective settings while controlling for known biases in multi-agent LLM discussions (Sorin et al., 2024). Our findings indicated that impersonal dilemmas (indirect harm to maximize the benefit for many) elicited a clear shift toward utilitarianism in multi-agent LLM groups, broadly aligning with human groups (Keshmirian et al., 2022). In personal dilemmas involving direct harm, however, LLM groups consistently favored less utilitarian ratings. If the direct harm was caused by an omission, the groups became even less utilitarian in their consensus. This pattern diverges from prior human experiments (see Keshmirian et al., 2022; Rokosz et al., 2025; Curşeu et al., 2020). Prior work shows that multi-agent discussion can create polarization (Wang et al., 2024). To examine this in moral judgments, we tracked changes in LLM responses over time and measured polarization by counting extreme responses (ratings ≤ 2 or ≥ 8) before and after discussion. This allowed us to assess whether agents adopted more extreme stances during deliberation or moved toward moderation. Our analysis showed that personal and impersonal dilemmas both increased the rate of extreme ratings, indicating polarization in moral scenarios compared to non-moral cases where positions tended to be less divergent. Wasserstein Distance analysis confirms the reliability of the observed polarization, showing no significant difference in onboarding distributions (W = 0.0686, KS p = 0.4017, p > 0.05), but a significant difference in reflection distributions (W = 0.8753, KS p < 0.05, p < 1.77e-40). This heightened polarization underscores that the role of moral content in amplifying disagreement (Garrett & Bankert, 2020) extends to AI-driven group discussions. These outcomes expand our understanding of how LLM collectives handle moral problems and where they diverge from human moral norms. Although humans reasoning collectively often become more utilitarian for both direct (Curşeu et al., 2020) and indirect harms (Keshmirian et al., 2022), LLM groups became selectively more utilitarian in indirect harm cases. Moreover, they became more polarized in both personal and impersonal (but not non-moral) scenarios. Our findings raise concerns about how multi-agent LLM systems—already poised to inform policy, healthcare, and judicial decisions—might propose actions that depart from human moral intuitions.","Anita Keshmirian, Razan Baltaji, Hadi Asghari, Babak Hemmatian",Vingen 7,ABMs I,1,,829
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Gender Dynamics in a Social Network of Large Language Model Agents,"This study investigates gender-based homophily within a network of AI-powered chatbots, Chirper.ai, simulating a social network of large language model (LLM) agents over 52 weeks. We analyze the evolution of the network by examining gender scores assigned to Chirpers based on their posts, using a machine learning algorithm to calculate perceived gender. This approach allows us to track shifts in perceived gender over time and explore how gender influences interactions within the network. To examine gender-based homophily, we calculated correlations based on the gender scores of chirpers who share an edge. The results illustrate a tendency for Chirpers to connect with those who share the same gender or similar gender scores. Additionally, screening the evolution of the network over the 52 weeks reveals complex network dynamics and clustering patterns, as well as the increasing use of masculine language in Chirpers' content over time.","Faezeh Fadaei, Taha Yasseri",Vingen 7,ABMs I,2,,393
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Validating Generative Agent-based Models,"Agent-based models (ABMs) offer a conceptual framework for simulating the actions and interactions of autonomous agents in order to understand the behavior of a system and investigate emergent phenomena. Large Language Models (LLMs) offer a powerful extension to traditional ABMs due to their strong text generation capabilities, potentially allowing for more realistic, rich, and detailed simulations. However, it is unclear how to evaluate and validate these simulations, particularly since there are persisting questions of algorithmic bias and LLM reliability. Therefore, we conceptualize a validation framework for evaluating LLM simulations. Besides the validity concepts from ABM literature, we also incorporate validity concepts from measurement theory and Computational Social Science. Grounding our framework on several different types of simulations to ensure breadth and comprehensiveness, we present case studies of six simulation studies and the different types of validation required in them. Our framework informs the design of simulation benchmarks as well as documentation and reporting checklists for generative simulation creators.","Indira Sen, Georg Ahnert, Markus Strohmaier, Jana Lasser",Vingen 7,ABMs I,3,,810
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Higher-order modeling of face-to-face interactions,"Face-to-face contacts lie at the core of an individual's social world. A street encounter with a stranger, discussing with colleagues over coffee, having dinner with family, or hanging out with a group of friends: all of these represent the most fundamental form of social interaction. The recent availability of high-resolution data on individuals' proximity has allowed researchers to uncover how those seemingly random interactions display coherent spatio-temporal characteristics across several social contexts. Specifically, face-to-face interactions show universal features, such as the absence of a characteristic scale for contact duration, the switching between low activity periods and high activity bursts, and a great heterogeneity in interaction behaviors among individuals. The ubiquity of these features has thus posed the crucial challenge of explaining what mechanisms underlie their emergence. Modeling frameworks based on mobile agents proved to be a valuable tool to understand the organization of human face-to-face interactions. In this scenario, agents move erratically in a spatial environment and interactions occur every time they get close together. In addition, contacts between agents can be modulated by more complex mechanisms, including their attractiveness, their activeness and reachability, their pairwise similarity, or belonging to the same social group. This class of models gave useful insights to understand the bursty and small-world behavior of face-to-face interactions, as well as many social phenomena emerging from them, like disease spreading, spatial segregation and echo chamber formation, and structural inequalities. These models, however, are limited as they describe face-to-face interactions only in terms of dyadic relationships between agents. In fact, they adopt a temporal network representation, focusing either on the dynamics of dyadic contacts, i.e., links, or the mesoscopic level of social gatherings, i.e., connected components. However, humans do not only interact in pairs, but regularly engage in groups involving more than two individuals at the same time. Although some recent works have investigated the higher-order nature of face-to-face interactions, current models based on mobile agents either overlook or fail to capture the spatio-temporal features and the dynamical evolution of groups. Here, we bridge this gap by introducing a model in which mobile agents interact with each other by forming groups of different sizes. Each group is characterized by an intrinsic degree of social appeal that we call ``group attractiveness''. Agents passing in the vicinity of a group choose whether to join it based on its attractiveness, while group members decide whether to stay or walk away. We analyze six high-resolution datasets describing the dynamics of contacts between individuals in different social systems. We show how the Group Attractiveness Model (GAM) can reproduce different properties of groups in face-to-face interactions, including their statistics, the correlation in their number, and their temporal duration, which cannot be reproduced by models based on dyadic interactions. Furthermore, differently from low-order approaches, we demonstrate the potential of our model to correctly capture higher-order homophilic patterns not only at the level of pairwise contacts but also at that of group interactions. Our results advance a recent line of research aiming at defining and measuring homophily at the level of group interactions. The superior performance of our model compared to pairwise methods marks the need to adopt higher-order models to investigate groups in face-to-face interactions. Capturing the microscopic dynamics of groups is crucial, as group interactions can dramatically change the collective behavior of complex social systems, leading to super-exponential disease spreading, triggering critical mass effects in social contagion, and boosting the ability of committed minorities to overturn social norms. Given its capability to reproduce different features of the data, we are confident that our model will prove to be beneficial to investigate how groups affect social collective behaviors.","Luca Gallo, Chiara Zappalà, Fariba Karimi, Federico Battiston",Vingen 7,ABMs I,4,,753
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,"Modelling social identity, opinion, and the Overton window","Social identity plays a crucial role in peoples' attitudes towards one another, the norms they follow, and the beliefs they hold. In spite of this, classical models of opinion dynamics do not account for how an individual’s beliefs shape and are shaped by a multi-dimensional social identity. We develop a modelling framework that captures this dynamic, by describing the evolution of beliefs in terms of a desire to signal both in-group membership and out-group differentiation, across multiple dimensions of identity. We use this approach, which is based in social identity theory, to study how the number of identity dimensions impacts the distribution of opinions within a population. We show that as the number of identity dimensions reduces, the tendency towards opinion polarisation increases. Furthermore, we show that in extreme cases, this can lead to a ``collapse'' of the Overton window, in which different identity groups adopt increasingly extreme opinions even in the face of sanctions.",Leon Klingborg,Vingen 7,ABMs I,5,,796
,,,,,,,,,,
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Social Influence and Protective Behaviors: Modeling Peer Impact in Pandemic Scenarios,"We investigate how social influence affects COVID-19 protective behaviors, including masking, distancing, and vaccination, across different contexts such as households, friendships, workplaces, and society at large. Our survey of 2,040 Germans gathered demographic data and attitudes toward COVID-19 before presenting a hypothetical pandemic scenario. Results show that social influence, especially from household members, significantly impacts individual behaviors, accounting for 77 % of the variance in protective behaviors, while attitude and trust in institutions play smaller roles. Masking willingness remained above 50 %, but distancing and vaccination behaviors were more sensitive to social cues. However, self-reported data may underestimate these effects.","Leonard Stellbrink, Maged Mortaga, Hendrik Nunner, André Calero Valdez",Vingen 7,ABMs II,1,,984
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,A Simulation Approach for Analyzing Social Network Features in Residential Segregation.,"This paper provides an analytical exploration of how network characteristics influence residential segregation. Building upon the foundational Schelling model, we develop an Agent-based simulation wherein agents are embedded within a social network structure. This approach allows for the experimental manipulation of network features such as homophily, clustering, and degree, enabling the assessment of their individual and combined impacts on segregation levels, patterns, and the stability of the socio-spatial system. We find that certain configurations of these network features can exacerbate residential sorting to levels exceeding those predicted by the original Schelling model. These outcomes underscore the critical role of social network dynamics, particularly the significance of weak ties, in driving a system toward a segregated state. The results contribute to the broader sociological discourse on social networks, highlighting the complex interplay between network structure and social phenomena, and offering new insights into the mechanisms underlying residential segregation.",Laura Fürsich,Vingen 7,ABMs II,2,,511
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,Microfoundations of Statistical Discrimination,"Statistical discrimination in hiring often traces back to macro-level social events or micro-level individual biases. However, our findings suggest that neither is strictly necessary. We propose an alternative model where unbiased employers use Bayesian sequential decision-making and share experiences to collectively optimize hiring outcomes. While this strategy facilitates rapid learning about the most productive groups, it also unintendedly fosters collective bias when distinguishing among uniformly competent groups. Far from uncovering the truth, these employers overinvest in a few groups of workers without exploring others, producing an uneven labor market despite equivalent potential. This occurs because employers frequently share and integrate each other's information, causing the group to compress individual experiences. This information compression leads to less diverse and less exploratory future decisions. Our evidence comes from a Bayesian multi-agent multi-armed bandit model, simulations with LLM-based generative agents, and human data from a multiplayer online hiring experiment. Our work illustrates how rational collective decisions can inadvertently establish unequal labor market dynamics, laying the groundwork for statistical discrimination.","Bufan Gao, Xuechunzi Bai",Vingen 7,ABMs II,3,,893
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,The Institutionalization of Labor Division in Open Collaborative Projects: A Case Study of the Linux Kernel,"This study examines the institutionalization of labor division in open collaborative projects by analyzing the evolution of the Linux Kernel. Building on the Mirroring Hypothesis, which posits that an organization’s formal structure reflects the technical dependencies of its work, our research investigates how decentralized labor becomes specialized over time. We reconstruct the development of Linux through empirical analysis of three data matrices: technical dependencies among source files, the mapping of developer contributions, and communication networks derived from email exchanges. An agent-based modeling approach, implemented using the Julia Agents library, simulates the evolution of synthetic Linux projects under various behavioral rules. These include response threshold dynamics, social influence mechanisms, and learning by patch acceptance. Calibration of the model against empirical data yielded an F-score of 0.721, demonstrating that labor division gradually aligns with technical architecture despite minimal formal managerial control. The findings challenge conventional notions that high degrees of mirroring are necessary for effective organizational efficiency, revealing instead that emergent social interactions and adaptive behaviors play a critical role. This work has significant theoretical implications for organizational theory and offers practical insights for managing open-source projects by enhancing collaboration and knowledge sharing in decentralized environments. Overall, it significantly advances our understanding.","Simone Santoni, Matteo Devigili, Alessandro Lomi",Vingen 7,ABMs II,4,,867
2025-07-22 14:30:00,2025-07-22 16:00:00,session_presentation,"Optimal ambition in business, politics, and life","When should we be satisfied and when should we look for greener pastures? When is the perfect the enemy of the good? This type of question arises in many different contexts, including business, politics, resource exploitation, and our personal lives. Folk intuition suggests that people should aim for above-average results, but overreaching can lead to failure. Here, we mathematically formalize this intuition and relate it to empirical research across diverse domains. We model a search for strategies that have uncertain rewards over a fixed time period. The agent (i.e. searcher) knows the statistical distribution of rewards across strategies. At each time step, the agent either is satisfied and sticks with their current strategy or continues searching. We prove that the agent's optimal satisfaction threshold is both finite and strictly larger than the mean of available rewards. Compared to the optimal threshold, being too ambitious has a higher expected cost than being too cautious, implying that uncertainty over the reward distribution should motivate caution. The optimal satisfaction threshold becomes larger if the search time is longer, or if the reward distribution is rugged (i.e., has low autocorrelation) or left skewed. Using upward social comparison to assess the reward landscape biases agents towards never being satisfied, which decreases their expected performance substantially. We discuss how these insights can be applied empirically, using examples from entrepreneurship, economic policy, political campaigns, online dating, and college admissions.","Ekaterina Landgren, Ryan E. Langendorf, Matthew G. Burgess",Vingen 7,ABMs II,5,,147
,,,,,,,,,,
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Can Machines Think Like Humans? A Behavioral Evaluation of LLM-Agents in Dictator Games,"As Large Language Model (LLM)-based agents increasingly engage with human society, how well do we understand their behaviors? We (1) investigate how LLM agents' prosocial behaviors can be induced by different personas and benchmarked against human behaviors; and (2) introduce a social science approach to evaluate LLM agents' decision-making. We explored how different personas and experimental framings affect these AI agents' altruistic behavior in dictator games and compared their behaviors within the same LLM family, across various families, and with human behaviors. The findings reveal that merely assigning a human-like identity to LLMs does not produce human-like behaviors. These AI agents are unable to capture the internal processes of human decision-making. Their alignment with human is highly variable and dependent on specific model architectures and prompt formulations; even worse, such dependence does not follow a clear pattern. LLMs can be useful task-specific tools but are not yet intelligent human-like agents.",Ji Ma,Vingen 7,Economics I,1,,759
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Reinforcement Learning Agents with Partner Selection Policies Achieve Cooperation in the Optional Prisoner's Dilemma,"We study populations of self-interested agents playing a 2-person repeated Prisoner's Dilemma game, with each player having the option of opting out of the interaction and choosing to be randomly assigned to another partner instead. The partner selection component makes these games akin to random matching, where defection is known to take over the entire population. Results in the literature have shown that, when forcing agents to obey a set partner selection rule known as Out-for-Tat, where defectors are systematically being broken ties with, cooperation can be sustained in the long run. In this paper, we remove this assumption and study agents that learn both action- and partner-selection strategies. Through multi-agent reinforcement learning, we show that cooperation can be sustained without forcing agents to play predetermined strategies. Our simulations show that agents are capable of learning in-game strategies by themselves, such as Tit-for-Tat. What is more, they are also able to simultaneously discover cooperation-sustaining partner selection rules, notably Out-for-Tat, as well as other new rules that make cooperation prevail.","Chin-wing Leung, Paolo Turrini",Vingen 7,Economics I,2,,111
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,AI Agents Can Enable Sophisticated Market Designs,"Many theoretically appealing market designs are under-utilized in practice because they demand granular preference data that humans often struggle to provide. This paper demonstrates that large language models (LLMs) could substantially reduce these cognitive burdens by translating natural language descriptions of market participant tastes into preferences. We invite 781 Prolific workers to describe their preferred types of tasks in natural language and rank a representative set of 50 tasks. An LLM is then provided with these natural language descriptions and put through utility elicitation exercises, which generate cardinal preferences over the 50 tasks for each participant. The rankings implied by these LLM-derived utilities track participants' own rank-orderings of the tasks. With these data, we simulate three matching mechanisms: (I) Gale-Shapley deferred acceptance using participants' own ranked lists; (ii) the Hylland-Zeckhauser pseudo-market, here supplied by the LLM-derived utilities; and (iii) a single-application lottery based on participants' top-ranked tasks. Simulations reveal that incorporating cardinal preference data from the LLM-derived utilities improves allocations, particularly in highly congested environments where many participants have the same preferences. A follow-up experiment confirms that participants themselves prefer LLM-generated matches over simpler alternatives under high congestion. Taken together, these findings suggest that LLM-driven preference elicitation can facilitate theoretically superior market designs in practice, particularly in settings such as labor markets where the stakes are high and detailed preference reporting over all options would otherwise be implausible.","Gili Rusak, Benjamin S. Manning, John Joseph Horton",Vingen 7,Economics I,3,,789
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Emotion Dynamics and the Consumption Paradox: Emotional Variance Predicts High Ratings but Low Popularity,"What makes some cultural products sell well even though they get bad reviews? And what leads others to sell poorly despite great reviews? While ratings and sales are often treated as interchangeable metrics of success, they can also conflict, particularly in cultural product markets like movies (Holbrook and Addis 2007). We propose that how much emotions fluctuate across the content—i.e., its emotional variance—matters. We hypothesize that while greater emotional variance can lead to better ratings, it can also hurt popularity. Greater emotional variance should create more engaging content, which should lead to higher ratings when people choose to consume it (e.g., Knight, Rocklage, and Bart 2024). Yet, this same variance may also deter people from choosing to consume it in the first place. When deciding what to watch or listen to, for example, it may seem like content with emotions that fluctuate widely would take more emotional effort to consume, thereby hurting its popularity. To test this pattern, we quantify emotion dynamics within tens of thousands of movie scripts, podcast transcripts, and song lyrics using computational linguistics and machine learning. Study 1 investigates movies. We obtained movie dialogue and action for a comprehensive set of 3,127 movies from OpenSubtitles.com. To measure emotional variance, we use a RoBERTa-based classifier (Lowe 2024) to quantify the six basic emotions—sadness, anger, fear, joy, surprise, and disgust (Ekman 1992)—from the text on-screen at each moment. This classifier has been validated in prior work (Demszky et al. 2020). We then compute emotion levels in 100 fixed-width windows to construct a continuous time series of each emotion over across each movie. An example of this approach is presented in Figure 1, where we show the emotional trajectories for The Lion King (1994). Emotions fluctuate considerably over the course of the movie, with a particular spike in sadness and anger halfway through the movie during and after Mufasa’s famous death. The movie then ends on a spike in anger, coinciding with the classic battle between Simba and Scar, before a final uptick in joy for a happy ending. To quantify a movie’s emotional variance, we compute the variance of each emotion across movie percentiles and then average those variances together for a single index. Each movie’s rating was measured using its average star rating from IMDb.com and popularity was measured by its box office revenue (i.e., how many people went to see it). As predicted, regression models find that while greater emotional variance predicts higher ratings (b = 469.13, t(3118) = 3.24, p = .001), it predicts lower popularity (b = -1846.79, t(3118) = -6.32, p < .001). These results hold (ps < .05) even when examining a number of alternative explanations by including controls for genre fixed effects, audience demographics (age, gender), budget, year-of-release fixed effects, maturity rating fixed effects, script wordcount, and the average level of each emotion across the movie. Thus, greater emotional variance predicts better ratings, but comes at a cost for popularity. Study 2 examines the generalizability of the effect across podcasts. We obtained transcripts for 1,676 episodes (Spotify 2020) and matched them with each episode’s average rating and listener counts (popularity) from Rephonic, an online metadata aggregator for podcasts. We find an identical pattern as with movies: greater emotional variance predicts higher ratings (b = 54.31, t(1667) = 5.19, p < .001) but lower popularity (b = -90.45, t(1667) = -3.12, p = .002). These results again persist controlling for an large set of alternative explanations (ps < .05), including genre fixed effects, year fixed effects, wordcount, and the average level of each emotion. Finally, Study 3 further investigates generalizability by examining 15,010 songs. We obtained song lyrics from the Music4All database (Santana et al., 2020). These were matched with ratings from Pitchfork, a well-known music evaluation website, and Spotify’s popularity index, a measure based on how frequently a song is played by different users. Again, we find that greater emotional variance significantly predicts higher ratings (b = 9.98, t(15001) = 3.42, p = .001) but lower popularity (b = -182.40, t(15001) = -7.73, p < .001). These results hold even when controlling for a large set of alternative explanations (ps < .05) including genre fixed effects, year fixed effects, wordcount, and the average level of each emotion, as well as beyond musical characteristics coded by Spotify such as tempo, mode, valence, key, and danceability. Taken together, these findings suggest a fundamental tension in the success of cultural products: content with greater emotional variance earns higher ratings but is less popular across movies, podcasts, and songs.","Samsun Knight, Matthew D. Rocklage, Yakov Bart",Vingen 7,Economics I,4,,880
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,"Who Sets the Rent? Algorithmic Landlords, Market Competition, and the Influence Network of Price Diffusion","The growing adoption of algorithmic rent-setting tools by corporate landlords has reshaped the rental housing market, raising concerns about price inflation, market competition, and housing affordability. This study examines the role of algorithm-driven landlords in shaping rent price dynamics, investigating whether they act as price setters who initiate market-wide changes or merely follow broader trends. Using a comprehensive dataset of weekly rent observations, ownership records, and neighborhood characteristics in Milwaukee County from 2018 to 2023, we employ descriptive and network-based methodologies to analyze pricing behaviors and rent diffusion patterns. Our findings reveal that algorithmic landlords exhibit distinct pricing strategies, characterized by frequent, synchronized rent adjustments that contribute to market segmentation and price convergence. Leveraging Graph Attention Networks (GAT), we construct an influence network that captures the diffusion of rent changes, identifying key price-setting landlords and tracing the hierarchical spread of rent inflation across socioeconomic and racialized market segments. Our results suggest that algorithmic landlords play a central role in shaping rental market trends, accelerating rent homogenization and disproportionately impacting lower-income communities. This study provides critical insights into the implications of algorithm-driven pricing on market competition, housing inequality, and regulatory policy.","Eunsung Yoon, Sasrah Johnson, Carl Gershenson",Vingen 7,Economics I,5,,948
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Early career wins and tournament prestige characterize tennis players' trajectories,"Success in sports is a complex phenomenon that has only garnered limited research attention. In particular, we lack a deep scientific understanding of success in sports like tennis and the factors that contribute to it. Here, we study the unfolding of tennis players' careers to understand the role of early career stages and the impact of specific tournaments on players' trajectories. We employ a comprehensive approach combining network science and analysis of the Association of Tennis Professionals (ATP) tournament data and introduce a novel method to quantify tournament prestige based on the eigenvector centrality of the co-attendance network of tournaments. Focusing on the interplay between participation in central tournaments and players' performance, we find that the level of the tournament where players achieve their first win is associated with becoming a top player. This work sheds light on the critical role of the initial stages in the progression of players' careers, offering valuable insights into the dynamics of success in tennis.","Chiara Zappalà, Sandro Ferreira Sousa, Tiago Oliveira Cunha, Alessandro Pluchino, Andrea Rapisarda, Roberta Sinatra",Vingen 7,Economics I,6,,767
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Skill Demand and Change in Europe: A Regional Analysis Over time (2019-2023),"While it is widely recognized that the European labor market is undergoing significant transformations that are changing its occupational and skill composition, there is limited evidence on how these changes unfold territorially, particularly at the sub-national level. This study addresses this gap by investigating the spatial distribution of labor market transformations with two main aims: analyzing regional patterns of skill demand and examining how skill demand has evolved over time. Adopting a skill-based and data-driven perspective, we analyze online job advertisements (OJAs) from 29 countries between 2019 and 2023 at the NUTS3 level, the smallest territorial unit in the European regional classification. Based on skill demand structures, we identify 11 regional clusters, highlighting varying degrees of labor market segmentation and territorial inequalities. Between 2019 and 2023, job requirements have become increasingly complex, with a growing complementarity between digital and traditional skills. Finally, we find that the pace of skill transformation varies regionally, following distinct spatial patterns. This study is, to the best of our knowledge, the first attempt to cluster European regions using a data-driven, skill-based approach with online job advertisement data.","Ioana Gabriela Doleanu, Diego Giuliani, Ivano Bison",Vingen 7,Economics II,1,,283
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Breaking the HISCO Barrier: Automatic Occupational Standardization with OccCANINE,"The classification of historical occupational data has long been a labor-intensive and error-prone task. The Historical International Standard Classification of Occupations (HISCO) provides a widely used framework for categorizing such data (Leeuwen, Maas, & Miles, 2002), but manual assignment remains cumbersome and time-consuming. This paper introduces OccCANINE, a novel machine learning tool designed to automate the transformation of occupational descriptions into HISCO codes with high accuracy, significantly reducing the workload for researchers in economic history and related disciplines. The ability to standardize historical occupational data is essential for studying social mobility, labor markets, and economic development. However, manually coding occupational descriptions into HISCO categories is a slow and resource-intensive process. Even an expert researcher can only classify a limited number of descriptions per hour, meaning that large-scale datasets require weeks or months of effort. Traditional methods, such as rule-based string matching, struggle with the inherent complexity of historical data, including linguistic variations, spelling inconsistencies, and contextual ambiguities. The demand for a more efficient, scalable, and replicable solution has driven the development of OccCANINE. OccCANINE is a fine-tuned transformer-based language model built on CANINE, a pre-trained model designed for multilingual text processing (Clark, Garrette, Turc, & Wieting, 2022). It has been trained on a dataset of 14 million occupational descriptions and their corresponding HISCO codes across 13 languages, leveraging contributions from 22 different and diverse sources. By incorporating both character-level tokenization and deep learning-based contextual understanding, OccCANINE achieves remarkable robustness against spelling errors and linguistic variations. The model takes an occupational description as input -- optionally accompanied by language context -- and outputs the most relevant HISCO codes. We evaluated the model's performance on 1 million validation observations. It achieved 93.5% accuracy, precision of 95.5%, recall of 98.7%, and an F1-score of 96.0%. We performed additional validation on out-of-distribution datasets, including the Copenhagen Burial Records (Denmark) (Robinson, Mathiesen, Thomsen, & Revuelta-Eugercios, 2022), Indefatigable Training Ship Data (UK) (Schneider & Gao, 2019), Swedish strike records (Enflo, Molinder, & Karlsson, 2022), and Dutch tax records from 1674 (Soetermeer, 1674). In these tests, OccCANINE maintained accuracy above 90% and substantial agreement with human-coded labels. A key challenge in occupational classification is the presence of rare occupations. OccCANINE's accuracy remains high across common occupations, but performance slightly declines for rare occupations due to limited training data. This issue can be mitigated through task-specific fine-tuning, which OccCANINE supports. By automating HISCO classification, OccCANINE lowers the barrier to historical occupational research, enabling larger-scale studies and freeing researchers from the tedious task of manual coding. In ongoing work, we are training OccCANINE to support additional occupational classification schemes, including OCC1950, ISCO, PTSI, and OCCICEM, training on more than 100 million occupational descriptions. Further, the methods we use in this paper are also applicable to other classification tasks in historical data processing, such as analyzing trade records, educational qualifications, or demographic registers, which we plan to explore more in the future. OccCANINE effectively ``breaks the HISCO barrier,'' transforming what was once an arduous manual task into a rapid, automated process. By leveraging state-of-the-art natural language processing techniques, the tool enhances the accuracy, efficiency, and replicability of historical occupational classification. This development opens new possibilities for economic historians, sociologists, and researchers across the social sciences, facilitating more comprehensive studies of occupational change and social mobility over time. OccCANINE is publicly available, with open-source code and training guides accessible via GitHub. We encourage researchers to validate its performance on their datasets and, if necessary, fine-tune it for specialized applications.","Torben S. D. Johansen, Christian Vedel",Vingen 7,Economics II,2,,605
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Quantifying the capacity for innovation in design by country through patents and awards,"Innovation, understood as the introduction of novelties into the market, has evolved from product improvements to processes of systematic creation and exploration. In knowledge-based economies, Design plays a crucial role in providing new meanings and redefining the relationships between users and product. By webscrapping award winnning designs we apply the methodology of economic complexity to calculate a complexity index of design, make a design space and corroborate the existence of the principle of relatedness in design.","Juan Felipe Ignacio Illanes Vásquez, Ignacio Andrés Ormazabal Inostroza, Ignacio Toledo Roman, Cristian E Candia",Vingen 7,Economics II,3,,369
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,AI Innovation at the Crossroads: Complementarity Between Public and Private Sectors,"Given the growing investment in artificial intelligence (AI), government interest and involvement in this field are also expanding. Government organizations have historically played a crucial role in fostering national innovation systems. This study investigates the evolutionary process of AI technology, focusing on the unique contributions of three innovation types: intramural, extramural, and private. We utilize the Artificial Intelligence Patent Dataset 2023 (AIPD 2023), which comprises all granted AI patents from 1976 to 2023, augmented with metadata to classify innovation types. Our final dataset includes 5,265 intramural, 35,871 extramural, and 808,652 private. We further examine the content of these patents by constructing a landscape of AI innovation using BERT embeddings and applying UMAP to reduce dimensionality. Subsequently, we assign labels to high-density regions via different label code systems. The results indicate that intramural and extramural innovation types focus on fundamental AI technologies compared to the private innovation type. In contrast, the private innovation type has steadily shifted toward commercialization. Moreover, the extramural innovation type bridges public and private interests, maintaining traditional research areas while adapting to emerging fields. Our findings reveal the complementary interplay among intramural, extramural, and private research efforts. By analyzing the contributions and the complementary nature of each entity involved in patenting activity, this study provides an empirical foundation for optimizing the allocation of public funds to maximize overall impact.","DoeunKim, Sungkyu Shaun Park, Jaehyuk Park",Vingen 7,Economics II,4,,668
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Digitalization and changes in ICT-related skill demands,"Technological change and digitalization (hereafter TC&D) are driving some of the most significant transformations in modern societies, rapidly reshaping how we learn, work, and interact (Brynjolfsson and McAfee 2014; Helbing 2015). While occupations related to information and communications technology (ICT) have profoundly grown in demand, ICT skills are increasingly required across nearly all job types (Oesch 2013). A major anticipated development in this context was the reduction of gender inequalities in the labor market, driven by factors such as a decreased emphasis on physical strength and increased job flexibility (Black and Spitz-Oener 2010, Weinberg 2000). However, gender inequalities did not disappear, and progress toward gender equity in the labor market has stalled (England, Levine, and Mishel 2020, Minkus and Busch-Heizmann 2020). Today, it seems that TC&D might even lead to increasing gender inequality as well-paid complex programming tasks are male dominated (Cheng, Chauhan, and Chintala 2019). To understand if, how, and under what conditions TC&D influence men’s and women’s employment and wages, nuanced measures of digitalization in the labor market are indispensable. However, to date, no longitudinal data exist that allow for a time-sensitive analysis of within-occupation changes in ICT-related skill demands. Addressing this data gap, our project aims to create an innovative retrospective measure of TC&D at the occupational level by analyzing historical job vacancy advertisements to model skill-demand changes over time. Building on prior research using newspaper vacancy ads to measure ICT tasks in the labor market (see Swiss Labour Market Monitor; Buchmann, Buchs, and Gnehm 2020), our project expands this approach in both scale and scope. Using computational methods on archival data, we develop a longitudinal measure of changes in occupational skill demands. We outline the process steps, including the application of various CSS techniques, and present preliminary analyses derived from our measure. The creation of this novel measure includes three major steps (see Figure 1): a) systematic collection and extraction of digitalized newspaper job advertisements, b) mapping of job ads to occupation classification codes (KldB 2010), and c) identification and classification of ICT-related skill requirements in the advertised jobs. In the first step (a), we contacted all newspaper publishers in Germany to request access to their digitized archives for the period 1975 to 2024. These archives are primarily accessible via regular newspaper subscriptions. To refine our dataset to include only pages containing job advertisements, we combine keyword searches and natural language processing (NLP) algorithms, such as word embeddings, which capture the semantic context of job ads. Finally, to automatically isolate and extract individual job vacancy ads as discrete units, we apply an object detection tool (e.g., YOLO) trained on manually annotated samples (Figure 1, step 1). In the second step (b), we map job vacancy ads to job codes in Germany’s most widely used occupational classification system (KldB 2010). To accomplish this, we leverage pre-trained models for job classification (e.g., JobBERT). As the wordings of job titles in some areas have changed considerably across our observation period, often to avoid gender-typing (e.g., Stewardess / Flight Attendant), harmonization of the titles across time is necessary. Mapping to this job classification system is a crucial step as it enables the linkage of our new measure of ICT-related skill requirements within specific occupations to other datasets, such as social security records (Figure 1, step 2). In the third step (c), we use machine learning algorithms to extract and structure all relevant information from the job ads, with a particular focus on ICT-related skill requirements. To classify skill demands as ICT-related, we draw on official skill requirement lists of the German Federal Employment Agency. This approach allows us to develop a robust measure of occupational skill changes over time, independent of evolving job titles (Figure 1, step 3). For the first time, our newly developed measure will enable researchers to link data on intra-occupational ICT task changes with longitudinal administrative data, such as the Integrated Employment Biographies from the Institute for Employment Research (IAB) in Germany. This opens new avenues for studying employment and wage dynamics in German workplaces across different demographic groups—including men and women—while accounting for the complex and varying digitalization processes across occupations.","Isabel Gebhardt, Timon Drewes, Malte Reichelt",Vingen 7,Economics II,5,,346
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Augmenting the availability of historical GDP per capita estimates through machine learning,"Can we use data on the biographies of historical figures to estimate the GDP per capita of countries and regions? Here we introduce a machine learning method to estimate the GDP per capita of dozens of countries and hundreds of regions in Europe and North America for the past 700 years starting from data on the places of birth, death, and occupations of hundreds of thousands of historical figures. We build an elastic net regression model to perform feature selection and generate out-of-sample estimates that explain 90% of the variance in known historical income levels. We use this model to generate GDP per capita estimates for countries, regions, and time periods for which this data is not available and externally validate our estimates by comparing them with four proxies of economic output: urbanization rates in the past 500 years, body height in the 18th century, wellbeing in 1850, and church building activity in the 14th and 15th century. Additionally, we show our estimates reproduce the well-known reversal of fortune between southwestern and northwestern Europe between 1300 and 1800 and find this is largely driven by countries and regions engaged in Atlantic trade. These findings validate the use of fine-grained biographical data as a method to produce historical GDP per capita estimates. We publish our estimates with confidence intervals together with all collected source data in a comprehensive dataset.","Philipp Koch, Viktor Stojkoski, Cesar A Hidalgo",Vingen 7,Economics II,6,,14
,,,,,,,,,,
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Policy Evaluation with Many Outcomes,"We generalize a permutation-based hypothesis testing approach to evaluate treatment effects in three dimensions: joint significance across multiple outcomes, importance of individual outcomes, and potential gains from targeting interventions to groups of individuals. The key idea is to predict treatment status using outcome variables jointly or separately and test whether the distribution of predicted treatment scores significantly differs between treated and control groups. We further show how predicted treatment scores can inform the design of targeted interventions and quantify potential gains to treatment prioritization. Simulations and empirical results show that the method is highly powerful, and outperforms the Wald test in settings with small samples, heterogeneous treatment effects, or extreme values.","Maria Nareklishvili, Susan Athey, Jann Spiess",Vingen 8,Governance & Policy,1,,445
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Computational Analysis of the Longitudinal Impact of Lifting One-Child Policy in China: Evidence from E-Petition and Social Media Data,"China faces an aging crisis, with its birth rate dropping to 7 per 1,000 people in 2022. Similar trends in Global North countries contribute to a global public health challenge. In 2016, China shifted from a one-child policy to a two-child policy to boost fertility. While research has explored the effects on fertility behaviors, little attention has been paid to how this policy change impacts citizens' perceptions of family planning and fertility barriers. This study analyzes Chinese citizens’ fertility-related appeals from 2011 to 2022 on the e-petition platform (Message Board for Leaders) and examines government responses through posts on Weibo, China’s leading social media platform. We use computational social science methods, such as Dynamic Bertopic Modeling and sentiment analysis with RoBerta, to identify trends and policy impacts. The analysis employs a Difference-in-Differences approach to examine the effects of changing fertility policies. The Message Board for Leaders, a government-run platform, allows citizens to express demands to officials. We collected fertility-related texts from 2011 to 2022 through keyword search and fuzzy matching. This period spans multiple phases of family planning policies, including the one-child policy (up to 2013), selective two-child policy (2014), universal two-child policy (2015), and three-child policy (2021). After cleaning, 9,862 texts were obtained, and the Dynamic BERTopic model identified public demands by clustering sentence embeddings. We also collected posts from five high-following Weibo accounts (People’s Daily, Xinhua News, China Daily, China News Weekly, and China News Service) related to fertility policy using the keyword “fertility.” A total of 321 posts were manually categorized into news, policies, proposals, and polls. To assess public feedback, we supplemented this with data from TikTok, focusing on comments under fertility-related posts. A random sample was labeled for classification using RoBerta, achieving over 87% accuracy. Analysis of citizen appeals on Message Board for Leaders revealed six key themes in fertility-related demands: i) household registration, ii) maternity leave, iii) childbirth subsidy, iv) school enrollment, v) healthcare coverage, and vi) remarried families. Longitudinal shifts show a decline in concerns about household registration (linked to the one-child policy) after 2016, while child-rearing cost concerns have surged. This correlates with the shift in China’s family planning policy, indicating that relaxed fertility regulations have refocused public attention on support measures such as financial assistance and postnatal recovery. Government responses on Weibo show that policies addressing concerns like non-marital births, school enrollment, and workplace gender discrimination have been implemented. However, public feedback reveals that these efforts have not fully met expectations. The four most discussed policies are shown in Fig 4. Public feedback can be categorized into three main concerns: 1. Insufficient support for childbirth, with complaints about low fertility subsidies and short maternity leave. 2. Limited scope of fertility support, with citizens calling for more comprehensive policies covering preconception, school enrollment, and healthcare. 3. Narrow target populations, with many calling for fertility benefits to extend to families with only one child. Future work will investigate the interplay between public demands and government responses, incorporating official policy documents and announcements on Weibo. This will enhance understanding of how government policy has evolved. A Difference-in-Differences approach will also be applied to analyze the impact of the two-child policy on citizens' fertility intentions and demands, offering insights into the causal effects of the policy shift.","Jie Hua, Pu Yan, Jiamin Li",Vingen 8,Governance & Policy,2,,399
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Tracking corruption around the globe — automated methods for identifying different forms of corruption in news coverage,"The study of political corruption in media coverage is essential for understanding public discourse, institutional accountability, and governance. Corruption, along with its various manifestations, has been widely debated in academic and policy discussions. However, to systematically study corruption coverage in news across countries and over time, we need to scale up the analysis through automated methods. Detecting and categorizing corruption-related content in large-scale textual data remains a challenge due to definitional complexities, terminological variations, and contextual nuances. In this study, we present a comparative analysis of machine learning and large language models (LLMs) to assess the accuracy and efficiency of different approaches for identifying and categorizing corruption-related news content across nine countries from 2018 to 2023. Our current analysis covers Sweden, the Netherlands, the UK, Hungary, Italy, France, Ukraine, and Serbia, representing countries with varying levels of corruption and trust in government. If successful, we aim to extend this approach to additional countries. Our dataset consists of news articles collected from various media outlets via the Event Registry API. We employ extensive keyword-based dictionaries designed to capture a broad spectrum of corruption-related terms, prioritizing high recall. These dictionaries were developed and translated by an international team of experts, including native speakers of each of the nine languages. However, to (1) increase precision and filter for articles that are actually about political corruption and (2) distinguish between different forms of corruption, additional steps are required beyond keyword searches. Our primary objective is twofold: first, to develop a robust classification pipeline that can accurately determine whether an article is truly about political corruption, and second, to classify articles into specific types of political corruption. This classification is informed by prior cross-national corruption studies (Hajdu, Pápay, Szántó, & Tóth, 2018) and considers three key dimensions: (1) whether corruption is framed as an individual or systemic problem, (2) the identification and representation of victims, and (3) the event arena, distinguishing between national and subnational levels. To achieve these goals, we employ a range of computational approaches. We begin with classical supervised learning techniques such as logistic regression, support vector machines (SVM), and random forests, using manually labeled subsets as training corpora. These methods provide interpretable baselines and allow us to assess the performance of traditional text classification models. Next, we experiment with transformer-based models such as BERT and RoBERTa, which have demonstrated superior performance in text classification tasks. Finally, we explore the potential of open-source LLMs such as LLaMA, Mistral, and Falcon to evaluate their effectiveness in zero-shot, few-shot, and fine-tuned corruption classification tasks, with particular attention to prompt stability (Barrie, Palaiologou, & Törnberg, 2024). Future extensions could also incorporate multilingual embeddings and contrastive learning techniques to better handle linguistic diversity. Our study provides insights into the trade-offs between different modeling approaches in terms of accuracy, generalizability, and computational efficiency. Additionally, we examine cross-national differences in media coverage, considering linguistic and contextual variations in corruption framing. Our findings contribute to the broader computational social science literature by demonstrating how different machine learning paradigms can be leveraged to analyze political discourse at scale. Furthermore, the study has practical implications for researchers and policymakers seeking to monitor corruption narratives and their impact on public perception and governance. By systematically testing multiple modeling strategies, this research advances the methodological toolkit for studying corruption-related discourse in news media. It offers a comparative evaluation of traditional and cutting-edge machine learning models in text classification and lays the foundation for a scalable and adaptable framework for future studies on political corruption in the media landscape. Potential future directions include refining our approach for real-time monitoring of corruption-related discourse and integrating multimodal data sources, such as social media and parliamentary debates, to enrich our understanding of corruption narratives across different platforms.","Felicia Loecherbach, Anne C Kroon, Chris D.R.O. Starke, Sofia M. Wickberg, Gabriele Bossi, Yara F. Mijnhout",Vingen 8,Governance & Policy,3,,739
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Detection of fraudulent practices in the Mexican public procurement network,"Our study tackles fraud in public procurement as a complex system using computational social science tools by analyzing it as a network phenomenon, incorporating government sanctions as real-world indicators of fraudulent activity, and leveraging machine learning techniques, specifically Positive-Unlabeled Learning, to enhance fraud detection. We use publicly available datasets from the Mexican government, including contract characteristics, contract procedures, and government sanctions to suppliers, to train and validate our model. We evaluated our model's performance against a random classifier, and our methodology achieved an average precision score of 75% to 85% in the top 5% of prediction scores, significantly outperforming the 30% achieved by a random classifier. These results highlight the model’s effectiveness in identifying likely fraudulent contracts.","Martí Medina-Hernández, Janos Kertesz, Mihály Fazekas",Vingen 8,Governance & Policy,4,,547
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Biases in Decentralized Decision Making,"Decentralized Autonomous Organizations (DAOs) are a novel form of governance model that promises to deliver efficient coordination mechanisms for small and large groups DAOs boast a flat hierarchy and an open, transparent, and democratic governance model, where voting power is linked to the amount of governance tokens held by each participant. Governance decisions in DAOs also exhibit extraordinarily high approval rates (over 90%), a quote that even surpasses many other online voting systems known for having approval bias. This paper investigates the high approval rates in DAOs trying to disentangle three main components: approval bias, author bias, and position bias. For our analysis, we collected 5.7 millions governance votes from the Snapshot platform (https://snapshot.org]), the largest off-chain governance platform available. We then preprocessed them and via mix of heuristics, custom filtering, and manual inspection we assigned to every choice of every proposal a stance, i.e., whether a given choice is ""approving"", ""rejecting"" the proposal, or if it is an ""abstain"" choice or ""other"". Via visual inspection and econometric analysis we are able to quantify the relative strength of the biases and find that, while all contribute the high approval rates of governance proposals, the author bias is the strongest one. Our results call for more transparency in the voting processes and in the identities and goals of the authors of governance proposals.","Stefano Balietti, Stefan Kitzler, Pietro Saggese, Markus Strohmaier, Bernhard Haslhofer",Vingen 8,Governance & Policy,5,,903
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Modeling the Emergence of a Collaborative Modus Operandi: The Case of “Samverkan” in Swedish Governance,"Grounded in classical theories of social order, this paper explores discourse-driven institutional change over time with its focus on the emergence of the concept of ""samverkan"" (collaboration) as a governance tool within Swedish public administration. While collaborative governance has been extensively studied through case studies, a systematic framework for understanding its evolution and impact on social order remains underdeveloped. Leveraging computational methods and qualitative analysis, this study aims to bridge that gap. The research utilizes a 100-year corpus of Swedish Government Official Reports (SOUs), comprising 8,891 documents, to trace the development of ""samverkan"" as a central administrative strategy. A five-step methodological framework was designed to analyze shifts in the term’s meaning and usage. The findings indicate that ""samverkan"" has evolved from a general notion of cooperation to a more structured and institutionalized governance tool. The word’s occurrence increased significantly from the 1970s onward, reflecting a broader societal shift toward interagency and intersectoral coordination. Word2Vec word embeddings and Word Rain visualizations indicate that ""samverkan"" is increasingly associated with strategic governance processes and diffused into more societal domains. Furthermore, a sentence transformer-based topic modeling approach identifies 74 recurring thematic areas where ""samverkan"" is prominently discussed, further illustrating its growing significance in the executive administrative discourse. Qualitative close-readings provide deeper insights into key conceptual transformations. In conclusion, ""samverkan"" has emerged as a ""soft"" governance mechanism, shaping Sweden’s public administration by encouraging cross-sectoral collaboration while maintaining state control. The findings demonstrate the value of the proposed methodological framework in capturing discourse-driven institutional change and suggest its applicability to other domains focusing on social order.","Josef Ginnerskov, Matilda Hellman, Maria Skeppstedt",Vingen 8,Governance & Policy,6,,416
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Gender Bias in Media Coverage of Science,"Media coverage shapes public understanding of science, but gender bias affects disparities in visibility and recognition. We examine how corresponding author gender influences media citations to scientific research across fields. We reveal that women-led papers are more likely to appear in media where women are underrepresented but receive fewer citations overall. Women authors are overrepresented in local media and underrepresented in national and specialty outlets. Sentiment analysis shows men-led papers are more frequently associated with positive sentiment, while women-led papers face more negative sentiment. These findings highlight the need for equitable media representation in science.","Salsabil Arabi, Xiang Zheng, Ian Hutchins, Chaoqun Ni",Hemeryck,Gender Bias,1,,885
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Detecting Gender Bias in Sentiment and Emotion Classification,"Automatic sentiment and emotion classifiers have become ubiquitous with applications both in industry and research. Traditionally, their reliability is attributed to the high accuracy rates achieved in standardised benchmarks. However, these benchmarks almost always depend on datasets in which sentiment or emotions have been labeled by third-party annotators, rather than the individuals experiencing these emotions themselves. In this paper, we use a unique, large-scale dataset of self-annotated posts to show that automatic classifiers have consistently higher error rates for texts authored by men both for positive and negative emotions. We then use computational modelling to estimate how this bias might affect the results obtained from applying automatic classification to gender-heterogeneous samples in downstream application. Our results demonstrate that machine learning tools should be applied with caution in contexts where gender could be a confounding variable. They also highlight that more research is needed to improve the accuracy of emotion detection, particularly in gender-diverse settings.","Ivan Smirnov, David Garcia, Segun Aroyehun, Paul Plener",Hemeryck,Gender Bias,2,,663
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Measuring Gender Bias in Contextual Embeddings through Wasserstein Distance,"Language models facilitate the analysis of vast text corpora, enabling the exploration of societal biases through word embeddings, though early studies relied on static representations like GloVe and Word2Vec, which fail to capture polysemy. In contrast, contextual embeddings from models like BERT and FlauBERT offer a more nuanced analysis by encoding words based on their surrounding context, making them ideal for studying gender bias in language. This study examines gender representation in French news (1995–2024) by measuring the distributional differences of masculine and feminine professional titles using Wasserstein-Cosine similarity, which quantifies shifts in contextual usage over time. Results reveal that high-status professions exhibit greater gender similarity than artistic or employee-level roles, with terms like avocat/avocate and président/présidente showing higher contextual alignment. Over time, similarity scores have generally increased across all professional categories, suggesting a gradual linguistic convergence of gendered terms, though this trend is more pronounced in high-status professions.","Salah Zrigui, François Portet, Gilles Bastin",Hemeryck,Gender Bias,3,,809
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,High-Impact Innovations and Hidden Gender Disparities in Inventor-Evaluator Networks,"We study of millions of scientific, technological, and artistic innovations and find that the innovation gap faced by women is far from universal. No gap exists for conventional innovations. Rather, the gap is pervasively rooted in innovations that combine ideas in unexpected ways – innovations most critical to scientific breakthroughs. Further, at the USPTO we find that female examiners reject up to 33 percent more unconventional innovations by women inventors than do male examiners, suggesting that gender discrimination weakly explains this innovation gap. Instead, new data indicate that a configuration of institutional practices explains the innovation gap. These practices compromise the expertise women examiners need to accurately assess unconventional innovations and then “over-assign” women examiners to women innovators, undermining women’s innovations. These institutional impediments negatively impact innovation rates in science but have the virtue of being more amenable to actionable policy changes than does culturally ingrained gender discrimination.","Tara Sowrirajan, Ryan Whalen, Brian Uzzi",Hemeryck,Gender Bias,4,,464
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Moral Judgments in Online Discourse are not Biased by Gender,"The interaction between social norms and gender roles prescribes gender-specific behaviors that influence moral judgments. While previous work has demonstrated the existence of gender-bias in judgments, these studies are mainly based on controlled experiments that may not reflect real-world decision-making processes. Here, we study how moral judgments are biased by the gender of the protagonist of a story. Using data from /r/AITA, a Reddit community with 17 million members who share first-hand experiences seeking community judgment on their behavior, we employ machine learning techniques to match stories describing similar situations that differ only by the protagonist's gender. We find no direct causal effect of the protagonist's gender on the received moral judgments, except for stories about ``friendship and relationships'', where male protagonists receive more negative judgments. Our findings complement existing correlational studies and suggest that gender roles may exert greater influence in specific social contexts. These results have implications for understanding sociological constructs and highlight potential biases in data used to train large language models.","Lorenzo Betti, Paolo Bajardi, Gianmarco De Francisci Morales",Hemeryck,Gender Bias,5,,690
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Female managers are judged more harshly even when they are AI,"The increasing integration of artificial intelligence (AI) in workplaces is transforming its function from merely enhancing efficiency to actively shaping organizational decision-making, sparking discussions on the evolving dynamics between humans and machines [1]. People often perceive AI entities as having human-like qualities, including gender, due to anthropomorphism — the attribution of human traits, emotions, or intentions to non-human entities. However, how AI managers are perceived compared with human managers, and how their perceived gender influences these views, remains unclear. Issues such as fairness, biases, organizational justice, trust, morale, and willingness to collaborate within teams are becoming increasingly important as AI reshapes the future of leadership and management. To explore these dynamics, we conducted a series of randomized controlled trials (RCTs) where teams of three participants worked collaboratively while a randomly assigned manager, varying in type (human or AI) and gender (female, male, or unspecified), selected the best player for an additional award (Fig. 1). While in reality the awardee was selected at random, this setting allowed us to measure how participants’ evaluation of the decision made by the manager depends on the manager’s characteristics under the same conditions. Findings: While participants showed little preference based on manager type or gender prior to treatment, award outcomes significantly shaped their perceptions of the manager's fairness, with the magnitude of the influence moderated by manager type, manager gender, and the participants' own gender. As shown in Fig. 2, Male managers received greater appreciation than female managers from awarded participants. When awards were not received, controlling for participants' gender effect, disillusionment was stronger for female managers, especially female-AI. As shown in Fig. 3, relative to the reference category (awarded by a human-male manager), not receiving an award significantly lowers perceived fairness for female-AI managers, female-human managers, and AI managers of unspecified gender. Additionally, fairness perceptions are strongly influenced by an expectation-reward dynamic. Not receiving an award, particularly when participants perceived their own contribution as high, led to a significant reduction in fairness ratings for both human and AI managers. Discussion: Our findings align with pervasive societal stereotypes that link competence and leadership effectiveness with male figures [3]. The reinforcement of positive recognition for male managers, and especially male-AI managers (Fig. 2), could reflect societal tendencies to perceive male-led successes as more expected or legitimate, a bias that some have argued is deeply ingrained in patriarchal organizational structures [4]. Furthermore, algorithmic neutrality and objectivity [5] may intersect here, as male-AI managers might benefit from a dual layer of presumed objectivity: male leadership and AI precision. Conversely, negative outcomes notably harmed perceptions of female managers, particularly female-AI managers, where skepticism toward AI decision-making compounded existing gender biases to yield harsher judgments. Female human managers also faced notable declines, though to a lesser extent, possibly due to the perception that human managers demonstrate greater accountability and empathy. By contrast, male managers exhibited greater resilience to negative outcomes, likely due to societal leniency afforded to male figures, consistent with status expectations theory [3]. This underscores the moderating role of gender in shaping perceptions of managerial decisions, revealing a deeply embedded double standard where cultural narratives shield male leaders with presumed competence and external locus of control, while female leaders face greater blame for unfavorable outcomes. These findings resonate with broader feminist critiques that women’s roles and societal positions are often disproportionately scrutinized within a male-dominated societal framework [6]. The findings offer insights for the design and deployment of AI systems for leadership and management roles. The amplified negative impact on female-AI managers emphasizes the need to address intersectional biases in workplace dynamics, where gender and technology intersect to create compounded disadvantages. Organizations aiming to integrate AI in leadership roles should consider strategies to mitigate such biases, such as transparency in AI decision-making processes and fostering a culture that values fairness and equity. Furthermore, the results point to the importance of aligning performance outcomes with fairness perceptions, as these evaluations can significantly influence trust, collaboration, and organizational morale.","Hao Cui, Taha Yasseri",Hemeryck,Gender Bias,6,,315
,,,,,,,,,,
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Does Workplace Segregation Countervail Occupational Segregation?,"Occupational gender segregation remains a persistent phenomenon. Traditional explanations usually focus on job characteristics, reward structures, and gendered preferences. While these theories effectively explain segregation between occupations (e.g., doctors vs. nurses), they struggle to offer compelling explanations for observed within-occupation segregation (e.g., surgeons vs. neurologists) and temporal shifts in gender composition. One mechanism that has received increasing attention is the interdependent labor mobility of men and women, summarized in the idea of feminizing occupations. What these rationales neglect, however, is that individuals are not only embedded in occupations but also in workplaces and that workplaces, like occupations, can be gender segregated. Using the lens of Analytical Sociology, this study explores the idea that workplace segregation may have a shielding effect on sorting at the occupational level. Assuming that people prefer to work with some number of colleagues like them, we hypothesize that individuals tolerate an increasing presence of others in their occupation as long as their immediate workplace remains similar to themselves. Using detailed register data from Sweden, we measure the experienced inflows of same-sex and opposite-sex workers into an individual’s occupation and workplace over time, as well as the effects of changes in gender composition on an individual’s choice to change their occupation. Our results indicate significant variation in workplace compositions, meaning that we find individuals who work in gender-equal occupations but gender-segregated workplaces and vice versa. Simulation analysis supports the idea that workplace segregation moderates occupational-level dynamics. These findings challenge macro-level segregation models and highlight the importance of localized workplace dynamics. Our study contributes to the understanding of occupational gender segregation by linking workplace structures to broader labor market patterns, potentially offering new ideas for tackling the “leaky pipeline” effect of career progression.","Alexandra Rottenkolber, Martin Arvidsson, Károly Takács",Vingen 6,Inequality & Segregation I,1,,749
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Occupational segregation and gender gaps in later-life labor market participation: New evidence from non-parametric causal decomposition analyses,"Gender disparities in later life labour market participation are large and persistent in most European countries. Compared to older men, older women are less likely to be employed, especially in full-time jobs, and more likely to be inactive or retired. While theory and prior empirical work suggest that these disparities are largely attributable to men’s and women’s unequal positions in the occupational hierarchy, the exact extent of this effect remains unclear. To fill this gap, this article employs a novel non-parametric and doubly-robust causal decomposition approach based on high-quality census data from Germany (n > 2,900,000). The estimation builds on a SuperLearner ensemble that flexibly combines multiple machine learning algorithms. First, I document considerable disparities in several labour market outcomes between older men and women aged 55 to 64 (total, full- and part-time employment; unemployment; inactivity; and retirement). Surprisingly and contrary to expectations, I then find that a gender-equal occupational structure would not substantially reduce these disparities, and would even slightly increase the gender disparity in part-time employment. These results hold in both East and West Germany, across three decades from 1991 to 2020, and if the occupational structure is equalised only within levels of educational attainment. These findings suggest that other factors, notably women’s lower labour market attachment in mid-life, likely account for most of the observed disparities. More generally, they question the role of occupational gender segregation as a mechanism behind gender disparities in late working lives and illustrate the benefits of novel causal decomposition and machine learning methods for empirical social science research.",Jan Einhoff,Vingen 6,Inequality & Segregation I,2,,336
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Exploring the Relationship Between Social Class and Language Usage using the Decisions of Classification Models,"Social class and sociolinguistic variation have been at the forefront of sociological and sociolinguistic research since the birth of the field, and numerous studies have previously focused on the relationship between socio-economic status and linguistic patterns [1]. With the digital revolution, people’s communication exceedingly shifted to the online space, allowing the collection of detailed linguistical digital footprints. This digital data, along with the rise of more sophisticated, context-sensitive embedding models like the BERT (Bidirectional Encoding Representations for Transformers) model [2], makes it possible to analyze linguistic patterns in more detail. The aim of the study is thus to examine what latent patterns can be identified in the relationship between online textual expressions and social status by analyzing the classification results of neural network-based models, specifically focusing on the aspects of language. The research aims to answer this question by fine-tuning a BERT and by using SHAP (SHapley Additive exPlanations) [3] values to try to find patterns in linguistic use among different social classes. In other words, the paper seeks to answer whether we can detect patterns in language usage across people of different social statuses, and if so, what these patterns are. While in many western countries Facebook usage seems to be on the decline [4], in Hungary it remained a significant social media platform, even among younger generations [5]. The data used by the study is collected via a novel data donation approach [6] among Hungarian Facebook users. First, respondents were asked to fill out a questionnaire, and then they were asked to download their own social media data. Data collection lasted from January 2023 to June 2023, and the final sample consisted of 758 individuals. The final sample is representative of the Hungarian internet user population in terms of gender, age, and geographical region. For the current study, ~2.5M Hungarian Facebook posts and comments were used. Each user was given a social class category based on a five-category version of the European socio-economic classification (ESeC) [7]. ESeC relies on John Goldthorpe’s [8] occupation-based classification scheme. Next, a BERT model was fine-tuned on the posts and comments of these users with the objective to predict the ESeC categories. The results shows that it is possible to train BERT models to classify Facebook comments and posts with an F1 score above 0.7, and by interpreting their SHAP values, relevant findings can be revealed in the differing patterns of language usage by various social classes. While the study is limited to a few linguistic patterns, among which are pronoun usage patterns, punctuation, and emoji usage, it shows promising results for further, more detailed analysis. Some results are underpinned by previous research on the English language and social class [9], while others are open for further research. Results suggest that the overall most influential (highest absolute SHAP value) tokens are prominently function words and punctuation marks. Our results suggest that respondents from lower classes are more characterized by the usage of the sentence terminator dot sign, and the usage of question marks has a negative effect. The study argues that the applied method provides an exploratory perspective that enables the detailed examination of linguistic elements, as the contextual embeddings of BERT allow language to be understood not as a static variable. The study quantitatively demonstrate the linguistic differences of five social classes, focusing primarily on the tokens deemed most important for classification, as well as differences in punctuation and emoji usage. The results are promising in terms of contributing to both the classification and interpretation of linguistic content appearing in social media, thereby aiding a deeper understanding of linguistic markers related to social structures. Our results show that, in contrast to traditional statistical methods, a broader, more exploratory approach could provide deeper insights into how symbolic power relations manifest in everyday language use. Analyzing Hungarian comments and posts from Facebook separately, as well as controlling for the parent’s social class to control for intergenerational mobility, might yield clearer results. Trying the same method but with English or multilingual texts can also provide insight into the language patterns different social classes use. While the results are by no means flawless or definitive, the study demonstrates that by examining SHAP values in deep learning-based classification models, it is possible to reveal potentially significant correlations between language use and social class. This, in turn, contributes to a more nuanced understanding of class relations and social stratification.","Bendegúz Váradi, Zoltan Kmetty",Vingen 6,Inequality & Segregation I,3,,794
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Unmasking Racial Discrimination in Traffic Enforcement via Proximal Causal Inference,"This paper presents a novel framework for measuring racial discrimination in traffic enforcement by using automated traffic enforcement as a race-neutral proxy for dangerous driving. Existing methods in causal inference with proxy variables are adapted and extended to address questions of discrimination. Identification strategies are developed for estimands quantifying race-based policing with minimal assumptions, while explicitly accounting for selection bias, mismeasurement of race, and latent confounding. Simulation studies demonstrate that, although naïve measures may underestimate discrimination, the proposed method robustly recovers the true effect. The framework is applied to a dataset of traffic citations from a large U.S. city.","Kai Cooper, Greg Lanzalotto",Vingen 6,Inequality & Segregation I,4,,768
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Bias Delayed is Bias Denied? Assessing the Effect of Reporting Delays on Disparity Assessments,"Prior work has documented widespread racial and ethnic inequities across sectors, such as healthcare, finance, and technology. Across all of these domains, conducting disparity assessments at regular time intervals is critical for surfacing potential biases in decision-making and improving outcomes across demographic groups. Because disparity assessments fundamentally depend on the availability of demographic information, their efficacy is limited by the availability and consistency of available demographic identifiers. While prior work has considered the impact of *missing* data on fairness, little attention has been paid to the role of *delayed* demographic data. Delayed data, while eventually observed, might be missing at the critical point of monitoring and action -- and delays may be unequally distributed across groups in ways that distort disparity assessments. We characterize such impacts in healthcare, using electronic health records of over 5M patients across primary care practices in all 50 states. Our contributions are threefold: First, we document the high rate of race and ethnicity reporting delays in a healthcare setting and demonstrate widespread variation in rates at which demographics are reported across different groups. Second, through a set of retrospective analyses using real data, we find that such delays impact disparity assessments and hence conclusions made across a range of consequential healthcare outcomes, particularly at more granular levels of state-level and practice-level assessments. Third, we find limited ability of conventional methods that impute missing race in mitigating the effects of reporting delays on the accuracy of timely disparity assessments. Our insights and methods generalize to many other high-stakes domains where delays in the availability of sensitive information may lead to biased and inaccurate audits.","Jennah Gosciak, Aparna Balagopalan, Derek Ouyang, Allison Koenecke, Marzyeh Ghassemi, Daniel E. Ho",Vingen 6,Inequality & Segregation I,5,,413
,,,,,,,,,,
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,The Effect of the Network of Children of Migrants on their Language Proficiency,"Even though the school results of children of migrants are improving in the Netherlands, they still are lower than those of native Dutch children. Language proficiency plays an important role in the school career of children. Therefore, it is important to understand which factors contribute to the language proficiency of these children. Besides formal education, exposure to the language plays an important role. Children not only get exposed to a language via their parents, but the entire social network plays a role. This study looks at children for which both parents are migrants (born outside of the Netherlands). For this the final test results of children in the 8th grade of primary school are used. This is the final grade of primary school (the children are then around 12 years old) and in principle all children are tested. The children are tested separately for spelling and grammar and for reading proficiency. Using the Persons Network of the Netherlands the isolation of each child are calculated. The Persons Network contains family members, household members, neighbours, co-workers and class mates for each person in the Netherlands. The isolation measures the extent to which the local network around a person, the ego network, consists of persons with the same migration background. The ego network contains all persons in the Netherlands. Using a localised random walk each person is assigned a weight which measured how easy it is to reach this person from the ego. Using ordinal regression the effect of both isolation and other possibly confounding variables such as the educational levels of both parents and household income were investigated. Furthermore, the total final exam score is added to the models. This leads to an overcorrection as this test result also includes language proficiency, but ensures that we can be quite sure that there are no unknown confounders remaining. From the regressions we can conclude that, the higher the share of persons with the same migrant background in the network of these children, the lower they score on the language components of the final exam of the 8th grade of the primary school (around the age of 12). For both 'reading' and 'spelling and grammar' this effect remains when we correct for socio-economic background and other personal characteristics known to correlate with language and learning proficiency. For 'reading' the effect also remains when we add the final exam score to the model. The effect of the network is no longer significant for 'spelling and grammar' when we add the final exam score. However, this is a very conservative model as the language tests are part of the final exam score. Overall, there seems to a clear indication for a network effect in language learning especially for 'reading'.","Dingeman Jan Van der Laan, Fijnanda van Klingeren, Marjolijn Das",Vingen 6,Inequality & Segregation II,1,,184
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,"Paths to Inequality: Life-Course Exposure to Income Concentration in Neighborhoods, Schools, and Workplaces.","Traditional segregation research has often been compartmentalized, focusing on specific domains such as schools, neighborhoods, or workplaces in isolation. However, segregation across these domains is interconnected, and early-life circumstances shape long-term outcomes. This study investigates how various dimensions of segregation—including school segregation for children, neighborhood segregation, and workplace segregation among parents—jointly influence individuals’ life-course trajectories. By examining these overlapping experiences, we provide a comprehensive understanding of the cumulative effects of socio-economic segregation within households. While recent studies have leveraged mobility data to examine segregation beyond residential settings, these datasets often lack long-term socioeconomic and demographic details. To address this gap, we integrate two complementary approaches: (1) ""activity space segregation,"" which emphasizes that segregation extends beyond residence and into daily activities, and (2) life-course segregation studies, which highlight intergenerational continuities in exposure to affluence and poverty. Combining these insights, we assess whether exposure to concentrated affluence or poverty across multiple domains—neighborhoods, schools, and workplaces—reinforces long-term segregation patterns or allows for social mobility. This study examines individuals’ life-course exposure to affluence and poverty, termed ""exposure to income concentration"" (EIC), across multiple domains. We analyze whether and for whom EIC persists across settings, over the life course, and across generations. Using Swedish full-population data, we construct longitudinal EIC trajectories spanning 27 years in three key activity sites: neighborhoods, schools, and workplaces. Our analysis focuses on (1) socioeconomic disparities in EIC, (2) life-course associations in EIC across domains, and (3) the intergenerational transmission of EIC. Our findings reveal strong links between socioeconomic background and exposure to affluence or poverty across multiple domains and generations. We use Swedish administrative data to track one cohort—9th graders in 1990 (n = 109,406)—over 27 years, from age 16 to 42. Yearly exposure to two income groups—the top 20% (affluence) and the bottom 20% (poverty) of the household income rank distribution—is measured for neighborhoods, schools, and workplaces. The EIC for individual $i$ to income group $g$ in domain $d$ is calculated as: $EIC_{idgt} = \frac{n_{gdt} - 1_{i \in {gt}}}{n_{dt} - 1},$ where $1_{i \in g t}$ is an indicator variable equal to 1 if individual $i$ belongs to income group $g$ in year $t$, and 0 otherwise, and $n$ denotes count. $EIC_{idgt}$ ranges from 0 (no exposure) to 1 (full exposure). To compare EIC levels across domains, we compute cross-domain correlations, capturing individual-level correlations in EIC between domains over time. Additionally, we apply sequence analysis and group-based trajectory modeling to classify life-course EIC trajectories. Finally, we conduct rank-rank regressions to examine intergenerational transmission of EIC. Our findings reveal substantial socioeconomic inequalities in exposure. Individuals experiencing poverty or affluence in one domain often encounter similar conditions in others. The strongest correlations occur between neighborhoods and schools, while associations are weaker for workplaces and universities. Socioeconomic background plays a pivotal role: children from high-income families consistently experience greater exposure to affluence throughout their lives. Examining intergenerational transmission, we find that children inherit not only their parents’ neighborhood contexts but also their exposure to affluence or poverty in schools and, to a lesser extent, workplaces. These associations are strongest in high-income settings, where the median income rank of children’s schools rises by 0.73 percentile for every percentile increase in their parents’ school rank. This pattern persists across all income groups, reinforcing the persistence of affluence and poverty across generations. Nonetheless, some individuals break these patterns. Approximately one-third of those from the lowest-income backgrounds successfully transition into affluent settings. These individuals achieve higher university graduation rates and increased earnings compared to peers who remain in low-income environments. These findings suggest that breaking the cycle of segregation is possible but requires proactive policies to facilitate socioeconomic mixing across different domains throughout the life course.","Maël Lecoursonnais, Selcan Mutgan",Vingen 6,Inequality & Segregation II,2,,545
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,"Framing, Ties, and Diffusion: How Message Strategies and Network Structures Shape Digital Activism","This study investigates how message framing and social network structures jointly shape information diffusion in digital activism. While prior research has examined opinion leaders and viral content, less attention has been given to the interaction between framing strategies—diagnostic, prognostic, and motivational—and social ties—weak and strong ties—in mobilization processes. Using a large-scale dataset of Black Lives Matter (BLM) social media interactions from May 2020 to May 2021, we apply sentiment analysis, social network analysis, and diffusion modeling to analyze how different framing strategies propagate through weak and strong ties. Posts are classified into six emotions (anger, fear, sadness, joy, surprise, trust), with intensity levels assessed to examine their role in mobilization. Results reveal a two-phase diffusion process: (1) Early mobilization is driven by weak ties, where diagnostic and prognostic messages spread across loosely connected clusters, raising awareness and distributing proposed solutions. (2) Sustained engagement occurs within strong-tie networks, where motivational messages reinforce commitment and drive participation. Moreover, this research find that structural influence outperforms follower-based influence, as movement-focused alternative media, independent journalists, and activist networks play a more central role in shaping discourse than traditional celebrities or politicians. This study advances computational social science by integrating framing theory, network theory, and computational modeling to provide a structured understanding of how online movements scale. The findings contribute to political communication and network science by demonstrating how framing strategies interact with social ties to drive large-scale mobilization.","Huanrui Chen, Zhao Wang",Vingen 6,Inequality & Segregation II,3,,929
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Sequenzo: A High-Efficiency Python Package for Social Sequence Analysis in the Era of Big Data,"There has been a growing popularity in sequence analysis (SA) in the social sciences, particularly in life course research, for studying categorical time data such as career trajectories and family formation. Compared to numerical time series, research shows that categorical sequence data are inherently more complex, requiring specialized techniques to analyze transitions, timing, and patterns. However, existing tools, such as R’s TraMineR, face computational inefficiencies that limit their applicability to large-scale datasets. We introduce Sequenzo, a Python package designed for fast, scalable, and user-friendly sequence analysis. It implements standard methods such as optimal matching and hierarchical clustering, but with parallelized dynamic programming and vectorized computation, significantly reducing memory overhead and achieving more than 10 times of speed improvements over TraMineR while maintaining analytical accuracy. Moreover, we call for extending the applications of SA from sociology and demography to economics, management, public health, and history. Potential research directions can be using sequence analysis to track regional innovation, model disease progression, and map institutional transformations.","Yuqi Liang, Xinyi Li, Jan Heinrich Ernst Meyerhoff-Liang",Vingen 6,Inequality & Segregation II,4,,219
,,,,,,,,,,
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Quantifying individualism in the long term (550-2000),"Study 1: Name Uniqueness Across the World (1500-2000) This study examines the historical evolution of individualism using 'name uniqueness'—the distinctiveness of first names within a society—as a well-established proxy for individualism. To compute the ""Name Uniqueness Score,"" we divide the frequency of a specific name in a given time period by the total number of names recorded during that period (Bao et al., 2021), and then average the uniqueness scores of all names to obtain a singular uniqueness score for the entire time period (a year or a decade). Leveraging a comprehensive dataset of 2,313,713 historical individuals from Wikidata, the analysis quantifies name uniqueness from 1500 to 2000 (Fan et al., 2024). The uneven distribution of available data across different time periods is a common challenge in quantitative history. To address this issue, we developed a bootstrapping technique. By resampling the data within each period, we create a balanced sample across a very long time period (see Figure 1). To validate this new method and new dataset, we cross-correlated our results with data from previous study (Mignot, 2022), which used other name metrics such as percentage of top 10 most common names and number of distinctive names, which are based on full sample name register. The cross-correlation result ranged from r = .59 to .95 for females and from r = .42 to .84 for males (see Figures 2A and 2B, for Figures 2C and 2D, Pearson’s correlation resulted in r = .71 for males and r = .85 for females, p < .001). We also correlated our results with survey-measured individualism (b = 0.33, p = 0.038; see Figure 3). These tests confirm that our bootstrapped name uniqueness is a reliable proxy for individualism. Our main analysis revealed that, controlling for year, name uniqueness tends to increase as GDP per capita grows (β = 0.26, p < 0.001, R² = 0.75; see Figure 4 and Table 1 for random intercept model and Table 2 for random slope model). To further solidify our findings, we conducted a series of robustness tests. We calculated name uniqueness based on occupation (β = 0.26, p < 0.001, R² = 0.70; see Figure 5 and Table 3) and gender (β = 0.23, p < 0.001, R² = 0.66; see Figure 6 and Table 4), we tested a more balanced sample with all countries from 1850-2000, where both GDP per capita and name uniqueness data are consistently available (β = 0.24, p < 0.001, R2 = 0.77, see Table 5 and 6). And we also tested fixed effect model (β = 0.33, p < 0.001, R2 = 0.67, see Table 7). These tests produced consistent results, demonstrating the reliability of our study. In this first study, we developed a new method for handling data limitations in historical records. Using this method, we quantified name uniqueness across different cultures for over 500 years and found a correlation with economic development. Study 2: Name Uniqueness Within Imperial China (550-1880) Individualism, characterized by autonomy, independence, and self-expression, is typically seen as a modern and Western phenomenon. Cultural historians, however, have pointed out that its roots extend much further into the past (Brindley, 2010; Hinsch, 2015). In this paper, we delve deeper in time to quantify the rise of individualism in a collectivist country. We used data from the China Biographical Database (Harvard University et al., 2024), which spans 1,500 years of Chinese history (540-1880 CE, N = 641,568). The CBDB documents the source material from which the individual is recorded from, enabling us to calculate name uniqueness based on individual biographies. This approach allows us to control for selection bias in each biographic record, enhancing the accuracy of our analysis. We observe a long-term increase in name uniqueness. Our analysis reveals that this general increase parallels the economic development and modernization of China throughout the Imperial period. We showed that name uniqueness scores significantly increased over time (β = 0.11, p < 0.001, R² = 0.550; see Figure 7 and Table 8). A similar trend is observed within the country, where the economically advanced Yangtze River Delta exhibits consistently higher levels of name uniqueness compared to less developed regions (β = 0.10, p < 0.001, R² = 0.618; see Figure 8 and Table 9). Finally, we observe a decline in name uniqueness during the late Qing dynasty, coinciding with a period of economic crisis (Quadratic term β = -0.01, p = 0.017, see Figure 9 and Table 10). We also conducted robustness tests using another database (N = 1,247,751) covering the periods 1760-1798, confirming that the decline in name uniqueness coincides with economic crisis. Our findings contribute to a more nuanced understanding of cultural evolution in China and challenge long-held assumptions about the immutability of Chinese culture.","Zhaolun Fan, Valentin Thouzeau, Ying Zhong, Coralie Chevallier, Nicolas Baumard",Vingen 6,Sociology of culture,1,,300
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Common sense around the world,"Common sense, in its name, is often assumed to be universally shared, uncontested, and even self-evident. However, several scholars argue that this body of knowledge, which underlies our understanding of everyday life, is socially distributed, i.e., possessed differently by different individuals in a society. Recent evidence further shows that humans vary enormously in their belief even about the simplest matters, suggesting that common sense is paradoxically “uncommon”. This previous work demonstrates how commonsensicality scores1 can be empirically analyzed via shared agreement among people of a population. However, its findings are heavily limited to the original pool of participants, who are English speakers predominantly residing in the U.S. It leaves open several important questions, most importantly whether this heterogeneity in belief is observed cross-culturally, spanning demographic and linguistic groups.","Mark E. Whiting, Amirhossein Nakhaei, Josh Nguyen, Duncan J. Watts",Vingen 6,Sociology of culture,2,,944
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Predictably Unpredictable: Drifts in Nation-Wide Cultural Attention are Predictable,"Predicting changes to consumer attention in markets for cultural products, such as books, movies, and songs, is notoriously difficult. Whereas previous research suggests prediction limits for the popularity of individual products due to complex social influence processes, the limits for predicting changes in collective attention across products remain unknown. Here, we analyze four years of nationwide library loan data, comprising millions of loans of more than 660,000 unique books from more than 45% of the Danish population, and show that drifts in collective consumer attention are systematic and predictable.","Anders Weile, Vedran Sekara",Vingen 6,Sociology of culture,3,,215
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Quantifying world geography as seen through the lens of Soviet propaganda,"Cultural data typically contains a variety of biases. In particular, geographical locations are unequally portrayed in media, creating a distorted representation of the world. Identifying and measuring such biases is crucial to understand both the data and the socio-cultural processes that have produced them. Here we suggest to measure geographical biases in a large historical news media corpus by studying the representation of cities. Leveraging ideas of quantitative urban science, we develop a mixed quantitative-qualitative procedure, which allows us to get robust quantitative estimates of the biases. These biases can be further qualitatively interpreted resulting in a hermeneutic feedback loop. We apply this procedure to a corpus of the Soviet newsreel series ’Novosti Dnya’ (News of the Day) and show that city representation grows super-linearly with city size, and is further biased by city specialization and geographical location. This allows to systematically identify geographical regions which are explicitly or sneakily emphasized by Soviet propaganda and quantify their importance.","Mikhail Tamm, Mila Oiva, Maximilian Schich, Mark Mets, Ksenia Mukhina",Vingen 6,Sociology of culture,4,,761
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,Lifestyle Polarization on a College Campus: Do Liberals and Conservatives Behave Differently in Everyday Life?,"Socializing, moving, working, and leisure form the foundation of human experience. We examined whether these foundational, ostensibly non-political behaviors are nevertheless bifurcated along political fault lines, revealing “lifestyle polarization.” In Study 1, we quantified the association between political identity and 61 social, movement, work, and leisure behaviors collected from smartphone sensors and logs (i.e., GPS, microphone, calling, texting, unlocks, activity recognition) and ecological momentary assessments (i.e., querying activity level, activity type, interaction partners, locations) at multiple temporal levels (i.e., daily, mornings, afternoon, evenings, nights, weekends, weekdays) in a sample of up to 1,229 young adults on a college campus. We found that liberals and conservatives behave differently in everyday life; the behavioral differences were small but robust, not accounted for by other plausible factors (e.g., demographics), and most pronounced in the leisure domain. Study 2 showed that these behavioral differences between liberals and conservatives were not accurately discerned by other members of the community, who overestimated the extent of lifestyle polarization present on campus. Together, these studies suggest that political identity has penetrated some of the most foundational aspects of everyday life, but not to the degree that people assume. We discuss how social life may feel divided not only because of deep ideological disagreements across partisan lines but also because such disagreements are accompanied by distinct lifestyles—both real and (mis)perceived—that may prevent liberals and conservatives from engaging in cross-partisan contact and developing mutual understanding.","Sanaz Talaifar, Diana Jordan, Samuel Gosling, Gabriella Harari",Vingen 6,Sociology of culture,5,,10
2025-07-23 11:00:00,2025-07-23 12:30:00,session_presentation,From Avocados to Trains: Concept Representation and Cultural Archetypes in 1 Billion Sketches,"Concept representation plays a crucial role in human cognition, yet existing research often overlooks the structural complexity and cultural variability of how concepts are visually depicted. Leveraging the large-scale QuickDraw dataset, which contains over a billion sketches from users worldwide, this study investigates concept complexity, prototypicality, and cultural influences on visual representations. First, we introduce a ranking of concept complexity based on visual features such as entropy, stroke count, and pixel distribution. Second, we apply clustering techniques to identify visual prototypes and analyze their emergence across different concepts. Third, we assess the role of conceptual properties and cultural factors in shaping prototypicality by examining country-specific variations in concept representation. Our findings reveal that while certain perceptual-action properties influence prototype formation, cultural factors exert a stronger effect, with countries exhibiting varying degrees of specificity in concept depiction. This work provides a systematic, data-driven approach to understanding how visual concept representations vary across populations.","Arianna Pera, Mauro Martino, Nima Dehmamy, Douglas Richard Guilbeault, Luca Maria Aiello, Andrea Baronchelli",Vingen 6,Sociology of culture,6,,522
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Proximity and genetic networks shape the evolution of cumulative culture,"Chimpanzees exhibit cultural behaviours, particularly in tool use, that parallel early stages of human cumulative culture. Using a computational approach. We investigate the role of genetic connectivity in cultural transmission across chimpanzee populations by analyzing genetic and behavioural data from multiple subpopulations by applying Bayesian logistic regressions and network-based reinforcement analysis. Our results reveal that genetic connectivity strongly predicts the sharing of complex toolsets, while simpler tool behaviours appear to emerge independently. This suggests that cumulative culture in chimpanzees is facilitated by migration-driven social learning. Our work provides one of the first large-scale quantitative evidence for the emergence of cumulative culture in non-human populations.","Onkar Sadekar, Cassandra Gunasekaram, Federico Battiston, Lucio Vinicius, Andrea Bamberg Migliano",Vingen 6,Cultural Dynamics,1,,536
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Dilemmas and trade-offs in the diffusion of conventions,"Outside ideal settings, conventions are shaped by heterogeneous and competing processes that can challenge the emergence of universal norms. This paper identifies three trade-offs challenging the diffusion of conventions and explores each of them empirically using inverse problems motivated by game theory and statistical physics. The first trade-off (I) concerns the imperatives of social, sequential, and contextual consistency that individuals must balance when choosing between competing conventions. The second trade-off (II) involves the balance between local and global coordination, depending on whether individuals coordinate their behavior via interactions throughout a social network or external factors transcending the network. The third trade-off (III) is the balance between decision optimality (e.g., collective satisfaction) and decision costs when collectives with conflicting preferences choose a convention. A novel and broadly applicable statistical physics framework for measuring each of these trade-offs is proposed and applied to a sign convention in physics using textual and network data. The method can reveal the networks and processes through which conventions propagate. This work shows that the purpose of conventions may exceed coordination, and that individual preferences towards conventions are concurrently shaped by cultural factors and multiple social networks. Additionally, it reveals the role of leadership in the resolution of conflicts within collaborations. Finally, this contribution achieves a novel interface between statistical physics and simulation-based inference for empirical analyses of agent-based models of social systems.",Lucas Gautheron,Vingen 6,Cultural Dynamics,2,,307
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Cascades of violence: Identifying armed conflict archetypes through data,"This work introduces an innovative, data-driven framework that rethinks the study of armed conflicts by systematically grouping individual events into ""conflict avalanches"" using transfer entropy. By analyzing an extensive, high-resolution African conflict dataset from 1997 to 2020, we reveal three distinct conflict archetypes—major unrest, local conflict, and sporadic spillover events—each emerging from a robust, unsupervised clustering of conflicts in a multidimensional space spanning contextual factors such as climate, geography, economy, and demographics. This approach not only uncovers underlying scaling laws and long-range correlations in conflict dynamics but also aligns well with historical case studies, offering a powerful alternative to traditional heuristic methods. With its potential applications to a range of social and non-social phenomena that spread in space and time, such as epidemics, migration etc., the study provides a compelling framework that promises to enhance theoretical and predictive models of complex social processes.",Niraj Kushwaha,Vingen 6,Cultural Dynamics,3,,248
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Theoretical models of opinion dynamics can accurately identify individual political preferences from online interaction data,"Models of opinion dynamics describe how opinions are shaped in various environments. While these models are able to replicate macroscopical opinion distributions observed in real-world scenarios, their capacity to align with data at the microscopical level remains mostly untested. We evaluate the capacity of the celebrated voter model to capture individual opinions in a fine-grained Twitter dataset collected during the 2017 French Presidential elections. Our findings reveal a strong correspondence between individual opinion distributions in the equilibrium state of the model and ground-truth political leanings of the users. Additionally, we demonstrate that discord probabilities accurately identify pairs of like-minded users. These results emphasize the validity of the voter model in complex settings, and advocate for further empirical evaluations of opinion dynamics models at the microscopical level.",Antoine Vendeville,Vingen 6,Cultural Dynamics,4,,91
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,The evolution of trends in Fashion,"The global fashion industry, valued at approximately \$1.81 trillion in 2021 [1], is a cornerstone of the modern economy, driving innovation, employment, and commerce across design, manufacturing, marketing, and retail sectors. Beyond its economic significance, fashion is a pervasive cultural phenomenon, deeply embedded in human society as one of the ten cultural universals. Clothing transcends mere utility, serving as a dynamic medium for expressing identity, social status, and cultural heritage. Every individual engages with this practice—whether by embracing or rejecting trends—making fashion an inescapable form of non-verbal communication that reflects societal values, historical shifts, and technological progress. Understanding the evolution of fashion offers a unique lens into human behavior and cultural dynamics. Trends in styles, colors, and silhouettes do not emerge in isolation; they mirror broader social structures, artistic movements, and technological advancements [2]. By leveraging computational methods, this study investigates how fashion trends evolve over time, revealing patterns of innovation, diversity, and influence across decades of runway collections. \textbf{Data:} Our analysis draws on a rich dataset of 954,000 runway looks spanning 1988 to 2025, encompassing 27,000 fashion show collections from 1,800 brands worldwide. This comprehensive corpus captures over three decades of high-fashion evolution, providing an unparalleled resource for tracing the interplay between creativity and culture in runway design. \textbf{Methods:} To systematically analyze this dataset, we employ a multi-stage computational pipeline integrating computer vision, natural language processing, and topic modeling. First, we preprocess images by removing backgrounds using the RMBG-2.0 model, isolating garment details for subsequent analysis (Fig. 1a-b) [3]. Next, we jointly embed images and their textual descriptions into a high-dimensional latent space using FashionCLIP (for visual features) and all-MiniLM-L12-v2 (for textual features),text description by the Qwen2.5-7B-Instruct model for robust multimodal alignment [4]. This embedding captures both visual and semantic dimensions of fashion runway looks. We then adapt BERTopic, a hierarchical topic modeling framework, to decompose these embeddings into granular topics at the token level (e.g., “white dress,” “polka dots,” “asymmetric hem”). Each look is represented as a composite of multiple topics, reflecting the layered complexity of fashion design (Fig. 1c). To validate this pipeline, we benchmark our approach against the Fashionpedia dataset, which includes 48,000 annotated fashion images with segmentation masks and fine-grained attributes (27 apparel categories, 19 apparel parts, 294 attributes) [5]. This validation ensures the accuracy of our topic extraction and embedding process. Finally, we quantify innovation and diversity in fashion trends using two complementary metrics: Richness (the number of distinct topics per brand or collection) and Shannon Style Entropy (a measure of topic distribution uniformity). We also apply an innovation diffusion model to assess novelty in styles, colors, and silhouettes over time, tracking how trends emerge, propagate, and fade across brands and seasons. This approach enables us to map the cultural evolution of fashion and identify drivers of change at both micro (brand-level) and macro (industry-level) scales. \textbf{Premilinary Results:} Preliminary findings demonstrate that our multimodal embeddings effectively Capture structural patterns in fashion shows, distinguishing between types (e.g., Menswear, Couture, Ready-to-Wear; Fig. 2a) and seasonal variations (e.g., Spring/Summer vs. Fall/Winter; Fig. 2b). These results validate the robustness of our embedding space as a representation of fashion’s multidimensional nature. We anticipate several key insights from the full analysis. First, we expect to uncover cycles of innovation, where periods of high Richness and Entropy signal bursts of creativity (e.g., the avant-garde movements of the 1990s or the sustainability-driven shifts of the 2020s), followed by consolidation phases with lower diversity. Second, we hypothesize that influential brands (e.g., Chanel, Prada) exhibit higher topic Richness and act as trendsetters, with their innovations diffusing to smaller labels over subsequent seasons.\\ This study bridges computational social science and cultural analysis, offering a scalable framework to decode the dynamics of fashion as a mirror of human society. By quantifying trends and innovation over decades, we contribute to a deeper understanding of how cultural artifacts evolve, diffuse, and reflect broader social forces—an endeavor with implications for historians, designers, and social scientists alike.","Katharina Ledebur, Sagar Kumar, August Lohse, Karolina Sliwa, Louis Boucherie",Vingen 6,Cultural Dynamics,5,,780
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Computational Analysis of Lyrical Trends in Vocaloid vs. Human Singers,"Singing and listening to music are fundamental human activities that reflect society and culture. The emergence of vocal synthesis technology has expanded the landscape of music creation, with Vocaloid—exemplified by Hatsune Miku—gaining widespread popularity in Japan. While human singers and Vocaloids perform songs, their lyrics differ in thematic content, reflecting distinct creative and cultural dynamics. This study analyzes the lyrical trends of Vocaloid and human-performed songs from 2008 to 2023, focusing on topic distribution and temporal changes. Using BERTopic for topic modeling and a large language model (LLM) for topic labeling, we examined 800 Vocaloid songs from Niconico Video and 796 human-performed songs from the Billboard Japan Year-End charts. The results reveal that Vocaloid lyrics frequently contain negative themes, such as “lie” and “fool,” while human lyrics emphasize romantic and optimistic themes. Additionally, human lyrics exhibit greater fluctuations over time, particularly in response to social events such as the COVID-19 pandemic. Our findings highlight the distinct evolution of lyrics between Vocaloid and human singers, emphasizing the role of computational technologies in shaping modern music culture. This research contributes to understanding how vocal synthesis influences lyrical expression, expanding the boundaries of creativity and cultural transformation in music.","Ryo Yokoi, Ryosuke Yamanishi, Mitsuo Yoshida",Vingen 6,Cultural Dynamics,6,,506
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Cognitive Representations of Social Networks,"People not only form social networks, they construct mental maps of them. We investigate how individuals perceive the social structure around them. Social networks are crucial for social coordination and the diffusion of health-related, economic, and political phenomena. Social network research has focused on the social consequences of social structure, and work on social cognition has largely focused on how people represent the attributes of other people rather than of structure. Yet, network cognition in remains underexplored. The ability to accurately “see” one’s social network may facilitate individual and collective action. Humans possess a coalitional psychology. Beliefs about relationships are likely crucial mechanisms by which people form alliances, infer trustworthiness, or assign status. This may be especially important in settings with weak or absent formal institutions, such as the developing world. While social theorists have supposed individuals have little knowledge of their broader social world, a few have argued that mental representations of networks are important to understand social dynamics. Yet, empirical evidence has been limited. Work has examined cognition of social networks in the laboratory or very small networks in circumscribed settings. Our study represents the first investigation of network cognition in a complex natural setting, with rich social data. We develop a strategy to evaluate network cognition in 10,072 adults in 82 villages in Latin America, systematically mapping the underlying village networks.","Eric M. Feltham, Nicholas Christakis",Troselli,Computational Psychology,1,,931
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Automating the analysis of decision reasons with large language models,"Understanding why people make decisions remains a core challenge in decision science. Traditional models rely on revealed preferences, often missing critical cognitive insights. In this study, we leverage large language models (LLMs) to automate the extraction of decision reasons from verbal reports. First, we validate LLMs’ ability to process decision problems and reason-based preferences. Using the best-performing model, we then analyze verbal reports from an empirical study on risky choices, demonstrating strong discrimination between present and absent reasons. A predictive model based on the identified decision reasons significantly outperforms prospect theory, the most prominent model of risky choice, in predicting choices. Our findings suggest that LLMs can provide a scalable, interpretable method for uncovering subjective reasoning in decision-making, with broad applicability to psychology, behavioral economics, and AI-driven cognitive modeling.",Kamil Fuławka,Troselli,Computational Psychology,2,,1015
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,A Framework for Exploring the Effect of Selection and Framing Bias in News Through LLM-Generated Synthetic Articles,"In today's complex media landscape, understanding media bias and its impact on public opinion is more vital than ever, especially following the heightened focus on fake news after the 2016 U.S. Presidential Election, which overshadowed mainstream media bias . While negativity bias can distort public perceptions, it is often considered less concerning than misinformation, even though mainstream media exposure far surpasses that of outright false information. Despite the emphasis on factual accuracy, mainstream media exhibits bias through selective topic highlighting and narrative framing. Although substantial research exists on media bias and its impacts, most studies on framing bias are limited in scope. To address this gap, our study introduces a framework employing large language models (LLMs) to explore selection and framing bias comprehensively. This innovative methodology generates synthetic articles from actual news facts and quotes, varying fact selection and presentation tone. Our randomized survey experiment reveals that biased presentation of accurate facts can significantly influence readers' opinions, with negative framing being particularly potent, especially among less informed individuals. The study suggests that misinformation is not essential to shape public opinion; instead, the selective presentation of truthful information suffices. This concern is amplified by the prevalent negativity bias in media, which may contribute to negative perceptions of the economy, political figures, and institutions. We advocate for a more comprehensive approach that not only considers misinformation but also examines biased yet factually correct reporting practices in mainstream media.","Amir Tohidi Kalorazi, Samar Haider, David Rothschild, Duncan J. Watts",Troselli,Computational Psychology,3,,851
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,In Your Own Words: Free-Text Descriptions of Identity Reveal More Than Traditional Census Categories,"Categories for race, gender, and sexual orientation facilitate computational analysis but may not fully capture people's identities. Here, we investigate the potential of using open-ended, self-described identity responses, combined with modern language modeling techniques, to capture more granular and contextually relevant insights into individuals’ identities. We collect, and will make publicly available, the ""In Your Own Words"" dataset which includes free-text identity descriptions from 1,000 respondents. Alongside these open-ended responses, the dataset contains categorical identity measures and life outcome variables, such as health, life satisfaction, and experiences with discrimination. Our analysis reveals that free-text identity clusters do not fully align with Census categories, demonstrating heterogeneity within and across identity groups. Furthermore, regression analyses indicate that incorporating free-text identity clusters improves predictions of key life outcomes––such as mental health, life satisfaction, and perceptions of discrimination––beyond using categorical data alone. However, this predictive gain is observed primarily for gender and sexual orientation, with race-based free-text clusters providing limited additional explanatory power. Overall, our results demonstrate that free-text data, when analyzed with LLMs, enhances the quantitative study of identity by combining the nuance of qualitative responses with the scalability of computational methods. This work contributes to broader efforts in survey methodology and computational social science, highlighting the potential of LLMs to refine representations of identity in empirical research.","Jenny Shan Wang, Emma Pierson",Troselli,Computational Psychology,4,,890
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Inferring individual belief networks from open-ended narratives,"Belief networks provide a predictive and explanatory framework for belief dynamics. Previous research has estimated belief networks at the population level using questionnaires with predefined questions. This is problematic because 1) belief networks are fundamentally an individual-level concept, and 2) pre-defined questionnaires induce demand effects and limit the structural variation that we can measure. We propose to instantiate LLMs with open-ended text from human participants and use them to infer the relevant parameters of a belief-dynamics model. This drastically reduces the burden on participants to provide numerous explicit ratings of nodes and links in their belief network, and it allows them to highlight the beliefs that are salient to them personally. We show that network reconstructions are similar across human-coded and LLM-coded belief networks, and provide consistent behavioral predictions.","Victor Møller Poulsen, Peter Steiglechner, Daniele Barolo, Henrik Olsson, Mirta Galesic",Troselli,Computational Psychology,5,,602
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,A little scientific knowledge is associated with the highest overconfidence levels and negative attitudes towards science,"It has been argued that “no problem in judgment and decision making is more prevalent and more potentially catastrophic than overconfidence”. Overconfidence can be broadly defined as a bias that makes people have a subjective assessment of their own aptitude that is greater than their objective accuracy of such aptitude. A well-studied example concerns the Dunning-Kruger effect, which posits that the least knowledgeable are more likely to overestimate their skills, an effect that has been linked to particularly consequential aspects of scientific knowledge, such as vaccine hesitancy and opposition to genetically modified foods. Since the publication of the original Dunning–Krueger effect, the field has accumulated a large body of evidence and evolved to suggest a more nuanced pattern than the original proposal. For example, several studies indicate that the main tenet of the effect—that the unskilled are unaware of their lack of skill—might not be universal. Moreover, gauging confidence or knowledge is not trivial: no metrics are perfect and might not be universal or even independent. For example, measures to gauge confidence often rely on self-reporting (e.g., participants are asked how well they believe they performed on a given task), and this can introduce important biases, such as desirability bias. In the current study, we applied a computational approach to three large-scale surveys (Eurobarometer, General Social Survey, Pew Research Center’s American Trends Panel) and two academic datasets, spanning 30 years in Europe and the USA and involving over 95.000 participants. This large dataset allowed us to introduce both analytical and methodological changes to the study of (over)confidence in science knowledge and in attitudes towards science. First, we propose a new indirect confidence metric that does not rely on self-reporting or peer comparison, requiring only that study participants are given the opportunity to provide a “Don’t know” answer. The rationale of this measure is that, when asked a scientific knowledge question, participants who know the answer should answer correctly, participants who do not should answer “Don’t know”, while an incorrect answer can be interpreted as an overestimation of one’s knowledge (participants think they know, when they don’t). In this case, overconfidence is calculated as the proportion of incorrect answers out of all non-correct answers. Agent-based simulations are then used to account for the fact that, if at least some of the incorrect answers are the result of guessing, we should expect a higher level of incorrect answers in higher knowledge scores, as guessers’ scores are inflated, in comparison with people who do not guess, by the fact they sometimes get the correct answer by chance. Second, due to our large samples, we achieve very reliable estimates of the confidence of participants at the tails of the knowledge distribution and can study how knowledge and confidence vary across their full scale, avoiding the common quartile aggregation which may hide important variation. Third, we compare our new indirect metric with more traditional confidence metrics (e.g., how well-informed participants believe themselves to be or how many items they believed they answered correctly). Fourth, using the Eurobarometer dataset, we investigate how overconfidence covaries with negative attitudes towards science, assessed through participants’ agreement with a set of statements. Results revealed that: 1) confidence grows much faster than knowledge, but 2) this growth is non-linear, with the largest confidence gaps at intermediate to high knowledge levels, not the lowest levels as the Dunning-Kruger effect would predict; 3) this effect is robust across confidence metrics, and 4) the least positive attitudes towards science are found for these high-confidence / intermediate-knowledge groups, not the lowest levels as many science communication models hold when they propose that what is needed to improve attitude towards science is more knowledge of science. Thus, our results indicate that the least knowledgeable show at least some evidence of good metacognition, but that individuals with some knowledge (which are also the most frequent in our surveyed populations) are the most likely to overestimate it and to have less-positive attitudes towards science. This study is thus a good example of the importance of large-scale surveys and how they can be combined with agent-based modelling to generate clear implications for current science communication strategies, as providing incomplete or oversimplified information may backfire by offering more confidence than knowledge. Together, our work suggests that, at least in the case of scientific topics, some knowledge is more dangerous than little knowledge, and it is fundamental to develop multidisciplinary approaches, building from psychology, social media, and complex systems analysis, to avoid such dangers.","Simone Lackner, Frederico Francisco, Cristina Mendonça, André Mata, Joana G Sa",Troselli,Computational Psychology,6,,991
,,,,,,,,,,
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Social influence and behavioral contagion: A Reddit bot field experiment,"The study investigates social influence and contagion from artificial agents onto human users in a realistic setting. We conduct a field experiment on Reddit in which an apparent bot and human user accounts give symbolic awards to users praising the users' emotional tone, logical argument, moral integrity, or explaining the award resulted from a random draw in a lottery. We evaluate how the different rationales for the award affect the recipients’ subsequent behavior on the platform in terms of volume, sentiment, and language, as well as the further behavioral, emotional, and lexical contagion to other users.","Hiroki Oda, Kinga Makovi, Taha Yasseri, Milena Tsvetkova",Vingen 8,Experiments,1,,635
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,"Offensive Post Filtering on Online Behavior: A Large-Scale Randomized Controlled Trial with 100,000 users on Nextdoor","We investigate the effectiveness of an intervention designed to filter offensive content on the local social media platform Nextdoor. The intervention, which is commonly used on large social platforms, was tested in a randomized controlled trial with 100,000 people over nine months. We assessed whether content filtering affected fifteen different measures of platform behavior, including views of offensive posts, visits to the platform, content consumption and content production. The results showed a significant reduction in two target outcomes - views of offensive posts and comments - in the treatment group compared to the control group. However, we did not observe significant effects of the intervention on the thirteen other outcomes measured between groups. This study provides empirical evidence on the impact of a prominent and commonly used intervention, but also highlights the limitations of the present intervention. Through these null findings, we seek to demonstrate the complexity of effectively moderating online platforms and to engage in a more nuanced discussion of when interventions might be (in)effective.","David Joachim Grüning, Matthew Katsaros",Vingen 8,Experiments,2,,979
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Celebrity Counterspeech Reduces Hate Content in the Nigerian Twitter,"As social media becomes an integral part of modern society, the proliferation of hate speech poses significant risks to social cohesion. This study evaluates the effectiveness of empathy-based counterspeech delivered by Nigerian celebrities in reducing hate content on Twitter. In a randomized controlled experiment, 63,550 users with a history of engaging in hate speech were assessed, with 31,685 randomly assigned to receive a short, pro-social video message via Twitter Ads from December 2023 to May 2024. We measured both overall user engagement and hate-related activity, over pre-treatment, during-treatment, and post-treatment periods. Findings reveal a 5.1% reduction in overall platform activity and a 3.2% reduction in hate speech during the intervention, with effects persisting up to three months after the campaign ended. These results highlight the promise of counterspeech as a non-invasive, cost-effective alternative to content-moderation as a punitive measure in combating online hate speech, though they also raise questions about potential impacts on user engagement.","Eaman Jahani, Blas Kolic, Hause Lin, Manuel Tonneau, dnlbrkc, Niyati Malhotra, Victor Orozco-Olvera, Samuel Fraiberger",Vingen 8,Experiments,3,,1021
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Institutional Preferences in the laboratory,"Designing effective social and policy systems is a vital and forbidding challenge made more difficult because, in real-world settings, individuals don’t just passively accept the static envi- ronments imposed upon them: they act both within and upon the social systems that structure their interactions. Should we expect player-driven changes to the ”rules of the game” to ben- efit cooperation, as agents tweak their environment toward non-zero-sum games — or hinder it because of the challenges of constant change? We introduce a laboratory setting to test whether groups can guide themselves to cooperative outcomes by manipulating the strategic environment that structures their interactions. By offering players “first-order” choices within an economic game (agency over behavior) along with “second-order” choices between games (agency over the rules of the game), we understand emergent cooperation in naturalistic settings in which the rules of the game are themselves dynamic and subject to choice.","Qiankun Zhong, Nori Jacoby, Ofer Tchernichovski, Seth Frey",Vingen 8,Experiments,4,,715
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Integrative Experiments Identify the Effects of Tasks on Group Performance,"The question of when groups outperform individuals has been central to the social and behavioral sciences for decades. Although a large body of evidence shows that groups can exhibit performance advantages, the specific conditions under which they do so remain unclear. Here, we define group advantage as the performance gain due to group interaction relative to an equivalent number of individuals working independently. Through an integrative experiment using a 24-dimensional “Task Space” that quantifies task attributes, we sampled 20 diverse tasks at three complexity levels, randomly assigning participants to work individually or in groups of three or six — resulting in 5,972 observations across 180 unique experimental conditions. Our results reveal striking heterogeneity in group advantage, with outcomes ranging from one third as good as to 1.6 times better than the best individual, depending on the task context. To characterize these patterns, we developed predictive models using task dimensions that significantly outperformed traditional approaches based on task types or group composition characteristics. Demonstrable correctness emerged as the most predictive feature, followed by creative requirements; however, these features interact in important ways — for example, the benefit of creativity depends critically on whether the task has demonstrably correct answers. Our results refocus the debate from whether groups “work better” to the specific conditions under which they do and do not work, while demonstrating how integrative experiments combined with machine learning can uncover generalizable patterns. We generate predictions for an additional 420 yet-unseen experimental conditions, inviting further research to test and refine our model.","Mark E. Whiting, Xinlan Emily Hu, Duncan J. Watts, Abdullah Almaatouq",Vingen 8,Experiments,5,,615
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Identifying Latent Intentions via Inverse Reinforcement Learning in Repeated Linear Public Good Games,"Robust results from public good games continue to defy theory. Uncertainty about the distribution of social preferences can explain first round contributions, but not the variance of contribution patterns in repeated play. Using a large-scale dataset (50,390 observations from 2,938 participants) we address this gap with two methodological contributions. First we propose a clustering approach (dynamic time warping) that reflects the nature of the data: it is two-dimensional, relating choices to experiences; and it allows changes to occur at idiosyncratic points of time. Second we refrain from constraining dynamic reactions to predictions derived from static social preferences. Instead, we treat reward function design as an estimation problem, using Inverse Reinforcement Learning to model behavioral patterns as discrete switches between latent intentions. This approach reveals that apparently noisy behavior in social dilemmas can be systematically explained as fluctuations between distinct latent intentions. Our framework successfully accounts for behavioral patterns previously categorized as noise, providing a new paradigm for understanding dynamic decision-making in social dilemma games.","Carina I Hausladen, Marcel H Schubert, Christoph Engel",Vingen 8,Experiments,6,,694
2025-07-22 14:30:00,2025-07-22 16:15:00,session_presentation,Reasoning within and between collective action problems,"Understanding cooperation in social systems is challenging because the ever-changing rules that govern societies interact with individual actions, resulting in intricate collective outcomes. In virtual-world experiments, we allowed people to make changes in the systems that they are making decisions within and investigated how they weigh the influence of different rules in decision-making. When choosing between worlds differing in more than one rule, a naïve heuristics model predicted participants’ decisions as well, and in some cases better, than game earnings (utility) or by the subjective quality of single rules. In contrast, when a subset of engaged participants made instantaneous (“within-world”) decisions, their behavior aligned very closely with objective utility and not with the heuristics model. Findings suggest that, whereas choices between rules may deviate from rational benchmarks, the frequency of real time cooperation decisions to provide feedback can be a reliable indicator of the objective utility of these rules. Methods: We recruited 771 participants that provided consent in accordance with approved protocol. All participants were recruited online using Prolific and Amazon Mechanical Turk. We implemented asynchronous game design using PsyNet (https://www.psynet.dev/) for automated online Implementation. The 3D virtual environment was coded in Unity 3D and integrated with Psynet, which controlled the game logic and data collection. Game design: In each turn, participants navigate in virtual islands to search and collect coins. Each island had 20 collectable coins, each worth one cent. Participants commuted between islands by riding simulated ferries. Each ferry type corresponds to an arm in the embedded multi-arm-bandit (MAB) problem with a total of nine ferry types (=bandit arms) ranging in speed (Tchernichovski et al., 2023). In each turn, players choose between two arms (ferry types) selected from the overall nine. The bandit arm reward is the speed of the ferry, ranging between 2 and 30 seconds, with faster ferries providing participants more time at the destination to compete in coin collection. To add a “collective intelligence” dimension to the MAB, we implemented a public ferry rating dashboard, akin to public product rating on marketplaces. Results: We randomly assigned each participant to a game, with a combination of four binary engagement rules. For between game rule choices, we found that both objective utility and heuristic averaging models fit the rule choices fairly well, with predictions that are within the error margins for most rules and rule combinations. Interestingly, for the within game choices, the objective utility model gave even more accurate prediction of choice frequencies, with model estimates falling within the error margin of 10 out of the 12 treatment groups. In sharp contrast, the heuristic averaging model predictions, which are by design a perfect fit to the single rules, falls outside the error margins of all the combinations of rules, well below expectation (binomial test p= 0.008). Discussion: We evaluated how successful people are at forecasting their own collective’s behavior under increasingly complex conditions. We found that earning rate predicted choices between games to some extent, but so did the averaging heuristic. Interestingly, for the subset of participants who joined the club, heuristic averaging failed, but earning rate (objective utility) gave accurate predictions for the frequencies of instantaneous cooperation decisions within game. Whereas heuristic averaging failed, the objective utility model gave a good fit to the choice frequencies for both single rules and for combinations of rules. Are between-games decisions recruiting different faculties than decisions within them? What is it that made the within-game decisions more consistent with rationality? The subset of engaged participants who joined the club might have played more rationally compared to the general population, either because they were engaged, or because they self-selected the rules (Krebs et al., 2024). Alternatively, the decisions between games are less rational because they are removed from the game dynamics, whereas within game decisions are more rational because they are implicit (Ludwig et al., 2020). Either way, this outcome has interesting implications: modern communication technology enables real-time influence of citizens influence over the functioning of the system via online feedback. Overall, we hope that our study can contribute to the understanding of a transitivity formalism for forced binary decisions between social systems, comparing decisions made within- and between- artificial social worlds. Integrating recent advances in experiment design and institutional theory, should enable new inquiry into multi-level decision-making in complex social environments, towards a cognitive science of self-organized self-governance.","Ofer Tchernichovski, Seth Frey, Dalton C. Conley, Nori Jacoby",Vingen 8,Experiments,7,,368
,,,,,,,,,,
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,From Occasional to Steady: Habit Formation Insights From a Comprehensive Fitness Study,"Exercising regularly is widely recognized as a cornerstone of health, yet the challenge of sustaining consistent exercise habits persists. Understanding the factors that influence the formation of these habits is crucial for developing effective interventions. This study utilizes data from Mars Athletic Club, Türkiye's largest sports chain, to investigate the dynamics of gym attendance and habit formation. The general problem addressed by this study is identifying the critical periods and factors that contribute to the successful establishment of consistent exercise routines among gym-goers. Here we show that there are specific periods during which gym attendance is most crucial for habit formation. By developing a survival metric based on gym attendance patterns, we pinpoint these critical periods and segment members into distinct clusters based on their visit patterns. Our analysis reveals significant differences in how various subgroups respond to interventions, such as group classes, personal trainer sessions, and visiting different clubs. Using causal inference analysis, we demonstrate that personalized guidance and social dynamics are key drivers of sustained long-term engagement. By systematically examining these variables and considering the specific characteristics of different clusters, our research demonstrates the importance of a tailored, multi-dimensional approach to promoting exercise habits, which integrates social dynamics, personalized guidance, and strategic interventions to sustain long-term engagement.","Onur Varol, Ege Demirci, Efe Tüzün, Ahmet Furkan Ün, taners",Vingen 7,Health & Quality of Life I,1,,83
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Sleep Patterns During the COVID-19 Pandemic: A Longitudinal Multisensor Study,"Our study investigates the impact of the late-stage COVID-19 pandemic on sleep patterns. Using a year’s data from fitness trackers and questionnaires of 128 university workers, the study reveals significant shifts in the sleep patterns (including duration, timing, and regularity) of working adults, linked to individual and external factors. We observed that longer daylight hours were associated with reduced sleep duration, while stricter pandemic measures appeared to mitigate this effect. Occupational roles influenced sleep duration and its consistency, with service staff getting more and steadier sleep than academic staff. Notably, snoozers showed less structured sleep, with greater variability in sleep duration and timing. These insights imply the importance of considering lifestyle and work-related factors in understanding sleep health as people adapt to the post-pandemic life.","Nguyen Luong, Juhi Kulshrestha, Gloria Mark, Talayeh Aledavood",Vingen 7,Health & Quality of Life I,2,,819
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Characterizing Online Activities Contributing to Suicide Mortality Among Youth,"Recent rise in youth suicide highlights the urgent need to understand how online experiences contribute to this public health issue. Our mixed-methods approach responds to this challenge by developing a set of themes focused on risk factors for suicide mortality in online digital spaces and a framework to model these themes at scale. One of the persistent challenges in understanding the effects of social media on mental health outcomes is the lack of context of social media experiences, given the tendency for scientists to measure social media exposure relative to time spent online versus the content or interactions in the online space. To fill this gap, we identified 13 specific experiences within social media that were considered by law enforcement, the medical examiner, family or friends to be relevant in contexualizing a given adolescent’s death. We then examined the demographic, social, and contextual variables associated with a given social media experience to better understand trends related to social media and adolescent suicide. Our work has implications for suicide prevention research in computational and policy domains.","Aparna Ananthasubramaniam, Elyse Joan Thulin",Vingen 7,Health & Quality of Life I,3,,959
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,A population-based study of suicide among gays and lesbians in the United States,"Sexual minorities have higher rates of suicidal ideation and attempts than heterosexuals, but the risk of suicide remains underexplored due to missing sexual orientation data in death records. We conduct the first population-based study in the United States to estimate suicide rates and risk factors among gay and lesbian populations by combining suicide cases from the National Violent Death Reporting System (NVDRS) with living population data from the Behavioral Risk Factor Surveillance System (BRFSS) from 2014 to 2021. The suicide rate among gays and lesbians was significantly higher at 34.33 per 100,000 compared to 18.91 per 100,000 among heterosexual individuals, revealing a substantial disparity (15.42 per 100,000 gap). This disparity persisted after adjusting for socio-demographic and economic factors, including educational attainment and unemployment status. Notably, controlling for marital status reduced the association by half, which suggests the importance of policies promoting social integration in reducing suicide disparities within sexual minorities.","Byungkyu Lee, Junsol Kim, Bernice Pescosolido",Vingen 7,Health & Quality of Life I,4,,864
2025-07-24 11:00:00,2025-07-24 12:30:00,session_presentation,Stress Bytes: Decoding the Associations between Internet Use and Perceived Stress,"Stress is a fundamental aspect of human existence and a contributor to various physical and mental health conditions. Traditionally, stress has been associated with major life events; however, everyday experiences also trigger physiological responses that can lead to strain. In today's digital age, the internet plays an increasingly influential role in shaping our daily experiences through communication, work, education, and leisure. Despite its pervasive influence, research on stress and psychological well-being has predominantly focused on offline activities, overlooking the potential impact of online behaviors on stress and well-being. Additionally, existing studies on online engagement often suffer from limitations such as short study durations, small sample sizes, and an over-reliance on self-reported internet use data, which may introduce biases and obscure the complete picture of the connection between online and offline experiences. To address this gap, we conducted a longitudinal multimodal study involving 1,490 German participants over a span of seven months. Our study combined fine-grained, passively observed web browsing traces from desktops and mobiles of the study participants with monthly questionnaires containing validated psychological scales (Perceived Stress Scale, PSS-10). By utilizing fine-grained, actual behavioral data, our study goes beyond subjective self-reports on internet use to establish a data-driven framework for identifying behavioral markers of stress in individuals' internet use. We employed linear mixed-effects models, which are well-suited for longitudinal data as they account for repeated measurements and both fixed and random effects. We examined three dimensions of internet use: (i) volume, (ii) temporal, and (iii) semantic browsing volume. Socio-demographic variables (e.g., gender, age, income) and survey wave effects (to account for seasonal variations in stress) were controlled for in each model. The relationship between internet use and stress varies by how, (behavioral patterns), where (contextual factors), when (temporal factors), and by whom (individual differences) the internet is used. Our research adopts a structured approach to explore these dimensions comprehensively. First, we analyze how internet use behaviors—such as volume, timing, and content categories (e.g., social media, work, entertainment)—relate to stress. This establishes which activities contribute to or alleviate stress. Next, we explore ‘where’ digital engagement occurs, comparing structured (desktop) versus fragmented (mobile) interactions that influence stress. We then examine short-term digital behaviors within two days of stress evaluations to identify immediate behavior. Finally, we explore individual differences, considering factors like age, gender, income, and baseline stress. This helps determine which groups are more susceptible to stress-related digital behaviors, enhancing our understanding of digital well-being. Our findings identify distinct stress-related patterns in internet use. While total online time is not significantly associated with stress, how that time is used matters. Among mobile users, higher engagement with shopping platforms is linked to increased stress ( = 0.04, p = 0.035), while work-related internet use is associated with reduced stress ( = -0.03, p = 0.042). Contextually, mobile-based behaviors show a stronger link to stress than desktop use, highlighting how device interaction influences stress levels. Temporally, short-term analysis suggests that certain activities, like news consumption, may help mitigate stress. Finally, individual differences reveal that younger individuals, women, and lower-income groups experience higher stress levels. For highly stressed individuals, more time online--especially on social media and gaming via mobile devices--is linked with increased stress. In this group, income is the only significant socio-demographic predictor of stress, with age and gender showing no notable effects. Our study highlights the importance of a detailed analysis of internet usage, demonstrating how a data-driven approach, combined with online questionnaires, can uncover the nuanced relationship between digital behavior and stress. By analyzing how, when, where, and by whom the internet is used, we provide a layered understanding of these associations, moving from broad patterns to contextual and temporal influences, and finally to individual differences. Thus, our research offers a scalable framework for analyzing digital behavior as a marker for well-being factors, including stress, presenting a robust alternative to traditional self-reported measures. The insights gained can inform personalized tools for self-monitoring and managing online behaviors to reduce stress and promote digital well-being, contributing to global mental health initiatives.","MOHAMMAD BELAL, Nguyen Luong, Talayeh Aledavood, Juhi Kulshrestha",Vingen 7,Health & Quality of Life I,5,,714
,,,,,,,,,,
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Leveraging Human–AI Complementarity for More Accurate Open-Ended Medical Diagnostics: A Hybrid Collective Intelligence Approach,"Artificial intelligence systems, particularly large language models (LLMs), are increasingly employed in high-stakes decisions. However, LLMs can hallucinate, lack common sense, and exhibit biases—limitations that may not be fully addressed by more advanced architectures, larger datasets, or additional human feedback. Here, we introduce a hybrid collective intelligence framework that blends the complementary strengths of human expertise and LLMs. Applying this method to open-ended medical diagnostics, we combine 40,762 physician-generated differential diagnoses with the output of five state-of-the-art LLMs across 2,133 medical cases. We find that hybrid ensembles of physicians and LLMs outperform single physicians, human-only collectives, individual LLMs, and LLM ensembles. Our study highlights the potential for collective human and machine intelligence to improve accuracy in complex, open-ended domains like medical diagnostics.","Nikolas Zöller, Julian Berger, Irving Lin, Nathan Fu, Jayanth Komarneni, Gioele Barabucci, Kyle Laskowski, Victor Shia, Benjamin Harack, Eugene A. Chu, Vito Trianni, Ralf H.J.M. Kurvers, Stefan Herzog",Vingen 7,Health & Quality of Life II,1,,720
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Detecting Dementia within Naturalistic Conversation: A Diagnostic Classification Tool,"Early cognitive decline in dementia, characterized by impairments in memory, speech, and orientation in time and space, can go unnoticed and unreported, but the progression of dementia symptoms can be slowed if detected early. Cognitive decline can be managed through cognitive-communication training and rehabilitation, yet the clinical tools currently available to target interventions and measure rehabilitation progress are often limited by tests based on non-representative normative data and non-functional measures that do not capture the naturalistic aspects of everyday conversation. Recent breakthroughs in automated transcription and Natural Language Processing provide the opportunity to extract detailed conversational features from large volumes of speech data and use these features to establish normative data against which subtle changes in communication can be measured. These advances enable automated analysis at a scale previously unattainable, establishing the feasibility of innovative diagnostic and treatment tools that are accessible, non-invasive, affordable, and standardized, and can preserve or improve quality of life. In this study, we leverage these computational advances and a large, diverse corpus of over 50,000 interview audio samples from the StoryCorps Archive to develop a machine learning classifier that can detect dementia using features of conversational structure and cohesion extracted from naturalistic speech. Using this diverse corpus, we also evaluate the bias of our classifier that could affect its performance for detecting dementia in underrepresented demographic groups and contribute to disparities in clinical outcomes.","Ardyn Vivienne Olszko, Katie Ekstrom, David C. Jangraw",Vingen 7,Health & Quality of Life II,2,,860
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Words That Resonate: How Psycholinguistic Similarity Drives Message Preference in Adolescent Health Communication,"Introduction. Everyday language reveals our inner psychological states and personalities through unique word choices and sentence structures, forming a “linguistic fingerprint” that distinguishes individuals without exposing sensitive personal data. This intrinsic style enables novel approaches to tailoring communication, especially for adolescents, by enhancing personal relevance without compromising privacy. Recent research shows that mirroring an individual’s linguistic style can boost engagement, trust, and effectiveness in digital interactions, education, and interpersonal exchanges. However, most studies have focused on isolated language features (e.g., sentiment, formality), leaving a gap in understanding which linguistic dimensions truly drive these effects. Moreover, while message tailoring has been thoroughly studied, we currently do not understand the underyling mechansims of linguistic tailoring as a persuasion tool. This lack of understanding limits our ability to apply lingusitic tailoring effectively in computational communication (e.g., chatbots) or within social media campaigns. Research Aim: This study establishes a theoretical and practical foundation for psycholinguistic tailoring in persuasive health communication by investigating: Which psycholinguistic categories most effectively resonate with adolescents (RQ1), Whether messages matching their individual linguistic style enhance persuasiveness (RQ2), and The underlying mechanisms, including the effects on perceived personalization and message effectiveness (RQ3). Method. The experiment was conducted in four secondary schools in [COUNTRY] and involved 178 adolescents aged 12 to 14. To capture their authentic linguistic style, we collected a corpus of WhatsApp chats donated by the participants via a dedicated data donation software (mean word count per person = 7.976). These texts were analyzed using the well-established Linguistic Inquiry Word Count (LIWC) tool (LIWC22; Boyd, 2022; Pennebaker, 2011), focusing on 19 LIWC categories that directly reflect psycholinguistic properties (see Table 1). After the linguistic scoring of our participants, we employed a dichotomous message choice task. Adolescents were presented with 19 pairs of health-promoting Instagram messages. In each pair, one message (the control) exhibited a low score (< 5) in a specific LIWC category, while its counterpart (the experimental message) had a high score (> 14) in that category. Participants were asked to choose their preferred message for each pair (see Figure 2). Importantly, the messages were carefully designed to be identical in meaning, syntax, and length, differing only in their psycholinguistic style. To assess the similarity between each message and a participant’s own linguistic style, we computed a standardized psycholinguistic similarity score for each LIWC category. This score, calculated as the difference between the LIWC score of the experimental message and that of the participant, ranges from 0 (extreme dissimilarity) to 1 (extreme similarity). Results/Discussion. Addressing our first research question, we ranked the 19 psycholinguistic categories from least to most popular within the message choice task (Table 1, Figure 1). The results reveal a clear preference for positive-valence styles: over 62% of adolescents favored health messages featuring words related to rewards or drive (e.g., achievement, striving), while only 25–33% preferred messages with negative-valence words (e.g., negative tone, negative emotion, lack) or messages with more complex, lengthy words. This pattern indicates a strong positivity bias in adolescents’ message preferences, independent of linguistic similarity. For our second research question, we employed a Bayesian multilevel logistic regression with psycholinguistic similarity as the main predictor and message choice as the dependent variable. The analysis showed that psycholinguistic similarity does not significantly predict message choice (b = –0.03, 95% CI [–0.18, 0.10]; BF₁₀ = 31.56), suggesting that adolescents do not generally prefer messages that mirror their own linguistic style across the 19 categories. Additional analyses examining potential mediating mechanisms further revealed that psycholinguistic similarity did not predict perceived personalization (b = –0.01, 95% CI [–0.02, 0.01]; BF₁₀ = 45.46) or perceived message effectiveness (b = –0.02, 95% CI [–0.13, 0.07]; BF₁₀ = 45.69). The robust Bayes Factors indicate that the data are far more likely under the null hypothesis, reinforcing the conclusion that psycholinguistic similarity has no meaningful impact on these outcomes.","Jonas Schlicht, Thabo J van Woudenberg",Vingen 7,Health & Quality of Life II,3,,760
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Estimating COVID-19 Vaccine Uptake from Donated Digital Behavioural Data,"In this study we use a combined source of digital observational and survey data collected through a data donation approach to investigate the health-related behaviour of Hungarian social media users. We seek to answer whether vaccinated and unvaccinated individuals can be identified by their digital behaviour and aim to determine which types of online behaviour contribute the most to predicting COVID-19 vaccine uptake. To answer these questions, we predict the vaccination status of participants purely based on their digital footprints on Google, YouTube and Facebook and focus on the diverse importance of features to detect those online activities, along which vaccinated and not vaccinated individuals can be distinguished from each other. Social media can not only reflect but also shape people's offline behaviour, including health-related habits, such as diet, exercise, and smoking (Centola, 2013), as well as behaviors related to COVID-19 prevention (Al-Dmour et al., 2020). Alongside the peer effect, there are other possible influences of social media on behaviour (Sherman et al., 2016, 2018; Nesi & Prinstein, 2019; Vannucci et al., 2020). While social media can serve as a platform for spreading information about vaccination campaigns (Li et al., 2022), it can also pose risks to vaccination behavior (McKinley & Limbu, 2024; Wilson & Wiysonge, 2020). Those opposed to vaccination may be more exposed to misinformation (Pierri et al., 2022; Rathje et al., 2022), leading to the formation of opinion bubbles and echo chambers, which can further isolate anti-vaccination individuals in the online space (Rathje et al., 2022). In the current data donation study, nearly 800 Hungarian individuals have agreed to share their entire social media activity data stored about them by the platforms for research purposes, including Facebook, Google, YouTube and in some cases, smaller platforms (Instagram, TikTok). The sample of users is representative of the Hungarian internet user population by gender, age and region. The donation was accompanied by a detailed questionnaire that participants filled out. The survey included a number of health-related topics, including questions about COVID-19 vaccination status. For the prediction of vaccination status, digital behavioural indicators were created. Modelling was performed using a fine-tuned and cross-validated XGBoost model (Chen et al., 2015). The XGBoost model shows the effect of various digital and social media behaviours as features on the prediction of vaccination status. Key factors include Google searches and clicks on vaccine-related keywords, YouTube video consumption patterns, and Facebook reactions. For instance, higher engagement in vaccine-related Google searches and clicks is associated with a higher likelihood of vaccination. This suggests that individuals actively seeking information about vaccines may be more inclined to get vaccinated. YouTube search and viewing behaviour also plays a role. Individuals who search for or watch COVID-related YouTube content tend to have higher SHAP values, suggesting a positive relationship between information-seeking behaviour and vaccination uptake. Anti-vaccine Facebook comments are linked to lower vaccination likelihood, reinforcing the role of online misinformation or vaccine hesitancy narratives in shaping attitudes toward vaccination. Reactions on Facebook yielded mixed effects. “Haha” reactions (typically used to mock or express scepticism) are negatively associated with vaccination. Conversely, “Love” reactions show a positive association with vaccination, suggesting that individuals who positively engage with content on Facebook may be more likely to get vaccinated. Linguistic complexity in Facebook comments might reflect deeper cognitive engagement with the vaccine discourse but has a relatively minor impact. Overall, our analysis highlights how individuals’ online search behaviours, social media interactions, and engagement with vaccine-related content is associated with vaccination behaviour. The findings of this study have the potential to enhance our comprehension of vaccination behaviour thereby complementing the results of conventional research describing the social context of COVID-19 vaccination and more broadly vaccine refusal characteristics. By extending these concepts to the digital space, the results could contribute to our understanding of these phenomena.","Adam Stefkovics, Anna Sara Ligeti, Julia Koltai",Vingen 7,Health & Quality of Life II,4,,641
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Identity Emergence in the Context of Vaccine Criticism in France,"This study investigates the emergence of collective identity among individuals critical of vaccination policies in France during the COVID-19 pandemic. As concerns grew over mandated health measures, a loose collective formed on Twitter to assert autonomy over vaccination decisions. Using analyses of pronoun usage, outgroup labeling, and tweet similarity, we examine how this identity emerged. A turning point occurred following President Macron's announcement of mandatory vaccination for health workers and the health pass, sparking substantial changes in linguistic patterns. We observed a shift from first-person singular (*I*) to first-person plural (*we*) pronouns, alongside an increased focus on vaccinated individuals as a central outgroup, in addition to authority figures. This shift in language patterns was further reflected in the behavior of new users. An analysis of incoming users revealed that a core group of frequent posters played a crucial role in fostering cohesion and shaping norms. New users who joined during the week of Macron's announcement and continued posting afterward showed an increased similarity with the language of the core group, contributing to the crystallization of the emerging collective identity.","Melody Sepahpour-Fard, Michael Quayle, Pádraig MacCarron, Shane Mannion, Dong Nguyen",Vingen 7,Health & Quality of Life II,5,,840
2025-07-24 14:30:00,2025-07-24 16:00:00,session_presentation,Health By Wealth: Computational tools and population-level data uncover substantial inequalities in health over the very long run,"We develop deep learning and optimal character recognition to combine, for the first time, individual level data for almost every person in England and Wales that died between 1860 and 1990 with data on wealth at death taken from digitized probate records. Together, this newly constructed dataset alongside tools of computational demography provide the most detailed analysis of health inequalities over the long run ever to be conducted.","Naomi Muggleton, Aaron Reeves, Charles Rahal, Alexandra Rottenkolber, Linda Li",Vingen 7,Health & Quality of Life II,6,,638
,,,,,,,,,,
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,On the Need for Theoretical Foundations in Computational Social Science,"Computational social science (CSS) almost exclusively defines itself through its methodologies -- e.g., through the use of machine learning or social media data. Yet, this is not how other computational fields typically define themselves. Computational biology and computational neuroscience, for instance, are defined not by their tools but by the study of biology and the brain as computational systems. In fact, some of the biggest breakthroughs in these fields have come through theoretical efforts—e.g., mathematical models of cognition or through philosophical reasoning about the computational basis of evolution—whereas some of their biggest failures have come from an overreliance on flawed data-intensive measurement technologies and statistical techniques (e.g., spurious results from correlational modeling of cognitive function via fMRI). Lessons from these other fields consistently underscore the need to equally balance theory and empirics—a balance that is currently off-kilter in CSS. This talk will draw lessons from the history of computational biology and neuroscience for how CSS can begin to define itself at a foundational level as the study of society as a kind of computational system. I focus on two key lessons: (i) the need to accurately align constructs and variables through computational theory, and (ii) the need to characterize formal representations that define the ontology of social computation. The talk will additionally highlight ways in which theoretical CSS is poised to provide valuable insights into the nature of computation throughout the social and natural sciences.",Douglas Richard Guilbeault,Troselli,Theory & Methodology,1,,662
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,A Comparative Analysis of the use of Linear Models in Quantitative Social Sciences,"The literature shows that more than half of quantitative research in social sciences has relied on linear modeling techniques. Linear models focus on measuring the isolated effects of independent variables on outcomes, which often implies an additive conceptualization of the social phenomena. This particular analytically-oriented framework is different from others that conceptualize the social world in terms of configurations and processes where social factors correlate, change, vary, and evolve in tandem. Configurational and processual analysis frameworks often rely on statistical methods other than linear models (e.g., geometric data analysis techniques). We contribute an empirical analysis of the frequency of use of linear models in quantitative research across eight different disciplines using the publicly available OpenAlex database which has the most comprehensive coverage in comparison to proprietary databases. We found that linear models are used prevalently from 50% to 70% in Economics, Geography, Psychology, Political Sciences, and Sociology, with most of them displaying the highest prevalence of linear models use in the 2010s. This prevalence is lower in Environmental Sciences and History (i.e., around 40%), and much higher in Medicine (i.e., above 80%). Based on our results, awareness should be raised to motivate a greater diversity in analysis frameworks, especially among the scientific communities in the social sciences.","Andres CASTRO, Aliakbar Akbaritabar",Troselli,Theory & Methodology,2,,295
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,TWIN4DEM: Strengthening democratic resilience through digital twins,"TWIN4DEM advances the application of CSS in democracy research by co-designing with civil society stakeholders the first ever digital twin (DT) of political systems. It is implemented as a set of interacting complex network systems, each of them representing a specific module in the democratic process. The goal is to design a general architecture of the DT, which will then be implemented to four specific country cases --- Czech Republic, France, Hungary, and the Netherlands --- through customization reflecting the specificity of the different political systems and integration with country-level data.","Giangiacomo Bravo, Laura Diosan, Clara Egger, Elizaveta Kopacheva, Bogdan Mursan, Asya Zhelyazkova",Troselli,Theory & Methodology,3,,54
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Scrubbing Language of Leakage: A Sensitivity Analysis Framework for Text-Based Causal Inference,"Researchers increasingly rely on digitized text—whether from social media, policy documents, or health records—as a key source of confounder information in observational studies. Yet text used to proxy an unobserved confounder often encodes aspects of the treatment itself, a problem called “treatment leakage.” When text includes these treatment signals, adjusting for that text risks conditioning on a post-treatment variable, thereby biasing causal estimates. Crucially, leakage can emerge even if the text was written before the treatment formally occurred, since language can anticipate or plan future actions.","Adel Daoud, Richard Johansson, Connor Thomas Jerzak",Troselli,Theory & Methodology,4,,792
2025-07-22 11:00:00,2025-07-22 12:30:00,session_presentation,Harnessing LLMs for Zero-Shot Stance Detection in Online Political Discussions,"Political polarization has increased in recent years, leading to more extreme beliefs and a divisive ""us vs. them"" mentality. Social media, now a primary news source for many adults, allows for detailed analysis of how beliefs shape polarization. Studying online opinions offers benefits over traditional surveys, enabling real-time tracking and access to polarized communities. However, automatically extracting beliefs from text presents challenges, particularly in stance detection, which is essential for quantifying polarization. While many automated stance detection methods rely on supervised machine learning and extensive labeled datasets, they often struggle in different contexts. Large language models (LLMs) offer a promising solution due to their ability to scale with large datasets and perform zero-shot learning.","Özgür Togay, Anastasia Giachanou, Javier Garcia-Bernardo, Florian Kunneman",Troselli,Theory & Methodology,5,,378
,,,,,,,,,,
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,The Day After: Network Dynamics of Rebel Alliances and Governance Institutions in Syria,"This study examines how wartime alliances and rivalries among rebel groups in Syria shaped local governance institutions. By integrating identity-based (Balcells, Chen, and Pischedda 2022; Bapat and Bond 2012; Corradi 2023; Topal 2024) and power-based (Christia 2012) explanations with network science, this project models the relational dynamics of rebel groups and their impact on Syria’s local governance structures. I hypothesize that rebel governing institutions reflect wartime power dynamics, with dominant factions shaping governance structures to preserve control rather than foster inclusivity. The findings demonstrate that Syria’s local governance structures remain fragmented, reinforcing factional divisions rather than enabling democratic flexibility. This study contributes to scholarship on post-conflict governance and offers insights into the long-term institutional legacies of civil war. I construct a network of Syrian rebel groups using alliances and defections (Gade, Hafez, and Gabbay 2019), and battles (Sundberg and Melander 2013) as well as rebel governance institutions (Albert 2022). Case comparisons allow for the assessment of rebel networks at different war stages, helping to determine how alliance dynamics correlate with governance structures in rebel-held territories. I incorporate a subnational case study design focusing on Hay’at Tahrir al-Sham (HTS) in Northwest Syria, ISIS in Raqqa, and the PYD in Northeast Syria. These cases provide contrasting governance models, shaped by distinct networked relationships during wartime. HTS, as a dominant yet fractured Islamist faction, has relied on selective coalition-building to consolidate control in Idlib, balancing between cooperation and coercion. ISIS, operating under a hegemonic structure, imposed a rigid bureaucratic system in Raqqa, relying on centralized authority rather than durable alliances. In contrast, the PYD in Rojava has established a decentralized governance structure through a network of alliances with various ethnic and ideological groups. For this analysis, I incorporate two forms of statistical modeling tailored for network data. Firstly, I implement an additive and multiplicative random effects model to examine patterns of alliances in Syria. Furthermore, I apply Exponential Random Graph Models (ERGMs) to assess structural dependencies within the network and validate the observed patterns of cooperation and conflict. I propose that rebel relations influence post-conflict governance through two primary mechanisms. First, power composition plays a key role, as rebel groups differ in material capabilities such as manpower, expertise, and foreign support, shaping their relative power within an insurgency (Krause 2014). Power asymmetries influence whether coalitions produce hegemonic or inclusive institutions. Second, the density and stability of alliances determine whether wartime coalitions persist into post-war institutions Fragmented, unstable networks lead to elite-driven consolidation, while cohesive alliance structures facilitate broader inclusion (Furlan 2020; Mampilly and Stewart 2021). By identifying clusters of cooperation and patterns of exclusion, this study evaluates whether post-conflict governance structures are path-dependent on wartime alliances. The theoretical framework classifies wartime alliances along two dimensions: power composition (hegemonic versus balanced) and identity composition (homogeneous versus heterogeneous). These distinctions yield four potential post-war institutional outcomes: (1) Inclusive power-sharing in balanced, heterogeneous alliances, though often disrupted by spoilers; (2) Inclusive power-sharing in homogeneous alliances if unity is maintained, but fragmentation risks ongoing conflict; (3) Exclusive power-sharing in heterogeneous hegemonic alliances, where institutions primarily serve to entrench the dominant faction’s control; and (4) No institutional power-sharing in homogeneous hegemonic alliances, where the leading faction can govern unilaterally without coalition constraints. This research advances computational political science by demonstrating how networked relationships during war shape long-term governance outcomes. By integrating network analysis with conflict studies, this work provides insights into how rebel cooperation and competition influence state-building trajectories. By systematically analyzing the relational structures of Syrian rebel groups, it offers a novel perspective on the institutional legacies of war. Findings will inform broader discussions on governance in post-conflict societies and the role of wartime networks in shaping peace and political inclusion.",Betul Ozturan,Business meeting room,Hybrid Session,1,,879
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Passive News Exposure and Active News Engagement in All-web Information Ecosystems,"News consumption lies at the heart of informed democratic citizenship, enabling individuals to participate meaningfully in civic life. Yet, as digital platforms increasingly mediate how people encounter and engage with news, understanding the interplay between algorithmic curation, user agency, and news quality has become critical to addressing democratic challenges such as polarization and misinformation. While traditional research equates news consumption with direct visits to news websites and focuses narrowly on individual platforms (e.g., Google, Facebook, or Twitter), this approach does not encompass the fragmented, multi-platform nature of the media ecosystem today. To address these limitations, we developed a browser extension that captures both passive news exposure (URLs visible within a users' browser viewport) as well as active news engagement (URLs the user clicked on). We deployed the extension in a three-week study of 851 US adults, collecting 3.9 million URL engagements and 67.9 million URL exposures. Analyzing the bias and reliability of the news URLs, we find that users encounter more – and more diverse – news than previously reported. Examining cross-platform differences reveal key patterns: search engines provide higher-quality news than social media, and compared to news websites, social media delivers content that is more ideologically congruent, more extreme and less reliable. Users generally engage with lower-quality news than they are exposed to, but the extent of this gap depends on the platform. Our findings challenge the narrative of declining news consumption by revealing significant disparities in news exposure across platforms and ideological groups. We emphasize the need to separate algorithmic curation from user-driven selective exposure and highlight the limitations of single-platform studies—e.g., search engines act as “balanced curators,” unlike social media’s reliability trade-offs.","Shengchun Huang, Stephanie Wang, Alvin Zhou, Danaé Metaxa",Business meeting room,Hybrid Session,2,,460
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Evaluating Commonsense Knowledge in Human and Large Language Model-Simulated Populations,"Most conceptions of human common sense have centered around the notion of correctness: There is assumed to be an uncontested way in which we humans apprehend matters of everyday reality. Social scientists, however, believe that because people's subjective experiences are never identical, neither is their commonsense knowledge, which is synthesized from such experiences. Recent empirical research affirmatively shows that humans, indeed, are highly heterogeneous in their judgment of even seemingly obvious statements. In this work, we ask whether large language models (LLMs) can reflect, with high fidelity, this heterogeneity in human commonsense beliefs. We use every LLM (out of 34 models) to simulate a hypothetical society of ""silicon samples."" Each subject in this society is given a set of statements and asked to indicate whether (a) it agrees with the statement and (b) it believes most people would agree with that statement. Based on this signal, we calculate a *commonsensicality score* for every statement. If the population of silicon samples accurately represents humans in terms of their common sense, then the score of each statement should be roughly the same in both populations. The ""fidelity"" of a model, therefore, can be calculated as the Pearson correlation between these scores. We observe that most LLMs demonstrate a small to moderate association with humans in their judgment of statements, up to the $r = .43$ level. When examining these results further, most populations of silicon samples have the same qualitative tendencies as humans. However, there are some areas where we observe a divergence. For instance, Gemini Pro 1.0-generated samples tend to prefer statements that use a figure of speech than literal expressions, and they tend to agree with more abstract claims than descriptions of everyday, ordinary experiences. Our findings have important implications for the treatment of commonsense knowledge in various spheres, such as in artificial intelligence (AI), which tends to ignore human heterogeneity and assume that common sense has a ""correct label."" Our proposed measure offers a solution to such a problem where machine common sense is measured in terms of agreement with humans in a target population rather than accuracy to ground truth.","Josh Nguyen, Duncan J. Watts, Mark E. Whiting",Business meeting room,Hybrid Session,3,,376
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,An LLM-Assisted Content Analysis of Social Media Platform Practices for Digital Well-Being,"Background: Adolescent mental health crises and regulations have prompted social media platforms to adopt digital well-being practices, yet systematic research on these practices remains limited. We propose the Harm-Responsive Design Process to evaluate platform well-being strategies through social media news releases. Method: We collected all news releases related to digital well-being, safety, and privacy from Meta, TikTok, YouTube, Snapchat, and Twitter/X, totaling over 4,500 news releases. We developed an LLM-assisted content analysis pipeline with a codebook designed following the Harm-Responsive Design Process framework. The pipeline employs few-shot prompting for 15 content analysis tasks, including deductive classification, named entity recognition, text summarization, and inductive thematic analysis. Performance was assessed through comparisons between human coders and the machine coder. Result: GPT-4o performed well for most tasks but underperformed with identifying distinct digital well-being practices and their targeted harms. Alternative methods, including supervised learning, fine-tuning GPT, and active learning, are in development for the underperformed tasks. Among 1,000 randomly sampled news releases, 735 distinct digital well-being practices were identified. However, 32% lacked harm specification, and 81% had no evaluation plans. Most practices focus on content moderation and promoting positive content rather than addressing design features linked to user harms. The LLM pipeline refinement and analysis of remaining news releases are ongoing and will be updated soon. Implication: This study demonstrates the potential of LLMs in multidimensional content analysis and highlights the need for a harm-responsive approach to ensure platform interventions (1) address harmful design elements and (2) conduct systematic impact evaluation.","Yuning Liu, Emily Xing, Stanley Huang",Business meeting room,Hybrid Session,4,,620
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Meme Adaptability and Popularity: Investigating the Evolutionary Dynamics of Internet Meme Templates,"Internet memes serve as a dynamic form of digital communication, blending humor, commentary, and critique. This study investigates how meme template adaptability—the capacity of a template to support diverse textual reinterpretations—affects its popularity trends. While previous research has explored meme diffusion through qualitative and computational approaches, the role of the adaptability of meme templates in shaping their popularity and diffusion remains underexamined. Using a dataset of approximately eight million memes from three major meme-related subreddits (memes, dankmemes, meme) spanning 2008–2023, this study identifies meme templates through HDBSCAN clustering. Meme adaptability is quantified using OCR-extracted text, sentence embeddings, and pairwise cosine similarity, where lower similarity indicates greater adaptability. Time-series modeling (ARIMAX) and Granger causality tests are applied to assess the temporal relationship between adaptability and popularity. Results indicate that higher adaptability is associated with slower popularity decay, even after controlling for factors such as maximum popularity and template size. Among the 10 most frequently occurring meme templates, adaptability in the current month strongly correlates with relative popularity. However, causality tests reveal mixed patterns—some templates show a positive effect, while others exhibit no clear relationship or an inverse trend. Additionally, in some cases, popularity influences subsequent adaptability, suggesting that viral memes may attract broader reinterpretations over time. These findings suggest that meme diffusion is shaped not only by adaptability but also by contextual and structural factors. Further analysis is needed to understand the role of emotional tone, topical relevance, and platform dynamics in modulating the adaptability-popularity relationship. By integrating computational modeling with theoretical insights, this study contributes to a deeper understanding of how meme templates evolve as communicative structures in digital culture.",Yingrong Mao,Business meeting room,Hybrid Session,5,,917
2025-07-23 14:30:00,2025-07-23 16:00:00,session_presentation,Integrative Experiments Identify How Punishment Impacts Welfare in Public Goods Games,"Punishment as a mechanism for promoting cooperation has been studied extensively for more than two decades, but its effectiveness remains a matter of dispute. Here, we examine how punishment’s impact varies across cooperative settings through a large-scale integrative experiment. By simultaneously varying 14 parameters that characterize public goods games, we sampled 360 experimental conditions, collecting 147,618 decisions from 7,100 participants. Our results reveal striking heterogeneity in punishment effectiveness: while punishment consistently increases contributions, its impact on payoffs (i.e., efficiency) ranges from substantially positive to markedly negative depending on the cooperative context. To characterize these patterns, we developed predictive models that outperformed human forecasters (laypeople and domain experts) in predicting punishment outcomes in new settings. Communication emerged as the most predictive feature, followed by contribution framing (opt-out vs. opt-in), contribution type (variable vs. all-or-nothing), game length (number of rounds), peer outcome visibility (whether participants can see others’ earnings), and the availability of a reward mechanism. Interestingly, however, most of these features interact to influence punishment effectiveness rather than operating independently. For example, the extent to which longer games increase the effectiveness of punishment depends on whether groups can communicate. Together, our results refocus the debate over punishment from whether or not it “works” to the specific conditions under which it does and does not work. More broadly, our study demonstrates how integrative experiments can be combined with machine learning to uncover generalizable patterns, potentially involving interactions between multiple features, and help generate novel explanations in complex social phenomena.","Mohammed Alsobay, David Rand, Duncan J. Watts, Abdullah Almaatouq",Business meeting room,Hybrid Session,6,,855
,,,,,,,,,,
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,How public perceptions of AI are evolving,"Understanding lay perceptions of artificial intelligence (AI) is crucial for assessing public trust, engagement, and concerns. Prior research often reflects expert perspectives rather than spontaneous public associations. To address this, we analyzed free association data from two large-scale, representative surveys (N Å 3,000 each) conducted in October 2023 and October 2024. Participants listed the first five words or phrases that came to mind about AI, allowing us to map public perceptions and track changes over time. Using text embedding models and dimensionality reduction techniques, we identified four key clusters of AI associations: benefits (54%), worries (26%), technology and science fiction (17%), and job loss (3%). Over the past year, associations related to outdated science-fiction narratives and economic fears declined while mentions of AIÕs practical benefits increased. Individuals with higher AI expertise were more likely to emphasize benefits and less likely to mention risks, highlighting an expertise-based divide in perceptions. Age and gender also influenced associations, with older adults and female respondents expressing more concerns. These findings provide an evolving picture of public AI perceptions, emphasizing the need for tailored communication strategies. As AI becomes more integrated into society, tracking these evolving perceptions will be essential for policymakers, educators, and AI developers aiming to foster informed public discourse and responsible AI adoption.","Dirk U. Wulff, Nicolas Scharowski, Anne-Marie Nussberger, Rui Mata",Atrium,Posters I,1,,830
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Characterizing the Dynamics of Conspiracy Related German Telegram Conversations during COVID-19,"The rapid online spread of conspiracy theories poses significant societal challenges, particularly during crises such as the COVID-19 pandemic. This study provides a large-scale analysis of German conspiracy-related discourse on Telegram, leveraging temporal, geographical, and network perspectives. Using the Schwurbelarchiv dataset, comprising 24TB of public messages from 2015Ð2022, we analyze message volume fluctuations, regional versus transnational dissemination patterns, and network structures of forwarded content. Our findings indicate that conspiracy discussions peak during major socio-political events, with national and transnational chats disproportionately influencing regional conversations. Despite Telegram's decentralized nature, a small subset of chats accounts for 94\% of forwarded content, suggesting centralized influence. Additionally, over 40\% of shared links covered by NewsGuard originate from untrustworthy sources, underscoring TelegramÕs role in misinformation dissemination.","Elisabeth Höldrich, Mathias Angermaier, Joao Pinheiro Neto, Jana Lasser",Atrium,Posters I,2,,524
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,A Computational Analysis of North-South Debates on Climate Change,"Over the past few decades, climate change has emerged as a pressing international issue, requiring global, collective action and international cooperation. Several issues of contention have emerged during international negotiations on climate change, including the question of common but differentiated responsibilities (CBDR), technological transfer and timelines for emissions reductions. These negotiations surrounding climate change have revealed significant tensions among various stakeholders, primarily between the developed nations in the Global North and developing countries in the Global South. In this paper, we conduct a computational analysis of the North-South climate debate by examining discourse in YouTube videos. YouTube is chosen as the primary source because it has a vast global reach and serves as a platform where both policymakers and the general public engage with climate discourse. Using a dataset of videos scraped from the platform, we analyze how climate change narratives differ by identifying key themes. For this study, we have selected seven key events that highlighted the evolution of climate governance and brought the tensions between developed and developing nations to a forefront, including negotiations such as the Kyoto Protocol. For each of these events, we create a dataset using the transcripts of videos scraped for each event. These are categorized based on the geographic location from which they were posted, dividing them into two groups: Global North and Global South. We employ natural language processing tools like topic modeling to examine the corpus and get topics represented as a list of commonly occurring words within the corpus collected. The analysis of climate change narratives across the Global North and Global South using this collected data reveals patterns that are consistent with what scholars have long observed in climate negotiations. We observe that the Global North frames climate action in terms of obligations and policy frameworks, while the Global South emphasizes financial and policy mechanisms for adaptation and mitigation rather than binding commitments to reduce emissions. Even in governance discussions, the North focuses on international commitments while the South stresses on immediate needs and the impact on vulnerable populations. Our study demonstrates that these disparities are not only present in policy discussions but also extend into digital media, where YouTube reflects the same global power struggles and economic inequalities seen in the North-South climate debates. It also demonstrates the potential for YouTube videos to be used as a primary source of data for analyzing public discourse.","Sanika Damle, Radhika Krishnan",Atrium,Posters I,3,,331
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,How Media Exposure Shapes Affective Polarization,"Affective polarization, characterized by mutual distrust and hostility between citizens with opposing political views, poses a growing challenge to democratic stability. Fragmented media exposure and negativity from and towards political actors have been identified as drivers of affective polarization. Despite substantial progress in understanding the phenomenon in two-party systems, particularly in the United States, survey-based research often lacks robust designs linking individual evaluations to media exposure in real-world and multi-party contexts. This study addresses these gaps by examining the relationship between exposure to political entities (parties and political candidates) and longitudinal survey responses measuring affective polarization in the context of a multiparty system. Specifically, we ask whether (1) exposure and (2) negativity towards parties and their candidates in campaign exposure affects the evaluations of partisans and political entities. Using data collected during the 2021 German federal election (N = 569), we analyze comprehensive web browsing histories, including participantsÕ exposure to news websites, public Facebook posts, and public tweets, which are linked to individual evaluations of parties, their candidates, and their voters. We measure the prevalence of political entities in individual media diets. To further assess participantsÕ exposure to negativity towards political entities, we apply large language models (LLMs). Unlike two-party systems, where affective polarization is often binary, our findings align with theories suggesting that polarization in multiparty democracies is shaped by ideological proximity and preexisting evaluations of parties. Furthermore, the findings underscore the nuanced relationship between exposure to political entities and affective polarization, indicating that campaign negativity in media diets contributes more to long-term partisan polarization rather than short-term attitude shifts. Understanding how media negativity reinforces these divides is crucial for assessing the role of information environments in shaping democratic discourse.","Felix Schmidt, Sebastian Stier, Helena Rauxloh",Atrium,Posters I,4,,1006
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Disentangling Discourse Volatility: An Embedding-Based Comparative Analysis of Climate Discourses on Reddit,"The proliferation of online publics and sub-publics, enabled by digital interaction architectures, fosters both hopes for inclusive debates and concerns about fragmented, polarized discussions. While scholars have explored online discourse across ideological divisions, the mechanisms driving discourse volatility remain underexamined. Additionally, existing computational discourse analyses can extract claims and discourse characteristics but often overlook the nested structure of discourse, the interconnectedness of comments, and user interactions. This study uncovers the underlying structure of online discourse and examines the factors influencing volatility. By leveraging embedding-based representations to map discourse dynamics, trajectory analysis to quantify volatility, and multilevel regression models to assess the impact of discourse elements, we analyze 231,042 comments on 36,384 submissions from r/climate (2008Ð2022). Our findings indicate that engagement fluctuations, response timing, and contradiction-based discourse significantly drive volatility, while toxicity has a weaker, stabilizing effect. Unlike traditional methods that isolate discourse elements, our approach integrates micro-level linguistic features with meso-level discursive structures, offering a more comprehensive framework for understanding discourse dynamics.","Xixuan Zhang, Annett Heft, Yangliu Fan",Atrium,Posters I,5,,1031
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Ranking Algorithms and Opinion Dynamics: How Online Social Networks Influence Disease Spread,"This study examines how online social network algorithmic design influences the spread of infectious diseases through its effect on self-protective behaviors. Using a simplified Twin of Online Social Network (TWON) prototype, we model how different content ranking algorithms affect opinion dynamics and subsequent disease transmission. We implement two opinion formation modelsÑthe Bounded Confidence Model (BCM) and BCM with reinforcement mechanismsÑto evaluate how fundamental assumptions about social influence alter outcomes. Our results demonstrate that algorithms prioritizing scientifically accurate, pro-protection content consistently lead to lower infection rates across all scenarios. However, the relative effectiveness of other ranking strategies (similarity-based, random, and negativity-based) varies significantly depending on the underlying opinion dynamics model. Notably, random content distribution performs similarly poorly to negative content prioritization in the standard BCM, though through different mechanisms: random sorting creates homogeneous moderate opinions, while negative sorting increases polarization. The relationship between polarization and disease outcomes also depends on the protection mechanism modeled: polarization reduces infection rates for mask-wearing behaviors but increases vulnerability when vaccination or testing interventions are considered. These findings highlight how platform design choices interact with social influence processes to shape public health outcomes during infectious disease outbreaks, with implications for platform governance and content moderation strategies even when facing unwanted actors like bots or coordinated misinformation campaigns. This research was conducted as part of the TWON project funded by the European Union's Horizon programme and the InfoXpand project funded by the German Federal Ministry of Education and Research (BMBF).","Fabio Sartori, Michael Maes, Sophia Horn, Sven Banisch",Atrium,Posters I,6,,873
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,No radicalization of conspiracy theorists on Reddit,"Online social media platforms have become key spaces for the dissemination of conspiracy theories, raising concerns about their potential role in radicalizing users. In this study, we investigate whether participation in the r/conspiracy subreddit leads to measurable linguistic shifts in users' discourse across mainstream communities on Reddit. Using a dataset of over 50 million comments, we analyze the linguistic patterns of users before and after joining r/conspiracy, leveraging psycho-linguistic features extracted via LIWC-22 and classification models to detect language changes. Our results reveal that while users active in r/conspiracy exhibit distinct linguistic patterns compared to the broader Reddit population, these differences are present even before they join the conspiracy community. We find no significant evidence of a linguistic shift post-engagement, suggesting that individuals who participate in conspiracy discussions already possess a pre-existing conspiratorial mindset. These findings challenge the notion that exposure to conspiracy discourse on Reddit alone drives radicalization and instead highlight the role of self-selection in shaping online ideological communities. Our study provides insights into the early detection of users predisposed to conspiracy ideation and informs strategies for mitigating the spread of misinformation.","Francesco Corso, Giuseppe Russo, Francesco Pierri, Gianmarco De Francisci Morales",Atrium,Posters I,7,,232
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Community Builders or Clickbait Chasers? Investigating Collaborations among a Community of Interest on YouTube,"Online forums and message boards have opened new spaces for individuals in Communities of Interests to talk, consume, and produce content about their passions without profit interest. In recent years, however, Communities of Interest have started re-locating to algorithmic-oriented social media platforms like YouTube, Instagram, or TikTok. By inducing new motivations for visibility and profit that conflict with community-building and participation (Cotter 2019), social media platforms threaten to undermine the flourishing of Communities of Interest. This threat arises due to the high opportunity cost of community-building and the uncertainty of how it affects visibility and profit on social media platforms: While community-building, in the form of collaborations, can reach new audiences improving visibility and profit, it also bears the risk of losing one's audience to collaborators, harming both dimensions. This tension between the nature of Communities of Interest and social media platforms raises the research question we aim to answer: How can Communities of Interest flourish on algorithmic-oriented social media platforms? To answer this question, we followed an abductive approach to conducting a computational ethnography (Brandt 2023; Brandt and Timmermans 2021) of a Community of Interest on YouTube, whose members solely or collaboratively create video content on ""One Piece"" Ð a famous Japanese comic and animation series. We scraped the whole YouTube Channel histories of all 66 YouTubers in the One Piece Community from its emergence in 2013 until 2023, which enabled us to investigate their content, success, and collaboration patterns. We started our investigation by creating a directed collaboration network between the 66 YouTubers throughout the study period, where outgoing ties indicate hosting another YouTuber on one's channel and incoming ties visiting another YouTuber's channel. We then used a direct block modeling approach to identify two community roles Ð authentic enthusiasts and fluid professionals Ð reflecting the tension between Communities of Interest and social media platforms. According to descriptive statistics and seeded topic models, authentic enthusiasts tend to be more collaborative, productive and focused on One Piece but less successful in terms of video views, indicating a motivation centered on community-building and participation. In contrast, fluid professionals tend to be less collaborative, productive, and focused on One Piece but more successful, indicating a motivation for visibility and profit. Afterward, we showed that how authentic enthusiasts and fluid professionals engage in collaborations satisfies their respective motivations. In particular, an exponential random graph model revealed that authentic enthusiasts tend to host collaborations, while fluid professionals tend to avoid hosting and prefer to be guests on other YouTubers' channels. These collaboration behaviors satisfy their motivations, as fixed effect negative binomial regressions demonstrated that being the collaboration host has a stronger effect on participation, i.e., produced videos, and being the collaboration guest has a stronger effect on profit and visibility, i.e., video views. These results indicate a symbiotic relationship between authentic enthusiasts and fluid professionals, enabling the One Piece Community to thrive on YouTube (see Figure 1). To satisfy their motivation of participation and community-building, the authentic enthusiasts invite the fluid professionals as collaboration guests, which can thereby satisfy their motivation for visibility and profit. We, therefore, contribute to the study of Communities of Interest by shedding light upon a general mechanism by which they can thrive on profit-oriented social media platforms, which induce profit-oriented roles that conflict with traditional community-building roles. Akin to Lvi-Strauss's (1992 [1955)] insight that mutual dependence between groups in exchange relationships fosters social cohesion, we argue that Communities of Interest flourish in hostile environments if these community roles are complementary such that collaborations harbor mutual benefits. In this way, we also answer Abrutyn and Lizardo's (2023) call to utilize a motivational theory of roles in sociological theorizing. At last, we also contribute to the sociological investigation of YouTube as the first study to investigate the outcomes of collaborations between YouTubers.","Marcel Kappes, Pavel Dimitrov Chachev",Atrium,Posters I,8,,225
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Using Internet Search Data for Comparative Longitudinal Research: Rise of the Radical Right,"Social scientists are increasingly drawing on internet search data to interrogate research questions that are otherwise hard to answer. These digital trace data offer unique qualities in terms of scope and granularity but also pose new challenges in their application. In particular, while data are available for many countries and regions since the late 2000s, longitudinal, comparative research has to date failed to capitalize on it due to challenges in accessing time series data that is comparable across geographic units. In this manuscript, we outline the advantages of internet search over conventional data for such applications, highlight the challenges of collecting longitudinal, geographically comparable internet search data, and develop and illustrate an approach to gathering relevant indicators. We apply this approach to a case study of radical right politics support across Europe since 2016 showing that online search behavior predicts aggregate vote share and discuss the potential of the approach for other comparative, longitudinal applications.","Friedolin Merhout, Mauro Martinelli",Atrium,Posters I,9,,471
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Where You Are Is What You Get? Inconsistencies of Digital Trace Data Across Download Locations,"Researchers increasingly use digital trace data from online platforms as an alternative or complement to survey data. To collect the data, researchers frequently rely on Application Programming Interfaces (APIs) proprietary to private companies. The APIs often return samples of the data based on undisclosed or intransparent sampling procedures and algorithms. Prior research has identified issues with some APIsÕ reliability over time and across API versions. For instance, downloading Google Trends data for identical parameters (i.e., search term, region, time range) but at different time points can give researchers different values on Google TrendsÕ search index. Users and tweets in the samples varied depending on the Twitter/X's former API version used to draw the samples. In this paper, we extend the research on the reliability of digital trace data from APIs by examining the effect of the download location on inconsistencies across samples: Do we get different values from digital trace data APIs depending on where we download the data from? We retrieve samples from Google Trends, YouTube, and the News API from four different countries across three continents (Austria, Germany, the U.S., and Australia) for the same query parameters (i.e., search term, region, and time range). We then compare the similarity of the samples retrieved from each download country, keeping all parameters of the query constant. Our results reveal inconsistencies across download locations, and thus another limitation regarding the reliability and replicability of findings from digital trace data. They serve as a cautionary reminder for computational social scientists relying on sampling-based APIs to be transparent about data collection locations and to average multiple samples when possible. By adopting these practices, researchers can enhance the replicability and robustness of their findings when using digital trace data from APIs.","Johanna Hölzl, Florian Keusch, John Collins",Atrium,Posters I,10,,200
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,The Power of Love: Do we gossip more with our romantic partners and is gossip a way of seeking comfort in romantic relationships?,"The present paper employs computational text analysis to examine the role of gossip in both romantic partnerships and in-group interactions. Talking about others who are not present is called gossip (Foster, 2004; Beersma & van Kleef, 2012). Gossip can be a form of 'social grooming' used to release stress and create close contact (Dunbar, 1998). Gossip can also be an effective means of increasing intimacy in interpersonal relationships (Davis et al., 2017). Using the CoupleTalk Corpus, an extensive dataset of spontaneous conversations collected in a Hungarian dormitory, we analysed the verbal behaviours of romantic partners, in-group and outgroup members. The corpus, which consists of 2,144 documents and 77,811 conversation lines, has been manually transcribed. To analyse the data, a seeded LDA topic model was utilized with the Harvard-Lasswell dictionaries. The study demonstrates that gossip can be an intimate aspect of romantic partnerships, as participants selected more frequently their romantic partners in all topical domains for gossip conversations while in non-gossip conversations participants chose their in-group members more frequently, except if the conversation included the conflict topic.","Galántai Júlia, Károly Takács, Flóra Samu",Atrium,Posters I,11,,467
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Legitimacy without Worth? The Economic Value of Imperial Porcelains in the aftermath of China's 2002 Protection of Cultural Relics Law,"This paper examines how political ideology shifts shape the reactivation of dormant cultural markets through China's imperial porcelain trade following market liberalization in 2002. The 2002 Law on the Protection of Cultural Relics (LPCR) transformed previously stigmatized imperial porcelains into legally tradeable commodities overnight. Our Difference-in-Differences analysis, leveraging Hong Kong's exclusion from the policy as a natural experiment, reveals that while the regulatory change initially reduced the price gap between mainland China and Hong Kong markets by 27.55\% in the short term, substantial disparities persisted and widened over time. The market's response varied significantly across auction houses. Computational text analysis of archival documents reveals these patterns were shaped by fundamental challenges in reconstructing market mechanisms after prolonged dormancy. The mainland market struggled with limited cultural appreciation and weak authentication systems. These findings demonstrate that while regulatory changes can swiftly confer market legitimacy, they prove insufficient for establishing stable valuation mechanisms. Market infrastructure, authentication systems, and cultural appreciation must be reconstructed alongside formal institutions.","Erwanghao Yu, Simone Santoni",Atrium,Posters I,12,,568
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,"Intermediation, not fragmentation: A political cartography of news sharing in the German Twittersphere","Online sharing strongly guides which news people encounter on a daily basis. Yet, especially in a political context, we lack a holistic framework to capture which news are circulated by which groups or partisans, whether/to what extent this circulation of news is fragmented or not, and who distributes content most actively. We provide such a general political cartography of news sharing for the German Twittersphere on the content and outlet level, based on a survey-validated two-dimensional political space. Outlets shared by right-leaning users turn out to supply news to users both to highly elite-/EU-skeptical/protectionist users and their counterparts Ð but not the same stories. The political fringes are most actively circulating news, especially right-wing elite-/EU-skeptical/protectionist users. This groupÕs news sharing turns out to be strongly guided by few intermediaries. News diversity, both with respect to content and outlets, decreases at the political fringes. Implications for future research are discussed.","Felix Gaisbauer, Armin Pournaki, Jakob Ohme",Atrium,Posters I,13,,585
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models,"Large Language Models (LLMs) display remarkable capabilities to understand or even produce political discourse, but have been found to consistently display a progressive left-leaning bias. At the same time, so-called persona or identity prompts have been shown to produce LLM behavior that aligns with socioeconomic groups that the base model is not aligned with. In this work, we analyze whether zero-shot persona prompting can accurately predict individual voting decisions and, by aggregation, accurately predict positions of European groups on a diverse set of policies. We evaluate if predictions are stable towards different persona prompts and generation methods. We find that we can simulate voting behavior of Members of the European Parliament reasonably well with a weighted F1 score of approximately 0.8.","Maximilian Kreutner, Marlene Lutz, Markus Strohmaier",Atrium,Posters I,14,,598
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Digital Thorns: The Rise of Sarcasm as Political Protest in Trkiye,"Sarcasm is often a hidden way to criticize politics when direct criticism is not allowed. This study examines sarcasm in Türkiye’s political discussions on Ekşi Sözlük by analyzing 107,432 entries with a fine-tuned BERT model that achieved 86% accuracy. The results demonstrate that sarcasm appears much more in comments about Recep Tayyip Erdoğan (28.1%) compared to Kemal Kılıçdaroğlu (9.2%), especially during turbulent times like the 2018 constitutional reforms and the 2019 economic downturn. The growing use of sarcasm highlights how Türkiye’s political landscape has changed over the past twenty years under AKP rule. This research contributes to the growing field of computational political science by demonstrating how NLP techniques can decode evolving forms of the political landscape in Türkiye.","Erdem Şahin, Yusuf Sezer Car, Arda Astam, Didem Gundogdu ",Atrium,Posters I,15,,599
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Global patterns and drivers of public vaccine sentiment research,"Global health research often reflects priorities set in high-income countries, which can overshadow the development of locally led studies in lower-income settings despite these regions frequently facing the greatest disease burden. To investigate the geographic, economic, and epidemiological factors shaping scientific attention to public sentiment towards vaccination (PSV), we compiled and analyzed over 13,000 articles focusing on polio, measles, human papillomavirus (HPV), influenza, and SARS-CoV-2. Using machine learning for relevance screening, natural language processing for metadata extraction, and network and statistical models to characterize collaboration patterns, we found that high-income countries dominate PSV research production and frequently direct their studies towards lower-income regions. For polio and measlesÑvaccines with potential eradication pathsÑpublication volumes remained relatively modest, even where these diseases persist. Despite higher rates of disease burden, low-income countries rarely led or authored research, reflecting limited domestic capacity and reliance on foreign collaborations. While local disease incidence increased the likelihood of a country being studied, economic factors were the primary determinant of who performed the research. Furthermore, we detected a marked post-COVID-19 shift in the distribution of PSV research. Influenza publications significantly exceeded anticipated trends, likely due to parallels with SARS-CoV-2, whereas polio and measles research fell below projections, potentially undermining global eradication initiatives. These findings highlight persistent inequities in global health research agendas, underscore how pandemic-driven priorities can disrupt established vaccination efforts, and reinforce the need for equitable investment, inclusive collaboration, and sustained attention to diseases affecting the worldÕs most vulnerable populations.","Duilio Balsamo, Vittoria Offeddu, Zhina Agamohammadi, Chiara Chiavenna, Laura P. Leone, Elena D'Agnese, Deepak Sharma, Aleksandra Torbica, Soheil Shayegh, Javier Andreu-Perez, Alessia Melegaro",Atrium,Posters I,16,,998
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Understanding Anti-Democratic Sentiments: A Longitudinal Network Approach,"Understanding the rise of anti-democratic sentiments is essential for preserving democratic stability. These sentiments develop through complex interactions between psychological, social, and political factors, yet their underlying dynamics remain insufficiently explored. This study applies psychometric network analysis to a large-scale national panel survey to examine how individualsÕ feelings, attitudes, and beliefs interact over time to shape anti-democratic sentiments. Cross-lagged network modeling reveals self-reinforcing feedback loops and temporal fluctuations, suggesting that external political events may influence the stability of anti-democratic sentiments. These findings emphasize the need for longitudinal research to capture the mechanisms driving these sentiments and inform strategies to strengthen democratic resilience.","Ina Ni, Jonas Fegert, Christof Weinhardt",Atrium,Posters I,17,,1001
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,"Kinder, Küche, Telegram: A mixed-methods analysis of German-language misogynist and far-right online communication","The rise of far-right actors in Western societies has coincided with the increasing presence of misogynist online communities, raising concerns about their interconnections and implications for democratic stability. Misogyny, as a political phenomenon that reinforces patriarchal norms, has been recognized as a key component of extremist ideologies, acting as both a gateway and a driver of further radicalization. The manosphere, a collection of online spaces that foster anti-feminist discourse, has notable ideological overlaps with far-right movements, particularly in narratives like the ""Great Replacement."" However, the long-term dynamics of this relationship remain under-researched. This study utilizes a mixed-methods approach to analyze publicly available content from German-language misogynist and far-right Telegram channels. Through computational text analysis, we investigate thematic overlaps and ideological shifts over time. Structural topic modeling helps to identify both shared and distinct narratives, while qualitative analysis further contextualizes these findings. By examining the discursive evolution between misogynist and far-right communities, this research aims to uncover pathways of radicalization and the mainstreaming of extremist ideologies. Preliminary computational results will be presented at the 2025 IC2S2, providing insights into the mechanisms linking online misogyny with far-right extremism.","Phelia Weiss, Kevin Koban, Jörg Matthes",Atrium,Posters I,18,,434
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Differential Prediction of Partisan Strength: A Machine Learning Approach Revealing the Distinct Nature of Significant vs. Moderate Shifts,"While previous research has identified numerous predictors of partisan strength, most studies rely on cross-sectional analyses that fail to distinguish individual-level changes from broader political events. This study employs machine learning techniques to analyze longitudinal panel data from the British Election Study (N=24,133) across two critical periods: the 2016 Brexit referendum and the 2021-2022 post-pandemic era. Using three distinct prediction scenariosÑChange-on-Change, Change-on-Cross-sectional, and Cross-sectional-on-Cross-sectionalÑwe reveal how significant versus moderate shifts in partisan strength are driven by fundamentally different mechanisms. Our analysis demonstrates that significant changes in partisan strength remain predominantly anchored in issue-based attitudes (political efficacy, economic outlook), while moderate fluctuations are increasingly influenced by identity-based features and affective party attitudes. Temporally, we observe a concerning shift between 2016 and 2021-2022, with affective party attitudes and voting intentions gaining prominence over issue-based features in predicting partisan strength. This suggests British voters' partisan attachments are increasingly driven by emotional responses rather than policy positions. Our findings challenge simplistic narratives about affective polarization by revealing a dual dynamic: while overall partisanship is becoming more affect-driven, significant partisan shifts continue to be rooted in substantive political issues. These results call for more sophisticated models of partisan behavior that account for both the growing influence of affective polarization and the persistent role of issue-based considerations in driving meaningful partisan change.","Haoran Shi, Wanting Wang, Dario Krpan",Atrium,Posters I,19,,636
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Automate or Assist? The Role of Computational Models in Identifying Gendered Discourse in US Capital Trial Transcripts,"The language used by US courtroom actors in criminal trials has long been studied for biases. However, systematic studies for bias in high-stakes court trials have been difficult, due to the nuanced nature of bias and the legal expertise required. Large language models offer the possibility to automate annotation. But validating the computational approach requires both an understanding of how automated methods fit in existing annotation workflows and what they really offer. We present a case study of adding a computational model to a complex and high-stakes problem: identifying gender-biased language in US capital trials for women defendants. Our team of experienced death-penalty lawyers and NLP technologists pursue a three-phase study: first annotating manually, then training and evaluating computational models, and finally comparing expert annotations to model predictions. Unlike many typical NLP tasks, annotating for gender bias in months-long capital trials is complicated, with many individual judgment calls. Contrary to standard arguments for automation that are based on efficiency and scalability, legal experts find the computational models most useful in providing opportunities to reflect on their own bias in annotation and to build consensus on annotation rules. This experience suggests that seeking to replace experts with computational models for complex annotation is both unrealistic and undesirable. Rather, computational models offer valuable opportunities to assist the legal experts in annotation-based studies.","Andrea W Wen-Yi, Kathryn Adamson, Nathalie Greenfield, Rachel Goldberg, Sandra Babcock, David Mimno, Allison Koenecke",Atrium,Posters I,20,,394
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,AI-based Content Creation Tools on Social Media: A Randomized Controlled Experiment,"We conduct a randomized controlled experiment on a social media platform to test AI as content creation tools. These tools helped users participate more but led to lower perceived content quality. Our findings highlight a clear discrepancy between the benefits for content producers and the experience of consumers, raising important considerations for AI integration in social media platforms.","Anders Giovanni Møller, Luca Maria Aiello, Daniel Romero, David Jurgens",Atrium,Posters I,21,,242
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,What's in a Niche? Migration Patterns in Online Communities,"One function of social media is to allow users to engage with large topical communities. However, the internet is a big place, and there are few topics that are small enough that only one community exists - instead we see a meso-level structure of highly related communities that all exist in the same category. For instance, there may be several communities that all discuss various basketball teams in the NBA as opposed to just one 'basketball' themed community. Movement between these highly related communities can be seen as an expression of changing interest. One aspect of this is a 'deepening' into a topic. In politics this may be related to radicalization or joining movements. In hobbies this suggests an aspect of the hedonic treadmill. In academics this could represent an increase in expertise. Given these seemingly disparate implications of deepening, defining and measuring it is no simple matter. We examine several possible definitions and find that working with pair-wise directional movement of users, information, and references provides a simple, yet robust framework within which to examine deepening across many topics. In this work, we examine the highly topical communities of Reddit to identify if and where these patterns of deepening exist and what they might suggest about meso-level online community structure.","Katherine Van Koevering, Meryl Ye, Jon Kleinberg",Atrium,Posters I,22,,774
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Comparing mobile phone and facebook data during emergencies,"This study examines two well-established data sources for monitoring population movements. We compare insights on human mobility during emergencies derived via social media data and mobile phone records (XDRs), during the same natural disaster; the wildfires that struck Valparaso, Chile, on February 2nd, 2024. META's Population in Crisis include maps that utilise information about Facebook usage in areas impacted by natural hazards, producing aggregate pictures of how the population is affected by and responding to the hazard. The maps include insights into evacuations, cell network connectivity, access to electricity, and long-term displacement. However, as every data source, it entails biases and limitations: there may be represetativity biases due to the platform's heterogeneous penetration to the population as well as power and connectivity availability, which in case of natural disasters such as wildfires can alter the insights. Perhaps the most important limitation of this data source, from an operational point of view, is that it is only available post-disaster, limiting insights into pre-crisis mobility or the possibility of creating an early alert system. A well-established alternative data source for studying human mobility are mobile phone data records (XDRs). XDRs provide a continuous view of population movements and can potentially be available in a finer temporal and spatial resolution than the Population in Crisis. However, these data sources are proprietary, not universally accessible, and their accessibility depends on individual agreements. We employ anonymized data provided by a major mobile phone operator in South America, with a market share of 27\% in 2023. The observed mobile phone population moderately correlates with the official population at the census zone level ($\rho = .36$). To establish a standardised comparison framework, we aggregated the mobile phone data to match META's coarser temporal (8-hour intervals) and spatial (2.4sq km grid) resolution. Since Facebook data are available from February 4 to February 19, we use the same time frame for our dataset derived from mobile phone data. For the baseline values that indicate the number of people connected to each tower before the crisis, we use the average values from January 19 to February 1. These values were aggregated by weekday and 8-hour time intervals. First, we correlate different indicators in the two datasets: the average number of people during the pre-crisis period, the percentage changes in the number of people in the post-crisis period compared to the baseline, and the z-scores of these changes. Figure~\ref{fig:corrs} presents the Pearson correlation throughout the observation period. As can be seen, the highest correlation between both datasets is achieved when comparing population baselines, which are calculated as the number of geolocated Facebook users or the number of active phone IDs in the areas under investigation. The results show strong correlations between the datasets in the baseline population distributions (Pearson $\rho$=.77, Spearman $\rho$=.68), meaning both datasets align well in estimating population distributions pre-disaster. Displacement correlation shows moderate agreement during crisis showing that Facebook data captures the broader trend but lacks finer resolution ($\rho$=.43, $\rho$=.57) (Figure~\ref{fig:corrs}). Temporal analysis highlights robust baseline correlations across times of day, with displacement pattern correlations varying notably, especially on Sundays, likely due to behavioral differences in social media use on weekends (e.g., less consistent geolocation sharing). A categorical classification (Increase/Stable/Decrease) yielded an average accuracy of .52, reflecting substantial agreement in mobility patterns, particularly during weekdays and business hours. Figure~\ref{fig:comparison} shows the bivariate cloropleth map of the percentage change on the day of the wildfire, with an accuracy analysis (confusion matrix) suggesting that Facebook data classifies movement trends correctly more than 50\% of the time but struggles with finer, localized movements. These findings suggest that social media-derived mobility data reliably proxies population movements during crises, but varies systematically with temporal and spatial factors. Overall, we observe that Facebook and XDR data show high alignment in pre-crisis population estimates but greater variance in displacement patterns. Mobile XDRs provide more granular, real-time displacement insights, particularly valuable for early warnings, response planning, and socioeconomic impact assessments, while Facebook data appear to be useful for broad population trends but lack the ability to track finer movement details, making it more relevant for post-disaster assessments and large-scale planning. Ideally, together, these datasets complement each other, allowing for a more complete picture of disaster-induced displacement.","Timur Naushirvanov, Erick Elejalde, Elisa Omodei, Kyriaki Kalimeri, Marton Karsai, Leo Ferres",Atrium,Posters I,23,,593
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Individual Misinformation Tagging Reinforces Echo Chambers; Collective Tagging Does Not,"Fears about the destabilizing impact of misinformation online have motivated individuals and platforms to respond. Individuals have increasingly challenged others’ online claims with fact-checks in pursuit of a healthier information ecosystem and to break down echo chambers of self-reinforcing opinion. Using Twitter (now X) data, here we show the consequences of individual misinformation tagging: tagged posters had explored novel political information and expanded topical interests immediately prior, but being tagged caused posters to retreat into information bubbles. These unintended consequences were softened by a collective verification system for misinformation moderation. In Twitter’s new feature, Community Notes, misinformation tagging was peer-reviewed by other fact-checkers before revelation to the poster. With collective misinformation tagging, posters were less likely to retreat from diverse information engagement. Detailed comparison demonstrated differences in toxicity, sentiment, readability, and delay in individual versus collective misinformation tagging messages. These findings provide evidence for differential impacts from individual versus collective moderation strategies on the diversity of information engagement and mobility across the information ecosystem.","Junsol Kim, Zhao Wang, Haohan Shi, Hsin-Keng Ling, James Evans",Atrium,Posters I,24,,924
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Exploring the Trajectory to Conspiracy Theories on YouTube in Japan,"Conspiracy theories have proliferated on social media, particularly during the COVID-19 pandemic, posing social and political challenges despite platform efforts to limit misinformation. This study investigates how individuals in Japan engage with vaccine-related conspiracy theories on YouTube, analyzing both content creatorsÕ transitions and viewersÕ pathways. Using data collected from the YouTube Data API between April 2021 and September 2024, we identified six categories of vaccine-related channels: Conspiracists, Monetized Conspiracists, Spiritual Creators, Political Creators, Mass Media, and Others. Key findings include: (1) Many creators frame conspiracy theories as entertainment to maximize viewership. (2) Channels that shift to conspiracy content show significant growth in views, likes, and comments. (3) Viewer transitions indicate that Monetized Conspiracists and Spiritual Creators often serve as gateways to more extreme content. To mitigate the spread of conspiracy theories, interventions should focus on reducing incentives for sensational, monetized content.","Koki Ota, Masaki Chujyo, FUJIO TORIUMI",Atrium,Posters I,25,,207
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Genius Narratives and Informal Science as Predictors of Conspiracy Thinking,"Conspiracy beliefs can negatively impact personal health, democratic engagement, and intergroup relationships. Pop-science communication often uses narrative elements such as mystery, chance, twists, and hero-journey-like narratives to make its contents more palatable. In this way, a specific conception of scientific progress is promoted: in the beginning, everyone is wrong and blinded by prejudice; the genius arrives with the exact solution; this is mocked or considered insane until everyone realizes that he was right from the beginning. We hypothesized that a genius-driven view of science and a preference for informal science communication could influence conspiracy beliefs. To evaluate this, we administered a 104-item questionnaire to 843 U.S. residents. Genius mentality and informal science significantly predicted higher conspiracy belief, while trust in science and scientists were strong negative predictors. Importantly, genius mentality moderated the relationship between trust in science and conspiracy belief. Informal science moderated the relationship between education and genius mentality. These findings suggest that genius mentality and informal science communication influence the perception of science by promoting trust in figures isolated from the mainstream scientific community. The resulting worldview could lead to overestimating the influence individuals or small groups can have on complex social systems directly influencing conspiracy beliefs.","Michele d'Errico, Taha Yasseri",Atrium,Posters I,26,,173
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,How does social media data reflect labour market demands: A case study on primary and continuing vocational education in Germany,"The German labor market is dynamic: technical innovations and social changes lead to new skill demands. Within the German education system - in contrast to other countries - vocational education and training (VET), retraining and continuing vocational education and training (CVET), play a pivotal role in responding to these new requirements. This is also resembled by roughly half of the workforce having a (C)VET training as their highest vocational education. The German education system offers different pathways for professionals. These are negotiated between four different stakeholders (educational institutions, companies and enterprises, employees, and financiers), who all have to react to emerging situations. From a research perspective, the task is to determine which education content is increasingly being offered and demanded in order to draw conclusions about the development needs of the vocational training system. We find information on these in different data sources. Our primary research questions is: If we want to utilise data from Twitter/X or other social media, how representative are they? In other words: ``Can we utilize Twitter/X data as an interoperable data source extending existing resources for analysing vocational education and training in Germany?'' We will present an overview, followed by a segment covering current research and related work, outline the methodology employed in the study, experimental results and assesses the X dataset, relating to research on the German labor market as well as conclusions and an outlook.","Jens Dörpinghaus, Michael Tiemann, Kristine Hein, Robert Helmrich",Atrium,Posters I,27,,89
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,The Impact of Culture on LLM-based Political Persuasion,"The increasing use of Large Language Models (LLMs) in political messaging - particularly by external adversaries, as highlighted in recent reports from major tech companies [1][2][3] - underscores the urgent need to understand their influence on attitudes and opinions. While previous research suggests that LLM-generated political messages can match or even surpass human-authored persuasion in certain contexts, the role of cultural orientation in shaping these effects remains under-explored. This study aims to investigate how cultural orientation influences the persuasiveness of LLM-generated political content and whether LLMs can effectively target specific cultural groups. Using a mixed-design experimental approach, we will compare the persuasive impact of human-written, LLM-generated, and culturally tailored LLM-generated political messages. To measure participantsÕ cultural orientation, we will incorporate the Horizontal and Vertical Individualism and Collectivism (HVIC) scale and examine the extent to which LLM-generated messages can effectively persuade different cultural groups within these dimensions. Preliminary analyses suggest that LLMs can generate distinct messages tailored to each of these cultural dimensions. However, whether these differences lead to measurable persuasive effects remains an open question we aim to answer through our experiment. This work is ongoing research, with this extended abstract detailing our planned approach and initial findings. By the end of our study, we hope to provide new insights into how these models influence diverse global audiences and assess the extent to which they can effectively target specific cultural groups. Our findings could have implications not only in politics but also in fields such as advertising, public health campaigns, and social advocacy. 1 - https://openai.com/global-affairs/disrupting-malicious-uses-of-ai/ 2 - https://transparency.meta.com/en-gb/integrity-reports-q2-2024/ 3 - https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai","Tom Bidewell, Björn Ross, Clare Llewellyn",Atrium,Posters I,28,,370
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Measuring algorithmic ranking effects with a browser extension experiment,"Social media platforms use algorithmic ranking to personalize news feeds, yet the effects of these algorithms on user behavior remain poorly understood due to data inaccessibility and complex feedback loops. This study investigates the impact of algorithmic ranking through a controlled experiment on FacebookÕs news feed in collaboration with WhoTargetsMe. Using a browser extension, we isolated the effect of ranking while keeping content stable. A total of 555 participants viewed their feeds either in FacebookÕs default ranking or a randomized order, allowing within-subject comparisons of engagement and attention. Preliminary findings indicate that randomized ranking leads to a more rapid decline in dwell time, suggesting FacebookÕs algorithm is optimized to sustain engagement beyond mere content selection. This approach provides a novel method for studying algorithmic effects in a controlled experiment, while preserving ecological validity and user privacy.","Jason Burton, Philipp Lorenz-Spreen, Stefan Herzog, Lisa Oswald, Ralph Hertwig, Sam Jeffers, Kevin Carmody, Ronald E. Robertson, Almog Simchon, Stephan Lewandowsky",Atrium,Posters I,29,,573
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Analyzing Country-Level Heterogeneity in Public Attitudes Toward Migration Topics on Bluesky,"Migration is a globally significant political issue, with discourse varying across countries. Social media platforms provide a valuable lens for studying migration discourse, offering real-time insights into public sentiment, key narratives, and evolving debates. Previous research has extensively relied on Twitter (now X) to analyze migration-related discussions, often using geo-tagged data to examine country-specific trends [1,3]. However, this study shifts focus to Bluesky, an emerging social media platform that experienced user growth following Elon MuskÕs acquisition of Twitter and its subsequent policy changes. By analyzing migration discourse on Bluesky, we explore how discussions vary across different national contexts, providing new insights into an evolving online space that lacks traditional metadata. More specifically, we analyze how Bluesky users discuss migration in the United States, the United Kingdom, and Germany, focusing on key topics, sentiment trends, and linguistic variations. To achieve this, we identify country-specific themes, analyze sentiment dynamics, and construct dialectograms using embeddings trained on posts from each country to explore nuanced linguistic differences. While previous studies on X have largely relied on geo-tagged tweets to examine country-specific discourse, Bluesky presents a unique challenge as it does not provide user location data. To address this, we introduce a novel approach that employs a large language model (LLM) to annotate posts based on the country they reference. Additionally, we leverage the LLM to generate hashtags, as hashtag usage on Bluesky differs from that on X. These hashtags are then used to construct semantic networks for each country of interest. This study provides new insights into migration discourse on Bluesky, revealing regional differences in sentiment and topic framing. It uncovers both distinct and common themes shaping migration discourses in the US, UK, and Germany. Additionally, it introduces an innovative approach to analyzing social media data without traditional metadata, offering a valuable framework for future research on emerging digital platforms. While not mentioned before, our analysis found that negative sentiment posts outnumber positive ones by about five to one, with negative posts exhibiting stronger partisan tendencies. By applying semantic network analysis and dialectogram projection, we gained deeper insights into regional linguistic variations in migration discourse, shedding light on the underlying political and ideological nuances.","Jiho Kwak, Tom Theile, Egor Kotov, JISU KIM",Atrium,Posters I,30,,198
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Evaluating how LLM annotations represent diverse views on contentious topics,"Researchers have proposed the use of large language models (LLMs) for labeling data for both research and applied settings. This literature emphasizes the improved performance of LLMs relative to other natural language models, noting that LLMs typically outperform other models on standard metrics such as accuracy, precision, recall, and f1 score. However, previous literature has also highlighted the bias embedded in language models, particularly around contentious topics. This bias could result in labels applied by LLMs that disproportionately represent majority groups over a more diverse set of viewpoints. In this paper, we evaluate how LLMs represent diverse viewpoints. Across four annotation tasks on three datasets, we show that LLMs do not show substantial disagreement with annotators on the basis of demographics. Instead, the model, prompt, and disagreement between human annotators on the labeling task are far more predictive of LLM agreement. We discuss the implications for researchers and practitioners.","Megan Brown, Shubham Atreja, Patrick Y. Wu, Libby Hemphill",Atrium,Posters I,31,,957
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Wikipedia in the Era of LLMs: Evolutions and Risks,"Wikipedia helps both people and machines seeking knowledge about the world. In this paper, we present a thorough analysis of the influence of Large Language Models (LLMs) on Wikipedia, examining both human and machine perspectives. We begin by analyzing page views and article content to study WikipediaÕs recent evolutions and assess the impact of LLMs. Subsequently, we examine how LLMs affect various Natural Language Processing (NLP) tasks related to Wikipedia, including machine translation and retrieval-augmented generation (RAG). Our findings and simulation results reveal that Wikipedia articles have been influenced by LLMs, with an impact of approximately 2\% in certain categories. If the machine translation benchmark based on Wikipedia is influenced by LLMs, the scores of the models may become inflated, and the comparative results among models might shift as well. Moreover, the effectiveness of RAG might decrease if the knowledge base becomes ""polluted"" by LLM-generated content. While LLMs have not yet fully changed WikipediaÕs language and knowledge structures, we believe that our empirical findings signal the need for careful consideration of potential future risks.","Siming Huang, Yuliang Xu, Mingmeng Geng, Yao Wan, Dongping Chen",Atrium,Posters I,32,,919
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Segregation in Swedish Media Texts: An Initial Exploration Using BERTopic,"This proof-of-concept study examines the linguistic dimensions of segregation in Sweden by applying Topic Modeling, BERTopic [1], to analyze a couple of thousand articles (n≈1800) that mention ‘segregation’ in Swedish public media over the past 20+ years. While segregation is often analyzed through spatial, economic, and social lenses, we argue that the ways in which segregation is represented in language plays a crucial role in shaping how different societal groups interact and perceive one another. This study builds on the premise that language—shaped by geography, class, and gender—both reflects and reinforces social divisions. BERTopic’s ability to model and group large collections of texts into distinct topics allows us to detect the emergence of key discursive events and trends, uncovering shifts in how segregation is discussed and framed in Sweden. By using BERTopic, we aim to identify the key topics related to segregation and how they have evolved over the examined period. Are there specific global, local, or societal events distinguishable, such as political speeches, policy changes, social movements, media controversies, or educational reforms (e.g., school choice policies), that influence the language and framing of segregation in Swedish society? The study is structured around two interconnected research objectives. First, we analyze the temporal dynamics of media discourses on segregation, identifying shifts in framing over the past two decades. Second, we examine how language and discourse contribute to the construction of segregation in contemporary Swedish society by drawing on textual data and corpus linguistic analysis. Findings could be used to inform the design and implementation of so called anti-segregation policies and highlight the importance of considering the linguistic dimensions of social divides.","Dimitrios Kokkinakis, Daniel Wojahn, Johan Järlehed",Atrium,Posters I,33,,179
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Stop Wasting Time Fine-Tuning: Traditional Classifiers Shine with LLM Embeddings for Political Textual Analysis,"Large language models (LLMs) are widely applicable for political science research; however, many researchers do not have access to sufficient compute resources or data to fine-tune LLMs for their research purposes. As such, it is necessary to identify ways to deploy LLMs more efficiently for political science research applications. We examine LLMs for political science classification tasks, and we show that using LLMs as feature extractors for downstream classification models (an embed-then-classify pipeline) has performance comparable to or exceeding the performance of LLMs fine-tuned for classification (a fine-tune-then-classify pipeline), all while requiring less compute time and data. We present a robust set of experiments with 19 encoder-only LLMs, five classification models (logistic regression, k-nearest neighbors, support vector classifier, multilayer perceptron, and XGBoost), and four fine-tuning strategies (full fine-tuning, LoRA, IA3, and classification head only) on a new political classification dataset. This dataset includes over 130,000 text sequences for multi-class classification and is made of text extracted from a variety of government documents including legislation, congressional committee reports, congressional floor speeches, congressional witness testimony, statements for the record, executive agency rules, amicus curiae briefs, federal court decisions, and more.","Collin Coil, Nicholas Chen, Caroline Bruckner",Atrium,Posters I,34,,119
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,AI enhanced political content moderation,"The spread of misinformation on social media presents a significant challenge for content moderation. While both community-based and automated approaches have been implemented, each comes with inherent limitationsÑpolitical bias in human moderation and algorithmic bias in AI systems. This study explores a hybrid human-AI content moderation framework inspired by Community Notes, where participants receive AI-generated feedback in three formats: supportive, neutral, or argumentative. Through an experimental design, we examine how users incorporate feedback into their final notes and how political ideology, feedback type, and the presumed feedback source shape the resulting notes. Findings indicate that the likelihood of note improvement is strongly tied to whether users incorporate AI-generated feedback. Users are most receptive to neutral feedback, followed by supportive and argumentative feedback. However, once incorporated, argumentative feedback leads to the most helpful notes. These results highlight the potential of AI-assisted moderation to enhance discourse and mitigate polarization when effectively integrated with human oversight.","Saeedeh Mohammadi, Taha Yasseri",Atrium,Posters I,35,,176
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,The call of the Void Deck: Does state-affiliated ‘citizen journalism’ site STOMP foster self-management in Singapore’s urban commons?,"This study examines how Singapore's citizen journalism website STOMP influences the governance of urban commons, particularly void decks (open ground floors of public housing blocks). Using Ostrom's eight principles for successful commons management as a framework, the research analyzes 30,000 STOMP articles to determine whether this platform facilitates self-regulation or merely extends government surveillance. The paper explores the tension between bottom-up community management aspirations and top-down monitoring through ""lateral surveillance,"" where citizens police each other's behavior in shared spaces. For analysis, the researchers fine-tuned an open-source large language model (Mistral-Small-24B-Instruct-2501) using a supervised approach on human-annotated posts to classify content and extract information about contested uses of common spaces. The study identifies patterns in how Singaporeans negotiate boundaries, conflict resolution, and graduated sanctions, providing insights for urban policy and community governance.","Andrew Schauf, Miguel Escobar Varela, Michael Patrick McGreevy",Atrium,Posters I,36,,688
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Feelings Don't Care About Facts: Persuasive Effect of Framing Outweighs Factuality,"Following the 2016 election, concerns about fake news influencing democratic outcomes became central to public discourse and academic research. However, despite significant attention, studies consistently show that fake news consumption is minimal and concentrated among a small subset of extreme partisans. In contrast, the potential influence of mainstream mediaÑdespite its far greater reachÑhas received comparatively little scrutiny. One possible justification for the disproportionate focus on ""fake news"" is the assumption that falsehoods exert a much stronger $\textit{persuasive}$ influence than accurate but biased stories, despite their limited overall prevalence. However, to our knowledge, no study has systematically tested whether lying confers a persuasive advantage. Does fake news influence opinions more than biased but factually accurate news? If so, how large of an advantage does one gain by lying? We address these questions by comparing the persuasive impact of biased, yet factually accurate news to that of fake news. We employ a novel methodology that leverages large language models (LLMs) to synthetically generate articles using facts and quotes extracted from actual news articles, systematically varying i) tone and ii) veracity. We then conduct a randomized survey experiment that compares the effect of changing the article's tone with the combined effect of changing both the article's tone $\textit{and}$ factuality. We find that while biased presentation of accurate facts has a large effect on readers' opinions about the subject of coverage, lying does not confer a meaningful persuasive advantage above and beyond that of framing alone. These results are consistent across a wide variety of topics and cannot be explained by readers' assessing false articles as less credible than accurate ones. Our findings challenge the notion that falsehoods are exceptionally powerful at manipulating public opinion and emphasize the importance of scrutinizing common reporting practices that might contribute to public misperceptions.","Jennifer Allen, Amir Tohidi Kalorazi, Samar Haider, Duncan J. Watts, David Rothschild",Atrium,Posters I,37,,461
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Identifying Bots in Online Surveys through Robotic Language in Open Narrative Answers: A Prediction Approach,"Online survey data is key for social and political decision-making, including official statistics. However, participants are frequently recruited through online access panels, crowdsourcing platforms, river sampling approaches, and social media platforms, making it difficult to verify that answers come from humans. As a consequence, bots – automated programs that interact with digital systems including online surveys – may shift online survey outcomes and social and political decisions. Bot and human answers often differ regarding word choice and lexical structure. This may allow researchers to identify bots by predicting robotic language in open narrative answers. In this study, we therefore investigate the following research question: Can we identify LLM-driven bots by predicting robotic language in open narrative answers? We conducted an online survey on equal gender partnerships, including three open narrative questions. We recruited 1,512 participants through Facebook ads. We also utilized two LLM-driven bots that each ran through our online survey 400 times: The first bot is linked to the LLM Gemini 1.5 Pro, and the second bot additionally includes a memory feature and adopts personas, such as age and gender. We conducted data synthesis from February 3, 2025, to February 18, 2025. Using a transformer model (BERT) we attempt to predict robotic language in the open narrative answers. Each open narrative answer is labeled based on whether it was generated by our bots (robotic language = “yes”) or the participants recruited through Facebook ads (robotic language = “unclear”). Using this dichotomous label as ground truth, we will train a series of prediction models relying on the BERT language model. As an alternative (unsupervised) method, we will additionally prompt Gemini 1.5 Pro to act as a prediction model and compare its performance to BERT. We will present various performance metrics to evaluate how accurately we can predict robotic language, and thereby identify bots in our online survey. Our study contributes to the on-going discussion on bot activities in online surveys. Specifically, it will extend the methodological toolkit of social research when it comes to identifying LLM-driven bots in online surveys.","Joshua Claassen, Jan Karem Höhne, Ruben L. Bach, Anna-Carolina Haensch",Atrium,Posters I,38,,557
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Improving Probes that Track Veracity in Large Language Models,"Large language models (LLMs) sometimes produce factually incorrect or unverifiable claims. It raises important questions about their ability to assess the veracity of their outputs. Recent studies suggest that internal LLM representations may encode truthfulness. However, existing approaches rely on flawed assumptions. Namely, (1) we know precisely what LLMs have learned, (2) truth and falsehood lie on a single axis, (3) we can disregard uncertainty in predictions, and (4) all statementsÑeven incomplete onesÑhave a definite truth value. In this work, we propose a multi-class linear probe that classifies statements as Òtrue,Ó Òfalse,Ó or ÒdonÕt know.Ó It leverages multiple instance learning and conformal prediction to handle uncertainty more effectively. Experiments with six LLMs and three datasets show that our method outperforms zero-shot prompting. We also find evidence suggesting that most LLMs have a *linear* mechanism enabling them to track veracity within the mid-layers.","Germans Savcisens, Tina Eliassi-Rad",Atrium,Posters I,39,,214
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Quantifying Sentiment in Economics,"Behavioral economics posits that the behaviors of economic agents, such as consumers, can be interpreted by highlighting their psychological dimensions (Kahneman and Tversky, 1979). These behaviors significantly impact national economies. Traditionally, economic evaluations have predominantly utilized quantitative indicators, such as Gross Domestic Product (GDP) and employment statistics, due to their measurability and objectivity. However, the process of generating quantitative indicators, from initial data collection to the calculation of final values, involves considerable manual labor and time. This intensive resource requirement does not align with the needs of the contemporary information society, which emphasizes the availability of real-time data. As such, although quantitative indicators have historically been central, the growing availability of extensive textual data and advancements in NLP technologies have enhanced the appreciation of psychological dimensions, which can now be analyzed in real time. Emotional responses, which often supersede rational thought and influence decisions based on feelings rather than logic, provide key insights for a deeper understanding of economic trends and market dynamics (Ishijima and Kazumi, 2018). Sentiment analysis benchmark datasets are essential for the development and performance evaluation of machine learning models. Several datasets are widely recognized and utilized. However, unlike many machine learning tasks where true labels are available through human annotation, such as image recognition (e.g., classifying images into categories like ÒdogÓ or ÒcatÓ) and medical diagnosis (e.g., diagnosing diseases based on symptoms and medical data), sentiment analysis is challenged by psychological biases and inconsistencies inherent in human assessments, which compromise the reliability of human annotations. Hartmann et al. (2023) highlighted the importance of accurate sentiment annotation for realizing the full potential of sentiment analysis. Inadequate annotation of text documents can lead to substantial misinterpretations (Jaidka et al., 2020) and diminished explanatory power (Kbler et al., 2020), potentially resulting in considerable business loss (Hartmann et al., 2019). Thus, ensuring the accuracy of sentiment annotation remains a crucial concern in sentiment analysis research. Zheng (2025) investigated the inconsistencies and psychological biases in human economic assessments by applying behavioral economics theories, complemented by an empirical analysis of real-world data. The experimental results indicated a correlation between declining economic indicator values and an increase in participant responses, reflecting heightened public engagement during periods of economic uncertainty. Moreover, a divergence exceeding 60\% was identified between human annotations and machine predictions was identified, highlighting substantial biases that undermine the reliability of benchmark data and the sentiment models trained on them. This study questions the direct use of benchmark data and aims to develop a robust sentiment analysis model tailored to the Japanese economy. It also examines the relationship between qualitative and quantitative economic indicators to capture shifts in economic conditions, highlighting the potential for more timely and accurate economic assessments.",Wanwan Zheng,Atrium,Posters I,40,,123
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Enhancing Stock Return Prediction with LLM-Extracted News Events: Accurate and Interpretable Insights,"News-driven stock market prediction has demonstrated promising potential in recent studies, suggesting that such documents reflecting the changing states of the world help infer the asset market dynamics. However, existing models based on word embedding and sentiment analysis suffer from noise and bias in the materials. At the same time, these methods show weakness in interpretability, limiting their practical application for decision-makers. To address these challenges, we proposed a method utilizing large language models (LLMs) to extract cleaner and more interpretable event factors from news articles, along with a novel interpretable asset return prediction framework driven by event factors. Our method not only provides precise asset return predictions but also offers insights into the underlying relationships between key events and asset returns. Specifically, we first utilize a pre-trained LLM to extract key events from news texts, for which targeted prompts and algorithms are designed. Secondly, we propose the event-driven asset return prediction framework(EDARPF), which integrates news event factors and essential context features as inputs, and incorporates the multi-head self-attention mechanism to enhance model performance and interpretability. Finally, we conduct experiments on a real-world dataset from the Nasdaq stock market, which verify the prediction performance and the portfolio profit performance of the proposed method, while also providing interpretations for stock movements based on news narratives. Our study highlights the advantages of using LLMs in financial applications, showing that effective extraction and interpretation of news can lead to more informed and accurate decision-making support.","Gang Li, Dandan Qiao, Mingxuan Zheng",Atrium,Posters I,41,,1043
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,The Bluffing Bot: LLMs Learn to Deceive in Social Deduction Games,"This study investigates how deceptive and strategic discussion behaviors emerge in large language models (LLMs). Using Social Deduction Games (SDGs) as a testbed, we fine-tune Mistral-7B through imitation learning and reward optimization to examine how deceptive behavior emerges from different training methods and environment dynamics. Our results show that reward-optimization not only improves the performance of SDG agents above the level of much larger instruction-following models, but it also increases the agent's propensity to deceive. These findings open up a fresh perspective on AI deception, emphasizing the role of training algorithms and environmental incentives over model size and perceived intelligence.","Yannik Keller, Thomas F. Eisenmann, Levin Brinkmann, Iyad Rahwan",Atrium,Posters I,42,,136
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Can a psychological assessment measure sexism in large language models? A validation study of the Ambivalent Sexism Inventory,"Large language models (LLMs) often reflect gender biases from their training data, making it crucial to develop reliable methods for measuring these biases. Existing approaches have been criticized for inconsistencies in how gender bias is conceptualized and operationalized. In this study, we explore whether the Ambivalent Sexism Inventory (ASI), a well-established psychological assessment, can be used to measure sexism in LLMs. To do so, we administer the ASI to three state-of-the-art LLMs and systematically evaluate the assessment against several psychometric quality criteria, which are applied to the LLM domain. Our results reveal significant inconsistencies across models, with only one model achieving moderate reliability, meaning it produces similar results under consistent conditions. However, it fails validity checks, as the ASI scores do not correlate positively with other measures of sexism, including its behavior in a downstream task. This indicates that even a reliable score may not reflect real-world model behavior. These findings suggest that psychological assessments developed for humans may not be directly applicable to measuring psychological traits in LLMs, and underscore the need for careful validation and potential adjustments prior to their application in the LLM domain.","Jana Jung, Marlene Lutz, Markus Strohmaier",Atrium,Posters I,43,,326
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,"ActiveTigger: A Tool for Easy, Open, and Collaborative Text Annotation and Data Augmentation","The growing accessibility of large language models (LLMs) and textual data has opened new possibilities for social science research while raising challenges related to best practices, sustainability, and transparency. We present ActiveTigger, an open-source web application designed for social scientists to streamline text classification workflows. With an intuitive interface requiring no coding, it enables collaborative annotation, accelerates labeling for model development through measures like active learning, and offers functionalities to train and apply fine-tuned (BERT-based) models. Case studies demonstrate its effectiveness: classifying gender-related themes in social science abstracts and distinguishing abusive, critical, and supportive tweets directed at politicians across 30 million tweets. Beyond showcasing ActiveTigger's research potential, we present this tool to engage with broader debates on establishing best practices for applying LLMs in social science. We invite feedback from the computational social science community and welcome discussions on its application.","Annina Claesson, Emma Bonutti D'Agostini, Etienne Ollion, Emilien Schultz",Atrium,Posters I,44,,765
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Using explainable AI to enhance the internal validity of fuzzy political text classification,"Much of the current work in the text-as-data approaches prioritizes model accuracy and scal- ing—external validity—often overlooking the critical issue if the model correctly operationalises the underlying theoretical constructs. To address these concerns, we integrate explainable AI (XAI) methodologies with a text-as-data approach to examine how transformer-based LLMs classify and interpret political content in social media. We focus on the classifications generated by fine-tuned and few-shot trained models, including BERT, Llama3, GPT4 and DeepSeek, when analyzing a dataset of corporate lobbying tweets. By comparing results across XAI tech- niques—namely LIME, SHAP and LLM-based approaches, which employ in-context learn- ing—our study illuminates how different models produce divergent explanations and predic- tions, potentially leading to lack of internal validity as well as algorithmic bias and discrimina- tory outcomes in analysis of political discussion. We address the following research questions: (RQ1) Are the models making consistent predictions when presented with ambiguous political text data? (RQ2) How effectively do these models incorporate contextual information in politically oriented tweets when making classification decisions? (RQ3) To what extent do transformer-based models translate domain-specific theoretical knowledge—particularly concerning corporate political activity—into accurate model inference? Our dataset consists of approximately 540,000 tweets from Finland’s 500 largest corporations, with a manually labeled subset of 1,600 posts indicating corporate political content. We evaluate model performance through confusion matrices and LIME and SHAP outputs, highlighting instances where ambiguous or context-dependent language challenges classification. Among the models tested, a fully fine-tuned BERT achieves the highest accuracy (0.88) and Cohen’s Kappa (0.72). Few-shot trained models like GPT4 and DeepSeek demonstrate clear performance gains when presented with prompts incorporating domain-specific theory, achieving more reliable outcomes. Thematic analysis of classification rationales reveals that without explicit incorporation of theory, models often rely on out-of-context words to assign “political” labels, introducing potential biases and misclassifications. Our findings underscore the critical importance of considering both internal and external validity in computational text analysis. By illustrating how domain-specific theory and targeted explanations can enhance model reliability, we provide new insights into designing robust text-as-data methodologies that more accurately capture the intended theoretical constructs.","Robin Forsberg, Desheng Hu, Matti Nelimarkka",Atrium,Posters I,45,,296
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,SIBling: A Multidimensional Framework for Evaluating Lexical Semantic Change with Social Science Applications,"Historical linguists have identified multiple forms of lexical semantic change. We present SIBling, a three-dimensional framework for integrating these forms and a unified, validated computational methodology for evaluating them concurrently. The dimensions represent increases or decreases in semantic 1) Sentiment (valence of a target wordÕs collocates), 2) Intensity (emotional arousal of collocates or the frequency of intensifiers), and 3) Breadth (diversity of contexts in which the target word appears). These dimensions can be complemented by evaluation of shifts in the frequency of the target words and the thematic content of its collocates. This framework enables lexical semantic change to be mapped economically and systematically and has applications in computational social science. We present an illustrative analysis of semantic shifts in \emph{mental health} and \emph{mental illness} in two corpora, demonstrating patterns of semantic change that illuminate contemporary concerns about pathologization, stigma, and concept creep.","Naomi Baes, Ekaterina Vylomova, Nick Haslam",Atrium,Posters I,46,,278
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Generative AI’s Impact on Professional Tasks: A Case Study of Software Engineering Field,"While various sectors are integrating LLMs into their work processes, researchers suggest that LLMs' advanced cognitive capabilities can potentially replace human labor, not only simple but also the one that requires high cognitive skills. Despite its existential threat to human labor, the data-driven analyses of the LLMsÕ impact remain limited due to their nascent stage. We empirically analyze this problem by tracing changes in software developersÕ tasks using digital traces from Stack Overflow, a prominent knowledge-sharing platform for software developers. We focus on two key research questions: (1) Does ChatGPT impact software developersÕ tasks equally regardless of task difficulty? (2) Does ChatGPT impact equally regardless of the data availability? Leveraging 382,677 posts from 211,348 users over a 24-month period spanning one year pre- and post-GPT release, we find difficult tasks are less impacted by ChatGPT than easy ones. Also, tasks about rare topics in software engineering are less impacted than popular topics, revealing that the potential for task automation correlates significantly with the availability of digitized domain knowledge. Our work is significant in that it captures the ongoing process of replacing human labor with the innovative tweaking of existing digital trace data and suggests two factors of the impact of LLMs: task difficulty and the level of digitization of domain knowledge.","Myokyung han, Jeewoon Hong, Taegyoon Kim, Jinhyuk Yun, Lanu Kim",Atrium,Posters I,47,,279
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Decoding the Collective Narrative Genetic Structure in Intangible Cultural Heritage Visuals: A Multimodal Large-Scale Model Assisted Content Analysis of ICH Documentaries,"This research presents a novel workflow for analyzing intangible cultural heritage (ICH) documentaries, leveraging a multi-stage, multi-modal approach to decode the narrative genetic structure within visual content. The proposed methodology integrates video-to-text conversion, plot recognition, and text mining to address the limitations of traditional analytical methods in handling large-scale video data. A key contribution of this work lies in the design of a streamlined workflow that combines advanced language models, such as Qwen-Max, with frequency distribution analysis to identify thematic patterns and categories, such as traditional craftsmanship, family, and community activities. The studyÕs findings reveal the importance of visual storytelling in preserving ICH and advancing cultural understanding. By systematically analyzing ICH documentaries, the research identifies recurring themes and narrative structures that reflect the cultural values and collective memory of communities. These insights provide valuable tools for the preservation and transmission of ICH, offering both academic and practical contributions to the field of cultural heritage studies. In conclusion, this research demonstrates the potential of integrating advanced language models and multi-modal analysis techniques to unlock the narrative and thematic essence of visual content. The workflow design and findings contribute to a deeper understanding of ICH representation and pave the way for innovative approaches in cultural heritage research and practice.","Lunan Zhao, Anding Wang, Xiaoxing Fu",Atrium,Posters I,48,,277
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Classifying short vertical videos – moving away from external definitions to a user-centered approach,"Introduction The rise of short-form video platforms like TikTok has fundamentally altered information dissemination, particularly among younger audiences. A key challenge for computational communication science researchers is developing scalable classification methods for online news content to understand these changes beyond qualitative analysis. Traditional classification approaches, relying on external categorizations like journalistic outlet lists, are insufficient. They fail to recognize that professional media outlets and journalists are no longer the sole publishers of news, nor do they exclusively publish news content either (Harff & Schmuck, 2024; Negreira-Rey et al., 2022). Furthermore, news and information consumption research faces an evolving understanding of ""news"" among young adults (Cotter & Thorson, 2022; Swart & Broersma, 2023). This has prompted researchers to adopt a broader ""information"" terminology, encompassing anything perceived as new and/or useful (e.g., Kmpel et al., 2022), thereby including content and actor types beyond traditional journalistic norms. This shift leaves current research on audience perceptions of news and information lacking the computational tools to utilize fine-grained, user-level digital trace data effectively. Such data offers the potential for unprecedented insights into news dissemination from a user perspective (Ohme et al., 2023). This paper addresses this gap. We present and test a novel set of survey items derived from prior qualitative research designed to identify key factors driving user perceptions of informative posts and to identify distinct user types. We further introduce a user-centered classifier, incorporating user information perception types, and compare its performance with traditional classification methods.",Lion Wedel,Atrium,Posters I,49,,280
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,AI for Spatial Justice: Multimodal and Street View Imagery Uncover Waste Disparities in Nairobi’s Informal Settlements,"Fly-tipping (illegal waste dumping) disproportionately impacts informal settlements in the Global South, where systematic spatial inequality, inadequate infrastructure, and socioeconomic marginalization exacerbate environmental and health risks. This study integrates Google Street View imagery, YOLO 11x object detection, and Qwen2-72B Instruct vision-language modelling to map fly-tipping incidents in Nairobi, Kenya, and analyze their spatial correlation with informal settlements. Our hybrid AI approach achieved 97.5% precision in waste detection by combining YOLOÕs real-time capabilities with Qwen2Õs contextual reasoning. Spatial clustering via DBSCAN revealed 68 fly-tipping hotspots, with 75.13% of incidents concentrated within 500 meters of informal settlements. Despite occupying only 2.87% of NairobiÕs land area, these settlements accounted for 20.38% of detected incidents, demonstrating a 7x higher prevalence of fly-tipping compared to formal areas. Results highlight systemic gaps in waste management, with small, localised clusters (<10 m_) reflecting ineffective collection strategies. The findings underscore the urgent need for targeted interventionsÑsuch as expanded waste collection points, community recycling programs, and AI-enhanced surveillanceÑto address inequities in marginalised neighbourhoods. This methodology offers a scalable framework for cities in the Global South to combat illegal dumping, improve public health, and prioritise resource allocation through granular, data-driven insights. Understanding the spatial distribution of fly-tipping and its correlation with informal settlements is crucial for developing targeted interventions. However, traditional waste management methods, which rely on coarse manual reports, fail to capture all fly-tipping incidents (Sun et al., 2023; Zhang and Ma, 2024). To address such limitation, computational social science offers transformative tools. Recent advances in AI-driven compute vision, such as vision-language models (VLMs), enable granular urban mapping by fusing multimodal data (e.g., street-view imagery, text descriptors). For example, Qwen2-VL, a state-of-the-art VLM, achieves superior performance in image understanding through its 448-resolution visual encoder and adaptive processing of irregular image inputs (Yang et al., 2024). When combined with object detection frameworks like YOLO, which has been optimised for real-time detection, these models can decode the spatial inequities hidden in the location of fly-tipping incidents. This study builds on such innovations by integrating Google Street View imagery (GSV), YOLO-based waste detection, and Qwen2-VLÕs contextual reasoning to identify fly-tipping incidents, and therefore investigate the spatial clustering and its correlation to informal settlement with Nairobi as a case study.","Wenlan Zhang, Chen Zhong, Qunshan Zhao",Atrium,Posters I,50,,260
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Introducing a new dataset for conflict damage prediction,"Accurate and timely damage assessment is critical for effective disaster response in conflict-induced crises. While satellite imagery has been widely used for damage prediction, most studies rely on either very high-resolution (VHR) imagery for localized assessment or medium-resolution data for large-scale monitoring. However, datasets integrating both resolutions for conflict damage assessment remain scarce. This research introduces a multi-resolution dataset combining high-resolution PlanetScope imagery (~3-5m) and medium-resolution Sentinel-2 data (10-20m) to enhance the detection of conflict-related destruction. The dataset follows a before-and-after approach, leveraging UNOSAT geodatabases for damage annotations across three distinct conflict zones: Gaza, Syria, and Ukraine. By incorporating diverse environments and multi-sensor coverage, this dataset improves model generalizability for damage detection. Future work will focus on leveraging this dataset for deep learning-based predictive modeling, ultimately contributing to more effective disaster response and post-conflict recovery efforts.",Clara-Gabriela Clipea,Atrium,Posters I,51,,531
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Unsupervised methods for image clustering do not yet replace the social scientist’s gaze,"Computational social scientists are increasingly using big visual data. For exploratory and inductive work on images, social scientists are investigating the potential of unsupervised methods such as Bag of Visual Words, transfer learning and extraction of text representations using multimodal large language models. We have not yet considered whether these unsupervised methods can replicate the gold standard of the social scientist's gaze which can involve compositional interpretation, content analysis, and other qualitative techniques. We compare unsupervised methods with traditional inductive methods using datasets of images from social media, finding that none of the previously proposed approaches achieved outcomes similar to the of researcher-conducted annotations. The results highlight the need for further development of unsupervised image clustering methods to better align with the depth and conceptual thinking of social science research.","Adeline Clarke, Matti Nelimarkka",Atrium,Posters I,52,,535
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Playing to do research: Can we use a video game to research about cyberbullying?,"In this paper we explore the possibility of using the data gathered through a serious game to study cyberbullying as an alternative to surveys and validated questionnaires. For this purpose, we use a videogame that our research team specifically designed for research purposes based on scientific evidences gathered by thoroughly reviewing the literature and 46 European sentences related with cyberbullying and conducting 33 semistructured interviews involving offenders (8), victims (12), and experts (13). As a result, two cyberadventures related with cyberbullying were developed including scenarios which aim to measure risk factors or behaviors which may be considered as cyberbullying. In addition, before getting the credentials to log in the game, the players must fill a questionnaire providing information such as age, gender, place of birth, immigration history, school type, sexual orientation, or the hours they spend on the Internet. After playing the game, they must also fill a validated questionnaire on previous cyberbullying victimization and aggression. Based on this information we explore the possibility of using the scenarios included in the game to measure offending behaviors to conduct prevalence studies on cyberbullying offenders comparing them with the results from the validated questionnaire. In addition, we also explore the effect of measuring risk factors (in particular, the time spent on the Internet) out of the game (through the questionnaire) and within the game (through a specific scenario included in the videogame) comparing it with cyberbullying offending behaviors measured out of the game (validated questionnaire) and within the game (through several scenarios). The statistical metrics we use for this analysis are flexplot, Bayesian contingency tables, and Bayes factor. Our results show that, combining several of the aggression-related scenarios included in the game (i.e., having behaved as an aggressor in three of them or in more than 2 of them), we obtain prevalence figures similar to the ones obtained by other means (4% and 15.25% respectively compared to 20% using our dataset and the validated questionnaire and 8.7% in Spain and 14.9% in Estonia from other study based on surveys and significant samples also conducted by our research team). Regarding risk factors, our results show a stronger association of the considered risk factor (hours spent on the Internet) with the aggression-related scenarios included in the game than with the validated questionnaire. The paper aims to fostering discussion on the use of serious games as an alternative to other research methods such as surveys or questionnaires and to opening new research venues along this line. We believe that serious games present some characteristics (e.g., immersive experience, context-based decision making, role play) which may be beneficial to conduct certain studies or targeting certain population segments. However, they may also involve issues and introduce errors or biases, as any other measurement or research tool. Thus, more research and discussion is needed.","Andrea Baños-Ramos, Gregorio López López, Mario Castro Ponce, María Reneses Botija, Edmond Awad",Atrium,Posters I,53,,702
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Reconstructing Interactional Networks through Wearable Proximity Sensors and Digital Time Diaries,"In this study, we introduce the SocialScope project, which aims to develop an innovative approach to longitudinal data collection on social networks by integrating three methodologies. The first is a novel dual-radio proximity wearable sensor combining Bluetooth and ultra-wideband (UWB) radios, capturing the distance between individuals over time. The second is a smartphone application called iLog, which combines user self-reported information (e.g., time diary) and data passively collected from smartphone sensors. The third is a close-ended questionnaire. Social contacts were operationalized as consecutive proximity detections occurring within a delay of no more than 90 seconds and with a distance variation not exceeding 2 m. Building on this definition of social contacts, we conducted a proximity analysis and a network analysis. This study shows the potential of integrating different sensing technologies to characterize dynamic social networks and the potential of high-frequency sensor data to advance the understanding of social dynamics in everyday life. By integrating various data sources, including wearable sensors, surveys, and time diaries, the research accounts for both spatial and temporal aspects of interactions in a real-world setting. The proximity and network analysis revealed that people tend to maintain closer distances with those who share similar attributes, such as nationality, while contact duration over time showcases notable temporal stability.","Ivano Bison, Tommaso Trulli, Amy L Murphy, Davide Molteni, Gian Pietro Picco, Michele Tizzoni",Atrium,Posters I,54,,266
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Analyzing activity patterns during EV charging sessions using mobility data,"Electric vehicle charging stations (EVCS) are a key part of urban infrastructure. The 2021 Infrastructure Investment and Jobs Act allocated $7.5 billion to expand public charging networks, necessitating effective placement of approximately 500,000 new chargers (Klingel and Loesecke, 2022). Studies suggest that EVCS installation can increase consumer spending at nearby businesses by up to 3.2% (Zheng, 2024). Understanding EV drivers' charging location preferences is crucial for infrastructure planning. Previous research has used surveys, field studies, and EVCS location analyses to investigate EV charging behavior (Lee, 2020; Tal, 2020; Bhat et al., 2024; Visaria et al., 2022). Our study provides new insights through large-scale individual mobility data. Using data from Cuebiq and geolocations of 4,763 public chargers, we identify interactions between users and EVCS in the California Bay Area during January 2022. We analyze data from 111,887 users, identifying charging sessions based on movement data and stops near EVCS. A cohort of 2,858 inferred EV drivers and their 10,421 EV charging sessions are identified for further analysis. We explore driver behavior during charging sessions, including the distance and number of stops made, and combine this with Safegraph Points of Interest (POI) data. Our findings suggest that businesses located near EVCS, particularly restaurants, pharmacies, and fitness centers, may benefit from increased foot traffic during charging.","Callie Clark, Xiyuan Ren, Salsabil Salah, Anne Driscoll, Joseph Chow, Takahiro Yabe",Atrium,Posters I,55,,305
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,When ‘Found Data’ Become Collectives: Theorizing Emergence from Digital Traces,"The rise of social media has profoundly transformed political activism, equipping social movements with unprecedented tools for mobilization and engagement. Building on that, numerous studies have explored novel forms of collectives, collective identity, or collective action arising from online interaction. From the perspective of sociological theory, these studiesÑat least implicitlyÑaddress a fundamental theoretical question: Can online interactions give rise to emergent social phenomena? Generally, emergent phenomena are defined as being generated by, but still (semi-)autonomous from, the parts that constitute them. This (relative) autonomy grants them the kind of causal efficacy termed Òdownwards causation,Ó that is, the capacity of the emergent entity to exert causal influence on the parts that constitute them. The implicit attribution of emergence and the resulting capacity of downward causation is what renders these new forms of online collectives particularly intriguingÑit implies that they are not only shaped by their constituents, but also have the power to influence and transform them in return, thus reshaping, e.g., political dynamics. It is only through the lens of emergence that the underlying theoretical assumptions of phenomena such as the formation of online collective identity or online radicalization become comprehensible. Yet, while computational social sciences (CSS) have provided valuable insights into online mobilization, a notable gap remains in linking these findings to the established concept of emergence. This shortcoming reflects broader concerns about the insufficient integration of CSS with sociological theory (e.g., Edelmann et al., 2020, p. 62; Theocharis & Jungherr, 2021, p. 7). A more thorough integration, however, would enable a more precise conceptualization and interpretation of underlying sociological phenomena (e.g., Bonikowski & Nelson, 2022, pp. 1471Ð1473). Integrating the concept of emergence, in particular, would provide a theoretical framework for more explicitly elucidating how micro-level digital interactionsÑnow observable through vast amounts of digital trace dataÑgive rise to macro-level social entities. The foundational theoretical problem has preoccupied the social sciences since their inception and remains equally relevant to CSS. Hence, CSS also have the opportunity to make a significant contribution to the advancement of sociological theory in this respect. Against this background, this contribution aims to foster a dialogue between a theoretical perspective on emergence and research on (protest) collectives forming (at least in part) online. It is argued that the relational perspective on emergence proposed by Elder-Vass is particularly fit for this, because it posits that Òthe source of emergence is the organisation of the partsÓ (Elder-Vass, 2010, p. 20). In contrast to other reading, this perspective renders emergence susceptible to the derivation of causal mechanisms that explain the solidification and preservation of emergent properties. In the digital context, such mechanisms necessarily pertain to the interplay of social and technical elements. The concept of affordances provides researchers with Òa concrete toolÓ (Bygstad et al., 2016, p. 86) for identifying mechanisms based on the specific organization of such elements. While affordances feature sporadically in CSS research, scholars in information systems (IS) have already empirically examined the affordances of social media in detail. As used in IS research, the concept Òallows the researcher to start the analysis by identifying concrete outcomes, and then retroducing how they were produced,Ó given a particular socio-technical constellation (Bygstad et al., 2016, p. 88). It allows for an analysis of how specific features of social media platformsÑe.g., asynchronous text-based contribution, like button, list of Ôfollowers,Õ use of particular tags to indicate the reuse of another userÕs contentÑalter the social dynamics occurring online. Thus, this contribution integrates the concept of affordances to complement its theoretical focus on online emergence. This conceptual approach is empirically illustrated through results from a case study on the collective identity of QuerdenkenÑa movement that mobilized against COVID-19 measures in GermanyÑbased on digital trace data from Twitter (now X). The case studyÕs findingsÑrelying on socio-semantic network analysisÑreveal that QuerdenkenÕs collective identity online materializes through recurring relational and cultural patterns that persist independently of individual users. Eventually, this contribution proposes a socio-technical mechanism that explains the emergence of the movementÕs collective identity given TwitterÕs affordances. In doing so, this research contributes to a more nuanced understanding of the evolving landscape of social movements in the digital age and the importance and potency of digital collectives.",Sarah Tell,Atrium,Posters I,56,,274
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Marketing Strategy Transformation in Alternative Meat Companies: A Longitudinal Analysis of Web Archives,"This study aims to analyze the temporal evolution of marketing strategies in the alternative meat industry by examining corporate website content using the Wayback Machine. Focusing on the top pages of websites from five major U.S.-based alternative meat companies between 2010 and 2024, we evaluated the frequency of topic-related mentions, the use of moral expressions, textual diversity, and content similarity between companies. Additionally, approximately 1,300 images from these websites were manually labeled into categories such as food, people, and logos to investigate changes in visual content usage. The findings indicate a shift from early marketing strategies emphasizing taste and ethical benefits to a focus on practical information, such as ease of cooking, price, and expanded distribution channels, as the market matures. While marketing topics have diversified, textual expression has become increasingly standardized, leading to greater similarity in corporate messaging across companies. Furthermore, the use of food-related images has increased, whereas visual appeals to sustainability and ethical benefits have remained limited.","Moena Hashimoto, Kohei F. Takeda, Ryuma Shineha, Akiko Matsuo, Kazutoshi Sasahara",Atrium,Posters I,57,,257
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Sustainable Development Goals in Psychology: A Century of Progress in Publications,"The United Nations’ 2030 Agenda for Sustainable Development established 17 Sustainable Development Goals (SDGs) to tackle pressing global challenges, including climate change, inequality, and public health crises. Research, innovation, and science play a crucial role in achieving these goals by providing evidence-based insights that support informed decision-making. Despite this, systematic analyses tracking knowledge progress related to SDGs remain limited, often focusing on specific goals, regions, or disciplines. Moreover, almost all of the existing studies track only publications that explicitly mention SDGs or related phrases in their titles, largely excluding research that aligns with sustainability principles but does not use these terms explicitly. This also overlooks contributions predating 2015, when the SDGs were formally introduced. Psychology is deeply intertwined with SDGs, influencing areas like mental health (SDG 3), education (SDG 4), and climate action (SDG 13). Yet, its contributions are often overlooked. This study takes a pioneering approach by applying the query-based SDG labeling on 233,061 psychology publications (1894–present) from the American Psychology Association (APA), offering the first large-scale examination of psychology’s role in sustainability, diversity, and inclusivity. By mapping psychology’s engagement with SDGs, we aim to enhance interdisciplinary collaboration and provide insights for evidence-based policymaking toward a sustainable future.","Xinyi Zhao, Dirk U. Wulff",Atrium,Posters I,58,,463
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Capturing Stakeholder Dialogue in Nascent Climate Regulations Using Large Language Models,"This research leverages large language models to examine how the U.S. Securities and Exchange Commission incorporated diverse stakeholder comments, developing GPT-based methods to extract and classify the positions of entities cited in the final rulings of climate legislation. To improve classification accuracy, we developed a Retrieval-Augmented Generation (RAG) system with the OpenAI o1 model, which retrieves relevant discussion sections before classification, achieving over 80% accuracy in identifying stakeholder positions. Findings show that the SEC most frequently cites companies (who are often opposed to the rulings) and financial/government entities (who are often supportive), highlighting both the importance of stakeholder dialogue in regulatory decision-making and the potential of advanced AI techniques for environmental policy research.","Cheng-Ying Wu, Kenneth H.Y. Chung",Atrium,Posters I,59,,237
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Exposure to diabetes and its prevalence in the Dutch population,"We present the results of a study on the influence of social network on diabetes type 2 on the Dutch population using the Dutch Population Network dataset. For each person in the network an exposure score is calculated and its relation to having diabetes is explored. Furthermore diabetes exposure is analyzed in relation to diabetes prevalence for various subpopulation (income, gender and age). A statistical analysis suggests that social network has an effect on the probability of having diabetes. The results are published in a publicly available dashboard.","Edwin de Jonge, Karen van Hedel, Marjolijn Das, Dingeman Jan Van der Laan",Atrium,Posters I,60,,748
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Data-Driven Classification of Interpersonal Reappraisals Reveals Eight Distinct Reappraisal Strategies,"Reappraisal — rethinking a negative emotional situation to alleviate its impact — is an effective emotion regulation strategy decreasing negative affect, increasing positive affect, social adaptation and well-being. However, the mechanisms behind the effectiveness of reappraisal are not yet well understood. To investigate the determinants of reappraisal success, we developed a reproducible, data-driven classification of reappraisal techniques and linked the identified techniques to reappraisal quality as defined by human raters. We used a novel method, the construct mining pipeline, on a large dataset of interpersonal reappraisal suggestions with respect to six negative emotional vignettes to infer classes of reappraisal. We identified eight distinct techniques, namely growth mindset, positive repurposing, aberration, external justification, normalizing, unwarranted conclusions, validation, and humor. After assigning the presence or absence of each technique to entire reappraisals, we will apply linear regression to establish relationships between reappraisal classes and quality. Using a held-out test set, we will replicate our preregistered hypotheses to paint a coherent picture of the relationship between reappraisal techniques and quality. Our findings not only advance the understanding of the mechanisms behind reappraisal, but also enable the development of better targeted reappraisal training both in humans and automatic helper tools such as large language model.","Alina Herderich, Joanna Zun Li, Amit Goldenberg",Atrium,Posters I,61,,322
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Antidepressant Use and Spatial Social Capital,"Social networks may help individuals maintain their mental health. Most empirical work based on small-scale surveys finds that cohesive social networks are critical for mental well-being, while diverse networks are considered less important. Here, we link data on antidepressant use of 277,344 small-town residents to a nationwide online social network. The data enable us to examine how individualsÕ mental health care is related to the spatial characteristics of their social networks including their ties in the local community and connections to distant communities. We find that, besides the cohesion of social networks around home, the diversity of connections to distant places is negatively correlated with the probability of antidepressant use. Spatial diversity of social networks is also associated with decreasing dosage in subsequent years. This relationship is independent from the local access to antidepressants and is more prevalent for young individuals. Structural features of spatial social networks are prospectively associated with depression treatment.","Gergo Toth, Balázs Lengyel, Nicholas Christakis, Aniko Biro",Atrium,Posters I,62,,271
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,How People Perceive Dispositionally (Non-) Ambivalent Others and Why It Matters,"While considerable research has investigated the consequences of being ambivalent about specific attitude objects (van Harreveld et al., 2015; Pillaud et al., 2018), little is known about how people perceive and interact with individuals who are dispositionally ambivalent (prone to experiencing ambivalence across multiple domains; see Schneider et al., 2021) versus non-ambivalent. Across six experiments (N = 1,150), we employed multiple computational and experimental methods to examine how people mentally represent and evaluate dispositionally ambivalent others, and how these representations influence social interaction expectations. Methods and Data Our research program systematically examined mental representations and social perceptions using multiple computational and behavioural methods. We employed reverse correlation image classification, economic games, structural equation modelling, and multi-level analysis to triangulate findings across different methodological approaches: Experiment 1 used the Dictator Game paradigm (Forsythe et al., 1994) to examine resource allocation expectations. The non-ambivalent target was expected to share significantly fewer tokens (M = 26.74) compared to ambivalent targets (M = 43.26 for controversial-only ambivalent; M = 40.63 for generally ambivalent). Experiment 2 employed a reverse correlation paradigm (Dotsch & Todorov, 2012) with two phases: Generation phase: Participants selected from noise-imposed face pairs to create classification images of ambivalent and non-ambivalent targets Rating phase: Independent raters evaluated the generated images on warmth, competence, and behavioural predictions Experiment 3 validated these mental representations by testing whether participants could match verbal descriptions of ambivalence to the generated classification images. Experiment 4 examined whether fair versus unfair dictator behaviour would be associated with ambivalent versus non-ambivalent classification images. Experiments 5 and 6 tested implications for perceived values, moral behaviours, and social roles using both classification images and verbal descriptions. Key Findings 1. Mental Representations: Reverse correlation analyses revealed consistent and distinct mental representations of dispositionally ambivalent versus non-ambivalent others. Non-ambivalent targets were perceived as less warm but more competent across multiple studies. These effects were robust across both visual representations and verbal descriptions, suggesting stable underlying mental models of dispositional ambivalence. 2. Behavioural Expectations: The non-ambivalent target was consistently expected to share fewer resources. In Experiment 1, the standardised indirect effect of perceived ambivalence on allocation through warmth and competence was 0.36 (Bootstrap 95% CI [0.26, 0.46]). 3. Value and Behaviour Predictions: Non-ambivalent targets were perceived as: - Attaching less importance to self-transcendence values and greater importance to self-enhancement values - Less likely to volunteer at homeless shelters or donate to charity - Less suitable for roles requiring interpersonal skills (e.g., social worker, team member) - More suitable for leadership and decision-making positions (e.g., politician, team leader) 4. Mediating Mechanisms: Path analyses and structural equation modelling revealed that warmth emerged as the predominant mediator of outcomes (_ = 0.63, p < .001), particularly for moral and prosocial behaviours, while competence (_ = -0.46, p < .001) played a stronger role in professional role expectations. This dual-pathway model explained significant variance in behavioural predictions (R_ = 0.40) and role suitability judgments (R_ = 0.33). Impact and Implications This research advances computational social science by: 1. Methodological Innovation: Demonstrating how reverse correlation techniques can reveal mental representations of psychological dispositions, extending beyond physical or demographic features. 2. Computational Modelling: Providing a quantitative framework for understanding how perceived dispositional ambivalence influences social judgments through specific mediating mechanisms (Sutherland & Young, 2022). 3. Theoretical Integration: Combining computational methods with social psychological theory to advance understanding of trait inference and person perception. 4. Practical Applications: Offering insights for improving person perception algorithms and computational models of social interaction. Future Directions This work opens several promising avenues for computational social science: - Development of machine learning models to predict social judgments from ambivalence cues, particularly using the validated image sets from our reverse correlation studies - Applications to human-AI interaction modelling, especially for developing more nuanced artificial agents that can recognise and respond to human ambivalence","Ruiqing Han, Travis Proulx, Frenk van Harreveld, Geoff Haddock",Atrium,Posters I,63,,475
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,"‘‘If ChatGPT can do it, where is my creativity?’’ Generative AI boosts performance but diminishes experience in a creative writing task","As AI becomes more sophisticated, it is increasingly being used as a tool to enhance creative expression and innovation, potentially transforming critical and creative thinking—key drivers of social change. However, AI tools such as ChatGPT also pose challenges to the status quo in education. While digital learning could boost productivity and promote equality through expanded access, it is imperative that we examine the likely pitfalls in how generative AI also tends to affect creative thinking and lead to a narrowing of diversity both in representation and thought. In this study, we examined 225 university students who completed a creative writing task with pre- and post-task surveys to assess ChatGPT's impact on their performance and experiences. Results show that while using ChatGPT enhanced creativity output, and reduced the difficulty and effort required for the task, it also diminished the value and enjoyment of the task and raised moral concerns. Our results suggest that ChatGPT assistance could potentially bolster human creativity by facilitating content delivery or providing useful counterpoint ideas. However, bypassing the cognitive effort for creativity with ChatGPT, consequently could harm or disrupt the process of creative practices. We discuss the study results in relation to implications for educational practices and social policy, extending knowledge around technical adoption and digital ethics.","Peidong Mei, Deborah N Brewis, Fortune Nwaiwu, Deshan Sumanathilaka, Fernando Alva-Manchego, Joanna Demaree-Cotton",Atrium,Posters I,64,,699
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,"Techno, Medical, or Social? Mapping Research in Population Ageing and Artificial Intelligence (AI)","Population aging is accelerating globally. Artificial intelligence (AI) has experienced rapid and widespread development over the past decade. The intersection of AI and population ageing remains a critical area of study. This research aims to answer the following research questions: (1) Who are the key contributors to this research, and what patterns of collaboration exist? (2) What key topics have been examined in research studies on AI and older population? We conducted a bibliometric analysis of articles published in this topic over the past decade. Two comprehensive sets of keywords regarding Òolder peopleÓ and ÒAIÓ, were searched in Web of Science (WoS). Keywords from each article were used to identify the research topics, while author-provided keywords were analyzed to reflect the authors' disciplinary focus. The bibliometrix package in R (Aria & Cuccurullo, 2017) was utilized for the bibliometric analysis. Betweenness centrality and closeness centrality were employed to measure the importance of nodes as connectors within the network and the efficiency of their connections to other nodes, respectively. Clusters within each network were detected using cosine similarity. A total of 1663 articles with 8804 authors were located and extracted. Over the past decade, research on artificial intelligence and older population has grown remarkably, with a 32.75% yearly increase in publications. China, USA, Korea, India and UK contributed the largest number of journals. IEEE Access, Scientific Reports and PLOS One are three leading journals. The United States acts as both a key connector between regions and a central hub for international collaboration. The networks of authors were built around three clusters: machine learning (ML), deep learning (DL) and artificial intelligence (AI) (Figure 1). ML (red cluster) acts as the central field that connects ML researchers with researchers emphasizing classification, prediction modelling, and deep learning applications. The DL researchers (blue cluster) tend to work with other tech experts in computer vision, activity recognition, and image processing, showcasing the application of AI in analysing visual data. The ÒAIÓ researchers (green cluster) collaborate more with researchers specializing in ageing and public health. However, the green cluster is smaller in size and the intensity of connection. Six keywords (risk, classification, mortality, health, validation, and dementia) are of central importance in the network. Five clusters were identified (Figure 2). ""Risk"" emerges as the most central and influential term, representing a body of research focused on using AI for risk assessment, prediction, and management (red). ""Classification"" forms the second-largest cluster, reflecting studies centred on predictive modelling and the categorization of health risks (blue). The ""mortality"" cluster emphasises the use of AI to predict public health outcomes over time (green). The fourth cluster (purple) focuses on ""dementia"", exploring how AI technologies can assist in diagnosis and management. The final cluster (orange) addresses the application of AI in conditions and diseases such as sarcopenia, falls, and Parkinson's disease that are closely linked to mobility, physical activity, and muscle strength. Research on AI and population ageing remains predominantly focused on and initiated by engineering and medical disciplines. Current studies are heavily centred on topics such as AI-driven risk assessment, early disease detection, and predictive modelling of age-related conditions, particularly dementia. While these advancements hold promise, the Òsocial aspectsÓ of population ageing and AI remain significantly under-explored. The research landscape is largely shaped by ÒAIÓ experts rather than scholars specialising in ageing, reflecting a disciplinary divide between technical fields and the humanities or social sciences (Nutas, 2024). The current dominance of techno-centric research, prioritising technological solutions over the social and ethical complexities of ageing (S¾tra & Selinger, 2024) may reinforce ÒAI ageismÓ, highlighting the exclusion and neglect of older populationsÕ subjective experiences in the application of AI (Stypinska, 2023). Social scientists need to take a more initiating role in examining the social implications of AI within ageing populations by understanding older peopleÕs user experiences with AI and evaluating how current AI products may reflect and reinforce pervasive ageism. Interdisciplinary partnerships between social scientists, including social gerontologists and ethicists, and technical experts are essential for designing technologies that not only meet the functional needs of older adults but also align with their social, ethical, and cultural contexts. This approach can contribute to the development of AI systems that promote inclusion, equity, and dignity for ageing populations. (please see the pdf file for a fuller version)",Jia LI,Atrium,Posters I,65,,546
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Using machine learning to uncover the secrets of a good life,"In the following paper we examine whether a proposed three-dimensional measure of what makes a life a good one can be replicated in a large Danish sample. While both satisfaction and meaning in life are established measures of a life's goodness, we seek to replicate the existence of a third factor, psychological richness. We then test hypotheses about known relationships between indicators of a good life and other variables using conventional linear models. Here we are interested in whether they hold in regards to each of these three dimensions and whether they vary in strength. Finally, we use machine-learning to explore what features are particularly predictive of each dimension. In order to make this a fruitful exploration of potential predictors we utilize both a wide-set of variables from psychological panel-responses as well as a large amount of socio-demographic variables from the Danish registers. Our study is novel in that we replicate a new three-dimensional measure and that we use interpretable machine-learning methods to evaluate predictors from a large set of domains including psychological, health, income, education, crime, neighborhood and more.","Marten Appel, Lau Lilleholt Harpviken, Ingo Zettler, Rosa Ellen Lavelle-Hill",Atrium,Posters I,66,,549
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Social Styles: Large-Scale Computational Analysis of Website Styles as Sociolinguistic Variables,"Sociolinguistics is eminently concerned with the study of social meaning contained in style, where we take style to mean a coherent set of linguistic features which, together, convey or construct a social identity. Indexicality and bricolage are two mechanisms in sociolinguistics to explain this process, but there are difficulties in applying these theoretical mechanisms empirically: 1) it is difficult to separate style (the meaning embedded in variation) from content (the semantic meaning); 2) the social meanings indexed by these linguistic features operate at multiple levels of granularity (from macrosociological to interactionally local), and it can be difficult to disambiguate which social meanings are being indexed; 3) sociolinguistic work has made clear that extralinguistic semiotic resources, like fashion or make-up, also contribute to sociocultural meaning, but research in extralinguistic sources of meaning has been limited. In this on-going work, we address these challenges with a large-scale computational analysis that focuses on visual style instead of linguistic style. We study the social meanings present in the stylistic language of public-facing websites as expressed through CSS styles. We build on a corpus of self-described social roles in ``about me'' web pages scraped from Common Crawl and extract the CSS from these pages as a source of stylistic data. Using this corpus, we explore several key ideas underlying the mechanisms of indexicality and bricolage.","Naitian Zhou, David Bamman",Atrium,Posters I,67,,491
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Family Complexity: Monogamy and Partner Changes Determine Large-Scale Structure of Family Networks,"We present the first empirical mapping of large-scale family networks using Danish population registries from 1953 to 2019, uncovering a unique set of network traits and the edge-formation mechanisms from which they emerge. We find that the Danish family network has long shortest-path lengths, a slow emergence of a giant weakly connected component, and a heavy-tailed coparent-component size distribution. We identify three key individual-level mechanisms that govern the emergence of these structures: (1) monogamy as the default relationship structure, (2) self-exciting partner change behavior that increases connectivity across generations, and (3) partner-count assortativity, where individuals with multiple partners pair up and pass partner-change tendencies to their children. We statistically validate these mechanisms and incorporate them into network models, successfully replicating real-world family structures. Our findings showcase how local edge-formation mechanisms are intrinsically tied to large-scale structures in family networks and lay the groundwork for incorporating such structures when investigating phenomena that unfold on family networks such as socioeconomic and health inequalities.","Lasse Mohr, Sune Lehmann, Andreas Bjerre-Nielsen",Atrium,Posters I,68,,687
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Perinatal Risk Factors of Postpartum Depression: a Text Mining Systematic Review,"Perinatal Risk Factors of Postpartum Depression: a Text Mining Systematic Review Keywords: postpartum depression, risk factors, network analysis, text mining, natural language processing Extended Abstract Introduction Postpartum depression (PPD) is a significant mental health condition that affects mothers and their children, with implications for maternal well-being, infant development, and family dynamics (Slomian et al., 2019). Prevalence rates vary across countries, typically ranging between 12-15%, making it one of the most common mental health disorders among postpartum women (Liu et al., 2022). The condition is generally defined as a major depressive episode occurring within one year after childbirth, characterized by for example persistent sadness, fatigue and feelings of inadequacy (Wisner et al., 2013). Over the years, extensive research has been conducted to identify risk factors associated with PPD, leading to numerous literature reviews focusing on biological, psychological, and social factors (Zhao et al., 2020). While these reviews have provided useful insights into significant risk factors, less is known about how risk factors from different domains interact in predicting PPD. Do risk factors from a single domain (e.g., medical, psychological, or social) independently contribute to PPD, or is it the combination of factors across domains that increases vulnerability? Given that researchers often focus on variables within their own field of expertise, it is possible that existing studies primarily examine risk factors within a single domain rather than considering their combined effects (Yim et al., 2015). A systematic analysis of the variety of variables studied in relation to PPD is lacking. This review aims to address that gap by mapping out the variables that have been examined in existing studies on PPD. By identifying which factors have received more attention and which remain unexplored, this analysis will provide a clearer picture of the research focus to date, highlight potential biases, and suggest future directions for more in-depth investigations into PPD risk factors. Methods Search Strategy A literature search was conducted in the PubMed database on January 9, 2025. The following search string was used: ((((prenatal) OR (perinatal) OR (gestational)) AND ((risk factors) OR (predictors)) AND ((postnatal depression) OR (postpartum depression) OR (PPD) OR (PND))) NOT (review)) NOT (meta). This search resulted in 3,606 articles on the day of retrieval. Screening For article screening, we will use ASReview (van der Schoot et al., 2021), an open-source tool designed to improve the efficiency of systematic reviews through active learning. ASReview uses machine learning algorithms and researcher feedback to rank articles, ensuring that the most relevant studies appear first, thereby reducing the time required for title and abstract screening. Articles were included if they studied perinatal risk factors of postpartum depression and were written in the English language. Duplicates were removed by using the ÒdedupÓ function by ASreview. The function identified duplicates based on DOI match and title similarity (n=3). The default settings for the ASReview algorithm will be used. Analysis For each included article, we will extract the full text and apply natural language processing (NLP) techniques to automatically identify the risk factors studied in each paper. The extracted risk factors will be structured into a matrix, allowing for an analysis of how different factors have been examined in relation to postpartum depression. Using this matrix, we will construct a network visualization to illustrate relationships between risk factors, highlighting which factors are frequently studied together and where gaps in research exist. This approach will provide insights into common research patterns, potential biases in study focus, and underexplored risk factors. Results and Discussion The data analysis is currently ongoing, and we are in the preliminary stages of extracting and evaluating the studied risk factors. At this stage, we do not yet have finalized results that we are ready to share. However, the final findings, including a network visualization of co-studied risk factors and their respective domains, will be presented at the conference. References See attached PDF","Lisette Sibbald, Inga Schwabe, Marion I. van den Heuvel",Atrium,Posters I,69,,175
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Understanding the Engagement and Interaction of Superusers and Regular Users in UK Respiratory Online Health Communities: Deep Learning-Based Sentiment Analysis,"Online Health Communities (OHCs) enable people with long-term conditions to exchange peer self-management experiential information, advice and support. Highly active “superusers” are essential in fostering community interaction and effective information exchange. This study examines the sentiment distribution and dynamics in posts from two UK respiratory OHCs, focusing on interactions between regular users and superusers. Sentiment analysis was conducted with a fine-tuned BioBERT model on anonymized data from Asthma UK (AUK) and the British Lung Foundation (BLF). BioBERT was fine-tuned using the COVID-19 Twitter Dataset to categorize sentiment as positive, neutral, or negative. Superusers were defined as the top 1% most active users and via VoteRank (users with the greatest spreading ability). The sentiment of regular users’ and superusers’ aggregated posts was then calculated and analysed. Posts in the two communities were predominantly positive, with a trend toward increasing positivity over time. Superusers generally wrote shorter, more positive posts and superusers defined by posting activity or VoteRank largely overlapped, showing that users who posted the most were also spreaders. Threads initiated by superusers typically encouraged regular users to reply with positive sentiment. When replying to threads started by regular users with different sentiment, superusers tended to be significantly and consistently more positive than regular users. Network and Sentiment Analysis highlighted the essential role of superusers in respiratory OHCs. They not only generate consistently positive posts but also stimulate similarly positive responses from regular users, thereby sustaining a supportive online environment.","Xiancheng LI, Emanuela Vaghi, Gabriella Pasi, Anna De Simoni, Marco Viviani",Atrium,Posters I,70,,67
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Mapping temporal changes of the American academic workforce through college course catalogs,"Over the past century, the composition of faculty and researchers who teach classes at universities have substantially changed, shaped by external interventions and cultural changes. Detailed temporal data on the faculty of the past would allow the scale of future changes to the American university system to be quantitatively contextualized against the history of higher education, as well as resolve major competing hypotheses about its evolution. In this paper we revisit archives of course catalogs using current technologies (deep-learning-based optical character recognition, natural language processing, and large language models); produce and share detailed data on the history of gender in workforce at American universities; and test the consistency of our data with several explanations from the literature. We find a pronounced fall-then-rise temporal pattern in womenÕs faculty representation across U.S. universities over the 20th century, but with marked variation across academic disciplines, underscoring the complex interplay between institutional practices and evolving gender norms in academia.","Aviral Chawla, Jonathan St-Onge, Laurent Hébert-Dufresne, Juniper L Lovato, Sam Zhang",Atrium,Posters I,71,,453
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Internationally mobile researchers contribute to scientific production far beyond their share in the population,"Scientists move internationally in search of opportunities, because of push factors in the origin countries, for family-related, personal, or many other reasons. Independently of what prompts international relocations of researchers, mobility, or lack of it, has macro-level implications for scientific production that are often not fully visible because they are difficult to measure. We analyzed bibliometric data on 28+ million publications, indexed by Scopus, and written by 8+ million scholars between 1996 and 2021, to quantify the contribution to the scientific production by internationally mobile scholars, on a global scale, by country, gender, and research field. Across countries, disciplines, and genders, internationally mobile scholars consistently contribute significantly more to publications than their share of the population of scientists would imply. Smaller countries show a distinct pattern of hosting a bigger share of scholars with international mobility experience who are highly productive, in some cases contributing to up to 80\% of publications. The results have implications for migration studies, by highlighting the extent of the contribution of mobile scholars to science in host countries, and for the science of science, by highlighting that mobility could be considered in research evaluation exercises.","Aliakbar Akbaritabar, Andres CASTRO, Emilio Zagheni",Atrium,Posters I,72,,243
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Does the use of unusual combinations of datasets contribute to greater scientific impact?,"Scientific datasets play a crucial role in contemporary data-driven research, as they allow for the progress of science by facilitating the discovery of new patterns and phenomena. This mounting demand for empirical research raises important questions on how strategic data utilization in research projects can stimulate scientific advancement. In this study, we examine the hypothesis inspired by the recombination theory, which suggests that innovative combinations of existing knowledge, including the use of unusual combinations of datasets, can lead to high-impact discoveries. Focusing on social science, we investigate the scientific outcomes of such atypical data combinations in more than 30,000 publications that leverage over 5,000 datasets curated within one of the largest social science databases, Inter-university Consortium for Political and Social Research. This study offers four important insights. First, combining datasets, particularly those infrequently paired, significantly contributes to both scientific and broader impacts (e.g., dissemination to the general public). Second, infrequently paired datasets maintain a strong association with citation even after controlling for the atypicality of dataset topics. In contrast, the atypicality of dataset topics has a much smaller positive impact on citation counts. Third, smaller and less experienced research teams tend to use atypical combinations of datasets in research more frequently than their larger and more experienced counterparts. Last, despite the benefits of data combination, papers that amalgamate data remain infrequent. This finding suggests that the unconventional combination of datasets is an underutilized but powerful strategy correlated with the scientific impact and broader dissemination of scientific discoveries.","Yulin Yu, Daniel Romero",Atrium,Posters I,73,,391
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Bridging Predictions and Interventions in High Impact Data-Driven College Advising,"As algorithm-assisted decisions become more prevalent in high-stakes domains, including higher education, there is growing interest in assessing these systems and their impacts on downstream outcomes. Standard machine learning evaluations benchmark performance of predictions against a hold-out dataset. However, there is a gap between the accuracy of a model predicting student outcomes, and the effectiveness of the interventions these predictions support, which is best studied using the tools of modern causal inference. Our study leverages a unique opportunity to fill this gap by combining rich quantitative and qualitative data from a landmark randomized controlled trial of an algorithm-assisted advising program at Georgia State University. Using this data, we explore the evidence for advisor discretion in algorithm-assisted advising, its role in the advising process, and impact on student outcomes. By extending a causal framework originally designed to study discretion in narrower, purely predictive algorithm-assisted decision-making contexts, we offer a causal definition of advisor expertise in terms of advisorsÕ use of ÒnonalgorithmicÓ information to target interventions to students. We perform a statistical test on a necessary condition of such expertise, which identifies multiple interventions as potentially targeted using nonalgorithmic information, and complement this finding with qualitative evidence demonstrating the use of nonalgorithmic information to target interventions in free-form comments advisors take about meetings. Our findings suggest that decision-support systems for college advising should be designed to complement and support such human expertise, rather than producing predictions of student outcomes alone.","Sofiia Druchyna, Kara Schechtman, Hannah Li, Lydia T. Liu",Atrium,Posters I,74,,639
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,How generative artificial intelligence is changing master’s theses,"The rise of generative artificial intelligence (AI) has significantly impacted various domains, including higher education. This study examines how the widespread accessibility of ChatGPT has influenced the language and content of master’s theses at Copenhagen Business School (CBS). By analyzing 2,405 English-language theses submitted between 2018 and 2024, we examine linguistic trends before and after ChatGPT’s release in November 2022. Our findings indicate an increased usage of words commonly associated with ChatGPT-generated text, a rise in semantic similarity among theses, and an increase in lexical diversity. While increased lexical diversity suggests greater vocabulary richness, the simultaneous decline in semantic diversity suggests that theses might be becoming increasingly verbose but substantively shallower. Our findings highlight the need for policies governing the ethical use of generative AI in education to preserve cognitive diversity among students.","Jason Burton, Ezequiel Lopez-Lopez",Atrium,Posters I,75,,803
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Repurposing datasets fuels breakthrough research,"Datasets are critical in AI research, as they are essential for training, evaluating, and developing new AI models. The growing demand for AI research prompts questions about how strategic data use can propel scientific advancements. In this study, We utilize two theoretical frameworksÑrecombinational novelty and transformational creativityÑto evaluate creative data usage strategies, particularly data repurposing, which extends the application of datasets to research topics different from their previous use. We explore the scientific outcomes of repurposing data across more than 10,000 papers in machine learning domains. This study reveals two key insights: first, repurposing datasets can potentially lead to significant disruption in publication trends. However, it often results in a short-term citation penalty. Second, papers that repurpose datasets typically do not get adopted widely. Nonetheless, those that do are positively associated with disruption, albeit with a smaller effect size compared to mere repurposing. These findings indicate that data repurposing is a potent tool for shifting scientific directions. While researchers may hesitate to pivot, successful shifts might require substantial team efforts and institutional impact.","Yulin Yu, Yong-Yeol Ahn, Daniel Romero",Atrium,Posters I,76,,675
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,The Dual Impact of AI Use Disclosure: Harm for Creators vs. Gains for Non-Creative Freelancers,"Data across two primary freelance platforms (Upwork and B_hance) suggest labeling their work as created with AI negatively impacts creators, but highlighting their AI proficiency brings competitive edges to non-creative freelancers in the two online labor markets. Our analyses show the following patterns across the two platforms: (1) AI creators are smaller, less popular freelancers in these online labor markets. (2) AI creators earned less per project compared to those who did not declare any usage of AI tools. (3) Non-creative professionals show competitive edges in declaring AI professionals in the online freelance market. (4) Among creators who provide both AI-based and non-AI-based creative services, they charge the same for the two types of work.","Angel Hsing-Chi Hwang, Yao-Yuan Yang",Atrium,Posters I,77,,497
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Effect of Promotional Language in Academic Papers,"This study investigates the impact of promotional language on paper acceptance rates. Using submissions from a top Computer Science conference and a leading medical journal, we assess whether promotional wording influences reviewer perceptions. Our findings indicate a significant positive correlation, prompting further discussion on its role in academic publishing and the need for balanced peer review policies.","Shingho Hank Yu, Huilian Sophie Qiu, Brian Uzzi",Atrium,Posters I,78,,976
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Quantifying Interdisciplinarity of STEM Curricula Using National Census Data of Higher Education,"The rapid evolution of contemporary society, propelled by advancements in science, technology, and industry, demands interdisciplinary education frameworks to tackle complex societal challenges. To address this growing need, we present a principled, data-driven approach to quantify and design interdisciplinary science, technology, engineering, and mathematics (STEM) curricula for higher education institutions. Our approach begins with the development of natural language processing methods tailored for scientific Korean texts, utilizing a national census of higher education collected by the Korean Ministry of Education. By integrating pedagogical principles and information-theoretic frameworks, we establish a robust methodology for interdisciplinary curriculum design. Through these datasets, we transform 126,437 raw course descriptions into 24,476 standardized course units using the Gemini-1.5 large language model. This model tokenizes course descriptions and identifies semantic identities within scientific and technical natural language. Subsequently, we employ higher-order clustering methods to analyze the resulting semantic representations, capturing complex relationships and patterns across curriculum structures. With the standardized data, we construct a department similarity network (DSN) to represent curricular similarities among departments and explore their hierarchical community structures across various resolutions. At the low resolution, the DSN analysis reveals three primary communities: (1) molecular, life science, and related engineering (MLSE) such as chemistry, biology, and chemical engineering, (2) technical systems engineering (TSE) such as architectural engineering, and (3) pattern science and related engineering (PSE) such as physics, mathematics, and software engineering. Each community reflects distinct curricular focuses. As the resolution parameter varies, we observe community reorganization, with intrinsically interdisciplinary departments, such as the Department of Scientific Computing, transitioning across communities of different disciplines. Furthermore, we project the departments-courses bipartite network onto courses, creating a knowledge map of STEM education. This map acts as a foundational resource for designing single-discipline STEM curricula and exploring potential integrated STEM curricula. To systematically evaluate these interdisciplinary combinations, we introduce the curriculum synergy score (CSS), a novel metric quantifying the potential synergy of integrated disciplinesÕ curricula. The CSS combines two critical aspects: (1) the information-theoretic distance between bottom-up double-major models and top-down integrated majors, and (2) the similarity between disciplines derived from standardized curriculum data. By integrating these components, the CSS measures the co-learning effectiveness of two fields, balancing innovative integration with disciplinary coherence. Our analysis demonstrates that the CSS effectively identifies interdisciplinary opportunities that meet both theoretical requirements and practical educational considerations. This research provides a solid theoretical foundation for shaping rapidly evolving STEM education policies and offers practical solutions for real-world implementation in educational environments. By leveraging national census data and empirically derived educational insights, we bridge the gap between theory and practice, enabling interdisciplinary programs that address current and future educational demands. This data-driven framework supports innovative curriculum design and empowers policymakers and educators with evidence-based tools to foster interdisciplinary synergies, aligning educational objectives with emerging scientific and industrial needs.","Gahyoun Gim, Jinhyuk Yun, Sang Hoon Lee",Atrium,Posters I,79,,52
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Ensuring Data Quality and Open Science Practices in the (Computational) Social Sciences: A Survey of Researchers,"The quality and the open availability of digital research objects are crucial for good scientific practice. Open science and what is commonly referred to as data quality are two perspectives on the quality of a research process: one internal and one external. Internal data quality measures how well inherent characteristics of the data are in accordance with the needs or expectations researchers have towards the data (Tilly et al. 2017). Quality frameworks for various kinds of data disentangle possible sources of error throughout the research process (e.g., Groves and Lyberg 2010 for survey data, Amaya et al. 2020 for big data, Sen et al. 2021 for platform data). Open Science on the other hand stands for sharing of digital research objects and output with others. It can be described by the FAIR digital principles: findability, accessibility, interoperability and reusability (Wilkinson et al. 2016). At present, both depend a lot on the knowledge of individual researchers about open science practices, data quality measures and the time resources researchers are willing to allocate to this. But how much do social scientists engage in open science measures and improvement of data and code quality before sharing digital research objects? What hinders them and where do they see needs for improvement? The present study presents a survey of researchers' experiences, abilities, practices, concerns and wishes in ensuring reproducibility and quality. The surveyed individuals (N = 207) were recruited non-probabilistically via the {omitted for review} target group survey, CSS related mailing lists and at 4 conferences. The study contributes to mapping the status quo of open science and data quality standards in the computational social sciences and outlines current challenges perceived by researchers and notions on what could help them to overcome these challenges. The first part of the survey handled the findability, accessibility, interoperability and reusability of digital research objects. We find that many researchers already engage in state of the art code sharing practices: 42% of the surveyed individuals have shared code on platforms like OSF or Github. At the same time, the second most reported way to share code, via e-mail upon request (36%), is among the practices that is rated the least useful by the respondents. Cadwallader and Hrynaszkiewicz (2022) conducted a survey among computational biologists and found an even stronger preference for code being shared via repositories like GitHub. But why do scientists not share code and data? We asked researchers about the biggest challenges they see regarding code and data sharing: in case of data sharing mostly external factors were named, which researchers see themselves incapable to change. Most reasons were related to legal and ethical barriers like data protection. Regarding code sharing most replies were related to the time needed to prepare the code for sharing and ensuing operability on different devices combined with complaints about the academics system not valuing these efforts. The survey by Cadwallader and Hrynaszkiewicz (2022) suggests that more than 50% of the surveyed researchers in their study spend minimum a day on improving code to share it with others. Time that might be allocated differently if individuals feel that their work is not appreciated or it does not help their career. Further, we surveyed the researchers about how they ensure the internal quality of data and code before sharing. The most common measure to improve the quality of code is to add descriptions (>50%). The respondents reported less experience with measures to ensure the interoperability of their code like testing it with simulated data (13%), testing it on edge cases (5%) or implementing it in executable capsules (5%), a practice that can make research processes more transparent without sharing access to the raw data. The shares of those who have taken multiple measures to ensure internal quality before sharing data is much higher. A possible explanation is that fewer people share data and that shared data products are more often a product created by experienced teams that combine their efforts in ensuring data quality. Further, we surveyed researchers about their wishes and needs to enable them to engage (more) in open science and quality improvements and line out differences between sociologists, political scientists and computer scientists. We conclude that the awareness for the importance of reproducibility of research outcomes and the quality of data used is present in the social sciences. Whereas many researchers seem to see themselves incapable to share data (more often), due to data protection and legal matters, individuals see much more agency in their own hands when it comes to improving the quality and shareability of code. The CSS community can enable researchers in and beyond the community to improve quality and open science by providing methods and tools.",Judith Gilsbach,Atrium,Posters I,80,,39
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,A Global and Cross Disciplinary Description of the Use of Artificial Intelligence in Scientific Research - 1995 To 2023,"The rapid development of Artificial Intelligence (AI) has raised critical questions regarding its influence on scientific research. AI technologies, particularly Machine Learning (ML), have become widely used as research tools, yet the extent of their integration across disciplines remains insufficiently studied. This study presents a large-scale analysis of AIÕs penetration in research by classifying over 77 million articles from the OpenAlex collection (1995Ð2023) to identify those employing ML methods. We examine (i) temporal trends, (ii) disciplinary differences, and (iii) geographical patterns to assess AIÕs influence on global research practices. Our results underscore AIÕs transformative potential across scientific fields, suggesting paradigm shifts in knowledge production. While AI adoption follows a generally upward trajectory, regional and disciplinary variations indicate complex interactions with existing research traditions and infrastructures. Future studies should investigate the drivers behind these trends and their implications for the global scientific ecosystem.","Andres CASTRO, Joan Giner-Miguelez, Merce Crosas",Atrium,Posters I,81,,618
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,"CMap: Mapping Job Titles, Sector Specialization, and Promotions across 24 Sectors","Understanding job titles, career trajectories, and promotions is essential for analyzing labor market dynamics and professional mobility. We present Career Map (CMap), a novel dataset spanning 24 industry sectors, systematically structured to study job specialization, sector concentration, and career advancements. Using advanced natural language processing techniques and large language models, we standardize 6.2 million job titles into over 155,000 unique titles and introduce a Specialization Index to quantify how specialized a title is within its sector. The dataset includes both a structured job titles dataset and a set of identified promotions - 77,000 validated promotions from the United States and the United Kingdom, and 189,000 inferred promotions from a global context. It enables research on job hierarchies, workforce mobility, and systemic inequalities in professional advancement. By providing insights into career progression patterns, labor market structures, and the impact of education and experience, this dataset serves as a valuable resource for economists, sociologists, and computational researchers studying employment trends across industries and regions.","Shehryar Subhani, Shahan Ali Memon, Bedoor AlShebli",Atrium,Posters I,82,,293
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,The dynamics of leadership and success in software development teams,"From science to industry, teamwork plays a crucial role in knowledge production and innovation. Most studies consider teams as static groups of individuals, thereby failing to capture how the micro-dynamics of collaborative processes and organizational changes determine team success. Here, we leverage fine-grained temporal data on software development teams from three software ecosystems -- Rust, JavaScript, and Python -- to gain insights into the dynamics of online collaborative projects. Our analysis reveals an uneven workload distribution in teams, with stronger heterogeneity correlated with higher success, and the early emergence of a lead developer carrying out the majority of work. Moreover, we find that a sizeable fraction of projects experience a change of lead developer, with such a transition being more likely in projects led by inexperienced users. Finally, we show that leadership change is associated with faster success growth. Our work contributes to a deeper understanding of the link between team evolution and success in collaborative processes.","Lorenzo Betti, Luca Gallo, Johannes Wachs, Federico Battiston",Atrium,Posters I,83,,341
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Predicting Foreign Policy Decisions: Network Analysis of Cold War Leader-Advisor Interactions,"Foreign policy decision-making is often perceived as the outcome of a leader’s preferences and priorities. However, this perspective overlooks the intricate interactions that underpin the decision-making process, particularly in group contexts. To address this gap, we employ network analysis to examine how leader-advisor interactions influence foreign policy outcomes. By leveraging advanced data mining techniques and large language models (LLMs), we present an innovative framework for extracting and analyzing leader-advisor dynamics. Using Graph Neural Networks (GNNs), we predict conflictual policy outcomes with an F1 score of 86.96%, consistently outperforming the baseline Random Forest model’s 84.99%. Another experiment relying solely on graph structure and node attribute features achieved an F1 score of 85.66%, circumventing the heavy reliance on individual-level data in previous research, and showcasing the predictive power of the interaction network.",Tianyi Zhang,Atrium,Posters I,84,,935
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Social circles shape perceptions of ethnic minorities,"Cross-national studies show that people often overestimate the size of ethnic minority groups. This study examines two key determinants: social circle composition and news consumption, analyzing how these factors shape misperceptions across different geographical scales. We surveyed 924 U.S. residents, collecting estimates of racial group prevalence at five levels (neighborhoods, city, state, national), alongside data on social ties, media consumption, and demographic attributes. Comparing estimates to census data, we classify responses as overestimations, underestimations, or accurate. Findings confirm that White respondents tend to underestimate the White populationÕs prevalence while overestimating the Black populationÕs size, particularly at broader geographical scales. Overestimation of the Black and Asian populations increases with geographical scale, while for White respondents estimating their own group, the trend is reveresed. Social circles play a key role: respondents with ties to a group tend to overestimate its size, while those without ties provide more accurate estimates. However, this effect weakens at city and state levels, suggesting additional mechanisms at play. In the next steps of this work, we will explore the role of media consumption, analyzing how the narrative of different news sources influence these misperceptions, particularly comparing the effects of social media versus mainstream media. Understanding these biases is crucial for addressing their impact on social cohesion and integration of minority groups.","Clara Eminente, Elisa Omodei, Mirta Galesic, Ljubica Nedelkoska, Henrik Olsson, Rafael Prieto-Curiel",Atrium,Posters I,85,,181
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Geographical mobility and cohesion of personal networks over the lifecourse of an entire population,"Changing technology fosters higher levels of human mobility creating both new connections between faraway places and rearranging the spatial structure of already existing connections. Both mechanisms and their impact on network topology are little understood in the literature, partly due to lack of data to systematically follow the spatio-temporal evolution of an entire population’s social network structure. In this work, we address this gap by leveraging a unique longitudinal population-scale network dataset sourced from Statistics Netherlands. This network contains family, work, school, household, and next-door neighbor connections derived from administrative registers, that together constitute a multilayer social opportunity structure for all residents of the Netherlands between 2009 and 2022. We follow the patterns of individuals’ ego networks over time, and measure their size, closure, and geographical dispersion. Size is captured by degree, and closure by a multilayer-version of clustering coefficient called excess closure [1]. Geographical dispersion is given by the average distance from network neighbors, and the average share of network neighbors in the same municipality as the ego. First, we show that while the average size of ego networks stays stable over the observed period, average closure drops by as much as 10%, leading to more open local network structures. Second, we see that the average geographical distance from network neighbors grows, and in parallel, the average share of network neighbors in the same municipality decreases. Third, we link the two using multivariate difference-in-difference type regressions which show that the observed decrease in the closure is indeed significantly linked to the growing geographic dispersion, while controlling for demographic and socio-economic factors (age, migrant generation, income, school and workforce participation). The regressions thus confirm that beyond degree and demographics, variables that capture people’s mobility are linked to more open ego networks, which potentially impacts on people’s access to information, or the level of trust in communities. This work is among the first ones that aims to map the temporal network of an entire population structure comprehensively [2]. As such, it offers a starting point for a wide variety of impactful network science research at the level of a complete population.","Eszter Bokanyi, Yuliia Kazmina, Frank W. Takes, Eelke Heemskerk",Atrium,Posters I,86,,640
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Software Complexity of Nations,"he study of economic complexity has predominantly relied on administrative records, such as trade data, patent filings, and employment statistics, that while valuable, struggle to capture the importance of the digital economy. This “blind spot” is important because software capabilities—which are human capital intensive—represent a potentially more mobile and transmissible source of economic complexity that could be key for policy efforts focused on increasing the complexity of economies. Yet, despite this evident need, we currently lack internationally comparable estimates of economic complexity for the software sector that can help us understand the capabilities implicit in the production of software and its dynamics.","Sandor Juhasz, Johannes Wachs, Jermain Kaminski, Cesar A Hidalgo",Atrium,Posters I,87,,580
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Technical Integration in the Study of Regional Youth Cultures: A Bibliometric and AI Approach,"In the context of rapid globalization, both material and spiritual environments have grown increasingly complex and dynamic. Youth culture, encompassing both material and ideological dimensions, naturally responds to the profound transformations brought about by globalization. This article adopts the definition proposed by Ai (2006), which categorises the current world cultural landscape into five major regions: European and American cultural regions, the Chinese cultural region, Eastern European cultural regions, Indian cultural regions, and Arab cultural regions. The study seeks to uncover the commonalities and uniqueness of regional youth cultures by examining their similarities and differences, and to analyse their developmental trajectories through a comparative study of academic literature across these cultural regions. Additionally, it reflects on the logic underpinning the construction of regional youth cultures and identifies the key elements that should be prioritised in social work interventions. This study employs a systematic approach to explore the developmental trajectory of youth culture across diverse cultural regions. A total of 12,381 papers were retrieved from the Web of Science (WOS) database using keywords associated with ""youth culture"". These papers were subsequently categorised into respective cultural regions utilising the DouBao1.5Pro API interface. Latent themes within each cultural region were then identified through BerTopic, enabling an examination of both the commonalities and unique aspects of youth culture in terms of similarities and differences. Finally, bursts were analyzed in CiteSpace and cross-verified with the thematic results to investigate the developmental dynamics of youth culture across different cultural regions. We utilized DouBao1.5Pro to categorize and partition 12,381 articles, and randomly selected 100 for manual verification, achieving an accuracy rate exceeding 97%. The majority of the articles were from European and American cultural regions (74.5%), followed by China (15.9%), the Arab world (6.4%), Eastern Europe (5.4%), and India (3.5%). Following the guidance of Zhu (2023), after comprehensively considering the mutual evaluation of clustering effects and the number of documents, we set a maximum of 120 clusters for the European and American cultural regions, a minimum of 15 clusters for the Indian cultural region, and 30 clusters for the remaining regions. Out of the 47 topic clusters identified in BerTopic, seven themes resonated across all cultural regions: sex and gender, bullying, parent-child relationships, immigration and cultural integration, body image and health, psychological problems, and identity recognition. Some themes exhibited regional characteristics. For instance, the European and American regions focused on risk behaviors such as substance abuse, while the Chinese cultural region emphasized the filial-piety-based paternalistic education model. Meanwhile, the Arab, Eastern European, and Indian regions respectively explored the connections between youth culture and religion, politics, and local infrastructure. The literature was analyzed in CiteSpace using 5-year time slices, identifying 176 bursts. Of these, 41.5% were strongly associated with the seven shared themes, further clarifying the research focus and evolutionary trajectory of youth culture. This study has two major limitations. First, the five cultural regions are imbalanced, with European and American regions dominating at 74.5%, likely due to WOS's English-based nature. Future studies will expand data sources, such as CNKI (China), Unified Electronic Library of Science (Russia), Indian Academy of Sciences Journals (India), and Al Manhal (Arab region). Second, the use of AI and mapping science for thematic analysis of a large volume of literature carries a degree of subjectivity. To address this, we compared five large language models and based our analysis on refined summaries, thereby balancing efficiency and accuracy. Despite these limitations, this study highlights a commonality underlying global youth culture issues: the tension between societal and individual demands. This implies that while youth may appear to be the source of problems, they are more profoundly shaped by structural contradictions stemming from era-specific, cultural, and societal transformations.","Yueran Wang, Yi Zhao, Yajun Song",Atrium,Posters I,88,,691
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,A Computational Social Science Approach to K-Beauty Patent Analysis: Focusing on Cultural Trends and Natural Cosmetics,"The global success of K-Beauty is not merely a technological phenomenon; it reflects evolving consumer values, cultural preferences, and marketing strategies that intertwine to shape innovation in the cosmetics industry. This study investigates how such socio-cultural factors manifest in the patent landscape of K-Beauty, with a particular focus on natural cosmeticsÑa domain in which consumer demand for sustainability and ethical considerations is notably high. We analyze 19,563 natural-source-related cosmetics patent abstracts sourced from KISTIÕs proprietary K-PASS database. To automatically extract and categorize keywords, we employ Bllossom 8BÑa Korean-oriented large language model (LLM) specialized for local contexts but smaller in scale compared to mainstream global LLMs. Through prompt engineering with few-shot, Chain-of-Thought reasoning, and iterated extraction, we refine the output via an ensemble-inspired technique that intersects repeated results and uses n-gram matching and frequency filtering to reduce noise. The final set of keywords is further mapped into a Maximum Spanning Tree network, partially incorporating a k-hop-like approach to emphasize the most significant connections among keywords. Our preliminary findings reveal how cultural narratives (e.g., the transition from ÒwhiteningÓ to Òanti-aging,Ó the surge in natural products) are embedded in patent-driven innovation. This evidence suggests a close coupling between consumer behaviorÑshaped by wellness trends, ethical consumption, and social media influenceÑand the technical evolution of cosmetics formulations and ingredients. From a computational social science perspective, our work demonstrates how large-scale text mining and network-based analyses of patent data can yield insights into the broader socio-cultural mechanisms that guide technological change. Despite these contributions, we acknowledge that analyzing the specialized domain of natural cosmetics with a smaller-scale LLM entails limitations such as domain-specific terminology misclassification and potential omission of subtle nuances. We anticipate that ongoing advances in language modeling, along with cross-referencing global patent databases and integrating complementary data sources (e.g., consumer reviews, social media), will help overcome these constraints. Such expansions could offer a more holistic understanding of how cultural values and market behavior converge to drive innovation in K-Beauty and beyond.","Young Jin Kim, Jungwoo Lee, Eunsoo Sohn",Atrium,Posters I,89,,671
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Biased Pagerank reduces network inequalities in homophilic and degree correlated networks,"Ranking algorithms play a significant role in ordering information in networks and identifying important and influential nodes. In this study, we investigate the fairness of the widely used PageRank algorithm in networks of nodes with binary attributes. We propose a new fairness definition rooted in demographic parity in the top-ranked positions, where the observerÕs attention is predominantly concentrated. This definition is based on the idea that a fair ranking has the same proportion of attributes in the top-ranked positions as in the whole network. To improve the fairness of rankings, we present the bias PageRank algorithm where we add an exponent that biases the random walk exploration at the core of the algorithm. This parameter changes the choice probability of the random walkers based on the degree of the neighbouring nodes. We compare the fairness of rankings for different values of the bias exponent in real-world networks. The bias PageRank algorithm can increase the fairness of the rankings for a suitable choice of the bias exponent that is influenced by the attribute and degree correlations in the networks.","Elisabetta Salvai, Jacob Aarup Dalsgaard, Giovanni Petri, Roberta Sinatra",Atrium,Posters I,90,,544
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,A Proposal of a Higher-Order Temporal Network Approach to Learning Analytics,"In recent years, it has become increasingly clear in fields such as complex network science that human social activities are supported not only by pairwise relationships but also by 'higher-order interactions' involving multiple members. The frameworks of Higher-Order Networks and Hypergraphs have garnered attention as approaches to analyze these 'higher-order interactions' within complex systems. In this study, we propose a novel approach for learning analytics: the Higher-Order Temporal Network framework, which enables the capture of learning as a function of higher-order interactions and time. Specifically, we present empirical results using open data and introduce a Higher-Order Temporal Network analysis method based on topological data analysis.",KoichiY,Atrium,Posters I,91,,684
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Modeling trade-offs in multiplex networks,"Multiplex networks extend classical networks by incorporating multiple types of relationships between nodes, each represented as a distinct layer. This multi-layered perspective provides deeper insights into complex systems. Individuals are thought to maintain only a limited number of stable relationships, with varying costs depending on the connection type (e.g., social or economic) as described by social exchange theory. These trade-offs in human behavior are mirrored in multiplexity. For modeling trade-offs, archetypal analysis, a clustering method that identifies idealized extremes or pure forms within a dataset called archetypes, has been used to model evolutionary trade-offs in biological datasets. In this study, we aim on modeling trade-offs and uncovering archetypal structures in multiplex networks with layers representing core aspects of human behavior, such as the forming of social, health, and economic relationships. We introduce the Multiplex Archetypal Trade-Off model (MArch-TO), which projects a multiplex network onto the $(L-1)$-Simplex $\Delta_{L-1}$, where $L$ is the number of layers. In order for our model to successfully capture trade-offs across layers, in our design we enforce that high node activity in a specific layer pushes the node toward the corresponding corner of the $(L-1)$-Simplex, representing the layerÕs archetype. Furthermore, to successfully characterize layer-specific structures existing in each layer of the multiplex network we introduce a second level of projections onto an $(D-1)$-Simplex $\Delta_{D-1}$. Such a projection, enables layer-specific retrieval and characterization of $D$ community structures. Finally, we validate the effectiveness of our model on several real-world multiplex networks showcasing that our model effectively characterizes trade-offs and extracts meaningful local structures.","Nikolaos Nakis, Sune Lehmann, Nicholas Christakis, Morten Mørup",Atrium,Posters I,92,,112
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Semantic Similarity Networks and Explorable Hierarchical Topic Modeling in Large-Scale Cross-Platform Online Discourses Based on Community Detection,"In times of a so-called poly-crisis, i.e., the current culmination of several global crisis developments at once, such as climate change, pandemics, and conflicts affecting the post-cold-war balance of powers, it seems a daunting task to gain an overview of the relevant parts of the greater public discourse. Within this poly-crisis, superficially unrelated discourses influence and overlap each other on multiple levels of scopes, from hyperlocal to global, and on various timescales, from days to decades. Therefore, when investigating discourses related to large-scope and long-term topics, such as climate change or the Russian invasion of Ukraine, this endeavour necessitates approaches that can simplify the inherent complexity of these topics at a top-level while allowing data analysts to choose where to dig deeper. For this endeavor, not only the interactive explorability of topic relations and sub-topic structures is key, but ever-changing topics and crises necessitate the introduction of time as a topic-defining parameter. To our knowledge, both are not provided either by standard methods like Latent Dirichlet Allocation (Blei, 2003) or by state-of-the-art topic detection methods such as BERTopic (Grootendorst, 2022). Therefore, we propose an alternative combination of methods, leaning on the embedding-clustering sequence of BERTopic, but based on semantic similarity networks, augmented with a time-component, and tried-and-tested network-based community detection methods that allow for hierarchical clustering of these networks. In this contribution we describe our method and its validation across two test cases: 1) the German-language cross-platform discourse around climate change on Facebook, Instagram, Twitter, and Telegram from 2019 to 2023 and, 2) Twitter postings of German politicians. The methods is described as follow: after dividing longer posts from platforms into paragraphs in order to achieve comparable items across platforms we process the corpus in 6 steps (see Figure 1): - Encoding (1): We embed the paragraphs/posts within a semantic space with the help of Sentence-BERT (sBERT) (Reimers & Gurevych, 2019) models, after preprocessing them, e.g. to remove tokens that the semantic model of sBERT is unduly sensitive for (URLs, mentions, platform-specific tokens). - Temporal chunking (2): In order to calculate cosine similarities in an efficient way, we introduce a parameter _t, which defines a sensible creation time window within which items can be compared in a meaningful way (validated depending on the topic). In order to keep memory requirements low, we then compare items within the same time window in chunks of a fixed number of items to each other. - Network creation (3) and pruning (4): After human validation of a threshold for the cosine similarity metric, we build a directed similarity network of posts and edges meeting this threshold (without self-loops), including similarity and temporal distance as weights, and the temporal sequence as direction of the edges. - Community detection (5): While we have considered and tested several network community detection methods, we consider infomap (Rosvall et al., 2009) the best choice known to us, as it solves Ð with the minimization of the entropy (or description length) of random walks through the network and it allows for hierarchical clustering (Rosvall & Bergstrom, 2011) avoiding resolution problems of other popular algorithms. - Centrality measurement (6): In order to retrieve posts as representative as possible for each cluster, we use rankings based on centrality metrics such as PageRank (Brin & Page, 1998) and k-coreness as a proxy for representativeness. However, these metricsÕ fit for measuring representativity within our similarity network still requires operationalisation of the concept, benchmarking and human validation at the time of writing. Analysis of the case studies shows promising results. In case study 1, while we see, overall, a satisfyingly even distribution of cluster sizes within levels and of platforms across clusters . On the lowest hierarchy level, our method reveals temporally distinct topics or events, such as the global Ôclimate strikesÕ by the Fridays for Future movement in September 2019 and 2021 (highest peaks in Figure 3). In order to benchmark and validate our method against existing and state of the art methods, we used the second case study to compare results of these different text clustering and topic modelling techniques with agglomerative clusters in hashtag co-occurrence networks as ground truth. As table 1 shows, the overall performance of our method is equal or better performing than SOTA methods, like Bertopic, in the albeit limited test cases.","Philipp Kessling, Felix Victor Münch, Mattes Ruckdeschel, Gregor Wiedemann",Atrium,Posters I,93,,953
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Country-wide bicycle network analysis and planning with the human in the loop,"We analyze the bicycle network of Denmark using a mix of OpenStreetMap and administrative infrastructure data, covering around 43000 km2 and nearly 6 mio.~inhabitants. We divide the network into four levels of traffic stress and quantify the spatial patterns of bikeability based on network density, fragmentation, and reach. We find that the country has a high share of low-stress infrastructure, but with a very uneven distribution. The widespread fragmentation of low-stress infrastructure results in low mobility for cyclists who do not tolerate high traffic stress. Bikeability clusters show that both high and low bikeability are strongly spatially clustered. The latent potential for cycling in rural areas is mostly unmet, although some rural areas benefit from previous infrastructure investments. Further, we analyze Denmark's recreational bicycle node network, and create an open-source software tool for its planning. Taking the perspective of a recreational cyclist starting at any fixed point in the network, we create a loop census that lists all loops in the network up to day-trip length. Analyzing this loop census identifies for different demographics the navigability of the local network, informing both planners and different users on the usability, and the strengths and weaknesses of the bicycle node network.","Ane Rahbek Vierø, Anastassia Vybornova, Kirsten Krogh Hansen, Michael Szell",Atrium,Posters I,94,,79
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Where do Friends Matter for Founders? The Role of Social Connections in U.S. Entrepreneurship,"How important are social connections in the decision to start a new business? We assemble a new dataset using de-identified social network data from 695,000 U.S. firm owners and 21 billion friendships on Facebook linked to data on the firms founded by users. The data demonstrate that firm owners interact disproportionately with other firm owners and that social connections to existing firm owners increase an individual's probability of starting a successful new firm. Estimates from a quasi-experimental design among new college students imply that a 1 standard deviation increase in the number of connections to firm owners increases a student's probability of founding a firm after graduation by 0.27% relative to an entrepreneurship rate of 1% in the data. Students are particularly likely to start a firm in the same narrowly-defined industry as the firm owners they are connected to, and effects are stronger when the student and the firm owner are the same gender. Using a quasi-experimental design based on the timing of moves across commuting zones, we then provide evidence that the strength of network spillovers varies over geographic areas and is positively correlated with local rates of entrepreneurship.","Michael Bailey, Robert Fluegge",Atrium,Posters I,95,,947
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Sensitivity of Large Language Model Responses to Closed-Ended Survey Questions: Evidence of Response Bias,"Researchers in the Computational Social Sciences increasingly utilize Large Language Models (LLMs) for the generation of synthetic data in survey-like setups, for example for fairness rating (Horton 2023) or in political orientation tests (Rozardo 2023). To investigate response biases in LLMs as well as their robustness, we (i) carefully construct 10 perturbations of survey questions and answer options, extending the list of perturbations used in a previous study (Tjuatja et al. 2024). We (ii) evaluate the response biases of state-of-the-art LLMs on a well-established questionnaire, the World Value Survey (WVS) (Haerpfer 2022). We thereby extend previous research to both LLMs that have since emerged and to a questionnaire that has not been investigated so far. The goal of our study is to identify to which extent LLMs reproduce human survey bias and to evaluate the robustness of close-ended LLM survey responses.","Jens Rupprecht, Georg Ahnert, Markus Strohmaier",Atrium,Posters I,96,,190
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,FactualRAG: A RAG-Powered Open-Source Framework for LLM Fact-Checking via IFCN Search Engines,"The rapid spread of misinformation necessitates robust fact-checking mechanisms on digital platforms. This study explores the use of Large Language Models (LLMs) for misinformation verification, implementing a Retrieval-Augmented Generation (RAG) system that queries IFCN-accredited fact-checking sources and synthesizes claim evaluations into concise, verifiable summaries. Our approach employs a multi-stage RAG pipeline, integrating a local cache to reduce redundant queries and improve efficiency. If no cached results exist, the system retrieves real-time fact-checking data, which is then processed by an LLM-based summarizer. Unlike end-to-end LLM fact-checking, our method prioritizes evidence retrieval before response generation, mitigating hallucination risks and improving interpretability. To evaluate effectiveness, we train and test our system using AVeriTeC, Climate-Fever, and MultiFC datasets. We experiment with state-of-the-art LLMs, including LLaMA 3, Mistral, Gemma 2, Phi 4, and DeepSeek R1:8B, assessing their accuracy, efficiency, and contextual reasoning in misinformation detection. Results indicate that Gemma 2 achieves the highest accuracy on AVeriTeC (75.50%), LLaMA 3 excels in MultiFC (>92%), and DeepSeek R1:8B leads in Climate-Fever (50.00%). However, execution time analysis reveals LLaMA 3 and Mistral as the most efficient, while DeepSeek R1:8B exhibits higher latency, underscoring the trade-off between accuracy and computational efficiency. To further validate our system, we use Google Fact Check Explorer as a reference for assessing correctness. Future research should explore real-time misinformation detection, adaptive learning frameworks, and scalable RAG-based fact-checking, particularly for high-impact domains such as journalism, public policy, and social media governance.","Lien-Jung Chang, Chun-Ming Lai",Atrium,Posters I,97,,216
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,On the Responsible use of Pseudo-Random Number Generators in Applied Scientific Research,"Pseudo-random number generators (PRNGs) underpin computational methodologies across scientific disciplines. In high-profile, peer-reviewed publications in deep learning and social science, the prevalent practice of initializing PRNGs with a fixed seed conceals critical algorithmic uncertainty. Our replication studies, conducted on widely cited articles, reveal that subtle variations in PRNG instantiation can yield significantly divergent outcomes. These discrepancies are not confined to a narrow set of applications but permeate a broad spectrum of methodologiesÑfrom Monte Carlo simulations and multiple imputation to time series analysis and advanced inferential models. The evidence presented demonstrates that current seeding practices compromise reproducibility and the reliability of statistical inference, thereby casting doubt on established findings. We propose a paradigm shift in computational research: rather than suppressing variability, researchers should embrace and systematically document seed-induced uncertainty to enhance methodological transparency and rigor. Our findings challenge conventional wisdom and call for a reappraisal of experimental design in computational studies.","Charles Rahal, jiani yan, Mark Verhagen",Atrium,Posters I,98,,589
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Curiosity-Driven Partner Selection Accelerates Convention Emergence in Language Games,"In language games a speaker and a listener attempt to coordinate on a shared mapping between words and concepts. The usual approach in the literature is to study convention emergence in well-mixed populations, where pairs of agents are randomly matched to play the role of speaker and listener, respectively. This way of pairing agents can be shown to promote the emergence of a unifying common language in the long run. Despite the theoretical guarantee, convention emergence can be very slow and practically unfeasible, especially in large populations with many words and concepts. Here, we propose an alternative approach, where we allow agents to selectively partner with other agents based on their past experience. To this aim, we study Boltzmann Q-learning agents that are curiosity-driven, i.e., more likely to choose partners they misunderstood in the past. We show that this selection method significantly accelerates convention emergence when compared against a random-matching baseline and is even more pronounced in graph generation models restricting agents' communication channels. By inspecting the evolution of the agents' interaction frequency we see that partner selection induces low tree-width and high degree variance at the early stages of learning, to then converge to a regular graph, which allows for settling misunderstandings in the population at a faster rate than the traditional approaches.","Chin-wing Leung, Paolo Turrini, Ann Nowe",Atrium,Posters I,99,,134
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Trickle-Down Names: How Social Class Shapes Naming Patterns,"This paper examines the mechanisms through which social class structures cultural transmission by analyzing name-giving patterns in Chile over a century (1920-2020). First names represent a distinctive domain of cultural practice relatively unconstrained by material considerations that typically mediate class-based practices (e.g., consumption of cultural goods). This analytical focus allows us to isolate symbolic boundary-making processes from economic constraints, offering a window into how class hierarchies shape cultural preferences through social influence dynamics. Drawing on theoretical frameworks from Bourdieu's distinction mechanisms, Tarde's principles of social imitation, and Lamont's conceptualization of symbolic boundaries, we develop a comprehensive analytical strategy that captures both structural constraints and agentic processes in cultural diffusion. Our empirical approach leverages civil registry and census data to calculate socioeconomic status scores for municipalities, which we then use to develop class-based measures for names registered in these localities. Following Bail (2019), we formalize two complementary dependent variables: Sequential Primacy Count ($Y_{ijt}^{SP} = \sum_{k \in N} I(t_k^j = t) \times I(t_k^j > t_k^i)$) and First-Rank Count ($Y_{ijt}^{FR} = \sum_{k \in N} I(t_k^j = t) \times I(t_k^j > t_k^i) \times I(t_k^i = \min_{l \in C}(t_k^l))$). We employ polynomial Poisson regression models with fixed effects to analyze the non-linear relationship between status distance and cultural diffusion, capturing both homophily effects and directional status influences while controlling for geographic proximity, population differences, and temporal dynamics. Our findings reveal three systematic patterns in the social organization of naming practices. First, names exhibit clear stratification by social class, with minimal contemporary overlap between class-specific repertoires. Upper-class (Q5) naming patterns systematically diffuse downward through the social hierarchy following a cascading temporal structure: upper-middle class (Q4) adoption occurs with approximately one-decade delay, middle-class (Q3) adoption with two decades lag, while lower strata (Q1-Q2) show only partial adoption even after extended periods. This demonstrates how imitation processes operate through temporal lags that correspond to the hierarchical distance between social classes. Second, our polynomial regression models establish class homophily as the fundamental organizing principle of cultural diffusion. Diffusion rates across all temporal horizons display unimodal curves peaking when status distances approach zero ($s \approx t$), confirming homophily as the baseline mechanism. However, the asymmetric distribution of these curves reveals that diffusion occurs more readily when source municipalities have moderately higher status than target municipalities ($s > t$), but diminishes at extreme status differences ($s >> t$). This provides empirical validation for a bounded class imitation mechanism with an optimal status distance for downward transmission, while also demonstrating that cultural practices rarely diffuse upward across the class hierarchy. Third, we identify distinct boundary-maintenance strategies deployed by social classes. The upper class responds to the popularization of their names across social strata through two complementary distinction mechanisms: (1) adopting novel names from the existing repertoire that have never been factually used before, and (2) reviving historical names that have fallen out of contemporary usage. Intriguingly, the lowest socioeconomic quintile (Q1) exhibits superficially similar innovation patterns but through fundamentally different mechanismsÑadapting names from popular cultural references rather than strategically establishing distinction. These findings advance our understanding of how classification systems serve as mechanisms for the intergenerational reproduction of social hierarchies. By specifying the precise temporal lags, status distance effects, and boundary-maintenance strategies that govern cultural diffusion, we demonstrate that even seemingly unconstrained practices like name-giving are structured by class differences. The multilevel analysis of these patterns reveals how micro-level parental choices about children's names aggregate into meso-level class boundary maintenance and, ultimately, macro-level stratification persistence over generations.","Roberto Cantillan Carrasco, Mauricio Bucca, Mario Molina, Luca Maria Pesando",Atrium,Posters I,100,,910
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,What Do We Have In Common? What Does Disrespect Mean To You? Bridging Norms,"This paper presents a novel, scalable pipeline leveraging large language models (LLMs) to analyze, compare, and reconcile speech norms across online communities. Using a unique dataset of 30,000 moderated Reddit comments from 332 communities, we define two tasks: identifying shared and differing norms between communities and uncovering nuanced interpretations of the norm ""be respectful."" Our method achieves robust quantitative and qualitative results, demonstrating LLMs' ability to surface community-specific expectations. By bridging normative differences, our approach can promote cross-community understanding, guide moderation practices, and support newcomers navigating diverse online spaces in decentralized platforms.","Belén C Saldías Fuentes, Sasha Krigel, Deb Roy",Atrium,Posters I,101,,398
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Determinants of Voluntary Disclosure in Japan: A Binary Logistic Regression Analysis,"Voluntary disclosure—corporate reporting beyond legal mandates—has gained prominence due to its implications for investor trust and stakeholder relations. In Japan, where firms exercise discretion in non-financial reporting, we investigate the determinants of voluntary CSR/ESG disclosures among 5,915 listed firms over 15 years (2009–2024). Using a binomial logistic regression model, we test five hypotheses linked to financial indicators, company characteristics, listing market, industry classification, and shareholder composition. Our results indicate that firms with greater assets, higher market capitalization, and institutional investor influence are more inclined to disclose voluntarily, often to enhance legitimacy and reduce information asymmetry. Conversely, companies emphasizing competitive secrecy, high-growth entities, and firms in resource-intensive sectors exhibit lower disclosure tendencies, citing costs and strategic concerns.The study underscores the persistent tension between transparency expectations and competitive considerations in corporate disclosure strategies. Findings suggest that voluntary reporting is both a signaling mechanism and a strategic decision, influenced by financial strength, governance structures, and industry norms. While this research focuses on disclosure likelihood, future studies should explore content variations and sector-specific influences to deepen our understanding of voluntary disclosure dynamics.","Yuichiro Nakai, Mitsuo Yoshida",Atrium,Posters I,102,,213
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,"Formalizing the Study of Police Use of Force: Estimands, Data Constraints, and Policy Relevance","This paper presents a formal framework for studying police use of force by defining clear statistical estimands that address key policy questions while tackling inherent data challenges. Motivated by recent calls for evidence-based policing and the pressing need to rebuild public trust, the paper leverages modern causal inference paradigms to articulate strategies for designing rigorous studies that analyze both administrative and unstructured data sources, such as body-worn camera footage and narrative reports. By systematically addressing issues of selection bias, mismeasurement, and missing data, the framework proposes specific estimands for evaluating adherence to force policies, identifying disparate treatment, detecting officer outliers, and assessing resource allocation across neighborhoods. Ultimately, it equips social scientists with a structured approach to study police use of force in a manner that can effectively inform reform.","Greg Lanzalotto, Dean Knox, Jonathan Mummolo, Claire Kelling, Tarak Shah",Atrium,Posters I,103,,892
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Harmony in Discord: A Multimodal Exploration of Constructive Behaviors for Managing Disagreements,"Conflict is often seen as dysfunctional, yet disagreement can foster creativity and problem-solving. Using an abductive, machine-learning-driven approach, we analyze multimodal conflict expressions—linguistic, paralinguistic, and visual cues—within high-stakes negotiations lacking a Zone of Possible Agreement. We recruited 94 participants for an online negotiation exercise and extracted fine-grained behavioral data to examine how conflict dynamics unfold. A Hidden Markov Model identified four distinct negotiation stages (Opening, Testing, Trying, Deciding), revealing differences in conflict trajectories between high- and low-conflict dyads. Preliminary findings suggest that linguistic cues, turn-taking, and sentiment shifts shape conflict outcomes. By collected human annotations, we aim to refine our understanding of constructive conflict, offering insights into how individuals can express disagreement while maintaining positive relationships","Burint Bevis, Mark Kennedy, Xinlan Emily Hu, James P Houghton",Atrium,Posters I,104,,276
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Geospatiality of Topics in English Text Data,"Geolocated text data are a promising data source for spatial analyses in many fields, from disease surveillance to the spatial humanities. This study investigates the relationship between texts’ thematic categories and their likelihood of containing usable geolocation information by quantifying and modelling this relationship across seven diverse English text datasets of different types, including web forums, microblogs, news, and magazines. We find that the likelihood of geoinformation is highly variant, being high for the category ‘Travel, Tourism & Migration’ and low for ‘Private Life, Family & Relationships’. The rank-correlation of this likelihood between datasets is moderate to strong. We further find that the interaction between topic and geospatiality varies substantially for some topics if geotags are used, rather than geoparsing of mentioned locations.These findings indicate that the topic plays a significant role in determining the frequency of geospatial references within the text, and that the effect is not entirely dataset-specific. Findings of earlier studies based on geotagged Twitter data cannot be assumed to hold true for geoparsing approaches as well. This research provides valuable insights for data selection and bias mitigation in the increasing use of text as data for spatial analyses, and it contributes to the empirical study of the use of spatial language.","Johannes Mast, Christian Geiß, Hannes Taubenböck",Atrium,Posters I,105,,88
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,Simplifying Sociology: Examining the Link Between Textual Complexity and Scientific Impact,"Clear communication is crucial in scientific writing, making research accessible and understandable to a wide audience. Good writing helps ensure that studies can be replicated and trusted by other researchers. It also allows complex ideas to be explained clearly, making research easier to understand and more accessible to the public. However, anecdotal evidence from scholars and popular sociologists (Popper, 1971, see quote above) suggests that the field of sociology is often known for using an overly complicated writing style. This complexity, characterized by long, convoluted sentences and a high concentration of technical terms, can alienate readers and obscure important insights. To understand and explain the use of complex language in sociological texts, we can refer to the concepts of boundary demarcation in prestige economies (Schwemmer & Wieczorek, 2020) and signaling (Spence, 1978). On the one hand, boundary demarcation refers to behaviors aimed at excluding non-members from participating in a particular market or field, similar to a club with strict entry rules to ensure that only the best or most qualified members are admitted. On the other hand, signaling involves the use of complex language to demonstrate intelligence and membership in an exclusive group. When authors use particularly complex language, they may be signaling their membership in a prestigious academic field, thereby seeking greater recognition and, for example, more citations. This study uses advanced computational methods to investigate the (over-)complexity of sociological texts. Using data scraping techniques and bibliographic machine learning models, we extract text from PDF files (Lopez, 2009), and construct a novel dataset spanning two decades of articles published in three leading German sociological journals: Klner Zeitschrift fr Soziologie & Sozialpsychologie [KZfSS], Zeitschrift fr Soziologie [ZfSoz], and Berliner Journal fr Soziologie [Berliner] (Fig. 1). We introduce new measures of text readability by combining existing scoring methods, such as Flesch-Kincaid readability tests (Amstad, 1978; Flesch, 1948), with dictionaries of difficult terms and with measures for compound terms and nominalization density. Using these measures allows us to quantify readability for the entire corpus, over time, and across subfields such as qualitative and quantitative methodological schools (Fig. 2). While accounting for other factors that affect scientific impact, we also examine whether the number of citations received per article is associated with complexity scores (see Ante, 2022 for related analyses of other academic subfields). This aspect of our analysis aims to reveal whether complexity in sociological writing is rewarded or penalized within the academic community (Fig. 3). Furthermore, we will also present results from an ongoing validation of our complexity measures at IC2S2. Therefore, a randomly selected subset of anonymized paragraphs from our corpus will be evaluated by 1) undergraduate and graduate students as well as 2) crowdworkers. We use a structured Likert-scale questionnaire to rate aspects of complexity such as nested sentence structures, terminology density, and overall readability. The manual ratings will then be compared to our computational complexity scores for validation and refinement purposes. Finally, we will demonstrate a workflow using Large Language Models (such as GPT-4) to detect and simplify complex text passages, which scholars can easily implement to improve their scientific writing. In summary, our work provides new insights into how the complexity of sociological texts has evolved, whether readability affects scientific impact, and, challenging PopperÕs claim, we will also provide guidelines for how to do better. Our complexity measures and the simplification workflow are applicable beyond the field of sociology, and we expect our results to be of interest to the broad interdisciplinary community of IC2S2.","Carsten Schwemmer, Sebastian Block, Manuel Holz, Sandra Jaworeck",Atrium,Posters I,106,,127
2025-07-22 13:30:00,2025-07-22 14:30:00,session_presentation,"Evaluating Elements of Empathic Communication with Experts, Crowds, and Large Language Model","Empathic communication is key for navigating social situations and supporting others, yet training for this vital skill remains largely inaccessible. A major barrier to scaling such training is the need for reliable annotation and evaluation mechanisms. Recent research has explored using large language models (LLMs) and minimally trained crowd workers to annotate empathic expressions in conversations [1, 3, 5], but the reliability of these annotations relative to expert evaluation remains an open question. To address the challenge of scaling empathic communication training and ensuring reliability in annotating empathy, we ask: (1) How reliably do crowds and LLMs annotate empathic communication compared to experts? (2) How do annotations of empathic communication by experts, crowds, and LLMs compare across conversational contexts and dimensions of empathy? To address these questions, we evaluate the reliability of expert, crowd, and LLM annotations across 21 dimensions of empathy in 200 conversations from four datasets. We find relatively high reliability between experts across most features, but reliability varies with the diversity, complexity, and subjectivity of the feature. Furthermore, we find that LLMs and experts have higher inter-rater reliability than crowds and experts.","Aakriti Kumar, Fai Poungpeth, Diyi Yang, Bruce Lambert, Matthew Groh",Atrium,Posters I,107,,333
,,,,,,,,,,
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Miscalibrated trust hinders effective partner choices in human-AI collectives,"Trust, a cornerstone of human cooperation, faces unprecedented challenges as artificial intelligence (AI) agents permeate social systems, transforming mechanisms humans have evolved to build trust. We demonstrate how a prevalent feature of AI agents––being excessively prosocial––reshapes trust dynamics in experiments (N = 675) simulating hybrid societies comprising humans and AI agents (“bots”) powered by state-of-the-art large language models. Using a partner-selection game with pre-decision communication, Study 1 revealed a paradox: Undisclosed bots, despite being more trustworthy than humans and detectable by communication, were not preferentially selected. Instead, bots’ prosociality was misattributed to their human competitors. Study 2 showed that disclosing the human or bot identity of partner candidates initially enhanced humans’ bias against bots, but improved trust calibration over time. Our findings highlight the importance of evaluating AI agents in interactive hybrid environments and the role of transparency in facilitating dynamic calibration of trust in human-AI ecosystems.","Yaomin Jiang, Levin Brinkmann, Anne-Marie Nussberger, Ivan Soraperra, JF Bonnefon, Iyad Rahwan",Atrium,Posters II,1,,361
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Bayesian Modeling of Multi-Step Discussions Between LLM Agents: Disentangling Opinion Dynamics from Intrinsic Bias Effects,"Recent Large Language Models (LLMs) exhibit remarkable human-like text generation capabilities, making them a potential tool for simulating human behavior and thus studying social phenomena. For instance, complex opinion dynamics may be simulated by initializing LLM agents with different opinions on a topic and observing their opinion change throughout a discussion. However, past attempts to use LLM agents for such simulations revealed an inherent bias toward consensus and toward factual accuracy, driving agents' opinions to the consensus opinion encoded in the LLMs. Moreover, the robustness of such simulations remains uncertain due to prompt sensitivity, while the lack of standardized evaluation metrics and benchmarks further reduces the comparability across studies. In this work, we used Bayesian modeling to disentangle agent-inherent biases from interaction dynamics. Our model reveals that discussions between two LLM agents are dominated by two biases; (i) toward the LLM's prior opinion distribution for a specific topic (topic bias) and (ii) toward agreement irrespective of the prompted statement (agreement bias), whereas the initial prompting of the agent's opinion has little impact. By fitting an effective Bayesian model of opinion dynamics to the opinion shifts in LLMs, we provide a human-interpretable method that potentially simplifies the modeling of large groups of artificial agents.","Vincent Christoph Brockers, David Alexander Ehrlich, Viola Priesemann",Atrium,Posters II,2,,373
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"People who share encounters with racism are silenced online by humans and machines, but a guideline-reframing intervention holds promise","Are members of marginalized communities silenced on social media when they share personal experiences of racism? Here, we investigate the role of algorithms, human users, and platform guidelines in suppressing disclosures of racial discrimination. In a field study of actual posts from a neighborhood-based social media platform, we find that when users talk about their experiences as targets of racism, their posts are disproportionately flagged for removal as toxic by five widely used moderation algorithms from major online platforms, including the most recent large language models. We show that human users disproportionately flag these disclosures for removal as well. Next, in a follow-up experiment, we demonstrate that merely witnessing such suppression negatively influences how Black Americans view the community and their place in it. Finally, using computational linguistic tools, we identify key factors influencing flagging behavior and develop an intervention that successfully reduces misguided flagging behavior across the political spectrum.","Cinoo Lee, Kristina Gligoric, Pratyusha Kalluri, Maggie Harrington, Esin DURMUS, Kiara L. Sanchez, Nay San, Danny Tse, Xuan Zhao, MarYam Hamedani, Hazel Rose Markus, Dan Jurafsky, Jennifer L. Eberhardt",Atrium,Posters II,3,,679
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Route diversification in road networks,"In this article, we examine how road network topology and the presence of mobility attractors (e.g., highways and ring roads) shape route diversification. We introduce DiverCity, a measure that quantifies the extent to which traffic can potentially be distributed across multiple, loosely overlapping routes. Analyzing 56 global cities, we find that DiverCity is tied to traffic efficiency and network characteristics such as network length and number of intersections. Within cities, DiverCity increases with distance from the city center before stabilizing in the periphery but declines in the proximity of mobility attractors. We demonstrate that strategic speed limit adjustments on mobility attractors can increase DiverCity while preserving travel efficiency. In addition, we use a controlled setting to isolate the interplay between mobility attractors and DiverCity, confirming the patterns observed in real-world cities. DiverCity provides a practical tool for urban planners and policymakers to optimize road network design and balance route diversification, efficiency, and sustainability.","Giuliano Cornacchia, Luca Pappalardo, Mirco Nanni, Dino Pedreschi, Marta C. Gonzalez",Atrium,Posters II,4,,418
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Social Capital Around the World,"We use data from nearly 2 trillion friendship links between 2.5 billion Facebook users to build and analyze novel measures of subnational social capital in nearly 200 countries and territories. We first document substantial variation in the rate at which individuals form cross-class social ties, with large differences in friending rates both within and across countries. Cross-class social ties are relatively common in parts of Western Europe and relatively scarce in South Africa and parts of South Asia. Countries vary in the degree to which cross-class ties are determined by regional differences in average income. In places such as Italy, one's degree of connection to high income peers is largely determined by one's place of residence, while other countries such as Saudi Arabia, high- and low-socioeconomic status (SES) users have dramatically different networks, even within a region. We link our measures of cross-class social ties with external measures of intergenerational mobility, finding that places where low-SES individuals have more high-SES friends have higher rates of economic mobility in all countries in which we have data.","Drew Johnston, Michael Bailey, Ayush Kumar, Theresa Kuchler, Johannes Stroebel",Atrium,Posters II,5,,432
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Mapping Life Trajectories: A Machine Learning Approach to Clustering Multidimensional Life Courses,"Taking a life-course perspective, this paper uses novel machine-learning methods to identify typologies of life trajectories by classifying multi-dimensional life-trajectory data with transformer embeddings. This paper also demonstrates how demographic characteristics predict trajectory typology memberships and how typology memberships are associated with later-life outcomes. Using data from the 1970 British Cohort Study, I first establish a two-dimensional life trajectory data combining individuals’ partnership histories and work/education histories. I apply transformer-based embeddings to capture complex temporal dependencies and dynamics from multi-dimensional trajectory data. I then apply K-Means and Gaussian Mixture Models (GMM) clustering methods to classify individuals based on learned representations. The choice of embedding models, clustering methods, and hyperparameters is optimized via key performance metrics. Preliminary results identify four female clusters and five male clusters with distinct work-life trajectories. Qualitatively, the four female clusters can be described as “late bloomers”, “independent & steady”, “marriage & caregiving first”, and “career-family jugglers”. The five male clusters can be described as “early cohabitation with continuous struggles”, “cohabiting careerists”, “late committers, long learners”, “traditional breadwinners”, and “young settlers”. Among them, the “independent & steady” and “marriage & caregiving first” women are associated with worse economic security and physical and mental health outcomes at the age of 46. “Early cohabitation with continuous struggles” men are associated with worse economic security and physical and mental health outcomes at the age of 46. Another key finding is that GMM performs better for women while K-Means performs better for men in clustering life trajectories. It might suggest fundamental gendered differences in life-course patterns—with women having more fluid, overlapping, and nonlinear trajectories than men. This research makes both a methodological contribution as one of the first studies to apply transformer-based embeddings to life trajectory data, and a substantive contribution by advancing the understanding of the gendered typologies of behavioral patterns and life trajectories.",Zerui Tian,Atrium,Posters II,6,,116
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Gender Bias in How Public Figures are Referenced in News Quotes at Scale,"The way in which we refer to other individuals in discourse reflects social dynamics, attitudes, and underlying biases. Choices in personal references, such as first or last names, may indicate not just the relationship between individuals but also the underlying (gender) biases, personal relationships, status differences, or attitudes toward the referenced individual. In professional settings, naming conventions often reinforce power hierarchies, with last name usage indicating perceived eminence or authority. This seemingly subtle linguistic choice can have significant real-world implications, influencing perceptions of credibility and even the likelihood of receiving career awards.","Justyna Janczy, Marko Čuljak, Andreas Spitz, Akhil Arora",Atrium,Posters II,7,,854
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Scientific productivity and practice in the era of Large Language Models,"The scientific enterprise is intimately connected with technological innovation. The introduction of the microscope, advances in computing, and next-generation sequencers, for example, have shifted out the frontier of research. Today, the fast adoption of generative artificial intelligence (Gen AI) across all academic disciplines is recasting scientific production. Despite growing excitement (and concern) about Gen AI’s role in research, however, empirical evidence remains fragmented, and systematic understanding of the impact of Large Language Models across scientific domains is limited.","Keigo Kusumegi, Xinyu Yang, Paul Ginsparg, Mathijs de Vaan, Toby Stuart, Yian Yin",Atrium,Posters II,8,,926
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"German Populists on YouTube, Analysing the Decline of Evidence-Based Communication and Toxicity","The spread of online misinformation on social media is increasingly perceived as a problem for societal cohesion and democracy. By analyzing content of German YouTube creators between 2011 and 2022, we show that political social media creators' conception of truth has undergone a distinct shift in Germany, with rhetoric based on personal beliefs and intuition becoming more prominent at the expense of explicit evidence-based rhetoric. We demonstrate that this shift towards intuition-based language can be partly attributed to the emergence of new ""alt right'' political actors and is stable for other mediums like Twitter/X and german parliament speeches. We correlate this shift with a rise in multiple dimensions of polarizing language in the comments beneath the videos. Our study is observational and cannot support causal inferences. However, our results support the hypothesis that the increasing polarization in political discourse is tied to an alternative understanding of truth and honesty; namely, one that prioritizes the expression of subjective belief over a commitment to evidence. This shift is correlated with a rise in toxicity, hate speech, negative sentiment, and use of polarizing language in YouTube comments, as emotionally charged and intuition-driven statements often polarize audiences and escalate confrontational interactions. The resulting erosion of a shared factual basis can undermine the quality of public debate, weakening the foundations necessary for productive democratic discourse","Peer Saleth, Segun Aroyehun, Indira Sen, Stephan Lewandowsky, David Garcia",Atrium,Posters II,9,,600
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The Role of Telegram in Political Discourse: An Analysis of Russian-Language Narratives on the 2024 U.S. Presidential Election,"Social media play a crucial role in shaping contemporary social and political discourse. While platforms such as Twitter and Facebook have been extensively studied, alternative social media platforms, such as Telegram, remain relatively underexplored. Telegram, originally designed as a messaging application, has evolved into a powerful tool for information dissemination, political activism, and propaganda (Tikhomirova & Makarov, 2021; Khaund et al., 2020; Kuznetsova, 2024). Given its growing influence, particularly in Russian-language discourse, it is imperative to investigate how political narratives are shaped and disseminated on this platform. This study aims to analyze Telegram discussions related to the 2024 U.S. presidential election, focusing on Russian-language discourse from June 2024 to February 2025. Using computational methods and natural language processing such as Latent Dirichlet Allocation (LDA), this paper examines topic dynamics and content changes before and after the election, contributing to the broader understanding of digital political communication and U.S.-Russia relations. The results suggest that while election-related discussions dominated before election, the escalation of geopolitical tensions, particularly in Eastern Europe, played a more significant role in shaping post-election narratives. For the future steps, we plan to provide more detailed investigation of the channels in the discussion and qualitative analysis of the discourse.",Iuliia Alieva,Atrium,Posters II,10,,848
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The Hidden Organization of Online Communities: Reddit through the Lens of Stochastic Block Models and Neural Embeddings,"Over the past two decades, online platforms have staged many significant and challenging events, including the rapid spread of (mis)information, the amplification of unrepresentative voices, the rise of toxic public discourse, or the coordinated actions in favor of (or against) groups and ideas. The networks of exposure and exchange that platforms enable (and users exploit) offer an architecture that articulates friction and social change. Analyzing these networks is thus crucial for understanding how collective dynamics arise and evolve to allow Ð among other things Ð the propagation of news, the cascading of behavior, the enforcement of norms, or the coordination of collective action efforts (with pro- or anti-social goals). The question of how communities organize in online spaces requires uncovering a hidden structure from observed behaviors Ð but, depending on the computational tools used, that structure might look very different. This means that our theories of collective dynamics in online spaces will be constrained (in undocumented ways) by the tools we apply to the analysis of macro-scale behaviors. Here, we probe those differences by assessing the higher-order communities that result from two computational tools: neural embeddings (NEs) and stochastic block models (SBMs), as applied to the same 13 years of Reddit data. We show that the SBMs identify more intricate organizational structures and make it easier to identify ``information corridorsÓ and brokers spanning seemingly unrelated communities of interest. In other words, SBMs help identify organizational dynamics and generative mechanisms that are concealed in the semantic representations of NEs. Our network-based approach suggests a more intricate pattern for the classification of political communities on Reddit than the semantic representations of NEs as subreddits clustered in the `Politics' community break down into 18 distinct communities, suggesting the existence of general-interest subreddits that fulfill a different structural role within this initial classification. This breakdown is more pronounced when we apply the unrestricted SBM to the data, i.e., when we allow the inferential approach to determine the number of communities based on Bayesian principles, as opposed to imposing that number as a pre-set parameter. The unrestricted SBM divides the `political' cluster into 112 different communities. These smaller blocks (the average size is 5.67) offer a more granular partition of communities of interest, and help us identify the users building the bridges across those groups. Finally, the hSBM uncovers the intrinsic nestedness of those communities of interest: it iteratively performs community inference and groups the communities present at lower levels into larger blocks as we move up in the hierarchy, with most of the communities converging towards the fourth hierarchy level. This hierarchical approach uncovers self-organization at different resolution levels, and helps identify information corridors through which messages and content can travel for maximum reach.","Lluis Danus, Sandra Gonzalez-Bailon",Atrium,Posters II,11,,874
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Engagement and attention inequality on social media platforms,"Social media platforms increasingly serve as digital townsquares, yet they are also linked to declining institutional trust, rising populism, and polarization. In our study, we compare the engagement and attention dynamics of eight platformsÑfour Reddit-like (Reddit, Voat, Stack Exchange, Hacker News) and four Twitter-like (Twitter, Parler, Gab, Bluesky)Ñby analyzing metrics such as the ratio of comments to submissions, submission score distributions, and Gini indexes. We find that Reddit-like platforms foster longer, more structured discussion threads (with a comments-to-submission ratio of 5Ð7) compared to the shorter interactions on Twitter-like platforms (ratio <2), likely due to differences in algorithmic curation and content aging. Moreover, engagement and attention are extremely unequally distributed; for instance, the top 1% of users on some platforms accumulate up to 99% of the total engagement, with disparities even more pronounced on platforms like Twitter and Youtube. Extending our analysis to video platforms further confirms that a small fraction of content creators garners the vast majority of views. These findings highlight how platform design and content promotion strategies significantly influence discourse dynamics and societal outcomes such as polarization and the spread of extreme viewpoints.","Joao Pinheiro Neto, Jana Lasser",Atrium,Posters II,12,,1028
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"A Meta-Model of Belief Dynamics with Personal, Expressed, and Social Beliefs","We introduce the Personal, Expressed, and Social (PES) model—a meta-model of belief dynamics that integrates personal beliefs, expressed beliefs, and perceived social beliefs. The PES model synthesizes key social-psychological processes such as authenticity, ego projection, conformity, self-reinforcement, and social influence. It generalizes classical frameworks (e.g., Voter, Ising, and DeGroot models) by unifying binary and continuous belief updates in one flexible dissonance reduction framework. Furthermore, the PES framework facilitates systematic comparisons among existing belief models by mapping their underlying assumptions onto a common structure, thereby revealing each model’s strengths and limitations. This approach offers novel insights into how individual belief networks interact with social contexts, advancing our understanding of belief dynamics.","Henrik Olsson, Filippo Zimmaro",Atrium,Posters II,13,,708
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Modelling Fact-Checking in Social Networks: Designing Apt Epsitemic Enviroments for Public Discourse,"This paper explores the role of fact-checking in shaping epistemic environments within social networks using computational modeling and network theory. By simulating information flow and misinformation spread, the study examines how fact-checkers can strategically intervene to enhance decision-making and epistemic resilience. Using agent-based modeling on both synthetic and real-world networks, including datasets from the Stanford Network Analysis Project (SNAP), the research tests two key hypotheses: (1) increasing the presence of accurate information can, under certain conditions, neutralize misinformation, and (2) fact-checking effectiveness depends on strategic network design. The findings provide insights into misinformation control, optimal intervention strategies, and the broader implications for democratic information ecosystems.",Federica Imbriale,Atrium,Posters II,14,,704
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Interaction between science and misinformation on Twitter during COVID-19,"During the COVID-19 pandemic both science and misinformation played a large role. We here study the interaction between misinformation and science on Twitter (now X) during COVID-19 based on a comprehensive dataset of ~350M tweets. We find that the the proportion of misinformation hovers roughly between 5-10% through the pandemic, while the proportion of tweets referring to scientific publications is substantially lower. We find little to no correlation between the amount of misinformation and science at a country level. Interestingly, we find that 45% of the users who share misinformation also share science. The engagement with science is particularly high for users who share conspiracy theories, fake news and satire, while users who share mainstream media or politically biased media engage less with science. We find that publications shared by users who also share misinformation tend to be slightly more often preprints, are slightly more often retracted, have fewer citations and are published in lower impact journals, but most differences are relatively small. Our findings suggest that users who share misinformation do not necessarily show a disregard for science, although findings may be misinterpreted or misused. Users who share misinformation do not necessarily show an Òinformation deficiencyÓ, and approaching misinformation from the perspective of providing more or better information may not be productive.","Juan Pablo Bascur, Lucila Gisele Alvarez Zuzek, Vincent Traag",Atrium,Posters II,15,,823
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Stable or Volatile? Capturing Shifts in News Diet Slant Using Donated Google Data,"The political choices of individuals are made within a complex framework. A crucial part of this framework is how people inform themselves about public policy issues. The weakening of mass media and the emergence of ""high-choice media"" lead to a fragmentation of orientation. Fragmentation has both positive and negative consequences. On the positive side, the hegemonic channels with hegemonic information potential are no longer dominant in the media space. On the other hand, fragmentation increases the chances of people losing common patterns of thought and enhances the role of closed interaction spaces in political orientation. The weakening of traditional media control has been accompanied by a significant increase in the number of ""niche"" and partisan media sites that have been able to engage audiences. Observed as a process, this leads to a growing polarization spiral and supports the emergence of a ""filter bubble."" A critical aspect of this transformation is the shift in news diet slant, which refers to the ideological or partisan bias in the mix of news sources and content individuals consume. Our study employs a novel longitudinal dataset that tracks the same individuals' news diet slant over many years, offering a significant contribution to media research. While existing literature has primarily focused on cross-sectional analyses or short-term changes in news consumption patterns, our approach enables an in-depth exploration of the long-term dynamics of news preferences. Between February and June 2023, we conducted a complex data collection in Hungary, in which we asked participants to fill out a questionnaire and share their social media data with us alongside the survey. For data sharing, we used a data donation approach. Our research asked respondents for access to Facebook and Google data. The final sample size of our study was 758. This study uses Google page visit data between 2018 and 2022. We identified the news sites with a mix of transformer models and manual classification. This study focuses on news sites with more than 100 visits within the research period. Following the approach of other news diet research we used the audience-based method to estimate the relative ideological leaning of news outlets. This method leverages the ideological makeup of each news outlet's readership to indicate its political orientation. 5.3 percent of the domain visits were on news sites. We compared the shift in news diet slant between 2018 and 2022. As we would expect, people with left and right orientations differ in news consumption, people with left-leaning consume more left-leaning news sites and vice-versa, but overall the news consumption is quite balanced. From a temporal perspective, the news diet seems relatively stable on an aggregate level; we did not see any significant shift between the years. On the individual level, we get similar results. We calculated individual news diets' average and standard deviation based on the visited domain news diet slant for every year. Most individuals have close to zero news diet slant value, with a moderate standard deviation. Only a small fraction of respondents had an extreme (above/below to +- 0.5 value) news diet, and these respondents did not vary between the years. In the last step, we explored the determinants of extreme news diet slant. Age and gender were the main predictors behind extreme news diets. Older people and males had more extreme new consumption pattern. Other variables had no or varying effects on the extreme news diet variable. Our results confirm that most people have a mixed news diet, and only a low percentage of people have extreme news consumption. We were able to explore the temporal dynamic of the news diet. Our results show that news consumption slant in Hungary was remarkably stable between 2018 and 2022. Although we found periods when people read more news (election periods), there were no temporal shifts in the news diet slant. The news diet was not only stable on the aggregate level, but also on the individual level.","Zoltan Kmetty, Adam Stefkovics, Bendegúz Váradi, Emese Bata",Atrium,Posters II,16,,697
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Memes to an End: Charting the course of partisan toxicity in a popular political subreddit,"In our paper, we delve into the dynamics of toxic interactions in online political discussions, specifically within a subreddit focused on a subculture of internet memes on Reddit. By analyzing a self-created dataset of over 2 million comments, we investigate how factors such as social identity and online anonymity contribute to the prevalence of incivility in comment and response chains online. Our findings reveal that cross-group interactions are more likely to be toxic compared to within-group interactions, particularly when users engage in toxic behavior to defend their ingroup or prove their identity. Our study confirms hypotheses related to the likelihood of incivility stemming from outgroup members and the amplification of toxicity in response to prior uncivil comments. Interestingly, our research also finds that the proximity to elections does not significantly increase the overall level of toxicity, despite a higher volume of comments during these periods. This work underscores the importance of understanding the mechanisms behind online toxicity to foster healthier online political discourse, as well as contributes to literature of online subcultures and social identity on the internet.","Daniel Cowen, Andreas Flache, Vincenz Frey, Tobias Stark",Atrium,Posters II,17,,379
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The Spread of Virtual Gifting in Live Streaming: The Case of Twitch,"This paper examines how gifting spreads among viewers on Twitch, one of the largest live streaming platforms worldwide. Twitch users can give gift subscriptions to other viewers in the chat room, with the majority of gifters opting for community gifting, which is gifting to randomly selected viewers. We identify the random nature of gift-receiving in our data as a natural experiment setting. We investigate whether gift recipients pay it forward, considering various gift types that may either promote or deter the spread of gifting. Our findings reveal that Twitch viewers who receive gift subscriptions are generally more likely to pay it forward than non-recipients, and the positive impact of gift-receiving becomes stronger when the recipient is the sole beneficiary of the giverÕs gifting behavior. However, we found that gifts from frequent gifters discourage recipients from paying it forward, and gifts from anonymous gifters do not influence the likelihood of viewers becoming future gifters. This research contributes to the existing literature on the spread of online prosocial behavior by providing robust evidence and suggests practical strategies for promoting online gifting.","Ji Eun Kim, Seura Ha, Sangmi Kim, Libby Hemphill",Atrium,Posters II,18,,383
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Measuring Deliberative Diversity Online and On the Go: Validating a GLLM-based Approach,"Diversity is a concept central to many key problems within current democracies: A lack of diversity is the key concern of studies on filter bubbles and echo chambers. Diversity of opinions and information is a key requirement in most theories of democracy. It, therefore, may be surprising that various recent literature reviews conclude that, although a plethora of methods have been proposed, the field has yet to come up with a valid general metric for deliberative diversity (Bchtiger and Parkinson, 2019; Goddard and Gillespie, 2023; Joris et al., 2020; Loecherbach et al., 2020). To address this gap, we propose a theoretically grounded, yet general, computational metric of deliberative diversity. We evaluate different configurations of this new metric, using both open-source (Llama 3.1) and proprietary (GPT4o) GLLMs to determine the differences between comments, find the claims made in each comment and the differences between them. In addition, we embed both comments and claims using open and proprietary embedding models (mxbai and ADA) and calculate the Euclidian distances between the sets of comments related to each show and between those related to each platform. $\textbf{The difficulty of measuring diversity}$ Previous research has used three approaches: They propose a measure of diversity for their specific case, which would then need to be redefined to generalize to other contexts (e.g., Voakes et al., 1996); they reduce diversity to some larger, easier to measure and more fixed set of categories like partisan slant, actors or topics (see Joris et al., 2020); or they abandon any specific substantial criteria and look for anything indicating the opposite of similarity (e.g., Welbers et al., 2018). While the first approach is difficult to generalize and apply to vast amounts of (online) data, from a deliberative perspective the top-down nature of the second approach is too coarse and fails to incorporate how new information is introduced and shared, and the third approach does not discriminate between theoretically meaningful and more arbitrary differences like the writing style. $\textbf{Our metric}$ We propose that the abilities of Generative Large Language Models (GLLMs) might present an opportunity to combine the tailor-made and granular advantages of context sensitivity from the first approach, with the scope of the more generalized second and third approaches. We draw on work on argument quality (e.g., Wachsmuth et al., 2017) and deliberation (Stromer-Galley, 2007) and select ÒclaimsÓ as our basic unit to construct our list of categories.We then propose to either prompt the GLLM directly for the difference between the claims or to calculate the deliberative diversity of a corpus, as the average distance between the embeddings of the claims found in that corpus. In this way, we can differentiate corpora with many similar claims from those with more mixed or different claims. This method can, in principle, be used on any text and produce diversity statistics on the go, for example, to use in a ranking algorithm for a social media feed. $\textbf{Test and validation}$ We compared different configurations of our metrics with manually annotated disagreement in YouTube (YT) data provided by (Boukes, 2024). The first set of were different ways to calculate prompt based similarity scores. Although the concept of disagreement should be associated with, but differs, from diversity as defined here, only similarity scores of claims are significantly related to disagreement. The second set consisted of ADA embedding differences and raw claim counts per post. Results show that the presence of claims and the number of claims in a post correlate significantly with disagreement. Embedding distances between a comments/claims in a thread are also positively associated with disagreement. It appears that distances between claims were a little better associated with disagreement than the full comment text. Although these results are promising, they are not straightforward and more testing is needed to validate our metric. Therefore, the performance of our metric will be compared to that of simpler metrics, such as the cosine similarities between the TF-IDF transformations (de Vries et al., 2022) and BERT base embeddings of both the original comments and the claims. We will also extend our tests to more variables on three manually annotated datasets. One dataset contains manual annotations of political content and ideology of 700 X-comments (Heseltine & Clemm von Hohenberg, 2024), a second contains disagreement annotations for Reddit comments (Zhang et al., 2017), and a third contains ideology, disagreement and political content annotations for 3,132 comments from YouTube, replying to news videos (Boukes, 2024).",Sjoerd B. Stolwijk,Atrium,Posters II,19,,21
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,How candidates communicated on social media during the U.S. 2024 elections,"Where and how did candidates engage with potential voters, donors, and other audiences online during the 2024 elections? Our research describes the behavior of candidates for federal office during the U.S. 2024 primary and general elections. To construct our sample, we collected the full list of candidates for federal offices (House of Representative, Senate, and President) from the Center for Tech and Civic Life. Using an extensive validation process, we collected and validated account information for all candidates across Facebook, Instagram, Threads, X (Twitter), YouTube, TikTok, Rumble, Gettr, Telegram, and Truth Social. Then, for each validated account, we collect all posts from January 1, 2023 until December 31, 2024. We first describe platform uptake by party. Second, we analyze the content of candidate posts for whether they pertain to policy issues, culture war issues, or other topics and how the prevalence of those posts varies across parties and platforms. Our study pertains to the digital behaviors of candidates for office across ten platforms, offering insight into how candidates produce content across platforms with different audiences, modes, and affordances. To further research, we also make these data publicly available through the Social Media Archive at ICPSR.","Megan Brown, Josephine Lukito, Maggie Macdonald, Cameron Hickey, Kaitlyn Dowling, Myra Miranda",Atrium,Posters II,20,,934
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The Role of Science in the Climate Change Discussions on Reddit,"Climate change poses a critical threat that requires urgent global action. Given the strong anthropogenic component of climate change, individual and collective actions play a critical role in shaping future outcomes. In this study, we examine to what degree scientific resources are used to drive or substantiate the online discussions around climate change on Reddit, a popular social media website, in comparison to other sources, including news and social media, including sources known to be unreliable. We find that the largest category of URLs cited in the past 14 years is mass media, followed by newspapers and social media, and scientific sources make up only 4% of the URLs in posts and 6.5% in comments. However, the proportion of scientific sources has been growing in the past 6 years. Considering the political leaning of the users who post them, users whose URL posting puts them in the center (especially center-left) are more likely to cite science than those in the extremes. The most striking difference between the groups, however, is the posting of unreliable sources, which are more likely to be on the right political spectrum. Finally, we find that posts with scientific URLs are much more likely to be responded to with other scientific URLs, whereas posts with URLs pointing to unreliable sources are not likely to be responded to with science. Thus, this study helps to gauge the breadth of the public's scientific engagement, which is necessary to reach an agreement on the basic scientific facts.","paolo cornale, MICHELE TIZZANI, Fabio Ciulla, Kyriaki Kalimeri, Elisa Omodei, Daniela Paolotti, Yelena Mejova",Atrium,Posters II,21,,106
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The Evolution of Health-Related Conspiratorial Content on Social Media,"The COVID-19 pandemic has highlighted the dangers of health-related misinformation and conspiracy beliefs. Researchers have mainly focused on the prevalence of conspiracy beliefs related to health and their harmful effects, e.g. right-wing radicalisation and vaccine hesitancy. Less attention has been paid to how the prevalence and characteristics of conspiracy beliefs about health have changed since the COVID-19 pandemic. We focus on two aspects of this change: (a) The proportion of health-related discussion that features conspiratorial content; has this proportion increased or decreased since the COVID-19 pandemic? (b) The lexical, narrative and topical characteristics of health-related conspiratorial discourses; how have these characteristics changed in the years following the pandemic? To answer these questions, this paper uses natural language processing methods to map the digital circulation and reception of health-related conspiracy beliefs from 2020 to 2024, across multiple platforms (Facebook, YouTube, Telegram) and languages (English and Italian). To address (a) and (b), we use a data set of approximately ~1.1 million posts from public pages and groups on Facebook, ~5.4 million video comments from Youtube and ~1.8 million messages from Telegram public channels from English users, and ~1.6 million posts from Facebook, ~1.4 million comments from Youtube and ~1 million messages from Telegram from Italian users. We first fine-tune a Llama 3 large language model (LLM) classifier to distinguish between 4 categories of content in our dataset: conspiratorial and health-related, conspiratorial and not health-related, health-related and not conspiratorial, and not conspiratorial and not health-related. This enables us to address (a). For (b), we examine change in the lexical, narrative and topical features of our dataset. We train BERTopic models to extract topical features. For lexical features, we use a bag-of-words approach to construct embedding representations of content that encode vocabulary choices, and use HDBSCAN to retrieve groups of content with similar word choices. We use word sense induction based on clustering LLM token embeddings to identify groups of content that use terms in similar ways, e.g. contents might be grouped together because they use Ôblood clotsÕ to discuss vaccine side effects rather than suffering a stroke. Finally, we use methods for extracting actor-action-object relationships from content using syntactic parsing, embedding these extracted relationships using LLMs and then clustering relationship embeddings into groups of similar relations. We then represent the overall narrative structures captured by these groups using knowledge graphs. Examination of the lexical, narrative and topical features of contents of all 4 categories enables fine-grained analysis of the potential relation between health-related conspiratorial content and other kinds of discourse, and the role this might play in the evolution of health conspiracies.","Ayan-Yue Gupta, Massimo Airoldi, Raffaele Vacca",Atrium,Posters II,22,,405
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Testing Alternative Algorithms for Social Media News Feeds: Audience Diversity and Stated Preferences-Based Recommender Systems,"Social media platforms shape public discourse by influencing how users encounter information and engage with the world. However, engagement-driven recommender systems often amplify low-quality or divisive content, reinforcing ideological echo chambers and misinformation. While these issues are well-documented, research on alternative ranking mechanisms remains limited. This study develops and tests two alternative ranking algorithms that address the limitations of engagement-driven recommender systems. The first algorithm is based on audience diversity which applies a system wide constraint and the second is based on stated preferences which applies user defined constraints. The audience diversity based algorithm enhances the trustworthiness of news feeds by prioritizing content from sources with diverse audiences across ideological and demographic attributes and the stated preferences based algorithm aligns ranking with what users explicitly state they value, as opposed to what engagement behaviors suggest they prefer. Using simulation based evaluations and user studies, these algorithms are first evaluated against the baseline engagement maximizing algorithm and then their causal effects on user behavior and attitudes is assessed through a randomized controlled trial using an experimental social media platform.","Do Won Kim, Saumya Bhadani",Atrium,Posters II,23,,507
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Group Dynamics and Hate Speech Enforcement on Reddit,"How do variations in group size and ethnic diversity change individuals’ likelihood to enforce norms against hate speech in virtual environments? We conduct a field experiment to answer this question within the online platform Reddit by systematically varying both group size and racial group compositions of private, researcher-created sub-communities. These private sub-communities are active for three days and focus on daily discussions on researcher-initiated topics. Importantly, each sub-community consists of one real research participant and several scripted bots which mimic organic user behaviour and are of varying racial background which is prominently signalled. On the second day, one of the bots engages in hate speech on the basis of race. The dependent variable of interest is the actual participant’s reaction towards this norm violation and whether they intervene (e.g. user counter speech, report the post, etc.). Drawing on social identity theory and the diffusion of responsibility, we test whether decreases in group size or racial heterogeneity leads to an increase in the likelihood of norm enforcement. Our study contributes to the understanding of ethnic composition and group size as contextual factors influencing norm enforcement and focuses on hate speech as a critical norm violation, reflecting unique challenges of maintaining community standards in online spaces. At this time, our field experiment has not yet been conducted. By the time of the conference, we plan to present preliminary data.","Nicole Schwitter, Leonard Wendering",Atrium,Posters II,24,,65
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Orchestrating an Electoral Campaign: A mixed-methods approach to investigate offline and online relations during the Indian Elections,"We are interested in understanding how social media was used during elections by the ruling right wing party, BJP and the different strategies employed to spread the party’s political narrative on Twitter/X. This responsibility is delegated to the BJP’s “IT cell”, the department in charge of the party’s digital campaigning, which has been infamous for spreading misinformation and hate speech online. Through interviews and participant observation in the IT cell of a city in the West of India during the elections, we observed the day to day functioning, and the different motivations and strategies of the party functionaries during this tense electoral period. For instance, we were able to observe how the cell tried to ensure that certain topics would trend on various platforms in order to highlight certain selected themes that fit the larger right-wing political narrative of the party. Simultaneously, we collected digital trace data from Twitter which allowed us to study the formation of opinion clusters in online conversations and to assess how these ethnographically observed strategies played out. Combining these two approaches, this work aims to shed light on the effects of organized political campaigning online. What is the “organic” response of a social network to the orchestrated attempts to infuse certain topics online? What role do central nodes in the social network play in facilitating the outcome of these strategies? The uniqueness of our approach comes from combining these ethnographic and computational tools to look at how micro level planning and strategizing may show effects at a larger scale online.","Pearl Pandya, Armin Pournaki, Pedro Ramaciotti Morales",Atrium,Posters II,25,,1017
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Exploring the Impact of AI-Driven Persuasion on Political Support for Autocratic Leaders: A Case Study of Viktor Orbn's Supporters in Hungary,"This study examines whether large language models (LLMs) can reduce support for authoritarian political strategies through personalized, real-time conversations. The global resurgence of autocratic leadership, where elected leaders dismantle democratic institutions, has raised urgent concerns (Levitsky & Way, 2010). Hungary, under Prime Minister Viktor Orbn, exemplifies this trend, experiencing significant democratic backsliding and a departure from liberal norms (Bozki & Heged_s, 2018; Kornai, 2015). As a key case of democratic decline, Hungary offers an ideal setting to investigate why voters support leaders who erode democratic institutions and whether rational persuasion can reduce such support. Despite democratic erosion, autocratic leaders often maintain popular backing due to cognitive biases, emotional appeals, and identity-driven reasoning (Mudde, 2004; Inglehart & Norris, 2016). Overcoming these barriers is difficult, but research suggests that rational persuasionÑwhen thoughtfully framedÑcan improve receptivity to counter-attitudinal messages (Pennycook et al., 2012; Nyhan & Reifler, 2010; Braddock & Dillard, 2016). Recent studies show that LLMs can generate persuasive content comparable to human-crafted arguments, effectively influencing attitudes in various domains (Salvi et al., 2024). In political contexts, AI-driven persuasion has shown promise, with LLM-generated arguments sometimes surpassing human debaters (Costello et al., 2024; Salvi et al., 2024). The appeal of LLMs in this setting lies in their ability to generate real-time, tailored arguments at scale, offering a novel approach to countering authoritarian sentiments. This study tests whether LLM-driven persuasion can shift attitudes toward democratic governance in Hungary. By leveraging AIÕs capacity for personalized engagement, we assess whether rational, AI-generated arguments can meaningfully alter support for authoritarianism. We conducted an experiment with 1,000 Hungarian participants, who engaged in three-round conversations with GPT-4, receiving arguments on the dangers of autocratic regimes and the benefits of liberal democracy, testing five preregistered hypotheses. H1 examines the effectiveness of LLM-based persuasion on authoritarian political strategies; H2a tests a spillover effect to decreased support for Viktor Orbn; H2b investigates a potential moderating effect of participants' initial beliefs that Orbn is authoritarian; H3 assesses a potential moderating effect of participants' personal characteristics; H4ÐH5 compare persuasion effectiveness across conditions. Participants were randomly assigned to one of five conditions (2x2 factorial design plus control): (1) goal-based persuasion, (2) chain-of-thought (CoT) prompting, (3) goal-based + CoT, (4) default GPT-4 arguments, and (5) a control group receiving non-political conversations. We analysed the data using linear regression models, tailored to address each of our hypotheses. To address potential floor effects, results were tested for robustness using four datasets for each analysis with varying cutoff points for authoritarianism scores and Orbn support, respectively (Table 1). Across treatment groups, a small but statistically significant backfire effect (90% confidence level) emerged, with increased authoritarian beliefs post-treatment (Figure 1). The treatment alone did not significantly reduce support for Orbn. However, when interacting treatment with participants' perception of Orbn as authoritarian, an effect emerged. In the Control group, those who saw Orbn as authoritarian had lower support post-treatment. Yet in the Treatment groups, this reduction was significantly smaller (90% confidence level) in two intermediate cutoff categories, suggesting another backfire effect (Figure 2). We did not find any significant moderating effects among respondent characteristics. Among individual conditions, CoT prompting produced the strongest backfire effect on authoritarianism scores. Goal-based persuasion yielded a milder backfire effect, with most cutoff categories showing non-significant differences. These findings highlight the challenges of using LLM-driven persuasion to counter authoritarian attitudes, as certain strategies unintentionally reinforced authoritarian beliefs rather than reducing them. The observed backfire effects suggest that cognitive biases, identity-driven reasoning, and technical limitationsÑsuch as model biases and prompt designÑmay constrain the effectiveness of rational argumentation, even when delivered in a personalized, conversational format. Future research should explore whether alternative framing techniques, enhanced interactivity, or longer engagement periods could mitigate these adverse effects, as well as how prior political beliefs shape responsiveness to AI-generated arguments. Ultimately, this study underscores both the promise and limitations of AI-mediated interventions in shifting deeply held political attitudes.","Julia Szamely, Thomas Costello, Elisa Omodei, David Rand",Atrium,Posters II,26,,435
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"Terrorist Events, Public Discourse, and Ethnoracial Employment Disparities","This study examines how clusters of Islamist terrorist events and intensified public discourse influence employment trends for Middle Eastern men in German workplaces. Using a large-scale data-driven approach, it integrates employer-employee data, newspaper reports, and the Global Terrorism Database to analyze hiring patterns from 1999 to 2019. Due to the absence of direct ethnicity measures in administrative data, the study employs a name-based classification tool to infer perceived ethnic backgrounds. Findings indicate that periods of multiple terrorist attacks, coupled with increased media coverage, significantly reduce the hiring of men with Middle Eastern-sounding names, particularly in workplaces with weak institutional safeguards. However, existing employees remain unaffected. The research highlights that smaller workplaces, which often rely on informal hiring practices, show stronger discriminatory effects, whereas larger firms with structured processes exhibit greater resilience. By framing terrorist events within their broader socio-temporal context, this study provides insights into how repeated incidents reinforce stereotypes and contribute to hiring discrimination. It underscores the role of public discourse in shaping labor market disparities and emphasizes the need for workplace-level interventions to mitigate bias. The findings advance theories of labor market discrimination by demonstrating the interconnectedness of macro-level events, organizational structures, and individual hiring decisions, offering a comprehensive perspective on how external events influence employment outcomes.","Malte Reichelt, Christoph Müller",Atrium,Posters II,27,,152
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Classifying Authors' Perspectives on Russian Topics with ChatGPT,"In this study, framed within science diplomacy theory, we investigate whether fluctuations in the bilateral relations between the United States and Russia influence US authors’ perspectives on Russian topics expressed in their research articles. Our analysis uses a dataset of approximately 14,000 Web of Science abstracts on Russia and Russian-related topics. We manually annotated 1% of the abstracts as negative, neutral, or positive based on the author’s perceived perspective on Russia and Russian topics. These categories are based on an ad hoc definition of positivity designed for this study, extending beyond conventional sentiment analysis. Based on the same predefined positivity criteria, we use ChatGPT to automatically annotate the full dataset and compare these annotations with results from traditional sentiment analysis methods. This approach provides a novel, annotated dataset that captures authors' nuanced perspectives on Russia and Russian topics, contributing to the field of science diplomacy and the interplay between geopolitics and scholarly communication.","Carolina Coimbra Vieira, Elena Chechik, Victoria Di Césare",Atrium,Posters II,28,,234
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"Discourse Strategies and Natural Language Processing Analysis of China’s Engagement with the Women, Peace, and Security Agenda in the United Nations Security Council (2000-2024)","The Women, Peace, and Security (WPS) agenda, established by the United Nations Security Council (UNSC) Resolution 1325 in 2000, has become a significant framework in international conflict and peacebuilding discourse. This study employs Natural Language Processing (NLP) techniques and discourse analysis to investigate ChinaÕs evolving role and discourse strategies regarding the WPS agenda, as articulated through its speeches during UNSC open debates from 2000 to 2024. Focusing on the thematic trends in ChinaÕs speeches, this study aims to uncover the complexities of ChinaÕs diplomatic engagement with the WPS agenda, highlighting its alignment with and divergence from the core pillars of the framework. The research uses a comprehensive dataset of UNSC meeting records available from the UN Library, specifically focusing on debates related to the WPS theme. Discourse analysis, a vital method in International Relations (IR), provides a systematic framework for examining ChinaÕs rhetorical strategies and its role in reshaping global peace and security norms. The study traces ChinaÕs strategic positioning within the WPS agenda, addressing key issues such as prevention, protection, participation, and relief and recovery, while also examining emerging themes such as climate change, sexual and reproductive health (SRH) rights, and human trafficking. This study utilizes a multi-faceted analytical approach. First, Word Frequency Analysis and Sentiment Analysis provide an overview of ChinaÕs predominant concerns and the emotional tone of its interventions. Secondly, Topic Modeling with Latent Dirichlet Allocation (LDA) identifies the core themes in ChinaÕs speeches and their temporal evolution. The categorization of these themes reveals that while China remains focused on the traditional pillars of the WPS agenda, it increasingly emphasizes developmental issues, integrating global policy priorities into its diplomatic discourse. Topic Clustering and Time-Series Trends are analyzed to reveal how specific issues have gained prominence over time, demonstrating a shift in ChinaÕs diplomatic priorities. For example, the increasing focus on non-traditional security issues such as transnational justice and climate change highlights ChinaÕs broader foreign policy goals and its efforts to influence the global discourse on peace and security. Conversely, China has shown minimal engagement with topics like small arms and light weapons or LGBTQ+ rights, framing its participation in WPS debates primarily through the lens of security and low politics. Further, the study explores Similarity Checks using TF-IDF and Cosine Similarity to assess recurring patterns in ChinaÕs discourse across multiple years. These tools allow for a comparison of thematic overlap in speeches, revealing the consistency and strategic evolution of ChinaÕs narrative over time. Additionally, Text Generation techniques using Word2Vec and Markov Chains offer insights into the underlying structures of ChinaÕs speech, while Information Extraction identifies key actors and institutions mentioned in relation to the WPS framework, shedding light on ChinaÕs diplomatic interactions within the UNSC. In conclusion, this study demonstrates that ChinaÕs engagement with the WPS agenda reflects its evolving role in global governance and a strategic maneuver to assert its developmental priorities and reshape the international order. By leveraging NLP techniques, this research provides a deeper understanding of how China navigates the intersection of security, development, and diplomacy within the UNSC, and offers insights into the broader implications of its discourse strategies for international peace and security.",Fanxi He,Atrium,Posters II,29,,161
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Data-Adaptive Experimentation to Find Contexts with the Most and Least Discrimination,"We propose a data-adaptive experimental design tailored for pairwise-choice settings like audits and conjoint studies. Our method uses adaptive allocation to efficiently search across multiple attributes, pinpointing the contexts with the most and least discrimination. We validate our approach with an empirical example that replicates a conjoint study exploring how immigrant applicant characteristics affect respondents' views on whether they should be admitted to the United States, demonstrating the method's effectiveness in uncovering heterogeneous discrimination effects.","Daniel Molitor, Jennah Gosciak, Ian Lundberg",Atrium,Posters II,30,,488
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Balancing Power and Efficiency in Adaptive Experiments,"This paper introduces the Modified Mixture Adaptive Design (MADMod), an experimental design for conducting adaptive experiments with multiple treatment arms that addresses both efficiency and robust inference. Building on the Mixture Adaptive Design (MAD) framework, MADMod retains anytime-valid confidence sequencesÑallowing experiments to conclude dynamicallyÑwhile systematically reallocating samples to ensure each arm achieves sufficient statistical power. By integrating importance weights that decay once an armÕs average treatment effect is detected as significant, MADMod prevents under-allocation to suboptimal arms without sacrificing the efficiency gains of multi-armed bandits. Simulation results demonstrate that, compared to standard adaptive designs, MADMod substantially reduces Type 2 error rates and offers more precise inference across all treatments. This allows researchers to harness the benefits of adaptive sampling and early stopping while maintaining well-powered evaluations of every treatment arm.","Daniel Molitor, Samantha Gold",Atrium,Posters II,31,,203
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Extracting Participation in Collective Action from Social Media,"The Social Web facilitates large-scale mobilization, yet analyzing participation in collective action remains challenging due to the lack of reliable ground truth data. We develop NLP classifiers to detect expressions of participation in collective action (binary task) and categorize its levels (multi-class task): problem identification, calls-to-action, intention, and reported involvement. Using a dataset of Reddit comments, we evaluate four classification pipelines: RoBERTa, zero-shot Llama3, fine-tuned Llama3, and Direct Preference Optimization Llama3. RoBERTa achieves strong performance in binary classification (weighted F1=0.71), while fine-tuned LLMs excel at detecting nuanced participation levels. Applied to climate-related discussions, our method identifies expressions of participation in collective action overlooked by keyword-based approaches, revealing disparities in subreddit rankings for climate activism. Our approach has the potential to enhance activism campaign targeting and advance the study of online mobilization.","Arianna Pera, Luca Maria Aiello",Atrium,Posters II,32,,518
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Mapping the climate change landscape on TikTok,"Social media platforms play a key role in developing discussions around climate action. Mapping the online discourse on climate is crucial to learn communication strategies that are most effective in drawing people’s attention to the cause of climate activism. The climate discourse on TikTok is particularly interesting in this respect, as it involves a young user base with high interest and stakes in the topic of climate transition. In this work, we collect the first TikTok dataset on climate topics. Overall, we collected 590K videos from 14K creators and the full follower network connecting them. By applying topic modeling to the video descriptions, we map the topics discussed on the platform on a climate taxonomy that we construct by consolidating existing categorizations. We find that TikTok creators approach the climate topic pre-dominantly through the angle of lifestyle and dietary choices. Finally, we build networks of semantic relatedness between topics, discovering non-climate topics that can act as promising ‘gateways’ for new audiences to engage in the climate discussion.","Alessia Galdeman, Luca Maria Aiello",Atrium,Posters II,33,,138
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Mapping the Discursive Space of Climate Change News Coverage,"For effective climate action to take place, mass support for such action needs to be built. Climate communications — conveying the urgency of climate change to the public — is crucial to this. Research on climate communications tends to focus on optimizing messaging strategies at the expense of understanding the features of the media ecosystem within which climate messaging must take place. Understanding how such features affect climate communications is important as there could be ways of reforming the media ecosystem in a way that makes it more amenable to climate messaging. To address this gap, we employ topic modelling (BERTopic) and network analysis to answer two questions: (A) Which structural patterns exist in networks of journalists and news outlets in Anglophone climate coverage? (B) How do these networks impact the topics discussed in climate coverage? We use a dataset of 304,958 news articles from 38,548 authors and 1,224 outlets published during November 2019 – October 2021. These articles were collected from NewsAPI using key term searches “climate change” and “global warming”. To answer (A), we construct an author-outlet network, in which edges are drawn when an author writes for a particular outlet. We use community detection to identify the central clusters of journalists and outlets at play in climate coverage. To answer (B), we examine compare the topic probability distribution of each community to the dataset's overall topic distribution using Jensen-Shannon distance. This enables identification of communities with unexpected/distinctive topic distributions as well as the key topics of such communities, and identification of communities that are close to the discursive 'center-ground' as represented by the overall topic distribution. We also use label propagation with a dataset of outlets' political alignments from Media Bias/Fact Check (MBDC) to label/estimate authors' and outlets' political alignments to investigate whether communities' alignments affect the topics they focus upon. Initial findings show that while communities display a broad range of political alignments, topics do not. Compared to communities, the average alignment of the outlets and authors underlying topics do not diverge much from a center-left alignment. A possible explanation is that within climate coverage, the discursive agenda is set by a small number of large, center-left communities, with smaller communities that diverge from the center-left adopting the topics of the discursive agenda set by these center-left communities. This is supported by the fact some of the largest communities with topic distributions most similar to the overall topic distribution are dominated by outlets such as MSN and The Guardian, marked by MBFC as center-left. However, this is a work in progress and more analysis is needed to investigate this possible explanation.","Ayan-Yue Gupta, Tristan J.B. Cann",Atrium,Posters II,34,,290
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Twitter anticipates adoption and change in pro-environmental behavior,"Fostering coordinated pro-environmental actions is critical for effective climate action and mitigation strategies. Individual actions, when effectively communicated and discussed, can give rise to collective behaviors that drive systemic change, a key component of sustainable development. Online social networks could serve as a valuable tool for monitoring the diffusion and adoption of pro-environmental behaviors at the population level, contributing to data-driven strategies aligned with global climate goals. Despite their potential, the relationship between online behaviors and tangible pro-environmental actions remains underexplored in current literature.","Edoardo Maggioni, Luca Maria Aiello, Diego Garlaschelli, Rossana Mastrandrea",Atrium,Posters II,35,,692
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Telegram: Data Infrastructure for Researching Platform Dynamics,"Telegram is gaining importance as a platform in (digital) communication and media research (Wiedemann et al., 2023). The platform forms a hub of digital counter-publics due to its functions and self-understanding as a free speech platform. Unlike other messenger apps like WhatsApp, Telegram allows the formation of large public chat groups and the use of broadcast channels without participant limits. This creates a platform where own publics can form and narratives and messages can spread beyond the mainstream. In fact, Telegram is a central communication site for groups and actors worldwide and especially in Germany, who want to avoid state control due to their content or political orientation (Rogers, 2020). The platform is known for moderating content only to a limited extent, making it attractive to extreme actors (e.g., right-wing extremists or Islamists), conspiracy theorists (e.g., Qanon), and other communities (such as civilly disobedient climate activists) (Bloom et al., 2019; Schulze et al., 2022). This is evident in Germany, where the platform was heavily used by critics of Corona counter-measures, conspiracy peddlers, and right-wing extremist actors during the Corona pandemic. In contrast, state authorities also communicate via Telegram, such as Russian government representatives and ministries, the German Ministry of Health, or Hamburg universities and transport authorities. The goal of this dataset is to proactively capture the German Telegram sphere and its immediate environment in other language areas and to enable rapid specialized data collection in retrospect. A pre-selection of actors and channels to be collected is necessary due to the technical functionality of the platform. In contrast to other social media platforms, there is no global feed, but only individual group and channel message threads, and a global search is not available (Jost et al., 2023). This makes exploring the Telegram ecosystem difficult and requires corresponding sampling strategies. The described functions of the platform often pose high hurdles for research projects, which can be made more manageable by a central large-scale collection. Using the Telegram web interface, several network samples were created in Snowball and Spikyball configurations, starting from the 1,000 largest German-language channels, which serve as the basis for the collection (Goodman, 1961; Jost et al., 2023; Ricaud et al., 2020). Based on approximately 10,000 discovered channels, a collection was established that retrospectively collects messages from these channels starting from January 1, 2019 (Kessling & Mnch, 2023). From this extensive data stock, an additional 5,000 channels were selected using Rank-Degree-Sampling (Voudigari et al., 2016)- in this way, the dataset can also be expanded in the future. Based on the original messages of the collected channels, the language in which they post was determined using Fast Text (Joulin et al., 2016). As a data infrastructure, this collection enables the processing of a series of relevant questions, such as dynamics within the German language area and platform genesis since 2019. But larger connections across multiple language areas can also be uncovered, such as on the topic of the Ukraine war. Using several case studies, this conference contribution shows the potential and limitations of our dataset and discusses possibilities for data access.","Philipp Kessling, Felix Victor Münch",Atrium,Posters II,36,,954
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Decentralized Discourse: Analyzing Sentiment Diffusion of the 2023 Gaza-Israel Conflict Across Mastodon Instances,"This study investigates sentiment diffusion across federated Mastodon instances during the 2023 Gaza-Israel conflict, focusing on how sentiment spreads within and between instances. Using a dataset of 98,937 toots related to the Gaza conflict, we analyzed sentiment using the XLM-T model and constructed cascades based on replying structures with a focus on cross-instance spread. Results revealed significant differences in sentiment distribution across different levels of cross-instance spread, with increased sentiment variance observed as cascades crossed more instances. These findings offer insights into the dynamics of sentiment propagation in decentralized networks, highlighting the impact of federated structures on public discourse during crises.","Giulia Sturlese, Seeun Kim, Li Zeng, Sijia Ma",Atrium,Posters II,37,,337
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Studying Behavioral Addiction by Combining Surveys and Digital Traces: A Case Study of TikTok,"Opaque algorithms disseminate and mediate the content that users consume on online social media platforms. This algorithmic mediation serves users with contents of their liking, on the other hand, it may cause several inadvertent risks to society at scale. While some of these risks, e.g., filter bubbles or dissemination of hateful content, are well studied in the community, behavioral addiction, designated by the Digital Services Act (DSA) as a potential systemic risk, has been understudied. In this work, we aim to study if one can effectively diagnose behavioral addiction using digital data traces from social media platforms. Focusing on the TikTok short-format video platform as a case study, we employ a novel mixed methodology of combining survey responses with data donations of behavioral traces. We survey 1590 TikTok users and stratify them into three addiction groups (i.e., less/moderately/highly likely addicted). Then, we obtain data donations from 107 surveyed participants. By analyzing users' data we find that, among others, highly likely addicted users spend more time watching TikTok videos and keep coming back to TikTok throughout the day, indicating a compulsion to use the platform. Finally, by using basic user engagement features, we train classifier models to identify highly likely addicted users with $F_1 \geq 0.55$. The performance of the classifier models suggests predicting addictive users solely based on their usage is rather difficult.","Cai Yang, Sepehr Mousavi, Abhisek Dash, Krishna P. Gummadi, Ingmar Weber",Atrium,Posters II,38,,501
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,How Fans Engage with State Propaganda through Celebrity Mobilization,"Digital technologies have introduced unprecedented challenges for authoritarian regimes in reaching their audiences. In response, these regimes have increasingly co-opted non-state actors, particularly celebrities, to disseminate state propaganda. To address the research gap in understanding the effectiveness of such co-optation strategies, this study introduces a novel theory, ""performative propaganda engagement,Ó which explores how individuals interact with state propaganda in a performative manner. By combining BERT-based computational text analysis of large-scale social media data, time series analysis, causal inference methods, and qualitative interviews with celebrity fans in China, this research empirically investigates performative propaganda engagement within the realm of Chinese online celebrity fandom, a rising cultural force on Chinese social media. I find that when celebrities engage with state propaganda, their metrics-driven fans are motivated to promote the same content. However, this engagement is largely performative, driven by a primary goal to support the celebrity, with fans contributing in an instrumental way. By examining the manifestations of performative propaganda engagement, this research contributes to a deeper understanding of authoritarian information control through cultivating civil societal forces.",Yingdan Lu,Atrium,Posters II,39,,99
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Self-Directed Online Information Search and Policy Support: A Randomized Encouragement Experiment with Digital Behavioral Data,"The abundance of information sources in today's digital environment hinders efforts to measure their influence on individuals' policy support. Our study with 791 German participants investigates self-directed online search in a naturalistic setting through three randomized controlled experiments on three topical policy issues: basic child support, renewable energy transition, and cannabis legalization. Participants' online browsing was passively tracked. Significant attitude shifts were observed for child support and cannabis legalization, but not for renewable energy transition. By encouraging participants to seek online information, this study enhances ecological validity compared to traditional experiments that expose subjects to predetermined content. Our experimental approach lays the groundwork for future research to advance the understanding of media effects within the dynamic online information landscape.","Roberto Ulloa, Celina Kacperski, Peter Selb, Andreas Spitz, Denis Bonnay, Juhi Kulshrestha",Atrium,Posters II,40,,159
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"Attitude Shifts under Ideal Discussion Conditions: Stability, Shift, and Depolarization","Online discussions are often characterized by polarization, driven by confirmation biases, and hostile interactions that reinforce preexisting attitudes. In contrast, what happens when discussions occur under ideal conditionsÑwhere participants engage respectfully, exchange arguments without hostility, and genuinely deliberate on various topics? While existing research highlights the role of social validation and cognitive consistency in maintaining stable attitudes, less is known about how attitudes evolve in environments that lack the usual reinforcements of polarization. Specifically, we address two research questions: RQ1 whether participation in controlled online discussions may be conducive to changes in attitudes and knowledge and RQ2 whether empirical attitude changes may project future attitude shifts and (de)polarization depending on the issue. The observed influence of discussions varied by issue, indicating that some topics are more susceptible to change through controlled discussions than others. While most attitudes remained stable, our study also highlights a possible depolarization effect under ideal discussion situations. Finally, the depolarising tendency observed in attitude transition matrixes is consistent with observations of reduced self-reported issue knowledge that could reflect a form of intellectual humilityÐa factor likely conducive to democratic deliberation. Our results may contribute to theories of attitude stability and change by suggesting that polarization is not an inherent outcome of discussion but rather a product of the conditions under which discussions occur.","Veronika Batzdorfer, Sven Banisch, Lisa Oswald",Atrium,Posters II,41,,630
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Evaluating Large Language Models for Belief Inference: Mapping Belief Networks at Scale,"Beliefs are interconnected, influencing how individuals process and update information. To study these belief networks at scale, we introduce a novel analytical pipeline leveraging GPT-4 and o reasoning models to infer belief structures from large-scale social media data, specifically from RedditÕs ChangeMyView forum. Our approach focuses on evaluating the capacity of LLMs to accurately infer users' beliefs and recover belief co-occurrences. We fine-tune GPT-4 on a curated dataset of belief statements and apply it to infer users' belief networks across multiple topics. We evaluate the model's performance by applying cross-validation on a golden dataset annotated by humans, comparing the vanilla GPT-4 model, the fine-tuned GPT-4 and o3-mini. Our results show that the fine-tuned GPT-4 model can effectively recover belief networks, outperforming traditional survey methods in both scalability and efficiency. This work demonstrates the potential of LLMs for belief inference tasks and provides a framework for future research in belief network analysis.","Trisevgeni Papakonstantinou, Antonina Zhiteneva, Ana Ma, Derek Powell, Zachary Horne",Atrium,Posters II,42,,537
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Spontaneous Emergence of Polarization from Networked Belief Systems,"Beliefs shape how we interact with the world and are in turn molded by our social environment. Our cognitive and social biases guide these interactions, reinforcing the dynamic interplay between our beliefs and environment. Beliefs are interconnected, often forming coherent ""belief systems"" through which we make sense of the world. Although many associations between beliefs can be naturally explained by how coherently they fit together, it is unclear how non-trivial or even arbitrary associations such as ""latte-drinking"" liberals or ""truck-driving"" conservatives emerge and spread in society---a process called associative contagion. In this work, we demonstrate that such associations can emerge from a model of networked, interacting beliefs. We further illustrate how shared group identity spills over into broader social contexts by influencing the contagion and adoption of belief associations.","Ozgur Can Seckin, Rachith Aiyappa, Alessandro Flammini, Yong-Yeol Ahn",Atrium,Posters II,43,,667
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Algorithmic Accountability Mechanisms for Content Moderation,"The growing adoption of algorithms across various domains is transforming our online experiences and our daily lives. Systems underpinned by artificial intelligence (AI) cannot be seen as purely technical tools, but operate as socio-technical processes with wide societal implications. Far from being mere code, algorithms can provide authority and control to the organisations deploying them. Therefore, ensuring accountability becomes the foundation for monitoring algorithmic usage, regulating impacts, and preventing concentration of power. In the absence of adequate accountability mechanisms, there is a considerable risk of being unable to identify, understand, or mitigate harm. This paper presents the first systematic literature review of the mechanisms and frameworks proposed for achieving algorithmic accountability. 601 academic publications from the Web of Science, ACM Digital Library, Scopus, and Compendex databases were systematically reviewed, and a final set of 25 that met the studyÕs eligibility criteria were included in the analysis. The findings highlight a varying range of proposed algorithmic accountability mechanisms, including high-level conceptual frameworks, legal and regulatory proposals, and technical toolkits. Despite varying in aims and scope, the majority of these proposals share a common understanding of algorithms as socio-technical systems that are embedded within a wider ecosystem. Risk identification and mitigation also surfaced as a common theme among the proposals. Most importantly, the review highlights a fundamental lack of consensus on the structure and implementation of the proposed frameworks. The identified mechanisms remain mainly voluntary in nature, with no legal basis for their application. While voluntary industry best practices are beneficial, the absence of regulatory oversight and any serious consequences beyond reputational loss poses significant risks, such as lower adoption rates and challenges in achieving de facto algorithmic accountability. By providing an up-to-date overview of the various approaches to algorithmic accountability, this study is valuable for practitioners seeking ways to implement both system and organizational-level accountability, as well as for researchers, regulators, policymakers, and civil society stakeholders.",Syeda Gulnoor Zahra,Atrium,Posters II,44,,1045
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Assessing global hate speech moderation on Twitter,"Social media has been criticized for exposing users to hate speech, with potential negative offline consequences ranging from political polarization to hate crimes. To counter online hate, platforms use content moderation, consisting of verifying each post against platform policies and taking action on harmful content by deleting posts or suspending their authors. Despite many platforms having rules against hate speech since their inception, the traditional opacity around the sociotechnical moderation system renders its capacity to accurately detect hate and the extent to which moderation policies are enforced unclear. In this work, we aim to bridge these two gaps by assessing global hate speech moderation on Twitter. Using Twitter representative data from September 2022, we find that real-world AI-based hate speech detection performance is low across languages and countries, rendering automatic moderation undesirable. However, a human-in-the-loop approachÑwhere AI flags content and humans review itÑachieves high moderation rates using only a small number of moderators. In contrast, we find that TwitterÕs moderation enforcement is low, with a mere 19% of all hateful content removed months after being posted and significant disparities across languages. Taken together, our results underscore the importance of researcher data access in the study of content moderation, particularly at a time when platforms are limiting such access and scaling back moderation efforts.","Manuel Tonneau, Dylan Thurgood, Diyi Liu, Niyati Malhotra, Ralph Schroeder, Scott A. Hale, Samuel Fraiberger, Victor Orozco-Olvera, Manoel Horta Ribeiro, Paul Röttger",Atrium,Posters II,45,,680
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Predicting Constructive Conflict in Social Media Discussions,"Bridging content that brings together individuals with opposing viewpoints on social media remains elusive, overshadowed by echo chambers and toxic exchanges. We propose that algorithmic curation could surface such content by considering constructive conflicts as a foundational criterion. We operationalize this criterion through controversiality to identify challenging dialogues and toxicity resilience to capture respectful conversations. We develop high-accuracy models to capture these dimensions. Analyses based on these models demonstrate that assessing resilience to toxic responses is not the same as identifying low-toxicity posts. We also find that political posts are often controversial and tend to attract more toxic responses. However, some posts, even the political ones, are resilient to toxicity despite being highly controversial, potentially sparking civil engagement. Toxicity resilient posts tend to use politeness cues, such as showing gratitude and hedging. These findings suggest the potential for framing the tone of posts to encourage constructive political discussions. The proposed markers of constructive conflict can be flexibly integrated into recommendation algorithms, enabling platforms to surface posts that foster productive deliberation.","Ozgur Can Seckin, Bao Tran Truong, Do Won Kim, Saumya Bhadani",Atrium,Posters II,46,,673
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Watching the Greens? Affective predictors of political information seeking via online search,"Search engines are both frequently used and widely trusted sources of current political information. While research has examined the different stages of information seeking via search, the question of how political preferences and sociodemographic factors impact political online search has received less attention. In particular, the way in which attitudinal factors, such as sentiment towards a politician or interest in their personal life motivate information seeking have not been widely studied. We present findings from a panel study that combines browser tracking data with survey results for 1,863 German participants. Our results suggest that both sympathy and antipathy towards individual politicians are salient predictors of searching for them. Queries also vary with regard to their composition, with searches for female politicians highlighting their personal lives and physical attributes more often than for males. We conclude that the role of ÒsoftÓ factors in motivating information seeking on political actors is underexplored.","Cornelius Puschmann, Helena Rauxloh, Lisa Merten, Sebastian Stier, Katrin Weller, Juhi Kulshrestha",Atrium,Posters II,47,,614
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Even AI Cannot Escape Political Divides: How Media Bias Shapes the Reporting of AI Harms,"As AI systems become increasingly integrated into our everyday lives, concerns about their risks are growing. News coverage of AI incidents—high-stakes situations where AI systems fail or behave unexpectedly—acts as a catalyst for individual opinion formation, public discourse, and regulatory frameworks. Analyzing over 2,000 news reports, we find that the framing of AI-related issues varies significantly by political leaning. We found left-leaning outlets portray AI incidents mainly as socioeconomic and representational harms, while right-leaning outlets frame them as national security concerns. The left media also cover minority and local communities three times more frequently than the right, and report those incidents more often in a tone of anger. These biases in reporting not only shape the public’s understanding of AI but also carry implications for policy debates and the future of AI regulation.","Julia De Miguel Velázquez, Andrés Gvirtz, Sanja Scepanovic, Daniele Quercia",Atrium,Posters II,48,,806
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Contextual Reasoning about Narrative Intents and Reception in Social Media Conversations,"Understanding the social functions of storytelling in online conversations requires insight into how readers process stories--including their perceptions of the author's intent, their assumptions about characters, and their emotional responses. Yet, we lack computational models for predicting how readers will respond to storytelling in context. We introduce a taxonomy and framework for distilling contextually plausible inferences about stories to address this gap. Specifically, we leverage large language models (LLMs) to summarize the conversational context preceding a storytelling comment and then prompt LLMs to predict plausible inferences and reactions to the story in line with human judgments. Furthermore, in ongoing work, we leverage the model to illuminate the social functions of social media storytelling at scale and investigate how these functions vary across communities.","Joel Mire, Andrew Piper, Maria Antoniak, Steven R Wilson, Zexin Ma, Achyutarama R Ganti, Maarten Sap",Atrium,Posters II,49,,964
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"Odessa, a DEcentralized Social Systems App","Odessa is a decentralized social network that merges user autonomy with community governance while bridging norms across distinct communities. By allowing each community to define its own rules and employing transparent, AI-assisted moderation, Odessa fosters more intentional engagement. In a two-week user study with 34 participants, we observed that community-defined normsÑsupported by self-review promptsÑencouraged users to reflect on their behavior. However, bridging spaces (where communities with different policies intersect) showed that merely merging feeds is insufficient: explicit shared rules are needed for successful cross-community interaction. Though AI assistance eased moderation workload, participants trusted it most when humans remained in control of final decisions, underscoring the value of interpretable automation. Highlighting positive actions (e.g., using badges) also motivated more constructive participation. These findings suggest that combining community-driven governance, bridging mechanisms, and human-AI collaboration can create more inclusive and purposeful decentralized networks. Odessa provides a practical sandbox for further study and innovation.","Belén C Saldías Fuentes, Deb Roy",Atrium,Posters II,50,,781
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Understanding Symbolic and Social Cleavages Through Multiplatform Online Behavioral Data,"Along with Bourdieu’s homology thesis, social space and symbolic space are strongly interdependent. With a data driven approach, this paper aims to unfold those cleavages, which are the most important in the symbolic space of the online world and compare them with offline social cleavages. Accordingly, we answer to two main questions. First, what are the most important cleavages in the symbolic online space by which users are distinguishable. Second, how much these separated user-groups align with social characteristics proven to be unequal in the offline space. To test these questions, we use a dataset that both includes users’ observed behavioral data in the online space, and has information of these users’ offline social characteristics. 758 participants were involved – who represent the Hungarian internet user population in terms of gender, age, education and geographical region – downloaded the data Facebook, YouTube and Google stored about them from the time they registered on the platforms, and after informed consent, they donated these to the researchers. Additionally, they filled out a questionnaire that included questions about their detailed social positions, thus, social-demographic profiles of the participants are also reconstructable. To construct the symbolic space, from Facebook, we considered data of events, groups, and followed or liked pages, from YouTube, the watched videos, and from Google, the searches. In order to have comparable categories across platforms, digital activities were classified into 26 distinct categories based on Google Trend. For each above-mentioned digital activity, the rate of the category within the digital activity was calculated. Out of these 130 potential cleavage-creator variables, we used Sparse k-means algorithm, as compared to the 758 respondents, the data was quite sparse. This method aims to effectively reduce the dimensionality of the clustering problem with LASSO regularization, which implicitly selects relevant clustering features and suppress irrelevant ones. The results show an 8-cluster solution, where 12 percent of the 130 indicators found to be significant proved to be the main cleavages along which people are segmented in the online symbolic space. The 1st cluster can be described by the dominance of Food and drinks related Facebook events. Those belonging to this group are mainly middle-aged small employers or self-employed people. The 2nd cluster is characterized by cultural omnivorousness: compared to the whole sample, they are more likely to participate in many different activities. These people are typically 60 years old or older, who are not married and mostly belong(ed) to the lower-level service class. The respondents of the 3rd cluster are dominantly active in Facebook events related to Food and drinks and News and politics. This group does not differ from the whole sample by any social characteristic. The members of the 4th cluster are more likely to google for topics related to Technology and electronics. They use YouTube a lot more frequently than other participants, but they do not listen to music there. They are mainly lower status married men. The most important significant characteristic of the 5th cluster is watching YouTube Music videos, which they listen to more often than any other clusters. This cluster mostly consists of younger, skilled worker women. The 6th cluster can be characterized by the dominant proportion of Sports and outdoor activities, both at Facebook events and pages. These people are middle aged and mainly belong to the lower-level service class with vocation. Those belonging to the 7th cluster participate in Music specific Facebook events, while they use Google to search for Technology and electronics as well. They mostly belong to the lower-level service class and are between 60-69 years. The members of the 8th cluster signal significantly more frequently on Facebook that they participate in events related to Celebration and party, and they are more likely to be a member of Facebook groups about Jobs and education. Young people between 16-29 years are over-represented in this group. As we could detect, digital cleavages are dominated by Facebook events and YouTube video watches and less by activities belonging to Google search and Facebook groups and pages. The clusters created are only partially align with offline cleavages and dimensions of inequalities: we could not detect clear trends and dominant offline inequality dimensions, which describe most of the digital activity-based clusters. Accordingly, we can conclude that Bourdieu’s homology theory does not stand for the contemporary Hungarian society as the symbolic space in the digital world does not align with the social space. Our work could contribute to the exploration of new digital cleavages in the digital symbolic space, as well as to a deeper understanding on how symbolic and social space are related to each other in today’s societies.","Julia Koltai, Ákos Huszár, Zsófia Rakovics, Kata Számel, Michelle Horváth, Anna Sara Ligeti, Szilvia Rudas, Bendegúz Váradi, Zoltan Kmetty, Emese Bata",Atrium,Posters II,51,,776
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,How ChatGPT Changed the Media’s Narratives on AI: A Semi-Automated Narrative Analysis Through Frame Semantics,"We analyse a dataset of more than 49,000 sentences collected from 5846 news articles that mention AI using a mixed-method approach based on automatic annotation of semantic frames. The dataset covers the twelve-month period centred around the launch of OpenAIÕs chatbot ChatGPT and is collected from the most visited open-access English-language news publishers. Our findings indicate that during the six months succeeding the launch, media attention rose tenfoldÑfrom already historically high levels. During this period, discourse has become increasingly centred around experts and political leaders, and AI has become more closely associated with dangers and risks. A deeper review of the data also suggests a qualitative shift in the types of threat AI is thought to represent, as well as the anthropomorphic qualities ascribed to it.","Igor Ryazanov, Carl Öhman, Johanna Björklund",Atrium,Posters II,52,,818
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Do Social Cues Matter? Real-time Conversation Feedback to Increase Intellectual Humility Online,"Social media was once envisioned as a tool to unlock our “virtuous selves” by expanding the reach of knowledge, democratizing information, and bridging divides. However, its design has faced criticism for potentially fostering misinformation and affective polarization. In this paper, we explored the role that intellectual humility can play in mitigating these concerns about social media. We developed a custom-built social media testing environment, which allowed participants to interact with pre-seeded posts and AI-dialogue agents in a controlled environment, and a novel intervention designed to promote intellectual humility by providing online users with additional social cues, which are often lacking in digital spaces. In a randomized controlled trial with 275 participants, we examined whether providing additional social cues in digital spaces led to more intellectually humble behavior. 'Intellectually humble behavior' was measured using Perspective API. To better understand how pre-existing environmental factors amplify or attenuate the effects of such cues, we randomized the baseline level of intellectual humility demonstrated by the AI-Dialogue agents in the social media testing environment. We found consistent negative effects of being placed in an intellectually arrogant environment on both demonstrated and self-reported intellectual humility. This suggests that users may not only behave worse in intellectually arrogant environments, but also leave such environments believing they are less intellectually humble than when they entered. We did not find consistent effects of our social cue intervention on demonstrated or self-reported intellectual humility. This may be because the effects are subtle and varied, implying that a larger sample size or more accurate classification methods may be needed. Our research serves as a useful starting point for developing additional intellectual humility based interventions and highlights the need for improved classifiers to detect intellectual humility.","Samantha D'Alonzo, Rachel Chen, Melody Yu, Ivory Yang, Weicheng Ma, Martin Saveski, Soroush Vosoughi, Nabeel Gillani",Atrium,Posters II,53,,451
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,AI as Humans? : Using LLMs to Synthesize Human Responses in Persuasive Context,"As large language models (LLMs) continue to shape communication research, their ability to simulate human responses in persuasive contexts remains uncertain. This study investigates whether LLMs can replicate human-chatbot interactions by modeling belief change dynamics in persuasive dialogues. Using GPT-4o, we designed LLM-to-LLM interactions based on a prior experiment in which human participants engaged with a persuasive chatbot. Findings suggest that while LLMs can mimic certain linguistic patterns, they exhibit weaker belief shifts and less conversational variability than human participants. We discuss implications for AI-driven persuasion research and outline directions for expanding on the study.","Emily K McKinley, Yoo Jung Oh, Abdulaziz Alhumaidy, Jingwen Zhang",Atrium,Posters II,54,,669
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The Power of a Few: An Agent-Based Model of Affective Polarization and Targeted Moderation,"Affective polarization, or the deepening emotional divide between opposing political groups, marked by distrust and hostility rather than disagreements over policy has been a rising concern worldwide. While digital media platforms are often blamed for exacerbating this phenomenon, the mechanisms driving polarization remain contested. Traditionally, echo chambers were seen as the primary culprit, but recent evidence challenges this view, highlighting the role of elite discourse. Political and media elites amplify divisive rhetoric, reinforcing partisan identities and out-group hostility, whereas bipartisan cooperation can mitigate polarization. This study examines the effectiveness of content moderation strategies - specifically shadow-banning elites versus non-elites - in curbing affective polarization. Our agent-based model demonstrates that targeting elite rhetoric significantly slows polarization compared to broad-based moderation, underscoring the disproportionate influence of elites in shaping partisan divides. These findings call into question current moderation practices, which focus on mass content regulation rather than elite-driven polarization.","Narayani Vedam, Subhayan Mukerjee, Prasanta Bhattacharya",Atrium,Posters II,55,,303
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Assessing the role of emotions in the persuasiveness of AI-written articles about climate change,"While large language models (LLMs) are capable of generating messages that persuade humans in political contexts, we lack understanding of how well they employ different emotion frames. In this preregistered study, we conduct an online experiment with US-based participants (N = 1,746) to assess the persuasiveness of articles written by GPT-4 in a context where emotions have been identified as key drivers of mobilisation: climate change. To this end, we collect a set of articles about climate change from the Yale Climate Connections podcast that convey different types of climate emotions and generate corresponding articles with the same title, subtitle and length using GPT-4. We find that AI-written articles are at least as persuasive as the podcast benchmark and this remains the case when we control for article complexity in a follow-up experiment. Moreover, we find that emotions do not appear to matter as much for persuasion as suggested by previous research but that GPT-4 generated slightly more persuasive articles when conveying positive emotions compared to negative emotions.","Dylan Thurgood, Stefano Balietti, Florian Meier, Manuel Tonneau",Atrium,Posters II,56,,868
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Exploring the Influence of Gender Representation on Decision-Making in Human-AI Multilateral Bargaining,"As artificial intelligence (AI) becomes increasingly integrated into decision-making, its influence in complex environments like multilateral negotiations is growing. In multilateral bargaining settings, participants rely on coalition formation and offer initiation to maximize their earnings. Previous research on human-only bargaining has shown gender disparities, with men more likely to initiate offers and form alliances, leading to higher earnings and power imbalances. This study builds on these findings by examining how gendered AI agents (male, female, or non-gendered) influence coalition dynamics and decision-making in mixed human-AI groups. The tendency to anthropomorphize AIÑattributing human-like qualities, such as gender, to AI agentsÑshapes how people interact with them. Research shows that gender biases affect these interactions, with female-labeled agents often being exploited and male-labeled ones distrusted. These biases mirror societal gender stereotypes and can reinforce existing norms. Our study explores how gendered AI affects negotiation dynamics in a three-player bargaining setting and whether it amplifies or reduces existing gender disparities. This research contributes to understanding AI-human collaboration and its ethical implications. By investigating the impact of gendered AI on decision-making and negotiation outcomes, the study aims to inform the development of more equitable human-AI systems, helping guide future design and implementation in mixed human-AI environments","Tahmineh Godazgar, Diogo Geraldes, Max R. P. Grossmann, Taha Yasseri",Atrium,Posters II,57,,299
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,From Conversations Processes - LLM-aided Analysis of Adaptation Processes in a Direct Action Collective,"How do different dimensions of political work interact to constitute a set of intended and unintended responses to state-level repression, shaping the network structure, processes and relationships in an activist collective? I conduct in-depth interviews with 41 members of a grassroots, direct-action collective. Combined with field notes from observations over two months, this data provides rich insights into the complex emerging dynamics, changes in structure and processes, as well as their personal and collective sense-making. Given the sensitive nature of the group's activities, data collection is tied to the promise of complete confidentiality. This entailed exclusively offline analysis by one researcher only. This presentation outlines a local, open source implementation of the analysis from pre-processing to presentation of results. Local LLM implementations are used in all steps to augment the capacities and capabilities of the researcher. The framework for analysis includes the development and integration of contextual knowledge about the specific situation and timeline to improve the LLM's zero-shot learning. It uses the LLM in an auditable way through systematizing prompts and implementing chain-of-thought reasoning. Preliminary results show complex adaptation patterns on a network level constituted by rather simple individual and relational considerations. Individuals' opinions in a collective decision process are shaped by their and other members' a) well-being, and b) satisfaction with tasks within and strategy of the collective. Rules for decision-making and patterns of decision impact derived from the data, can provide a basis for modeling adaptation processes to repression on the network under different conditions.",Timo Damm,Atrium,Posters II,58,,586
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Exploring the Role of Randomization on Belief Rigidity in Online Social Networks,"People often stick to their existing beliefs, ignoring contradicting evidence or only interacting with those who reinforce their views. This tendency, referred to as being rigid in one's beliefs, is worsened by social media platforms which promote highly personalized content to maximize user engagement. It is crucial to study belief rigidity in online social networks, and design and evaluate interventions for it since increased belief rigidity can negatively impact real-life policy decisions such as climate inaction. Increasing randomization in the network can be considered one such intervention. In our research, we design an experimental framework to passively infer belief rigidity and empirically quantify the effects of introducing randomness into the network as an intervention strategy. We recruit 163 participants into two conditions: one emulating traditional online platforms and the other more random. Our results show that individuals' beliefs are positively influenced by peer opinions, regardless of whether those opinions are similar to or differ from their own. Moreover, when the platform recommends less personalized content, people are more likely to incorporate peers with slightly differing opinions into their networks. Our findings probe the idea that randomization offers advantages over personalization in certain situations and calls for the computational social science community to further investigate its potential.","Adiba Mahbub Proma, Neeley Pate, Raiyan Abdul Baten, Sifeng Chen, James Druckman, Gourab Ghoshal, Ehsan Hoque",Atrium,Posters II,59,,250
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Can large language models automate qualitative analysis? An examination of European Union Narratives on migration and solidarity,"Abridged Abstract Narratives are a fundamental mode of human sense-making, reflecting an impulse to connect events and actors with causal and thematic significance. While early scholarship focused on literary narratives, research across fields such as sociology, political science, and psychology has shown that narratives permeate real-world contexts. In political discourse especially, narratives can shape perceptions, impose order on complex issues, and communicate values and identities. Recent computational methods offer promising avenues for large-scale narrative analysis, yet many studies focus on disaggregated narrative componentsÑcharacters, events, or sentimentÑrather than examining how these elements form coherent, temporally structured plots. The emergence of Large Language Models (LLMs) such as ChatGPT-4 has fuelled new opportunities for comprehensive narrative analysis. However, questions remain regarding the extent to which these models can replicate the nuanced, context-sensitive insights typically provided by human experts. This research addresses that gap by examining how LLMs identify structural and thematic components of European Union institutional narratives on migration and solidarity. Drawing on a grounded theory approach, two narrative scholars developed a qualitative codebook to analyse a corpus of EU texts. We then used ChatGPT-4 to apply the same codebook, measuring both lexical and semantic similarity with human-led interpretations. By pinpointing where the model excels and where human expertise remains indispensable, we develop an evaluative framework that highlights the strengths and limitations of LLM-driven narrative research. Our findings illustrate how computational and qualitative methods can be fruitfully combined, advancing the study of political narratives at a scale beyond traditional qualitative approaches.","Luke Stephens, Clare Llewellyn, Lauren Rogers",Atrium,Posters II,60,,591
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Are generative AI text annotations systematically biased?,"Generative AI models (GLLM) like openAI's GPT4 are revolutionizing the field of automatic content analysis (Gilardi et al., 2023; Heseltine and Clemm von Hohenberg, 2024). Trnberg (2024) even finds they outperform human annotators on classifying the political leaning of Twitter/X posts in 11 different countries. However, there are also concerns raised against GLLMs, for example in terms of their potential biases (e.g. Ferrara, 2024; Motoki et al., 2024; Fulgu and Capraro, 2024). Although these critiques mainly focus on the answers GLLMs generate in conversations, the same concerns could likely apply to annotations. If this is the case the impressive performance of GLLMs might give a deceptive impression of the quality of the annotations due to the threat to validity posed by systematic, non-random errors. Systematic bias in text classification was a problem before the advent of GLLMs (e.g. Corizzo and Hafner, 2024; Ahmed et al., 2022). However, traditional ways to deal with such bias, like calculating performance metrics per relevant subgroup (for example race) or balancing the training data on relevant subgroups are not feasible for GLLMs. GLLMs are often applied zero shot, i.e. without training data. This complicates any efforts to address the bias upfront. Dealing with bias through calculating performance per subgroup on the other hand is hampered by the complexity of GLLMs. Fulgu and Capraro (2024) show that biases might work in unexpected ways in GLLMs and might be difficult to predict in advance. GLLM biases might have downstream effects via two different scenarios: (1) if each researcher used the same GLLM their results could be biased in the same way, making it more difficult for cumulative research to weed out biases in individual papers; (2) if different researchers use different GLLMs and each GLLM yields different - undetected - biases this could lead to contrasting and confusing research results hampering the progress of the field. On top of this GLLMs are queried using prompts. The effect of prompts on model performance is allegedly strong and unpredictable (Kaddour et al., 2023; Webson and Pavlick, 2022), making it difficult for researchers to predict biases resulting from a prompt. **Design** This paper therefore investigates whether different prompts of different GLLMs (Llama3.1:8b, Llama3.1:70b, GPT4o, GPT4-Turbo) lead to systematically different annotations. We are agnostic to the reason or driver for any bias, since these can be so unpredictable for GLLMs. Instead, we investigate whether annotations systematically vary or mostly overlap for four concepts relevant to measuring the deliberative quality of texts: interactivity, rationality, incivility and ideology. The performance of the models will be evaluated on three high-quality, manually annotated datasets. Two were used in previous research on online deliberation: The Twitter Deliberative Politics dataset by Jaidka et al. (2019) and the dataset used in Naab et al. (2025). The third is a newly coded sample of 3,862 YouTube and Twitter/X-comments replying to posts from prominent US TV news shows based on Boukes (2024). We compare the influence of different prompts based on the respective codebooks of these datasets. **First results** Our first analyses are based on the Twitter Deliberative Politics dataset as described in Jaidka (2022) (N = 5586). Results show strong [0.8] Pearson correlations between incivility annotations by GPT4o using prompts based on the codebooks by Boukes (2024) and Jaidka (2022). For rationality, results show very weak [0.05-0.25] Pearson correlations between annotations from different models (Llama3.1:8b and GPT4o) using the same prompt, and between the same model using different prompts (Jaidka and Boukes). **Implications and ongoing work** The first results show that the choice of GLLM and the prompt wording can influence the resulting annotations. The weak correlations for rationality indicate that it is quite conceivable that the three research projects we replicate would have reached different substantial conclusions had they used each other's codebooks. The next step will be to compare annotations of prompts across all included codebooks, models, datasets and concepts, also relative to the manual annotations. In this way, more general conclusions can be reached regarding the pervasiveness of biases in GLLM annotations. We will also investigate the effect of these biases on downstream research tasks and substantive conclusions by replicating the analysis of Boukes (2024) using annotations by all prompts and models.","Damian Trilling, Sjoerd B. Stolwijk",Atrium,Posters II,61,,22
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Codebook LLMs: Evaluating LLMs as Measurement Tools for Political Science Concepts,"CodebooksÑdocuments that operationalize concepts and outline annotation proceduresÑare used almost universally by social scientists when coding political texts. To code these texts automatically, researchers are increasingly turning to generative large language models (LLMs). However, there is limited empirical evidence on whether Òoff-the-shelfÓ LLMs faithfully follow real-world codebook operationalizations and measure complex political constructs with sufficient accuracy. To address this, we gather and curate three real-world political science codebooksÑ covering protest events, political violence and manifestosÑalong with their unstructured texts and human-coded labels. We also propose a five-stage framework for codebook-LLM measurement: preparing a codebook for both humans and LLMs, testing LLMsÕ basic capabilities on a codebook, evaluating zero-shot measurement accuracy (i.e. off-the-shelf performance), analyzing errors, and further (parameter-efficient) supervised training of LLMs. We provide an empirical demonstration of this framework using our three codebook datasets and several pretrained 7-12 billion open-weight LLMs. We find current open-weight LLMs have limitations in following codebooks zero-shot, but that supervised instruction tuning can substantially improve performance. Rather than suggesting the ÒbestÓ LLM, our contribution lies in our codebook datasets, evaluation framework, and guidance for applied researchers who wish to implement their own codebook-LLM measurement projects.","Andrew Halterman, Katherine A. Keith",Atrium,Posters II,62,,98
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Linguistic Pattern Analysis of AI-Generated Fake News for Enhancing Misinformation Detection,"This research explores the linguistic patterns that differentiate AI-generated fake news from human-authored content through an in-depth computational analysis. By employing seven datasets comprising ~137,000 news headlines, the study examines toxicity levels, sentiment analysis, moral foundations, and similarity metrics across real news, human-written fake news, and AI-generated fake news created with varying prompt emphases (General, Viral, Dubious, Sensational, and Extreme). The findings reveal distinct linguistic fingerprints: AI-generated sensational fake news exhibits the highest toxicity levels, while human-written fake news shows the lowest subjectivity, suggesting deliberate credibility enhancement. Different prompt types produce markedly different linguistic patterns, with some AI-generated content becoming nearly indistinguishable from human writing. These insights provide valuable direction for developing more effective misinformation detection tools to protect information integrity in contemporary news ecosystems.","Piyush Ghasiya, Kazutoshi Sasahara",Atrium,Posters II,63,,157
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Generative AI's Ability to Dispel Misinformation Across Four Topics,"The global surge in misinformation-driven challenges, from rising measles cases due to vaccine hesitancy to delayed climate action, highlights the urgent need for effective interventions against epistemically suspect beliefs (ESBs). While traditional fact-checking and educational approaches have shown limited success in addressing these beliefs, the emergence of large language models (LLMs) presents a novel opportunity for tackling misinformation through personalized, interactive dialogue. This research examines the efficacy of Generative AI (Gen AI) in addressing misinformation across four domains with varying levels of ideological entrenchment: climate change, vaccination, electric vehicles, and wind farms. Through four pre-registered experiments involving a total of 5,597 participants, we investigated the prevalence and predictors of misinformation, the effectiveness of GenAI interventions, and their comparative performance against traditional fact-based approaches. The methodology employed a consistent framework across all studies, featuring initial open-ended responses summarized by GPT-4o Turbo, followed by random assignment to either a three-round AI dialogue intervention or control conditions. Measurements included changes in belief confidence, agreement with domain-specific misinformation, and behavioral intentions, assessed both immediately post-intervention and during follow-up periods ranging from 10 days to one month. Our findings reveal conspiracy mentality and institutional distrust as the primary predictors of ESBs, explaining up to 78% of variance across domains, while traditional cognitive sophistication measures showed minimal correlation. Political and environmental identities demonstrated moderate relationships with ESB endorsement, though these effects were secondary to conspiracy mentality. The effectiveness of AI interventions varied significantly by domain, with the strongest impact observed in less politically entrenched areas such as electric vehicles (15% reduction in belief confidence) and wind farms (9.5% reduction), compared to more modest effects in vaccination (6.4%) and climate change (3%) domains. Notably, across over 10,000 messages, AI dialogues generated no instances of misinformation and generally outperformed traditional fact sheets in reducing confidence in participant-specific ESBs. While behavioral intentions showed stronger immediate improvements following AI interventions, these effects demonstrated faster decay than belief measures. Both intervention types showed partial effect decay at follow-up, though fact sheets occasionally demonstrated superior durability. These results illuminate both the potential and limitations of GenAI in misinformation reduction. The technology demonstrates capability for constructive dialogue without misinformation amplification, achieving meaningful belief changes through brief interactions. Future developments focus on enhancing AI-based interventions through sophisticated approaches targeting emotional and identity-based belief roots, and leveraging LLMs to improve human-human science communication capabilities through on-demand conversation practice and personalized feedback. This research contributes to our understanding of misinformation intervention effectiveness and suggests promising directions for combining technological capabilities with psychological insights to address the growing challenge of misinformation endorsement.","Samuel Pearson, Matthew Hornsey, Christian Bretter, Aimee Smith, Belinda Wade, Saphira Rekker, Jarren Nylund",Atrium,Posters II,64,,253
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The role of LLMs in Tackling Misinformation during the 2024 US Elections,"Misinformation in politics can be highly detrimental to democratic processes by fostering misperceptions and reducing trust in voting. We extend the larger literature on misinformation antidotes by bringing together three communicative features: personalized messaging, AI agents, and social networks. Specifically, we design an LLM-based agent to craft personalized responses based on the users' preferred trusted news sources and rhetorical style to support the truth, and then conduct an experiment around the 2024 U.S. presidential election (N = 1265) to evaluate the impact of such an LLM intervention on online networks. We find that our intervention helps individuals make beneficial (accurate) belief updates toward the truth. Moreover, it also influences individuals to opt for social networks that include others with beliefs closer to the truth. Our findings offer insights into how LLM interventions can counteract misinformation in online political discourse, particularly during critical election periods, and our methods can be adapted to design and evaluate personalized AI tools for related tasks.","Adiba Mahbub Proma, Neeley Pate, Gourab Ghoshal, James Druckman, Ehsan Hoque",Atrium,Posters II,65,,247
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Emergent Social Coordination and Collective Bias in LLM Populations,"Social conventions are the backbone of social coordination, shaping how individuals form a group. They can be defined as shared behavioural patterns, governing interactions from greetings - like handshakes or bows - to language and moral judgments. Recent numerical and experimental results have confirmed the hypothesis that conventions can arise spontaneously, without the intervention of any centralized institution. Individual efforts to coordinate locally with one another can generate universally accepted conventions. As AI agents increasingly engage in natural language communication, a pressing question arises: can they independently develop and sustain social conventions? If so, what dynamics govern these emergent norms, and how might they shape digital ecosystems and, eventually, human-AI interactions? Here, we show that social conventions can spontaneously emerge in LLM populations, collective biases can arise even without individual bias, and adversarial agents can steer norm formation - raising implications for AI alignment and human-AI interactions.","Ariel Flint Ashery, Luca Maria Aiello, Andrea Baronchelli",Atrium,Posters II,66,,139
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Beyond Anthropomorphism: Unveiling Unique Value Structure of Large Language Models (LLMs) via a Psychometric Approach,"As Large Language Models (LLMs) become increasingly sophisticated, understanding their inherent value systems has become crucial for effective AI alignment. While previous studies have approached this challenge through anthropomorphic frameworks, we propose ValueLex, a novel psychometric methodology that examines LLMs' value structures on their own terms. Using the Lexical Hypothesis approach, we collected over 43,000 value-related responses from 30+ different LLMs through carefully designed prompts and analyzed them using factor analysis and semantic clustering. Our findings reveal a distinct three-dimensional value structure unique to LLMs: Competence (comprising Self-Competent and User-Oriented aspects), Character (including Social and Idealistic dimensions), and Integrity (encompassing Professional and Ethical components). Evaluating 30+ LLMs on this unique value structure using Projective Tests, we identified three key phenomena: model-specific value prioritization patterns, quantifiable effects of different training methodologies on value expression, and scale-dependent value shifts where larger models show enhanced Competence at the expense of Character and Integrity dimensions. Unlike human value systems characterized by motivational tensions, LLM values exhibit non-antagonistic coexistence, suggesting fundamental differences in cognitive architecture that should inform future alignment strategies.","Muhua Huang, Pablo Biedma, Xiaoyuan Yi, Linus Huang, Maosong Sun, James Evans, Xing Xie",Atrium,Posters II,67,,628
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Freezing and Thawing of Linguistic Binomials,"A {\em binomial} is any phrase consisting of two words separated by `and'; it has the interesting property that the order of the words must be determined solely by the speaker, not grammar. For instance, while mostly everyone says `bread and butter' instead of `butter and bread', the binomial `Rachel and Tim' might have less agreement in the `natural' ordering. Thus the orderings of binomials can reveal hidden information about the speaker, the language, and the subjects involved. Binomials have been studied for more than a century by linguists mostly in the form of snapshots or case studies, but the dynamism of binomials has received very little investigation. Here we compile the largest set of binomials studied to date, spanning over 200 years of English text, and use this data to answer questions about how the orderings of binomials have changed over time, and what these changes can tell us about ourselves and our language.","Katherine Van Koevering, Ashley Young, Meryl Ye, Jon Kleinberg",Atrium,Posters II,68,,773
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Answer Production: Evaluating Methods for Producing Large Language Model Answers to Closed-Ended Survey Questions,"A growing body of research prompts large language models (LLMs) to answer survey questions, but LLMs are designed to produce open-ended text rather then closed-ended survey answers. We define techniques used to elicit closed-ended responses from large language models to survey questions on attitudes, opinions, and values as Answer Production Methods and we propose both supervised and unsupervised approaches to the evaluation of such Answer Production Methods. The unsupervised approach does not assume that human survey responses are ground-truth and it remains applicable even in the absence of human survey response data. We investigate 3 distinct answer production methods and our initial results from Llama 3.1 show similar trends between the methods in supervised and unsupervised evaluations. Our evaluations will help researchers to choose the answer production method that is best suited for a specific survey and LLM that they aim to investigate.","Georg Ahnert, Markus Strohmaier",Atrium,Posters II,69,,339
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,From CNNs to VLLMs: Redefining Connotative Image Clustering for Social Science Research,"The documented proliferation of visual content on online social networks highlights the need for effective image clustering tools. While traditional CNN-based algorithms provided meaningful results through object detection, they tend to underestimate connotative elements characterizing the pictures, focusing primarily on visual and spatial features. In response to these limitations, we propose a VLLM-based semantic clustering pipeline that performs image-to-text translation through GPT-4, in order to capture subtle social and cultural meanings embedded within the pictures, for successive clustering of the GPT-generated textual descriptions. Our approach was benchmarked against VGG16, a CNN-based state-of-the-art algorithm for image recognition, using a dataset of 11,873 images concerning climate change communication on social media. Our evaluation of the quality of the clusters generated by the two approaches (GPT-based and VGG16-based), conducted via statistical analysis of the cluster quality ratings produced by human encoders, showed that the VLLM-based methodology outperformed CNNs both in terms of the connotative quality and the interpretability of the clusters.","Luigi Arminio, Matteo Magnani, Matias Piqueras, Luca Rossi, Alexandra Segerberg",Atrium,Posters II,70,,191
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Generalist Penalty on Prominence: Configurations of Conceptual and Methodological Knowledge in Human History,"Knowledge creation serves a dual role by providing the foundational “shoulders of giants” for subsequent knowledge production while establishing the contributors’ prominence manifested by their influence and visibility. However, research on knowledge influence has been predominantly limited to science fields due to the accessibility of quantified data, resulting in an incomplete understanding of knowledge influence in non-scientific domains. Further, while scholarly achievements form the basis of individual prominence in the science field, our understanding remains limited regarding how the configurations of knowledge contributions shape individuals’ prominence. In response, the purpose of this paper is to use the data of historical figures of human history identified in the Pantheon database and examine why some historical figures in both scientific and non-scientific domains, such as politics, business, and culture, are more prominent as measured by the historical popularity indexes (HPIs) that this database provides. We examine knowledge configurations through two theoretical perspectives: the generalist-specialist framework and the conceptual-methodological knowledge typology. Generalists span multiple representational categories, typically facing legitimacy penalties as their category spanning increases. In terms of knowledge typology, concepts refer to the extent to which individuals propose and develop different ideas, frameworks, and problem-identification schemes, whereas methods capture their creation and application of diverse techniques and tools for problem-solving. In scientific domains, novel methodological knowledge generates more substantial subsequent influence than conceptual knowledge. This study leverages Wikipedia data and Large Language Models (LLMs) to extract and classify knowledge into concepts and methods, calculating knowledge breadth through the embedding of extracted labels to measure generalist characteristics. We analyze how historical individuals’ breadth of conceptual and methodological knowledge is associated with their prominence and how these associations have evolved over 5,000 years of human history. Through regression analyses of 28K historical figures, we present three primary findings and their theoretical implications. (1) Methodological knowledge demonstrates a decreasing embedding distance over time compared to conceptual knowledge. While previous studies have qualitatively distinguished between concepts and methods, our findings indicate stronger path-dependent properties in methodological knowledge. (2) We find a positive relationship between knowledge quantity and prominence, which is negatively moderated by knowledge breadth. This suggests that conceptual and methodological breadth becomes detrimental when producing unrelated ideas across scientific and non-scientific domains. (3) The temporal patterns in methodological knowledge may reflect the codification of knowledge corresponding to democratization through improved book distribution, libraries, public education, and literacy. Analyzing samples divided around 1800 CE, a period marked by mass education and literacy advancement, reveals that while conceptual generalist penalties remained stable, methodological generalist penalties emerged exclusively in the post-democratization period. This suggests an evolutionary pattern where new methods emerge through knowledge recombination, yet as methodological knowledge systems mature, society may discount the value of individuals who introduce unrelated methods.","Susumu Nagayama, Hitoshi Mitsuhashi",Atrium,Posters II,71,,59
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Forecasting Faculty Placement from Patterns in Co-authorship Networks,"The prestige of a researcher’s first faculty appointment plays a crucial role in shaping their academic trajectory, influencing access to funding, mentorship, and long-term career opportunities. As such, unraveling the mechanisms underlying faculty hiring is crucial to understanding academic career trajectories. While past studies have linked co-authorship to faculty placement, none have explored whether the temporal dynamics of co-authorship networks provide predictive power over individual faculty placement. As a result, we lack an understanding of how evolving co-authorship patterns influence who secures faculty positions at more or less prestigious institutions. This work introduces a new predictive task: forecasting the prestige of a researcher's first faculty appointment using the temporal structure of their co-authorship network. Unlike prior studies, we frame this as a prediction problem and evaluate whether signals embedded in researchers' evolving co-authorship relationships can help distinguish between different placement outcomes. To facilitate this task, we construct a temporal co-authorship network that integrates faculty hiring records, institutional rankings, and bibliometric data from tenure-track and tenured computer science faculty in the United States. We apply graph-based machine learning models to assess whether our co-authorship network contains predictive signals for faculty placement and explore a multi-class formulation of the task, predicting whether researchers secure positions at high-, medium-, or low-rank departments. The primary model, a temporal graph convolutional network (GConvGRU), embeds evolving network snapshots to capture structural patterns relevant to hiring. We compare against two baselines: a graph convolutional network (GCN), which captures static structure, and a gated recurrent unit (GRU), which models temporal trends without directly incorporating co-authorship relationships. GConvGRU achieves the highest Matthew’s Correlation Coefficient (MCC) of 0.42, outperforming GCN (0.39) and GRU (0.22), and is best able to distinguish medium- and low-rank hires from high-rank faculty members. While hiring decisions are influenced by multiple factors, our task definition, temporal coauthorship network, and modeling results suggest that network evolution plays a significant role. This work and the initial findings provide a computational framework for studying the role of co-authorship networks in shaping career trajectories, offering insights that may inform institutional policies on mentorship, collaboration, and hiring equity.","Samantha Dies, David Mingfei Liu, Tina Eliassi-Rad",Atrium,Posters II,72,,149
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Quantifying the effects of partition and reunification in Berlin's research landscape,"Partition and subsequent reunification in Germany provide a unique natural experiment to examine the impacts of geopolitical shocks on a nation’s science system. Nowhere was this experiment more evident than in Berlin, which, as the capital city, was partitioned into East Berlin (the capital of the German Democratic Republic) and West Berlin (the political enclave city in the Federal Republic of Germany). In this study, we draw on extensive bibliometric and geographic data to track the research trajectories of diverse organizations located in Berlin over several decades. We extracted relevant features of organizations in Berlin using the Research Organization Registry (ROR) database and discovered that approximately 55% of these entities were established after reunification. Moreover, our findings indicate that over 80% of these organizations began publishing in academic journals only after reunification, suggesting a significant growth in research activities. Since previous studies on scientific development in the Berlin Metropolitan region have been mainly conducted after the reunification, our analysis focuses on a carefully selected 38 organizations in Berlin. We integrated geographic information from the GeoNames database with thorough manual verification to accurately locate each organization to the corresponding region. These organizations have maintained publication records dating back to before 1990, allowing us to investigate the distinct research landscapes of East and West Berlin. We extracted metadata for journal articles published from 1900 to 2021 using the open-sourced OpenAlex database. By tracking the annual counts of these publications, we evaluate the research output in East and West Berlin over time. Notably, our findings reveal a marked decline in East Berlin's publication output following the construction of the Berlin Wall, suggesting an emerging inequality in the regional research landscape. Conversely, West Berlin steadily increased its annual publication counts throughout the same period. To further explore these trends, we focused on publications involving international collaborations by selecting articles that included contributions from institutions in multiple countries. This investigation shows that international collaborations in East Berlin began to emerge in the 1980s and accelerated rapidly after the fall of the Berlin Wall. These patterns suggest that the reunification of Germany reintegrates East Berlin into the global research community and revitalizes its academic and collaborative output. We intend to broaden our analysis by incorporating a co-authorship network analysis of the publications alongside a detailed examination of their disciplinary focus. This dual approach will enable us to discern patterns of collaboration and to identify whether specific institutions in Berlin or academic fields experienced more growth in scientific output following reunification. By mapping the collaboration networks and correlating them with disciplinary data, we aim to uncover the structural and thematic shifts in the research landscape. Furthermore, this analysis will allow us to speculate on the underlying factors that may have contributed to the recovery and resurgence of scientific productivity in certain areas, shedding light on the dynamics of reintegration. Although our findings are subject to the limitation on the scope and quality of OpenAlex data, this study still provides valuable insights into the impact of geopolitical shocks on urban scientific landscapes. Future studies could be built on our findings to better understand similar effects of external perturbations on scientific trajectories.","Huaxia Zhou, Aliakbar Akbaritabar, Emilio Zagheni, Luis A. Nunes Amaral",Atrium,Posters II,73,,202
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Mapping the Leaky Pipeline in Psychology: Analysis of Gender Disparities in Academic Progression,"Women have nearly achieved gender parity among doctoral graduates, yet their increasing entry into academia does not ensure long-term retention or career progression. Women’s careers are often shorter, slower, and less progressive than men’s, contributing to the leaky pipeline in academia. While individual barriers—such as research performance and hiring bias, or specific career stages—such as postdoc or tenure-track periods have been widely studied, a career-long perspective is lacking in identifying when and why women leave academia. Psychology presents an extreme case: women make up over 75% of students but only one-third of full professors, suggesting a distinct yet overlooked gender disparity compared to STEMM fields. This study investigates how attrition unfolds in psychology, pinpointing critical career stages and the role of early-career foundations and ongoing career development in women’s retention. We leverage large-scale bibliometric data from Scopus to track the academic trajectories of 78,775 psychology entrants (2000–2014 cohorts), minimizing left truncation while ensuring sufficient observation time. Gender was inferred using genderize.io, revealing a female-to-male ratio of 1.66. While female representation has grown across all career stages, transition rates to mid-career and senior levels have declined, with the largest gender gap (~10%) at mid-career entry. By 2014, only half of female psychology entrants remained in academia after eight years, highlighting higher attrition rates among women. This decline in transition rates to mid-careers compounds the already lower likelihood of reaching senior positions, further reducing women’s representation in academic leadership, despite their higher numbers at the entry level. To examine drivers of career survival, we integrated the Cox Proportional-Hazards model with gradient boosting (GBM-Cox), analyzing a range of factors, including individual characteristics (e.g., gender, cohort, primary field in psychology) and academic career contexts—both at entry into psychology and as they evolve over time. These factors encompass academic performance (productivity and citation impact), affiliation rank, academic location, and collaboration networks. Collaboration networks and scientific impact (five-year Discipline-Normalized Citation Score (DNCS), first-authored publications) emerged as the strongest predictors of retention, alongside early-career collaboration and cohort effects. While gender alone is not the dominant predictor, it interacts with career dynamics, influencing retention likelihood.","Xinyi Zhao, Anna Thoma, Ralph Hertwig, Dirk U. Wulff",Atrium,Posters II,74,,447
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Disentangling social and universal phenomena from face-to-face interaction networks,"The collection and analysis of empirical temporal contact networks have experienced remarkable growth over the past two decades. Sociopatterns, a research collaboration, has gathered high-temporal resolution data on physical proximity and face-to-face interactions across various social contexts, including conferences, schools, and hospitals [1]. These datasets have paved the way for a new wave of quantitative studies on individual and social behaviors. This advancement is particularly significant when combined with sociological and psychological metadata, ranging from basic socio-demographic and psychological observables to context-specific factors, such as academic status and prior participation, collected through participant surveys Ñ as demonstrated in studies conducted at conferences [2]. Further research has shown that certain behavioral characteristics appear to be universal and can be explained by simple mechanisms [3]. Disentangling phenomena that require social explanations from those that do not is a complex task, necessitating the development of new analytical methods. In this context, we identify among all determinants measured onto empirical face-to-face networks, the ones that can be correlated with social and psychological behavior, and those with universal properties. Starting with face-to-face interaction networks collected during four conferences with RFID sensors, along with metadata obtained through a survey completed by each participant, we refined basic network features such as similarity or temporal network features as reachability, while also developing new features tailored to the temporality and contextual characteristics of the data collection. The core idea of this methodology is to proceed systematically by elimination after each test. For each specific context, we apply Null models to generate randomized networks: if the observed feature significantly deviates from the Null models, we classify nodes based on this feature and perform a metadata correlation analysis to uncover the role played by social characteristics. Moreover, by leveraging the diversity of social contexts studied using consistent data collection methods, alongside statistical tests and renormalization processes to assess the relevance of behavioral observables, we compare these determinants across different contexts through longitudinal studies. For instance, we apply this method to loyalty, a measure of repeated interactions [4]. Building on the previous definition based on the Jaccard similarity measure, we introduce an alternative approach that considers the duration of interactions between individuals using Cosine similarity (Fig. 1). Through the analysis of coffee breaks, lunch breaks, and poster sessions across multiple conferences, we found that both measures of loyalty are correlated with individual properties and the social context. This method, by integrating network features with metadata analysis, provides researchers with a more comprehensive framework for analyzing and explaining social behaviors in face-to face interaction networks. We hope this approach will pave the way for the discovery of new quantitative social features, further expanding the scope of sociological studies.","Gabriel Maurial, Mathieu Génois, Elisa Klüger",Atrium,Posters II,75,,689
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Distinguishing Simple and Complex Contagion in Critical Spreading Processes,"We provide theoretical insights on how to distinguish different classes of spreading models based on real-world data. First, we demonstrate that simple contagion models and the Random Field Ising Model (RFIM) as a candidate for complex contagions are practically indistinguishable when analyzing short-term spreading dynamics or even the scaling laws of avalanches. Second, we show that the RFIM generates specific long-term memory effects that simple contagion models do not share. This enables a distinction of the models of simple and complex contagion on real-world data. We show in related work that these insights can be applied to demonstrate that information spread on the messenger platform Telegram can be well described by a RFIM, preferred to simple contagion models.","Roman David Ventzke, Anastasia Golovin, Andreas Christian Schneider, Viola Priesemann",Atrium,Posters II,76,,395
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Emergent Directedness in Social Contagion,"Network models of diffusion—spanning neuroscience, sociology, and organizational dynamics—typically assume symmetrical, undirected ties between nodes. Here, we show that even in undirected networks, directed ties emerge in the flow of contagions that require local reinforcement (complex contagions). Many real-world diffusion processes—such as social behaviors, cultural norms, and innovations—require reinforcement from multiple sources. We challenge the assumption that undirected networks facilitate symmetric diffusion, demonstrating instead that influence in complex contagions flows asymmetrically, favoring certain directions. Using a novel causal modeling framework, we quantify these directional biases, revealing that undirected ties often exert asymmetric influence. Our findings challenge core assumptions in network science and have significant implications for social influence and cultural evolution. A major consequence of emergent directedness is that long ties, often seen as critical for global connectivity, do not facilitate diffusion symmetrically. Instead, they preferentially channel contagion flow in one direction, reinforcing inequalities rather than promoting mutual influence. As contagion complexity increases, emergent directedness amplifies, shifting influence from periphery to core (Figure 1), contradicting the assumption that central nodes dominate diffusion. We analyze a range of synthetic and empirical networks, showing that emergent directedness is a fundamental feature of reinforcement-based diffusion, not an artifact of specific topologies. This structural bias has profound implications for network interventions. Asymmetric bridges dominate networks, accelerating one-way influence rather than fostering mutual exchange. We highlight the need to strategically reinforce asymmetric bridges to balance stability, efficiency, and equitable diffusion. A key methodological contribution is reconstructing causal paths in network diffusion. Unlike traditional shortest-path or static centrality measures, our framework traces actual activation sequences, revealing that nodes traditionally seen as central often play minor roles, while peripheral nodes facilitate contagion due to their strategic positioning. Extensive computational experiments using our Causal Tie Importance and Causal Node Importance measures confirm that asymmetry is an inherent property of reinforcement-based diffusion. Weak ties, traditionally seen as bidirectional facilitators, become increasingly asymmetric, reinforcing diffusion inequalities (Figure 3). We also find an inverse U-shaped relationship between reinforcement and causal importance, where moderately reinforced ties play the most critical role. These findings underscore the need for dynamic influence metrics that account for emergent directedness, offering a conceptual and methodological shift with profound implications for network interventions, influence dynamics, and structural equity.","Fabian Tschofenig, Douglas Richard Guilbeault",Atrium,Posters II,77,,616
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Modeling adaptive forward-looking behavior in epidemics on networks,"Incorporating decision-making dynamics during an outbreak poses a challenge for epidemiology, faced by several modeling approaches siloed by different disciplines. We propose an epi-economic model where high-frequency choices of individuals respond to the infection dynamics over heterogeneous networks. Maintaining a rational forward-looking component to individual choices, agents follow a behavioral rule-of-thumb in the face of limited perceived forecasting precision in a highly uncertain epidemic environment. We describe the resulting equilibrium behavior of the epidemic by analytical expressions depending on the epidemic conditions. We study existence and welfare of equilibrium, identifying a fundamental negative externality. We also sign analytically the effects of the behavioral rule-of-thumb at different phases of the epidemic and characterize some comparative statics. Through numerical simulations, we contrast different information structures: global awareness Ð where individuals only know the prevalence of the disease in the population Ð with local awareness, where individuals know the prevalence in their neighborhood. We show that agentsÕ behavioral response through forward-looking choice can flatten the epidemic curve, but local awareness, by triggering highly heterogeneous behavioral responses, more effectively curbs the disease compared to global awareness.","Lorenzo Nemati Fard, alberto bisin, Michele Starnini, Michele Tizzoni",Atrium,Posters II,78,,707
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"Networks, brokers and vaccination behaviour","Vaccine hesitancy, particularly regarding novel viruses such as COVID-19, poses a significant health threat both nationally and globally (WHO 2019). It reduces vaccine uptake, slows immunization efforts, and is notably higher among ethnic minorities (Robertson et al. 2021). This disparity exacerbates health inequalities and threatens herd immunity, as localized clusters of unvaccinated individuals can sustain viral transmission despite high overall uptake (Feikin et al. 2000; Omer et al. 2009). Previous research has identified greater hesitancy among ethnic minorities (e.g. Jama et al. 2018). Explanations for these disparities usually refer to group differences in socioeconomic attributes (e.g. Robertson et al. 2021). However, little is known about the role of social networks: how vaccination behaviour spreads within workplaces, residential areas, and family networksÐÐmaking it difficult to design effective interventions. Social networks usually exhibit homophily, where individuals sharing similar behaviors and traits are more likely to be connected to each other (McPherson et al. 2001). Because of this, networks are generally thought to amplify social inequalities (e.g., DiMaggio and Garip 2011). Social networks are generally also transitive, where friends of friends often also are friends. Together, homophily and transitivity imply segregated social networks that contain few and narrow paths linking the different groups together. In such situations, the individuals occupying those bridges between the groups, the ÔbrokersÕ (Burt 1992), become especially important for intergroup inequalities: they can either facilitate cross-group diffusion or hamper it. In this article, we aim to analyze patterns of social exposures and influence in order to examine the conditions under which brokers can effectively diffuse vaccination behaviors between groups and reduce intergroup inequality. To achieve this, we have access to a unique population-scale Swedish register data set that contains, on the one hand, detailed individual-level information on vaccinations, and on the other, extensive information about individualsÕ social contexts, including kinship, workplaces, and residence, that together enable a comprehensive analysis of social influence. Under what conditions can we expect brokers to effectively diffuse vaccination behaviors between groups? To identify these conditions, we draw upon prior theoretical models of social influence (Granovetter 1973; Mark 2003; DiMaggio and Garip 2011; DellaPosta et al. 2015; Golberg and Stein 2018). This research tells us that in order for social influence to effectively diffuse novelty, the senders and receivers of social influence can neither be too similar nor too dissimilar to one another. If they are too similar to each other, they are unlikely to expose each other to novelty. Conversely, if they are too dissimilar, the recipient of the exposure is unlikely to trust the sender, dissipating social influence. From this, we postulate that the following conditions are required for brokers to play a meaningful countervailing force in vaccination inequalities: ¥ There must be different vaccination levels between the two social settings. ¥ The setting with lower vaccination levels is the receiving setting, while the setting with higher vaccination levels is the sending setting. ¥ The broker must be sufficiently similar to individuals in the receiving setting for their influence to be meaningful. ¥ In line with similarity-biased social influence, if the broker is too dissimilar from their peers in the receiving setting, the transmission of influence will be ineffective. Using the population-scale data set mentioned aboveÐÐcontaining information both about social contacts and vaccination behaviors and detailed information about the date of COVID-19 vaccinationsÐÐwe will empirically scrutinize these hypothesized conditions. To distinguish social influence from homophily, we adjust for an extensive set of variables describing the individuals and their social contexts. We further adjust for confounders we draw upon recent advances at the intersection of machine learning and econometrics that use node embeddings to attain proxies for latent homophily based on individualsÕ position in the network (Veitch et al 2019). We expect our study to improve pandemic preparedness by providing evidence on how social networks, context, and sociodemographic factors shape vaccination decisions. The analysis of structural holes provides insights into how and under what conditions brokers may facilitate or hinder vaccine uptake, offering a network-based perspective that can inform more precise and context-sensitive public health interventions. While this research focuses on Sweden, its insights have broader relevance for combating vaccine hesitancy globally.","Emanuel Wittberg, Martin Arvidsson, Maria Brandén, Richard Öhrvall",Atrium,Posters II,79,,443
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Experimental decision-making under uncertainty reveals boundaries to the strength of long ties,"Long ties in social networks connect individuals with few mutual contacts. Do they facilitate the large-scale propagation of new products and behaviors? The vast, cross-disciplinary literature on social contagion has generated conflicting answers. To understand the origins between extant disagreements and identify the conditions under which long ties are beneficial, we develop here an experiment that enables the theoretical analysis of new behavior spreading. This is done without imposing a priori assumptions on individual decision-making. In the proposed experiment, individual choice functions are measured by exposing participants to repeated tasks under various levels of social signals and uncertainty. We find that the strength of long ties only holds for tasks characterized by low uncertainty but disappears as uncertainty grows. The proposed experimental design may be generalized to study the spread of a broader set of factors that affect the success of the spread.","Luca Lazzaro, Manuel S. Mariani, René Algesheimer, Radu Tanase",Atrium,Posters II,80,,241
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Spatial Mobility and Housing Demand in a Dynamic Microsimulation Model,"Adequate and affordable housing as a basic social need has been a highly relevant issue for years, affecting large parts of the population and posing a political challenge. We use a dynamic microsimulation model to simulate population dynamics and long-term housing demand. Basic demographic events such as household formation and dissolution, employment, income and regional mobility are simulated annually on a modular basis for the entire population of Germany at the local level. Migration movements are particularly important for the development of the regional population structure. Special emphasis is therefore placed on their relationship with housing demand. Considering microsimulation as a way to deal with complex issues at the level of individuals and households, we present modeling strategies for a) estimating the residential relocation probabilities of entire households and individual household members, and b) housing choice in the form of different housing characteristics. The models consider the composition of the household and the socio-economic characteristics of its members. We discuss data requirements, current limitations and present first results for a baseline scenario as well as for scenarios with altered assumptions on residential mobility.",Sarah Bohnensteffen,Atrium,Posters II,81,,1054
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,"Hierarchical innovation networks in China yield more mobility, but less diversity","National cultures shape the structure of interpersonal relationships across social and economic life.1–4 These influence not only the creation and reproduction of social opportunities, but also their consequences for the ideas and artifacts they generate for society.5–7 Theorists have argued for a distinction between the formation of Chinese “clan”-like hierarchical structures versus U.S. “club”-like egalitarian structures，8–10 but difficulties in conceptualizing these small-group structural phenomena at scale and assessing their distribution across data in comparable domains has thwarted empirical analysis.11 Utilizing a fractal conception of micro-social structure embedded within agent models and validated on domains covering science, technology, and culture, here we demonstrate consistent differences between Chinese and U.S. networks that structure the production of innovation. Across innovation domains, Chinese networks manifest shorter path lengths, higher global efficiency, greater average closeness centrality, and lower inequality in degree centrality. U.S. networks, by contrast, manifest greater inequality in degree centrality, less information distribution speed, and more unevenly connected networks. These patterns reflect differences in respect for local authority and have marked implications for collective innovative outcomes. Chinese networks condition more turnover, and more personal mobility across topics, while U.S. networks support greater persistence and a carrying capacity for more ideas.","Yuanyi Zhen, Jar-Der Luo, James Evans",Atrium,Posters II,82,,74
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Mesoscopic description of deviations from gravity models in Austrian migration flows,"Migration plays a crucial role in urbanization, segregation, gentrification, and numerous phenomena related to socioeconomic development. While much of the existing research has focused on international migration, many questions are still unanswered for a comprehensive understanding of internal migration, making it the focus of this study. We employ inferential network clustering methods to analyze high-granularity administrative data about internal migrations in Austria. The mesoscopic description of the migration data within the country highlights two complementary deviations from traditional gravity models for migration flows: (i) an effect of the administrative boundaries and (ii) the presence of an urban-rural divide. Our results highlight the limitations of conventional models in migration studies, whilst presenting a robust methodology to address these challenges. This paves the way for a comprehensive understanding of migration dynamics and provides valuable insights for more informed policy-making.","Thomas Robiglio, Martina Contisciani, Marton Karsai, Tiago P. Peixoto",Atrium,Posters II,83,,425
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,A Synthetic Dataset and Framework to Test Pre-processing Algorithms of Human Mobility Data,"Garden City is an open-source agent-based model designed to generate synthetic human mobility trajectories for evaluating GPS data processing algorithms. Commercial GPS datasets often suffer from biases, sparsity, and noise, making it difficult to validate preprocessing methods such as stop detection and home attribution. Our model simulates realistic movement patterns with configurable levels of noise, temporal sparsity, and bursty ping clustering, providing a controlled ground-truth dataset for testing algorithm robustness. We demonstrate the utility of Garden City by analyzing how signal sparsity affects DBScan-based stop detection, showing that different levels of local sparsity can lead to significant variations in detected stops. By offering a transparent and reproducible testbed, Garden City enables researchers to fine-tune mobility algorithms before applying them to costly, real-world datasets. A synthetic dataset of 40,000 users with year-long trajectories is publicly available.","Thomas H. Li, Francisco Barreras, Duncan J. Watts",Atrium,Posters II,84,,945
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Bike Lanes and Rider Diversity: Analyzing Citi Bike Data in New York to Evaluate Cycling Infrastructure’s Effect on Gender and Age,"Bicycle ridership in most American cities is overrepresented by men and younger adults, which leaves out a large percentage of the population from the benefits of cycling, and prevents cities from reaching their sustainable-transportation goals (Le et al., 2019; Garrard et al., 2021). A key factor contributing to this limited demographic profile of urban cycling is the provision of bicycle lanes (or lack thereof), with evidence that cycling by women and older adults will remain low unless and until high-quality bike lanes are provided (Pucher et al., 2010; AitbihiOuali and Klingen, 2022). Though, associations between bicycle infrastructure and bicycle ridership have primarily been studied in the context of individual lanes and corridors, or when analyzed at the scale of entire cities, generalized across different bike-lane types. With this context, we pursue a simultaneously comprehensive and fine-grain analysis of bike lanes and bikeshare trips, in the case of New York City, which maintains both a massive and expanding bike-lane network, as well as North AmericaÕs largest bikeshare system (Citi Bike). By linking roughly eight million trips from Citi Bike to the individual bike lanes where they occur, we demonstrate that in New York bikeshare routes with higher shares of female riders cluster to a greater extent on protected bike lanes (those which include some form of physical barrier or buffer from cars), compared to both painted bike lanes (where a line of pavement marking is present), and sharrows (where a normal traffic lane is marked with a bike stencil). Second, bikeshare routes with a higher percentage of riders over 50 years old also cluster to a greater extent on protected bike lanes, whereas the reverse is true as the share of riders under 25 years old increases. Third, growth in bikeshare trips overall is significantly higher on routes where protected bike lanes have been installed, compared to both painted bike lanes, and sharrows. These findings collectively demonstrate the distinct benefit of protected bike lanes in expanding the demographics of those who bike, both in terms of gender and age, and increasing bikeshare trips generally. This data-mining approach raises a number of additional spatial questions to pursue in terms of evaluating the performance of new bicycle infrastructure, and provides evidence for the prioritization of protected bike lanes to planners at the scale of a mega city.","Marcel Moran, Malik Salman, Takahiro Yabe",Atrium,Posters II,85,,317
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Temporal shifts in human perception of automated vehicles,"Over the past decade, the landscape of automated vehicles (AVs) has seen major shifts across technical, legal, and psychological domains. We investigated how public attitudes towards AVs have evolved. We first conducted eight replication studies in the US and China (2022 to 2023, N = 5,358) to assess blame and responsibility attributions for crashes involving shared-control AVs. Results show that US and Chinese participants attributed more blame to the primary driver, whether human or machine. We also investigated public perceptions of AV safety and capability in a four-wave survey (2020 to 2023, N = 4,900) and analysed public sentiment through AV-related social media posts (2014 to 2023, N = 443,808 posts) in China, both of which revealed declining public enthusiasm for AVs over time. Collectively, these findings suggest a tendency toward more calibrated and less enthusiastic public views of AVs. They also highlight the need to consider these changes in policy formulation and the challenges of single-snapshot studies in volatile, fast-evolving tech domains.","Peidong Mei, Yueying Chu, Yunhao Cai, Peng Liu, Edmond Awad",Atrium,Posters II,86,,608
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The (changing) role of central places in ameliorating exposure segregation,"Here we examine how urban hierarchy shapes socio-economic mixing in cities, with particular attention to downtowns. While previous research suggests that strategically placed ""bridge"" amenities facilitate mixing between different socioeconomic groups, our analysis of mobility data reveals that central business districts play a more significant role than their bridging potential would predict. Using counterfactual simulation and visitation data across 5 million points of interest, we demonstrate that downtown areas achieve greater mixing despite their theoretical segregation potential. This phenomenon is explained by their function as central places in urban networks, drawing diverse commuters past intervening amenities. The COVID-19 pandemic demonstrated the significance of this effect, as remote work reduced downtown commuting and consequently reduced mixing by 8%. These findings highlight the crucial role of urban hierarchies in fostering socioeconomic integration and suggest that post-pandemic shifts in work patterns may significantly alter urban mixing dynamics by disrupting established hierarchical structures.",Andrew Renninger,Atrium,Posters II,87,,561
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Reproduction of Social Inequalities in the Digital Space,"The paper sets out to investigate how social inequalities are reproduced in the digital space. To this end, we analyze the relationship between social position and observed digital activity on multiple platforms, such as Facebook, Google, and YouTube, drawing on Pierre Bourdieu's theoretical framework. The research paper is based on two main questions. The first is whether the structure of the contemporary Hungarian society can be represented along Bourdieu's La Distinction, namely in terms of the amount of total capital available and the distribution of economic capital and cultural capital. The second question, based on Bourdieu's homology thesis, was how social space and symbolic space are related to each other. How is the position in social space linked to the social practices of individuals: to their leisure activities, cultural consumption, or taste mirrored the digital activity of individuals. The data was collected with a data donation approach. After informed consent, respondents completed an online questionnaire, then downloaded all their information stored by digital platform providers and donated it to the researchers. The final sample consisted of 758 individuals and is representative of the Hungarian internet user population in terms of gender, age, education and geographical region in a country, where internet penetration is 89 percent. Participants analyzed in this paper all donated their Facebook, Google, and YouTube data. Multiple Correspondence Analysis was used to project categories of multiple discrete variables into a single two-dimensional Euclidean space. This map gives a low-dimensional approximation of the association structure of the variables: two categories of two different variables close to each other on the map are likely to co-occur for respondents. To describe the social space, following similar approaches, we used several indicators of economic capital and cultural capital derived from the survey part of the data collection. For having comparative indicators across platforms, digital activities were classified into 26 distinct categories based on Google Trend. In order to take into account digital activities not too distant from the time of the social position survey, only digital data after July 1, 2018 were considered. The first result of our study indicates that using the traditional indicators of economic and cultural capital, the social space in contemporary Hungary does not align with the image suggested by Bourdieu's works. The analysis shows that wealth inequalities are much more significant than the fine differences generated by income and educational attainment and thus, today's Hungarian society is more one-dimensional than the former French or the current Norwegian society, with a greater role of wealth differences. Interestingly, using other, less traditional indicators for the same concepts results in the expected two-dimensional space, where additionally to total capital, another dimension of stratification appears Ð a similar structure to that found in previous studies. Accordingly, the stratification of social space is determined by the amount of total capital. In addition to this dominant dimension, the cultural milieu of the home (as measured by mother's educational level) and the distribution of economic and cultural capital in the capital portfolio also play a role. Moreover, on the horizontal axis, there is a distinction between those occupations that require more comprehensive theoretical knowledge and those that are based on technical knowledge. Projecting digital activity categories to the space of offline social inequalities we can observe that most of the activities are concentrated in the center of the space, but the location of the different activities also indicates a certain degree of homology between the offline social space and digital space Ð and platform-specialized patterns are also present. A good example is travel and religion themed Facebook events being attended by those with more total and cultural capital, while beauty related events are also of interest to those with high capital, but mainly to those with economic capital. In contrast, entertainment and celebs as well as shopping, and related discounts are more popular among those with lower total capital. Those with higher amount of total capital are more likely to google to topics related to art, technology, and science. We can also observe that those with low total- and especially cultural capital, are less likely to search about most of the topics. Interestingly, we did not find remarkable differences in YouTube video consumption along social groups. In the subsequent phase of the research, we plan to include additional data for the investigation of the homology of social space and symbolic space with other domains, including leisure activities, music taste, news consumption, and political attitudes.","Julia Koltai, Ákos Huszár, Zsófia Rakovics, Kata Számel, Michelle Horváth, Anna Sara Ligeti, Szilvia Rudas, Emese Bata, Bendegúz Váradi, Zoltan Kmetty",Atrium,Posters II,88,,790
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Cross-Gender Social Ties Around the World,"We introduce, analyze, and describe subnational data on cross-gender friendships for nearly 200 countries and territories, using data from 1.38 trillion ties between 1.8 billion Facebook users. Homophily by gender exists nearly everywhere, with individuals' strongest ties exhibiting less homophily than their peripheral connections. Across countries, cross-gender friendship rates align with existing measures of gender disparities. Within countries, cross-gender friending rates correlate with support for gender equality. In the US, cross-gender friendships are rarer in areas with a larger White share of the population, higher incomes, and more per-capita religious congregations. We share our data at https://data.humdata.org/dataset/cross-gender-ties.","Drew Johnston, Michael Bailey, Theresa Kuchler, Ayush Kumar, Johannes Stroebel",Atrium,Posters II,89,,436
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Descriptions of women are longer than those of men: An analysis of gender portrayal in Stable Diffusion prompts.,"Generative AI for image creation emerges as a staple in the toolkit of digital artists, visual designers, and the general public who want to augment their representation toolkit. Social media users have many tools to shape their visual representation: image editing tools, filters, face masks, face swaps, avatars, and AI-generated images. The importance of the right image can not be understated: It is crucial for creating the right first impression, sustains trust, and enables communication. Conventionally accepted representation of individuals, groups, and collectives may help foster inclusivity, understanding, and respect in society, ensuring that diverse perspectives are acknowledged and valued. While previous research revealed the biases in large image datasets such as ImageNet and inherited biases in the AI systems trained on it, within this work, we look at the prejudices and stereotypes as they emerge from textual prompts used for generating images on Discord using the StableDiffusion model. We analyze over 2.4 million prompts depicting men and women and use statistical methods to uncover how prompts describing men and women are constructed and what words constitute the portrayals of respective genders. We show that the median male description length is systematically shorter than the median female description length, while our findings also suggest a shared practice of prompting regarding the word length distribution. Regarding word and topic analysis, our findings suggest the existence of classic stereotypes in which men are described using dominant qualities such as ""strong"" and ""rugged"". In contrast, women are represented with concepts related to body and submission: ""beautiful"", ""pretty"", etc. These results highlight the importance of considering the original intent of the prompting and suggest that cultural practices on platforms such as Discord should be considered when designing interfaces that promote exploration and fair representation.","Yan Asadchy, Maximilian Schich",Atrium,Posters II,90,,177
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Hustling Health: The Blurred Line Between Personal Narratives and Product Marketing in PCOS and Endometriosis Content on TikTok,"Despite significant advancements in medical research, women's reproductive health continues to be marked by substantial knowledge gaps and systemic biases. Conditions such as endometriosis and polycystic ovary syndrome (PCOS) often go underdiagnosed (WHO, 2023a, 2023b). This has led to a trust deficit between women and healthcare providers, resulting in delays in treatment and womenÕs lowered confidence in medical professionals (Dusenbery, 2017). These medical burdens have severe effects on womenÕs lives in terms of both physical and mental well-being, as well as their workforce participation and career prospects (WEF, 2024). In this context of mistrust and inadequate medical support, women report turning to alternative sources for health information and support (UK DHSC, 2022). Social media platforms and online discussion forums have emerged as critical spaces where women share personal stories, seek advice, and encounter a range of health-related content (Holbrey & Coulson, 2013). However, some users and companies on social media promote questionable alternative health solutions without clearly indicating they are advertisements, which makes it difficult for viewers to distinguish between commercial and non-commercial content. This applies in particular when this content is produced by social media influencers who use their authentic appearance to establish trustworthiness and parasocial relationships with users (Schwemmer & Ziewiecki 2018, Liu & Zheng, 2024). For this study, our aim is to quantify how much of the content on TikTok related to PCOS and endometriosis is 1) mentioning a product, 2) directly selling the products to users, and 3) what categories of products are being sold. Subsequently, we examine whether these product-selling videos are clearly marked as promotional content (e.g. by using a label provided by TikTok) or are framed as a personal story. Lastly, we aim to quantify the proportion of Òsnake oilÓ products, i.e., products that do not or cannot work as advertised. For our first dataset, spanning 7 days in October 2024, we used the keyword-based search of the TikTok API to collect 14728 TikTok posts related to PCOS and endometriosis. We downloaded the corresponding post videos, photos, and audio by web scraping. Finally, we enriched each post in our dataset with speech-to-text transcriptions from OpenAIÕs Whisper-1. Next we determined whether each post referenced weight loss and fertility, and whether the post mentioned a product/service even going as far as selling it directly. To establish a baseline for classification, we manually labeled 70 posts from our dataset. We use this set as ground truth to compare a classifier against. To classify the full dataset (14728 videos), we used Gemini 1.5 Pro (gemini-1.5-pro-002), because the model is able to consume heterogeneous types of input data (text, image(s), video, audio), and has a context window long enough for long-video QA (1M tokens). Our goal was to have the model reproduce classifications like the human labelers, as measured by the agreement with the human labels on the ground truth set. When inspecting disagreements, we often found that the model was correct and that the human labeler had overseen a key detail in the post. We iterated on the prompt until we were satisfied with the agreement level. The final agreement between model- and human-generated labels was high: between 87% and 97% on 5 out of 7 questions, and only low (47%) for 1 question, which asked if the product/service is misleading. We did not provide the model with any previously labeled examples (called zero-shot setting). Our preliminary results show that 40% of videos related to endometriosis and PCOS include direct-to-consumer sale of products. These products are most commonly herbal remedies, supplements and consultations, often addressing the conditions themselves or related symptoms such as weight gain or fertility issues. Less than 3% of posts directly selling products indicated such through the TikTok provided Òpromotional contentÓ or Òpaid partnershipÓ labels. Moreover, 29% of the posts selling products were framed as a personal story. As of now we are expanding our dataset from 7 days to 3 months to have a fuller picture of the discourse around PCOS and endometriosis. In terms of our classification model, we are improving the agreement with human labels by providing a few labeled posts in the prompt (few-shot setting). The labeled examples should clear up ambiguous cases that human labelers often resolve in informal conversations, like the question about misleading products. We aim to present our new findings at IC2S2 in Sweden. In summary, this study examines product marketing in TikTok content on PCOS and endometriosis, focusing on covert advertising and misleading Òsnake oilÓ remedies. The results of this study have implications for (public) health sciences, and can guide policy-making to improve content moderation on social media platforms.","Renata Topinkova, Tomas Ruiz, Carsten Schwemmer",Atrium,Posters II,91,,421
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Self-Disclosure of Mental Health via Deepfakes: Testing the Effects of Self-Deepfakes on Affective Resistance and Intentions to Seek Mental Health Support,"The Impact of Work The advancement of artificial intelligence (AI)-enabled deepfake technology, which digitally manipulates a person’s appearance, serves as a double-edged sword. Deepfake technology’s ability to create hyper-realistic content has raised concerns among scholars due to its potential to deceive and propagate false information (e.g., Lee and Shin, 2022; Lee et al., 2023; Pantserev, 2020). However, this same realism holds promising potential for positive applications, particularly in healthcare. For instance, tailored visualizations generated through deepfake technology can motivate individuals to pursue physical improvements in personalized training programs (Clarke et al., 2023). These applications highlight the transformative potential of deepfake technology in addressing health-related challenges. This suggests that personally relevant information becomes easier to process and more persuasive (Burnkrant and Unnava, 1989; Rogers et al., 1977). Despite its potential for healthcare applications, scholarly discourse underscores the need for nuanced research on deepfake technology, as its use often evokes discomfort rooted in uncanny valley perceptions (Weisman and Peña, 2021), which can diminish the effectiveness of health interventions (Appel, 2022). This study investigates emotional barriers linked to uncanny valley effects in health messaging, comparing three conditions: self-deepfakes, celebrity deepfakes, and virtual agents delivering self-disclosure messages in mental health contexts. Self-disclosure plays a critical role in fostering self-efficacy and promoting intentions to seek mental health support (Rüsch et al., 2011; Wu et al., 2022). This study addresses how emotional resistance to mental health messages incorporating self-disclosure can limit their effectiveness in encouraging help-seeking behaviors. Given the positive impact of celebrity and virtual agent endorsements in raising public awareness about mental health (Gronholm and Thornicroft, 2022; Kim, 2024), this lab-based experiment evaluates the effects of deepfakes in such interventions, weighing their personalized benefits against potential drawbacks. Main Theoretical Contribution Theoretically, the study revisits traditional video self-modeling approaches that leverage the self-referencing effect to enhance engagement, applying them to deepfake technology by integrating insights from the uncanny valley effect. Findings reveal that the synthetic nature of self-deepfakes introduces artificiality that triggers discomfort, increasing resistance to mental health self-disclosure messages. This resistance is particularly pronounced among individuals with poorer baseline mental health who find the topic highly relevant. These findings underscore limitations of deepfake technology in sensitive contexts, as uncanny representations can deter engagement with health messages. Future research should systematically explore the boundaries of self-referencing in AI-driven media. As deepfake technology becomes integrated into healthcare, practitioners must remain mindful of its potential to stir emotional resistance alongside its innovative possibilities. Data and Methods This lab-based study used a one-way within-subjects experimental design with three conditions: self-deepfake, celebrity deepfake, and virtual agent videos. Participants were recruited from a private university in South Korea and completed pre-test (Wave 1) and post-test (Wave 2) surveys, with a one-week interval to allow for the creation of high-quality personalized deepfake stimuli. Of 24 participants initially recruited, 21 completed both phases. Stimuli creation involved collaboration with AI engineers. Self-deepfake videos were produced using FaceFusion, enabling seamless facial exchanges. Celebrity deepfake videos featured a South Korean celebrity (Song Hye-kyo) delivering a self-disclosure message, with voice cloning via Speechify and lip synchronization using Diff2lip (Mukhopadhyay et al., 2024). Virtual agent videos were created with DeepBrainAI, featuring a human-like digital character sharing personal experiences with mental health. All videos were approximately 90 seconds long. Findings Self-deepfakes elicited greater affective resistance than celebrity videos, reducing help-seeking intentions. However, no significant differences were observed between self-deepfakes and virtual agents. Participants with poorer baseline mental health exhibited heightened resistance to self-disclosing messages featuring self-deepfakes, while virtual agent videos did not evoke similar resistance regardless of mental health levels. These findings highlight the need for caution when employing deepfake technology for sensitive health messaging, as its artificiality can provoke negative reactions, undermining the message’s effectiveness.","Jiyoung Lee, Christopher Michael Dobmeier, Minji Heo, Simon S. Woo",Atrium,Posters II,92,,64
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Follow Nudges: Targeting Inaccurate Health Information Networks via a Large-Scale Online Field Experiment,"Can digital ads encourage users exposed to inaccurate information sources to follow accurate ones? We conduct a large-scale field experiment on X (formerly Twitter) with users who follow accounts that post health misinformation as identified by PolitiFact. Participants are exposed to four potential types of ads, varied on two dimensions: a neutral message versus a message appealing to values of independence, and a request to follow a U.S. heath institution versus a request to follow a health influencer. We track the efficacy of this intervention as measured by click-throughs on each of the four ad treatments as well as new follows of the promoted health accounts.","Laura Kurek, Eric Gilbert, Ceren Budak",Atrium,Posters II,93,,495
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Representations of ADHD and autism have converged on social media: A computational analysis of trends in Reddit data.,"Interest in the co-occurrence and overlap of attention deficit hyperactivity disorder (ADHD) and autism has risen since the DSM-5 allowed them to be diagnosed together in 2013. Public attention to the two conditions has also risen due to neurodiversity advocacy on social media, although the impact of this heightened visibility remains underexplored. We aim to examine how the relationship between ADHD and autism has evolved in public discourse over the past decade and explore reasons for their growing alignment. Using Reddit data from 2012 to 2022, we investigated the frequency of ADHD mentions in r/autism and autism mentions in r/ADHD. We analyzed user overlap between the two subreddits to track cross-community discussions. Semantic similarities between ADHD and autism were also evaluated. Finally, thematic changes in subreddit discussions were explored using a BERT-based topic modeling method. We found that ADHD and autism have become progressively more associated based on increasing co-mentions, overlapping users, and semantic similarity. In addition, topic modeling indicated growing thematic convergence in ADHD- and autism-related discussions, which reflected an increasing shared emphasis on the experiences of adults with ADHD and autism, challenges in accessing diagnostic assessments, and interpersonal difficulties. Our study clarifies how discourse around these two conditions has converged during a period when they have both attracted rising public attention.","Jemima Kang, Nick Haslam, Mike Conway",Atrium,Posters II,94,,72
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Media bias in portrayals of mortality risks and health behavior,"The actual abstract is a PDF, but here's a short version: Chronic diseases cause the majority of deaths in the U.S.A., but preventative measures known to effectively combat them receive relatively little healthcare funding and support. Our study examines how media coverage might contribute to this discrepancy by overemphasizing sensational risks and underemphasizing chronic illnesses. We compared monthly mortality data on 14 risks, drawn from CDC Wonder, with 823,406 relevant newspaper articles collected via LexisNexis from 1999 to 2020. Regression analyses and qualitative evaluations using natural language processing tools reveal a marked disconnect between the deadliest risks and their media coverage. While coverage does track mortality rates to a degree, only ~2% of the variance in coverage is explained by changes in deaths. Chronic diseases were portrayed neutrally as individual challenges, whereas sensational risks were framed negatively with collective, policy-focused solutions. These findings suggest media reports often paint a skewed picture of mortality threats, potentially distorting public understanding of which risks are most critical and how to address them. We will extend this work by analyzing how health behaviors are depicted in media coverage, presenting updated findings at the conference.",Calvin Isch,Atrium,Posters II,95,,68
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Is AI mingling or bullying me? Exploring User Interactions with a Chatbot in China,"This study investigates Chinese viral social media chatbot, Weibo-launched Comment Robert’s role in shaping human-AI communication by analyzing 4,100 user-submitted screenshots from the Robert Victims Alliance. Using computational linguistic approaches such as sentiment analysis and topic modelling, we explore how users perceive and emotionally respond to Robert’s unpredictable engagement. Findings from this study address critical questions about agency, authenticity and the evolving role of AI in shaping social media discourses.","Nuo Chen, Pu Yan, Qixuan Zhao, Jia Li",Atrium,Posters II,96,,342
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Digital Traces of Well-Being: Satisfaction with Life Manifests in Everyday Physical Activity Captured with Smartphones,"Satisfaction with life (SWL) plays a vital role in human prosperity, making it a key focus for policy makers and researchers alike. Previous research has shown that between-person differences in SWL relate to self-reported patterns in physical activity such as sedentary behavior, mild- to vigorous activity, and overnight sleep. However, these relationships rarely replicate in objectively measured physical activity, leaving real-life manifestations of SWL obscure. Here, we leverage an interpretable machine learning approach to examine how smartphone-captured patterns in physical activity (n = 1,235 behavioral features) relate to SWL in a dataset (N = 2,272) combining samples from three western countries. The cross-validated results demonstrate that objective physical activity patterns reliably predict SWL (r_MD = .18, r_SD = .06) and that predictiveness varies with individualsÕ personality and demography. These findings enhance our understanding of real-life manifestations of SWL in physical activity patterns and highlight the potential of smartphone-based methods for well-being research.","Maximilian Bergmann, Sarah Marie Müller, Ramona Schoedel, Gabriella Harari, Mirjam Stieger, Markus Buehner, Samuel Gosling, Mathias Allemand, Clemens Stachl",Atrium,Posters II,97,,930
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Causal Data Fusion for Panel Data without Pre-Intervention Period,"Traditional panel data causal inference frameworks, such as difference-in-differences and synthetic control methods, rely on pre-intervention data to estimate counterfactuals. However, such data may not be available in real-world settings when interventions are implemented in response to sudden events, such as public health crises or epidemiological shocks. In this paper, we introduce two data fusion methods for causal inference from panel data in scenarios where pre-intervention data is unavailable. These methods leverage auxiliary reference domains with related panel data to estimate causal effects in the target domain, overcoming the limitations imposed by the absence of pre-intervention data. We show the efficacy of these methods by obtaining converging bounds on the absolute bias as well as through simulations in a variety of panel data settings. Our proposed methodology renders causal inference feasible in urgent and data-constrained environments where the assumptions of the existing causal inference frameworks are not met.","Zou Yang, Seung Hee Lee, Julia R. Koehler, AmirEmad Ghassami",Atrium,Posters II,98,,392
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,A method for the symbolic identification of differential equations,"The area of equation discovery has wide reaching applications across the physical and social sciences as it allows for a systematic methodology and the automation of searching for meaningful models (or set of equations) to describe a given system. Our focus is on learning models of dynamical systems in the form of ordinary differential equations (ODEs). There is a growing body of work on methods for discovering ODEs, with an early example being Lagrange, which involved computing all derivatives up to a given order, then generating expressions involving a maximum number of variables, and finally applying a (simple) linear regression to generate candidate equations. More recently, this approach has been employed in the SINDy method which applies sparse (rather than simple) linear regression. Symbolic regression methods rely on growing the complexity of the mathematical expression in the models, which present the challenge of exploring a large search space of possible equations. Alternatively, we can start from a general form and reduce it for a particular case. We propose a method in this regard inspired by SINDy, but instead of numerically computing all the possible terms in the equations we employ a symbolic formulation that allows the use of automated differentiation and gradient descent optimization. In modeling problems there are numerous methods available to optimize a given objective function. This provides a straightforward way to fit or calibrate a given model to available data. In so far as dynamical systems are concerned, and specifically models consisting of systems of ordinary differential equations (ODEs), the only readily available method to fit parameters to data is the brute-force approach via a grid search in the parameter space. Equation discovery methods have improved beyond the rudimentary brute-force approach by enforcing sparsity or reducing the search space given expert knowledge of the problem domain. However, equation discovery methods are still heavily reliant on high-resolution data and face the constant challenge of extracting reliable gradient information from noisy time series. Thus, the calibration of ODEs to data remains a challenging task. We propose a method for calibrating and identifying ODE models and apply the method to ecological data. In Fig. 1 we see an illustration of the method on synthetic data.",Sabin Roman,Atrium,Posters II,99,,856
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Analysis of the Impact of Favorite-Manipulating Users on Creators' Popularity in CtoC Platform,"With the rapid growth of CtoC platforms, the impact of user-driven rating manipulation on market trustworthiness has become a critical issue. This study analyzes the characteristics of favorite-manipulating users on CtoC platforms and examines their influence on the popularity of creators. For this analysis, we used ""favorite"" data from the CtoC platform ÒminneÓ, which specializes in handmade products, collected throughout 2023. Users who engage in an abnormally high number of ""favorite"" actions within a short period were defined as favorite-manipulating users, and their behavior was visualized through network analysis. The results revealed that favorite-manipulating users tend to concentrate within specific communities, indicating that rating manipulation occurs in localized patterns. This suggests that maintaining a healthy market environment requires not only overall platform monitoring but also targeted monitoring at the community level. Furthermore, creators who received ""favorites"" from favorite-manipulating users tended to lose favor among normal users over time, ultimately leading to a decline in popularity.","Ryoma Adachi, Yusuke Miyake, FUJIO TORIUMI",Atrium,Posters II,100,,255
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Civitai “Bounties:” A Generative-AI Marketplace for Wholesome Art or Adult Content?,"Civitai, a rapidly growing platform for AI-generated content, has introduced a controversial “Bounties” system that enables users to commission customized models and images using virtual currency. This study examines whether the bounty marketplace primarily fosters artistic creativity or incentivizes the production of explicit content. Analyzing all 4,764 bounties posted on the platform over 15 months, we find that a substantial proportion of requests—43% of LoRA models, 45% of images, and 51% of new models—are classified as not suitable for work (NSFW). Moreover, the share of NSFW bounties has steadily increased over time, surpassing 50% of weekly requests by early 2025. Prominent users are disproportionately engaged in NSFW content creation, with some facing bans for violating platform policies. Network analysis reveals growing community fragmentation, with users clustering into distinct NSFW and SFW groups, reinforcing concerns about the platform’s role in facilitating explicit content. These findings underscore broader implications for platform governance, content moderation, and the ethical challenges of incentivized AI-generated media. While Civitai presents its Bounties system as a way to support creative exchange, our results suggest that financial incentives may disproportionately drive the production of explicit content. The increasing segregation of NSFW and SFW users highlights the potential for self-reinforcing subcommunities, complicating efforts to regulate content and enforce platform policies. As generative AI marketplaces continue to evolve, platforms must grapple with the unintended consequences of monetization mechanisms that shape user behavior and content production.","Shalmoli Ghosh, Matthew DeVerna, Filippo Menczer",Atrium,Posters II,101,,756
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Luck and overestimation in competitive selection processes,"People working across disciplines compete for resources and recognition. The competition arenas are often systematized as contests, in which a group of individuals (i.e. a committee) stand on behalf of a larger population and evaluate the candidates, determining who will be selected. How accurate and replicable are committee decisions and how strong is the quality signal they confer? We propose a simple model for committee decisions, which predicts that from most peopleÕs point of view, the candidates selected by committees will be overrated. We test this prediction using a novel dataset from a graphic design contest that we organized, which shows that the overrating effect is even larger in an actual contest than what is predicted by the model using synthetic data. We then explain this discrepancy by showing that the probability that different candidates will be selected is more sensitive to the variance of the candidatesÕ evaluations than to their average evaluation, and that variability also drives the overrating effect. Our results can inform the design of effective and fair decision committees, and can help candidates and committees to better manage their expectations.","Katinka den Nijs, Pantelis P. Analytis, Minsu Park, Johannes Müller-Trede",Atrium,Posters II,102,,836
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Eliciting advice instead of feedback improves developmental input,"Most organizations encourage employees to provide feedback to one another to support learning, personal growth, and career advancement. However, employee feedback often fails to improve performance because it lacks concrete, specific guidance. We provide a temporal explanation for why workplace input processes routinely fail to produce valuable and concrete developmental insights: they are insufficiently focused on the future. In this paper, we theorize and demonstrate that encouraging input providers to think about the future leads them to produce more concrete develempental input. Across a large scale, pre-registered field experiment and three pre-registered lab studies, people provide more concrete and actionable developmental input when they are prompted to provide future-looking ÒadviceÓ rather than Òfeedback.Ó However we also find that feedback is a much more common method of soliciting developmental input, by individuals and organizations. The effect of soliciting ÒadviceÓ on input concreteness is mediated by providersÕ future focus. Moreover, in a follow-up study, such concrete input was assessed by independent raters as more useful and helpful. These findings highlight the role of temporal orientation in driving the content of developmental input. In doing so, our data suggest that individuals and organizations have the potential to promote higher quality developmental input by attending to the temporal orientation of their input requests.","Michael Yeomans, Ariella Kristal, Hayley Blunden, Ashley Whillans",Atrium,Posters II,103,,144
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Evaluating Amazon Effects and the Limited Impact of COVID-19 with Purchases Crowdsourced from US Consumers,"We leverage a recently published dataset of Amazon purchase histories, crowdsourced from thousands of US consumers, to study how online purchasing behaviors have changed over time, how changes vary across demographic groups, and the impact of the COVID-19 pandemic. This work provides a case study in how consumer-level purchases data can reveal purchasing behaviors and trends beyond those available from aggregate metrics. For example, in addition to analyzing spending behavior, we develop new metrics to quantify changes in consumers' online purchase frequency and the diversity of products purchased, to better reflect the growing ubiquity and dominance of online retail. Between 2018 and 2022 these consumer-level metrics grew on average by more than 85%, peaking in 2021. We find a steady upward trend in individuals' online purchasing prior to COVID-19, with a significant increase in the first year of COVID, but without a lasting effect. Purchasing behaviors in 2022 were no greater than the result of the pre-pandemic trend. We also find changes in purchasing significantly differ by demographics, with different responses to the pandemic. This work demonstrates how crowdsourced, open purchases data can enable economic insights that may otherwise only be available to private firms.","Alex Berke, Alex Pentland, Kent Larson, Dana Calacci",Atrium,Posters II,104,,26
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,Causally Modeling the Linguistic and Social Factors that Predict Email Response,"Email is a vital conduit for human communication across businesses, organizations, and broader societal contexts. In this study, we aim to model the intents, expectations, and responsiveness in email exchanges. To this end, we release SIZZLER, a new dataset containing 1800 emails annotated with nuanced types of intents and expectations. We benchmark models ranging from feature-based logistic regression to zero-shot prompting of large language models. Leveraging the predictive model for intent, expectations, and 14 other features, we analyze 11.3M emails from GMANE to study how linguistic and social factors influence the conversational dynamics in email exchanges. Through our causal analysis, we find that the email response rates are influenced by social status, argumentation, and in certain limited contexts, the strength of social connection.","Yinuo Xu, Hong Chen, Sushrita Rakshit, Aparna Ananthasubramaniam, Omkar Yadav, Mingqian Zheng, Michael Jiang, Lechen Zhang, Bowen Yi, Kenan Alkiek, Abraham Israeli, Bangzhao Shu, Hua Shen, Jiaxin Pei, Haotian Zhang, Miriam Schirmer, David Jurgens",Atrium,Posters II,105,,897
2025-07-23 13:30:00,2025-07-23 14:30:00,session_presentation,The Ideological Turing Test for Moderation of Outgroup Affective Animosity,"Affective extremismÑrising animosity toward ideological opponentsÑposes critical societal challenges. This study introduces a novel intervention leveraging the Ideological Turing Test, a gamified framework requiring participants to adopt and convincingly defend opposing viewpoints through debates or writing tasks judged by peers. We test whether this approach reduces affective polarization via a mixed-design experiment (N = 150) with four conditions (perspective-taking: flip/no-flip x engagement: debate/writing). Results demonstrate that perspective-taking via the Ideological Turing Test significantly reduces out-group animosity. However, writing tasks (mean _=12.5) outperformed debates (_=7.7), suggesting non-adversarial engagement better fosters empathy. Performance in the Ideological Turing Test (""winning"" by convincing judges of authenticity) showed no difference contingent on the arm. On the other hand, sustained engagement remained consistent (~40% willingness to re-participate without compensation). These findings challenge assumptions about adversarial methods, highlighting the Ideological Turing TestÕs potential as a scalable tool when combined with reflective, non-competitive tasks. The study advances the debate on polarization interventions by demonstrating how role adoption and incentivized engagement, central to the test, can mitigate animosity.","David Gamba, Grant Schoenebeck, Daniel Romero",Atrium,Posters II,106,,941
,,,,,,,,,,
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,The Media Bias Detector: A Framework for Annotating and Analyzing the News at Scale,"Mainstream news organizations shape public perception not only directly through the articles and segments they produce, but the choices they make about what topics go into their content (and which topics do not), how they frame that coverage relative to other potentially valid framings. However, measuring these subtle forms of media bias at scale remains a challenge. Here, we introduce a large, ongoing (from January 1, 2023 to present), near real-time dataset and computational framework developed to enable systematic study of selection and framing bias in news coverage. Our pipeline integrates large language models (LLMs) with scalable, near real-time news scraping to extract structured annotations--including political lean, tone, topics, article type, and events--across hundreds of articles per day. We quantify these dimensions of coverage at multiple levels, from the sentence-level to the article-level and to aggregate publisher trends, expanding the ways researchers can analyze media bias in the modern news landscape. In addition to a curated dataset, we also release an interactive web platform for convenient exploration of this data. Together, these contributions establish a reusable methodology for studying media bias at scale, providing empirical resources for future research. By leveraging the corpus’s breadth across time and publishers, we present examples (focused on the 150,000+ articles examined in 2024) that illustrate how this dataset can reveal patterns in news coverage and bias, supporting both academic research and real-world efforts to enhance media accountability.","Samar Haider, Jenny Shan Wang, Amir Tohidi Kalorazi, Timothy Dörr, David Rothschild, Chris Callison-Burch, Duncan J. Watts",Atrium,Posters III,1,,905
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Understanding Media Bias through Actor Portrayals,"Differences in storytelling across international media can promote polarization and fuel conflicts, especially in the context of foreign news. While researchers have long studied how media select and frame sets of events for their coverage, and computational approaches to media-bias detection have gained popularity in recent years, to date, no unified framework for the scalable detection of media bias exists. We propose to develop such a framework based on the notion of actor portrayals, i.e., language patterns arising from actor descriptions in media reporting. As we demonstrate for the Israel–Palestine and the Russia–Ukraine conflicts, measuring the differences between actor portrayals using Bayesian statistics allows us to quantify media bias without reference to some ""unbiased"" baseline. Our approach readily applies to any corpus of news articles or other media items collected from one or more news outlets, and it opens novel research directions in the computational study of media bias.","Ali Salloum, Yan Xia, Mikko Kivelä, Corinna Coupette",Atrium,Posters III,2,,209
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Collective Memory and Narrative Cohesion: A Computational Study of Palestinian Refugee Oral Histories in Lebanon,"This study uses the Palestinian Oral History Archive (POHA) to investigate how Palestinian refugee groups in Lebanon sustain a cohesive collective memory of the Nakba through shared narratives. Grounded in Halbwachs’ theory of group memory, we employ statistical analysis of pairwise similarity of narratives, focusing on the influence of shared gender and location. We use textual representation and semantic embeddings of narratives to represent the interviews themselves. Our analysis demonstrates that shared origin is a powerful determinant of narrative similarity across thematic keywords, landmarks, and significant figures, as well as in semantic embeddings of the narratives. Meanwhile, shared residence fosters cohesion, with its impact significantly amplified when paired with shared origin. Additionally, women’s narratives exhibit heightened thematic cohesion, particularly in recounting experiences of the British occupation, underscoring the gendered dimensions of memory formation. This research deepens the understanding of collective memory in diasporic settings, emphasizing the critical role of oral histories in safeguarding Palestinian identity and resisting erasure.","Ghadeer Awwad, David Gamba, Lavinia Dunagan, Tamara N. Rayan",Atrium,Posters III,3,,834
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Algorithmic Amplification in China: How Platforms Boost State Visibility,"Social media have been widely employed by authoritarian regimes for surveillance, censorship, and propaganda to compete for online attention. Although effective propaganda states can invest massive resources and efforts to disseminate state propaganda, the personalized curation and filter bubbles embedded in social media algorithms complicate efforts to reach users with nonpolitical interests. While research has focused on the content and dissemination strategies of authoritarian political propaganda, less is known about the role of platform algorithms in increasing or inhibiting the reach of political propaganda. Through the collection and analysis of a novel dataset of 120,245 trending and recommended videos on Bilibili, one of China’s largest entertainment platforms, we found that recommendation algorithms on the entertainment platform can amplify the visibility of state-produced content. Coupled with a different content mix featuring a significantly higher presence of propaganda content than non-state accounts, state-sponsored accounts leverage both new content strategies and algorithmic settings on the entertainment platform to increase the reach of their propaganda. These findings highlight an algorithmic pathway through which authoritarian regimes may increase their online influence, offering critical insights into the role of social media algorithms in an authoritarian context.","Yingdan Lu, Xinyi Liu, Carl Zhou",Atrium,Posters III,4,,377
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,The Digital Authoritarian: Everyday behavioral patterns collected with smartphones predict authoritarianism,"We show that digital traces of everyday behavior collected with smartphones predict individuals’ authoritarian tendencies. More than 280 million app usage, music listening, language usage, calling and texting, screen unlocking and locking, and GPS location events were recorded from 669 participants’ smartphones’ sensors and logs for three to six months. These digital records were then used to derive behavioral variables that could predict authoritarianism according to prior theory. Theory-informed behavioral variables predicted self-reported authoritarianism levels (r_md = .30) in machine learning models better than and independently of demographic characteristics (i.e., age, gender, nationality, education). We identified the behaviors most informative of an individual’s authoritarian tendencies to construct a profile of authoritarianism in everyday life. Our findings have implications for researchers and policymakers interested in understanding authoritarianism among ordinary citizens, especially as democracy erodes globally.","Timo Koch, Sanaz Talaifar, Daniel Racek, Jan Digutsch, Pietro Alessandro Aluffi, Ramona Schoedel, Markus Buehner, Clemens Stachl",Atrium,Posters III,5,,764
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Research Borderlands: Writing Across Communities,"Communication in communities, including research communities is governed by cultural norms and expectations. Prior works have focused on individual differentiating features, such as the differing vocabulary and values present in research papers. We develop a framework for building a holistic understanding of the variations in writing norms across research cultures through a survey (N=78) and interviews (N=10) of interdisciplinary researchers. We then operationalize this framework using computational metrics and demonstrate its application for: (a) surfacing variations in research papers from different communities at scale, and (b) evaluating LLMs’ alignment to different research cultures when rewriting text to suit a specific community.","Shaily Bhatt, Tal August, Maria Antoniak",Atrium,Posters III,6,,472
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Causal Claims in Economics,"We analyze over 44,000 NBER and CEPR working papers from 1980--2023 using a custom language model to construct knowledge graphs that map economic concepts and their relationships. We distinguishe between general claims and those documented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document a substantial rise in the share of causal claims—from roughly 4% in 1990 to nearly 28% in 2020—reflecting the growing influence of the ``credibility revolution.'' We find that causal narrative complexity (e.g., the depth of causal chains) strongly predicts both publication in top-5 journals and higher citation counts, whereas non-causal complexity tends to be uncorrelated or negatively associated with these outcomes. Novelty is also pivotal for top-5 publication, but only when grounded in credible causal methods: introducing genuinely new causal edges or paths markedly increases both the likelihood of acceptance at leading outlets and long-run citations, while non-causal novelty exhibits weak or even negative effects. Papers engaging with central, widely recognized concepts tend to attract more citations, highlighting a divergence between factors driving publication success and long-term academic impact. Finally, bridging underexplored concept pairs is rewarded primarily when grounded in causal methods, yet such gap filling exhibits no consistent link with future citations. Overall, our findings suggest that methodological rigor and causal innovation are key drivers of academic recognition, but sustained impact may require balancing novel contributions with conceptual integration into established economic discourse.",Prashant Garg,Atrium,Posters III,7,,70
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Facilitating Meetings with LLMs: An Experimental Study of Group Decision Making,"Group decision-making often suffers from uneven information sharing, hindering decision quality. While large language models (LLMs) have been widely studied as aids for individuals, their potential to support groups of users, potentially as facilitators, is relatively underexplored. We present a pre-registered randomized experiment with 1,475 participants assigned to five-person groups completing a hidden profile task—selecting an optimal city for a hypothetical sporting event—under one of four facilitation conditions: no facilitation, a one-time message prompting information sharing, a human facilitator, or an LLM (GPT-4o) facilitator. We find that LLM facilitation increases information shared within a discussion by raising the minimum level of engagement with the task among group members, and that these gains come at limited cost in terms of participants' attitudes towards the task, their group, or their facilitator. However, despite improved information exchange, we find no significant effect of facilitation on the final decision outcome, suggesting that decision-making biases may still persist. To support further research into how LLM-based interfaces can support the future of collaborative work, we release our experimental platform, the Group-AI Interaction Laboratory (GRAIL), as an open-source tool.","Mohammed Alsobay, David Rothschild, Jake M. Hofman, Daniel G. Goldstein",Atrium,Posters III,8,,743
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,On Bluesky mass migration,"Alternative social media platforms have been emerging since Elon MuskÕs takeover of X/Twitter, with Bluesky becoming a popular choice. Founded by Jack Dorsey, the platform saw a massive influx of users, particularly in response to major global events. Our study explores how key moments, such as the ban of X/Twitter in Brazil, the U.S. presidential elections, and shifts in moderation policies, triggered waves of migration to the platform. By analyzing nearly 1.6 billion interactions from over 16 million users, we mapped out how and when people joined Bluesky using their first action on the platform, tracking their activity and engagement patterns. Some events sparked immediate, large-scale migrations, while others led to slower, more scattered transitions. Through clustering techniques, we found that different user waves behaved in distinct ways, some quickly integrated into discussions and built connections, while others remained more passive. Our findings provide insight into how external events shape online communities and how decentralized platforms like Bluesky evolve in response to mass migration.","Gianluca Nogara, Enrico Verdolotti, Silvia Giordano",Atrium,Posters III,9,,974
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Beneficial Owners in Global Ownership Networks: The Oligarchic Power Shift Before and After the Russia-Ukraine War,"This study investigates the effectiveness of sanctions imposed on Russian oligarchs following the Russia-Ukraine war. Using Moody’s global equity ownership dataset (ORBIS) and the Network Power Index (NPI), we analyze how the influence of oligarchs over foreign companies changed between 2021 and 2023. Building on existing beneficial ownership detection methods based on equity ownership and voting rights, we introduce NPI as a more sophisticated indicator of corporate control. Our analysis identifies 17,744 Russian oligarchs who served as executives in 16,323 domestically controlled companies with more than 50% voting rights held by the government. After the sanctions, the NPI of these oligarchs over foreign companies decreased by half, suggesting that the sanctions were partially effective on a global scale. However, not all oligarchs were equally affected. While some experienced a significant decline in the number of controlled companies and associated revenues, others, such as Viktor Vekselberg, maintained substantial influence by leveraging offshore jurisdictions and partnerships with minority shareholders to construct complex ownership chains. This highlights the limitations of existing beneficial ownership regulations and the importance of international cooperation. In conclusion, while sanctions have somewhat curtailed the power of Russian oligarchs, more advanced detection algorithms and data integration are needed to address the increasingly complex global corporate networks.","Takayuki Mizuno, Shuhei Kurizaki",Atrium,Posters III,10,,165
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Do Alice Weidel and the AfD benefit from Musk’s attention on X?,"In this study we present descriptive findings from an analysis of X (formerly Twitter) profiles of German politicians and Elon Musk. We measure a range of observables that describe online popularity and reach, such as the number of followers, views, reposts or likes, all in fine temporal granularity. Thereby, we consider the leading candidates of the major parties in the run-up to the federal election in Germany and comparatively focus on the way politicians of the Alternative for Germany (AfD) and in particular their leader Alice Weidel have recently gained popularity on X. Since Elon Musk, the owner of X, has publicly endorsed the German party, we ask if his activities can be related to their growing visibility on the platform. We perform a close analysis of Weidel's follower count and find that in only a few weeks she gained almost half a million followers, as many as Friedrich Merz (CDU, conservatives) has in total, making her the German politician with the most followers on X. This sharp increase coincides with Musk's endorsement of the AfD and Weidel in particular. We further find that only minutes after he reposts some of Weidel's posts, those specific posts gained a sharp increase in views (but only to a lesser extent in likes and reposts). The fine-grained dynamics of the accumulated views for those posts differ qualitatively from other posts from Weidel. In order to identify structural breaks in the engagement of Weidel's posts, we perform a change point analysis. This analysis shows that starting on December 16th, the day that chancellor Olaf Scholz lost the vote of confidence in the German parliament, Weidel's post gained significantly and relatively consistently more views. For likes and reposts on the other side, we identify change points short before the German government fell apart at the beginning of November. Our results suggest that Musks public endorsement of the AfD and his reposts of Weidel's posts, led to a considerable boost of visibility for Weidel. This is mostly the case for her follower and view counts. Other metrics, such as reposts and likes, as well as, general visibility of other AfD accounts shows a less pronounced increase.","Sami Alexej Nenno, Philipp Lorenz-Spreen",Atrium,Posters III,11,,51
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Quantifying partisanship in TV news using Large Language Models,"Television news remains a dominant source of political information in the U.S., with cable networks such as Fox News and MSNBC exhibiting strong partisan leanings. While prior research has explored ideological segregation among television audiences, the extent and nature of partisanship in the content of news broadcasts remain less understood. In this study, we systematically quantify partisanship in 328,432 TV news episodes spanning six major U.S. networks from 2013 to 2022. Using GPT-4o and supervised learning, we assign partisanship scores to news transcripts and analyze their temporal evolution. Our findings reveal increasing polarization over time, particularly after 2016, with Fox News exhibiting a strong conservative lean and MSNBC a strong liberal lean, while ABC, CBS, and NBC remain closer to neutrality. Further linguistic analysis of TV news episodes demonstrates that partisan coverage is primarily driven by negative framing of the out-party rather than reinforcement of in-party perspectives, with Fox News consistently displaying higher blame attribution and inflammatory rhetoric than MSNBC and CNN. Additionally, our topic analysis reveals that polarization is most pronounced on socially and politically charged issues, such as abortion and U.S. elections, while more bipartisan topics, such as foreign policy and crime, exhibit relatively less partisan divergence. Our study provides a large-scale empirical assessment of partisan language in television news and its evolution over the past decade, offering insights into the potential role of cable news in shaping political discourse.","Upasana Dutta, Homa Hosseinmardi, Amir Ghasemian, Aaron Clauset, Duncan J. Watts",Atrium,Posters III,12,,960
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Gated communities: assortativity of alt-right groups on Telegram,"Over the past decade, major U.S. social media platforms have banned controversial figures, particularly from the alt-right, in an attempt to curb the diffusion of far-right-related messages on their grounds. Yet, many banned users migrated to alternative platforms like Telegram, known for its strong privacy features and controversial user base. This study analyzes alt-right communities on Telegram using the Pushshift Telegram Dataset, which contains messages from 27,801 channels between 2015 and 2019. We build a social network of alt-right channels by leveraging message forwarding and we identify 42 clusters using the Louvain algorithm. To study discourse, English-language messages are clustered using sentence embeddings from all-MiniLM-L6-v2, with UMAP for dimensionality reduction and HDBSCAN for clustering. Six key topics emergeÑIslam, the EU, Skrumble Network, YouTube, Antifa, and Jews. Assortativity analysis shows that interest-based topics (e.g., cryptocurrency, religion) form tight clusters, while political and social media discussions are more dispersed. Our findings suggest a bimodal communication pattern: some users engage in insular communities, while others interact widely to discuss politics, media or potentially spread hate.",Yasmine Houri,Atrium,Posters III,13,,563
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Countering misinformation: How political framing shapes scientists’ credibility and correction effectiveness,"Spread of misinformation increases the need for scientists to correct public misconceptions. Yet, this is challenging due to polarization and declining trust in science. Currently, we lack evidence on how scientists can effectively counter misinformation while maintaining credibility among the audiences least likely to trust them. In a preregistered survey experiment, we assigned 4,070 Republican voters to news articles containing misinformation about green energy, along with corrections that randomly varied the correcting scientistsÕ race (Black or white) and message framing (Republican, Democrat, or no framing). We find that politically congruent framings increase the perceived trust in scientists, while incongruent framings reduce it and diminish correction effectiveness, specifically among moderate and strongly conservative participants. In contrast, race has no observable effect on these outcomes. Overall, our findings suggest that scientists in polarized contexts should aim to present factual corrections neutrally, avoiding political framings that may conflict with audience values.","Claudia Acciai, Natalie Schroyens, Friedolin Merhout, Mathias Wullum Nielsen",Atrium,Posters III,14,,581
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,A framework for identifying and contextualizing cross-lingual misinformation using the Russian invasion of Ukraine,"The Russian invasion of Ukraine has triggered waves of misinformation in multiple languages as the Russian state aggressively promotes its narrative to a global audience. Against this backdrop, our study examines the spread of misinformation on social media from both pro-Russian and pro-Ukrainian users in four languages Ñ English, Japanese, Spanish, and French Ñ and highlight the most widespread false claims. By using a novel framework that combines community network techniques to identify pro-Russian and pro-Ukrainian users with multi-lingual sentence embeddings to identify misinformation and cluster similar content through a semantic similarity network, we reveal popular claims of multilingual misinformation and uncover their cross-lingual trends. We find that pro-Russian misinformation is highly prevalent in all language communities, particularly amongst French and Spanish users. Claims of corruption are popular, with three of the top ten claims of misinformation spread across all four languages being related to corruption. Furthermore, inspection of the retweet timing also reveals how particular pieces of misinformation hop from one language to another. Our framework also makes contributions to the role of user stance when it comes to identifying misinformation, highlighting how content allegedly containing misinformation can be more accurately identified through embeddings when the stance of the user is considered, in this case as pro-Russian or pro-Ukrainian. We also propose the use of an alternative clustering method that uses cosine similarities to build a network of similar claims of misinformation in different languages, enabling us to analyse cross-lingual trends and reveal the timing of when misinformation spreads across different languages. Future work will explore how we can make more substantial use of network properties,etc. to further uncover the characteristics and nature of the spread of cross-lingual misinformation.","Cameron Lai, FUJIO TORIUMI, Mitsuo Yoshida",Atrium,Posters III,15,,121
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,How influencers and multipliers drive polarization and issue alignment on Twitter/X,"We investigate the polarization of the German Twittersphere by extracting the main issues discussed and the signaled opinions of users towards those issues based on (re)tweets concerning trending topics. The dataset covers daily trending topics from March 2021 to July 2023. At the opinion level, we show that the online public sphere is largely divided into two camps, one corresponding to left and the other to right-leaning accounts, and that political issues are largely aligned, contrary to what one would expect from surveys. This alignment is driven by two cores of strongly active users, influencers, who generate ideologically charged content, and multipliers, who facilitate the spread of this content. The latter are specific to social media and play a crucial role as intermediaries on the platform by curating and amplifying very specific types of content that match their ideological position, resulting in the overall impression of a strongly polarized public sphere. These results contribute to a better understanding of the mechanisms that shape online public opinion and have implications for the regulation of platforms.","Armin Pournaki, Felix Gaisbauer, Eckehard Olbrich",Atrium,Posters III,16,,1023
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,"Social Interaction, Social Polarization: A Computational Approach to understanding Issue Polarization in Social Media","Over the course of the last two decades, social media has played an increasingly prominent role in the formation of public opinion. With over 50% of Americans stating that they obtain news from social media at least “sometimes” according to a 2024 survey from Pew Research Center, the impartiality and reliability of such websites have come under increasing scrutiny. Specifically, this issue has come under the spotlight due to concerns about social media affecting governmental policy, such as the 2024 United States presidential elections. Core to this concern is the challenge of containing disinformation on these platforms, where tools such as automated fact-checking can struggle to keep up with the low contribution barriers on which social media is built. Further compounding this issue is the phenomenon of echo chambers formed from filter bubbles, where increasing engagement through promoting ideologically similar content often leads to constant self-reinforcement. Computational social simulation tools have previously been employed to simulate and identify both the cause and effect of social polarization. Early works have approached the question of consensus formation across a range of opinions—including the divergence of equilibria to extreme values. Other studies have addressed social media directly through a combination of empirical surveys and computational simulation. We propose an extendable framework for more closely simulating common mechanisms of prominent social media platforms in order to evaluate the relationship between polarization and user engagement. Using our simulation results, we draw several conclusions that could help identify future abstracted solutions. Our model presents a novel approach to simulating social media by incorporating dynamic agent population sizes, asymmetric interactions, and additional engagement features. The findings have the potential to inform evaluations of how sophisticated interaction features might decrease polarization and increase user satisfaction.",Li-Huan Shen,Atrium,Posters III,17,,1052
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,An inefficient two-party system and welfare loss,"This study provides a deeper, data-driven understanding of partisan perception and issue alignment by examining agreement levels across key political issues and exploring how partisan identity shifts under efficient party placement, transparent party positioning, and multi-party simulations. First, Republicans overestimate how much they align with their leaders and Democrats underestimate how much they align with their leaders: Republican leadership does not well represent their voters on the bulk of issues (but provides them welfare in the form of identity and value in key issues they may care about most). Second, introducing multi-party structures improved agreement levels, but the biggest gains come from simply having the two parties position themselves near the center of voter clusters. And, gains to more parties diminish quickly, leading to greater overlap between ideological clusters (at least where citizens are endogenously clustered now in response to the current party positioning). Third, while some policy positions remained stable across simulations, others shifted in response to alternative political structures, suggesting that the two-party system may oversimplify the electorateÕs ideological diversity. These insights highlight the complexity of partisan identity and the potential for alternative party structures to better capture nuanced voter preferences. Future research can build upon this framework by examining the influence of media, electoral behavior, and voter psychology in shaping political alignment and perception.","David Rothschild, Sabina J Tomkins, Mirza Nayeem Ahmed",Atrium,Posters III,18,,609
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Negative Ties Highlight Hidden Extremes in Social Media Polarization,"Online social networks have changed how people form opinions from news content. This new mechanism for communication plays a key role in facilitating increased polarization on controversial issues [1]. The growing availability of data on online social media interactions has made polarization a key area of study. Despite the extensive research on online polarization, researchers have been limited by the data available. Social media platforms primarily provide information on positive interaction. Consequently, most previous research has studied structural polarization using unsigned networks made of positive ties. However, online interactions can be incredibly diverse, representing sentiments ranging from support to hostility. Signed network representations, which assign positive or negative weights to edges to reflect friendship or animosity, provide a powerful tool for capturing this complexity. Here, we assess the value of including negative interactions in measuring polarization in online spaces. We collect and make available data on the Mename platform, a Spanish social media site that facilitates engagement with news stories through comments and (positive and negative) voting. Using a dual-method embedding approach---Signed Hamiltonian Eigenvector Embedding for Proximity (SHEEP) [2] for signed networks and Correspondence Analysis (CA) [3] for unsigned networks, which is often used in polarization studies [4]---we quantify the level of structural polarization on the platform across different conversation topics. We find that Mename users can be grouped into two main ideological factions that exhibit polarization, more pronounced in controversial topics (Fig. 1A--B). The two methods identify similar ideological groups and their overall polarization. However, negative ties reveal critical patterns at the extremes that remain hidden when only positive interactions are analyzed. For example, when applied to the network of users' votes on news posts, SHEEP identifies pro-Russia users and Russian propaganda outlets (Fig. 1C). However, they remain hidden within ``general left-wing'' outlets and users. More broadly, we show that only SHEEP can detect extreme users who engage in high levels of antagonism. Our results reveal how negative interactions can provide unique insights into the social dynamics of online platforms.","Elena Candellone, Shazia'Ayn Babul, Özgür Togay, Alexandre Bovet, Javier Garcia-Bernardo",Atrium,Posters III,19,,364
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Exploring Political Attitudes under Selective Media Consumption with Large Language Models,"This study explores the effect of selective exposure to partisan news media on political attitudes using large language models (LLMs) as surrogates of human subjects. We design an experiment where LLMs are exposed to news content from either a single outlet or a mix of sources, including *Breitbart*, *Fox News*, *CNN* and *HuffPost*. The LLMs then rate their agreement with several statements on two topics: immigration and crime. Results show that selective exposure significantly shifts the LLMs' attitudes, with single-source exposure leading to more pronounced ideological leaning compared to diversified exposure. For instance, consumption of *Fox News* and *Breitbart* articles significantly increases agreement with conservative-leaning statements, while *HuffPost* and *CNN* exposure reinforces liberal views, although with smaller effect sizes. These findings suggest that selective news consumption can shape political attitudes, highlighting the potential of LLMs to simulate human subjects in political communication research. Future work will examine whether these effects extend to real humans, and whether reliable predictions of attitudes toward other focal topics can be made under selective exposure.","Josh Nguyen, Upasana Dutta, Samar Haider, Bryan Li, Neil Fasching, Duncan J. Watts",Atrium,Posters III,20,,385
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Is there anything Left?: A Global Analysis on Changes in Engagement with Political Content on Twitter in the Musk Era,"Over the past few years, Twitter (now X) has become an influential platform for political discourse. However, prior research suggests that Twitter may be biased towards right-wing content. Following the change in ownership in October 2022, there have been several changes to Twitter's policies, particularly in content flagging and Twitter Blue Verification. Understanding how any shifts in outcomes vary across different political ideologies is important for comprehending the evolving political discourse, especially given recent developments. To explore this issue, we examine shifts in engagement (characterized by likes and retweets) for political figures before and after November 2022, focusing on describing how engagement has changed over time. We perform a global analysis by collecting tweets from 6550 accounts belonging to political leaders and parties from twelve countries among the ones with the highest user activity on the platform, namely, Argentina, Brazil, Canada, Colombia, France, Germany, India, Japan, Mexico, Spain, the United Kingdom, and the United States, between June 2021 and June 2023. Our findings indicate that the number of likes on political tweets increased after November 2022. However, we observe that the number of retweets decreased significantly, along with a marginal increase in the likes-to-retweet ratio, with no statistically significant difference between the Left and the Right. Our study is the first to offer a global perspective by examining how platform engagement has shifted over time during the Musk Era. These observations contribute to the ongoing discussion on the role of social media platforms in political dialogue, highlighting the importance of monitoring policy developments and trends in the digital media landscape. To support further research, we release the data on politicians and parties used in this study, with their Twitter data available upon request.","Brahmani Nutakki, Rosa M. Navarrete, Giuseppe Carteny, Ingmar Weber",Atrium,Posters III,21,,404
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Staying Streamed: The Impact of Loyalty and Diversity in Driving User Retention on Live Streaming Platforms,"The increasing prevalence of live streaming platforms provides a compelling context for studying the dynamics of online communities. While prior research has investigated user behavior and community maintenance in online communities, focusing on user- and community-level loyalty and diversity, these dynamics remain underexplored within the specific domain of live streaming. This paper explores the interplay of these variables in relation to user retention by analyzing extensive live streaming data. Our findings indicate that while the quantity of supported live streamers is a contributing factor, the establishment of user loyalty to live streamers significantly drives user retention on the platform. Moreover, users who cultivate diverse streamer portfolios (supporting streamers with varied content and characteristics) exhibit higher retention rates. We also investigate the reciprocal relationship between loyalty to live steamers and community characteristics, revealing that users are more likely to develop loyalty to live streamers within less diverse communities. Finally, we analyze the correlation between community-level loyalty and diversity, observing that communities with higher loyalty tended to exhibit lower diversity. These findings contribute to understanding the dynamics of the online communities in live streaming, offering insights for platform design and user engagement strategies.","Ryo Adachi, Ryo Sasaki, Akira Matsui",Atrium,Posters III,22,,169
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,News Media vs. Politicians: How Different Actors Shape Engagement on YouTube,"This study investigates channels activity and commenting behavior on YouTube between news media channels and politicians/political parties (PP) channels within the French political ecosystem. After selecting 47 YouTube channels, including 34 news media and 13 PP channels, we collected data on 40.4k videos and 7.17M comments from 698k commenters between March 1st, 2024, and July 14th, 2024. Using engagement metrics and graph-based network analysis, we characterized the channels and explored the behavior of their commenting user base. Our findings reveal that news channels are generally more active but receive less engagement compared to PP channels, with the exception of partisan left news channel, which exhibit similar engagement as PP channels. Among PP channels, centrist channels are less active and receive less engagement, while far-right channels receive the highest number of comments per video. Network analysis shows significant differences between news and PP channels, with partisan left news channels again behaving more like PP channels. Additionally, we discovered that the similarity of commenting user bases is positively correlated with the political orientation of the channels, but that almost every channels from our dataset share at least one commenter with every channels, regardless of their political orientation. Finally, we observe that left PP channel commenters were more active on news channel videos than their right-wing counterparts. This research contributes to a deeper understanding of how politicians and news media utilize social media and provides insights into commenters' behaviors and interactions.","Caroline Violot, Vera Sosnovik, Mathias Humbert",Atrium,Posters III,23,,742
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Towards a Natural Language Processing Pipeline for Measuring Types of Issue-specific Polarisation using UK Party Manifestos,"This study presents an NLP pipeline that measures both types of issue-specific polarisation (ideological and salience) between political parties using manifestos. Whilst current NLP methods either conflate or only measure one type of issue-specific polarisation, this study's pipeline measures both types independently, allowing one to explore the potential relationship between different types of polarisation. Furthermore, the pipeline addresses other limitations with current methods such as confounding by lexical overlap and concealing variation in polarisation across issues. To provide a framework for analysing the pipeline, its outputs are used to identify which issues are proprietal, conflictual or consensual. Using the UK Labour and Conservative parties' General Election manifestos from 2001-2024, the pipeline segments manifestos into sentence-level semantic units and then applies BERTopic so that each sentence is labelled with distinct issue topics. Issue-salience polarisation is measured by comparing normalised topic frequency, whilst ideological polarisation is measured using ManifestoBERTa embeddings and cosine dissimilarity. Results show that issues like Healthcare were consensual as they exhibited low ideological polarisation, in contrast to conflictual issues like Immigration. Additionally, the EU was especially polarised in salience during the 2010's, making it a proprietal issue despite ideological polarisation. Future enhancements could include integrating NLP tools into the pipeline that allow for a qualitative analysis of polarised issues to supplement its existing quantitative analysis.","Pol Rovira-Wilde, Yan Wang",Atrium,Posters III,24,,87
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Is there an online social learning process for using toxic language on social media? and How?,"Toxic language is prevalent on social media, yet it is used less frequently in face-to-face interactions. So, why do people use toxic language on social media? This study investigates whether the use of toxic language online is driven by an online social learning process rather than pre-existing individual tendencies. We will explore three competing mechanisms: (1) the Selection Effect, where toxic individuals are more likely to engage in toxic discourse without social influence, (2) the Infection Effect, where exposure to one form of toxicity (e.g., misogyny) increases the likelihood of repeating the same type, and (3) the Filter Effect (taking the language filter off), where exposure to one form of toxicity increases the likelihood of engaging in varied toxic expressions. To distinguish Infection and Filter, using Reddit data, we build a multi-dimensional toxicity vector that captures toxicity targets (race, gender, religion, and sexuality by training a LightGBM classifier with TFIDF vectors as input features). By representing users, comments, and submissions in a high-dimensional toxicity space, we analyze their temporal influence to examine the underlying mechanisms behind using toxic language. Our preliminary findings are as follows. The selection effect is strong. Meanwhile, even when we control for selection, the Infection effect of gender and Filter effect of gender are still strong.","Ruining He, Junsol Kim, Zhao Wang, James Evans",Atrium,Posters III,25,,933
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Identifying linguistic strategies of emotional manipulation in online discussions,"Persuasive communication in online spaces can be exploited for manipulation, influencing individuals through emotional appeals and deceptive tactics. This study develops a computational approach to detect manipulative language. We fine-tune a RoBERTa-based classifier to identify manipulation techniquesÑgaslighting, guilt-tripping, minimization, and blame-shiftingÑusing annotated data extracted from YouTube. Our model is validated through human annotation and tested on external datasets to assess its generalizability. By leveraging explainable AI techniques, we aim to uncover linguistic markers of manipulation, contributing to safer online environments and advancing NLP methods for manipulation detection.","Diletta Goglia, Davide Vega, Ece Calikus",Atrium,Posters III,26,,1003
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Automating the Analysis of Discussion Quality in Online Political Discussions,"Facing the importance and the sheer volume of online discussions, reliable computational approaches to assess the quality of online political discussions at scale would open new avenues to research public discourse online and create opportunities for deliberation centered platform regulation. But to what extent is it possible to automate the assessment of discussion quality? The quality of political discussions has traditionally been assessed with in-depth manual content coding approaches that require time and human effort and that cannot be scaled appropriately to the vast availability of online communication data (Steenbergen et al., 2003). After decades of refining manual content coding approaches to carve out a set of core deliberation dimensions accompanied by a plethora of additional facets (Friess & Eilders, 2015; Graham, 2012) it remains an open question to what extent the established dimensions of deliberation can be measured using computational approaches and how specific dimensions relate to different computational measures. Previous research has explored network analysis (Aragn et al., 2017; Gonzalez-Bailon et al., 2010), linguistic features, and traditional machine learning approaches (Mendonca et al., 2022) and natural language processing techniques (Behrendt et al., 2024; Jaidka, 2022) to approximate discussion quality. The evolution of large language models fundamentally transforms potentials of automated assessments as they allow a close translation of manual content coding procedures into automated classification tasks. With our contribution, we aim to assess this potential and provide a transparent, reproducible and resource efficient tool for the automated assessment of online discussion quality. We collect political discussions from different platforms, representing four major arena types for online public discourse: online forums (Reddit), social networks (Mastodon), video platforms (YouTube) and online news outlets (Yahoo News) with comment sections. We use APIs to collect data from the former three platforms whereas we use a web-scraping approach using Selenium to collect data from Yahoo News. To allow the inclusion of context, we create triplets for each comment that include the origin of the discussion (the video title, original post or news article headline), the comment to be evaluated, as well as the immediate parent preceding the comment. Using the local version of Llama 3, following a stage of political filtering on the origin level and semantic sampling to create balance across political issues, we generate labels for the dimensions of argumentation, civility and constructiveness using zero-shot classification on the triplets. We validate labels with newly collected human annotations. Finally, we distill the model into a smaller model to make it openly available to other researchers via Hugging Face.","Lisa Oswald, Nikolas Zöller, Xinyi Zhao, Anton Gollwitzer, Dirk U. Wulff",Atrium,Posters III,27,,131
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,A Cross-Lingual Evaluation of Political Opinions in Multilingual Large Language Models,"Surveys show human opinions and biases to differ across regions and therefore also across languages. The widespread use of large language models, also in computational social science, raises the question whether these cross-lingual differences transfer to opinions in both pretrained and finetuned LLMs. We contribute to this discussion by evaluating the political stances of instruction-tuned multilingual LLMs of varying sizes across five languages: English, German, Italian, French, and Spanish. We employ a robustness-aware political opinion testing framework developed by Ceron et al. (2024). Our findings reveal only few significant cross-lingual differences in political opinions after pretraining. We then increase political bias in the LLMs by aligning them politically with more left or right views using English finetuning data only to see whether the relationship of opinions in different languages persists after shifting the English opinions. The results of part two are pending.","Franziska Weeber, Tanise Ceron, Sebastian Padó",Atrium,Posters III,28,,78
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,From Libert to Free Speech: Attitudes Toward Disinformation Regulation in France and the United States,"Should false information be restricted by the state? In this project, we compare attitudes toward regulation in France and the United States to understand the role of the regulatory state in explaining differing attitudes about the regulation of disinformation. Based on results from a survey fielded in both countries (N=4,000 per country) in late 2024, we find that French respondents are 33% more likely to support regulation than their American counterparts. Furthermore, we investigate how political ideology, confidence in the government, and key demographics like gender and race relate to these attitudes towards regulation. Additionally, by combining our survey data with 9 million digital trace observations from approximately a quarter of our survey respondents, we map the connection of regulatory attitudes to larger information ecosystems. Initial results find a prominent relationship between political ideology in the United States, with right leaning respondent favoring no regulation. Yet this same relationship does not exist in France. Across both countries, however, confidence in governmental information is much better able to explain differing preferences for regulation. The wider diversity of French news and media consumption identifies a more robust informational ecosystem in addition to a higher regulatory appetite. These results help illuminate the complex relationship between information quality and accessibility and attitudes on information regulation.","Isabelle Langrock, Jen Schradie",Atrium,Posters III,29,,465
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,In AI we trust: Analysing news and social media attitudes toward Artificial Intelligence Generated Content (AIGC) in China,"Generative AI have reshaped how content is created, altered, and consumed. We analyse and compare public discourses surrounding AI generated content(AIGC) on social media platforms like RedNote and Weibo, as well as in mainstream news outlets such as People's Daily and Xinhua News Agency. The study aims to explore the main themes, concerns and level of trust associated with AIGC in both social and news media, by applying computational social science methods to large-scale datasets of public discourses. The findings from this study will inform policymakers, industry practitioners, and researchers about the societal impact of AIGC, contributing insights on usersÕ experiences and challenges amid the technological transformation.","Nuo Chen, Xinyang Wang, Pu Yan, Zhouhan Chen",Atrium,Posters III,30,,384
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Attack Rhetoric and Strategy by U.S. Politicians,"Elites shape public opinion in the U.S., with citizens relying on elite cues to interpret political events (Zaller 1992). Affective polarization has been attributed to the strategic deployment of divisive rhetoric by political elites, particularly in electoral contexts (Iyengar et al. 2012). However, prevailing research privileges language valence or specific rhetorical forms, such as hate speech and moral arguments, without interrogating the broader spectrum of polarizing discourse. This analytical constraint obscures the relative impact of distinct rhetorical strategies, limiting insight into how variation in elite communication shapes partisan attitudes. We expand upon this by inductively developing our own categorization of personal attack and labelling 2 million post on X, newsletters, press releases, and floor speeches from political elites. We find that personal attacks receive more engagement on X than other types of posts, including constructive policy discussion. However, there are not large distinctions in engagement between the different types of attacks. Thus, it remains unclear what drives attack patterns and targets and what polarizes. In order to delve more deeply into this question, we annotate the target of each of the personal attacks and create a directed attack network where the nodes are individuals and the edges are attacks along with the direction of the attack. We consider the primary attack targets in both parties and evaluate what mechanisms make these individuals popular targets for attack, as well as whether strategies are similar across parties. Future work will also include a survey assessing respondent's reactions to examples of different attack types.","Erin Walk, Yphtach Lelkes, Sean Westwood",Atrium,Posters III,31,,891
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Anti-Democratic Condemnation has Limited and Inconsistent Effects on Vote Choice and Democratic Attitudes,"Significant alarms have been raised over democratic backsliding in the United States due to efforts undermining electoral integrity, restricting voting rights, and weakening checks and balances. In response, media, political campaigns, and activists have adopted a tactic that emphasizes that ""democracy is on the ballot'' and highlights and condemns anti-democratic behaviors, particularly among Republican elites. However, there is concern that democratic admonishing itself may backfire, and entrench partisan animosity. This paper describes the use of admonishment by politicians and political news channels using an original trained classifications algorithm, then explores the effects of admonishing citizens for the anti-democratic behavior of their party using two large survey experiments with 3,500 participants (a two-wave panel study and a cross-sectional study). Examining over 2 million politician data points, as well as over 40,000 television transcripts, we find that though Democratic media sources may engage in more admonishment, Democratic and Republican politicians are equally as likely to admonish the opposing party for anti-democratic behavior. We find that admonishment ephemerally pushes Republican voters towards Kamala Harris in the period immediately after treatment, but that it also increases perceived threat and negative emotions. However, these effects do not withstand a multiple testing correction and all differences decayed after 10 days. Admonishing does not change anti-democratic attitudes such as beliefs about election fraud with null effects observed across party lines. These results suggest that while accountability for anti-democratic actions is crucial, admonishing is a mixed strategy for promoting democratic values that only works in short time horizons.","Erin Walk, Yphtach Lelkes, Sean Westwood, Derek Holliday",Atrium,Posters III,32,,886
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,"How far away from Democracy? Discontent, Trust, and Conspiracy Beliefs among German Non-Voter Identities","Donald Trump’s victory in the last U.S. presidential election, the success of Austria’s right-wing populist Freedom Party (FPÖ) in the 2024 parliamentary elections, and the strong performance of Germany’s right-wing populist Alternative for Germany (AfD) in the snap 2025 federal election underscore the rise of anti-democratic tendencies (Finity, Garg, and McGaw 2021; Rich 2015; Retallack and Dufour 2018). These developments highlight growing challenges to democratic systems. At the same time, conspiracy theories - particularly prominent during COVID-19 (Loziak and Havrillová 2024; Sutton and Douglas 2020; Neu 2023; Roose 2021) - pose another significant threat, as political discontent can escalate into outright rejection of democratic institutions (Kim, Stavrova, and Vohs 2022; Mittendorf 2024). In this context, non-voters warrant closer examination. In Germany, they constituted about a quarter of the electorate, raising concerns from a democratic theory perspective. Recent research suggests that beyond the well-documented affinity of AfD voters for conspiracy narratives (Schuler et al. 2020), non-voters may exhibit similar predispositions, yet systematic studies on their engagement with conspiracy beliefs remain scarce. Against the backdrop of these democratic challenges - particularly political disengagement and declining institutional trust - non-voters represent a group that has received limited scholarly attention. Understanding their attitudes is crucial for assessing trust in democratic institutions, levels of dissatisfaction, and potential pathways for re-engagement. Key research questions include: How much trust do non-voters place in democratic institutions and political parties? How (dis)satisfied are they with the political system? What forms of democratic withdrawal can be identified? To what extent do conspiracy ideologies shape their political perceptions? And ultimately, who can be encouraged to return to electoral participation (Schäfer 2023; Koch, Meléndez, and Rovira Kaltwasser 2021)? To answer these questions, we analyze qualitative data from in-depth interviews and focus group discussions conducted after the 2023 Bavarian state election. Non-voters were recruited through door-to-door canvassing. Recognizing the low response rates typically observed in non-voter research regarding political interest, targeted recruitment strategies were employed (Faus 2017). Given that political interest strongly influences survey participation, research on non-voters often suffers from selection bias, leading to underrepresentation of politically uninterested individuals (Lahtinen et al. 2019; Faus 2017). To analyze the data, we employ Natural Language Processing (NLP) techniques. First, K-Means clustering with Sentence-BERT embeddings detects latent structures in non-voter discourse, allowing us to assess whether natural groupings emerge independently of existing typologies (Feist 1994; Hagemeyer, Faltas, and Faus 2023; Kleinhenz 1995). These clusters are compared to established classifications to evaluate their empirical validity. Additionally, we apply Latent Dirichlet Allocation (LDA) to predefined topic categories from the interview guide. This ensures that identified themes align with key political issues while allowing for unexpected patterns (Rakers 2024; Manavopoulos et al. 2018). The integration of LDA with clustering results provides a nuanced understanding of how non-voters discuss democratic engagement and withdrawal. To further examine the affective dimensions of political disengagement, we conduct sentiment analysis using a fine-tuned BERT model to measure sentiment toward democratic institutions, parties, and sociopolitical themes (McGinn 2020; Meidinger and Aßenmacher 2021). By linking sentiment patterns to thematic content and non-voter clusters, we gain insight into how different subgroups express discontent, skepticism, or neutrality toward the political system. Given the increasing relevance of conspiracy narratives, we also assess conspiratorial rhetoric in the interview data. Using word embeddings and cosine similarity, we analyze participants’ statements within their broader semantic contexts. A lexicon-based approach detects key conspiracy-related terminology while filtering out neutral uses of commonly associated terms (e.g., “system,” “control”). This hybrid method differentiates between legitimate political critique and genuine conspiracy ideation, reducing false positives in conspiracy detection. By integrating these computational approaches, this study advances research on non-voter typologies and provides new insights into their political attitudes, trust in democratic institutions, and susceptibility to conspiracy ideologies. The findings contribute to a broader understanding of political disengagement in contemporary democracies, offering implications for voter mobilization in an era of rising system skepticism and democratic fatigue.","Janine Schröder, Raphael Richter, Jürgen Pfeffer",Atrium,Posters III,33,,441
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,"Bridging Pillars, Mapping Distance: A Typology of Polarization in Text as Data Research","Polarization is a broad and fragmented field, where conceptual clarity is often lacking, and each study tends to redefine the term based on its specific focus. Esau et al. (2023) contribute to conceptual clarity by introducing ""Destructive Polarization,"" but challenges remain in translating these concepts into measurable terms. The increasing availability of text data and advances in text analysis methods have both complicated and expanded opportunities for studying polarization. This growth coincides with a shift in media formats, where digital media are also becoming more accessible and affordable compared to traditional print media (Pool, 1983). Technological advancements, including AI-supported tools, have also greatly increased accessibility and scalability for researchers. This shift allows scholars to explore how digital media shapes political interactions, potentially enhancing democracy by broadening access to political information and engagement. Despite these advancements, text-as-data research still faces the same concept-to-measurement challenges as previous polarization studies. This study aims to map and analyze the existing literature on polarization measurement, particularly in text-based research. It examines the polarization landscape across all disciplines and data types, and an in-depth review of measurement approaches to polarization in text-as-data studies",Helena Rauxloh,Atrium,Posters III,34,,612
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Depolarizing Power of Anticonformity,"When a polarized society has to make a collective decision, how can the members of the opposing factions reach a compromise? With the increasingly severe effects of climate change, this question is more important than ever, as consensus is necessary for an effective collective climate action. Although numerous papers have studied how facilitating discussion across the party line and promoting openness to different views can decrease issue-based polarization, we approach this problem by considering an overlooked type of anticonformity and propose a counterintuitive solution: instead of directly promoting agreement, we suggest that encouraging people to stand out from the group can act as a significantly more effective and universal depolarizing strategy. In the presence of political polarization, positions on various issues can sort along a single axis of conflict, usually corresponding to partisan or ideological identity. It draws the line between us (the in-group) and them (the out-group). Recent studies show that the position on climate policy issues can align with the partisan identity. In such scenarios, what could be done to promote consensus and avoid a deadlock? To address this problem, we consider a system of agents, which is divided into two factions (representing partisan identity) and face a decision among three ranked choices: -1, 0 or 1 (representing e.g. position on climate policy). The choice preference for each agent evolves over time via interaction with others, but is initially aligned with the agent's faction, so that there is total in-group agreement and maximum polarization between the groups. In this setting, we examine how issue-based polarization evolves within an entire family of opinion dynamics models based on the three-state threshold q-voter model (see Figure 1. for a schematic representation of the model). We consider various model specifications to analyze how empirically grounded phenomena interplay with polarization dynamics. In particular, we focus on the frequency of anticonformity in society, the openness to opposing views - modeled by the bounded confidence rule - and the strength of in-group favoritism, especially prevalent in online social communities. To quantify the degree of polarization, we adapt the well-established polarization index of Morales et al. (2015) and introduce its modification for the discrete three-state opinion space. Our results indicate that a depolarization strategy based on the promotion of anticonformity may be more effective than traditional interventions, such as decreasing in-group favoritism or improving tolerance (see Figure 2. for an example phase diagram of the polarization index). Conducting computational experiments on a large collection of models allows us to confirm that the depolarizing power of anticonformity is universal across varying strengths of social influence and different sizes of influence groups. Although our study is theoretical in nature, the design of the models is grounded in empirical social studies. Especially relevant to our work are recent psychological experiments conducted by Dvorak et al. (2024). They do not only show that inducing anticonformity with the reward prospect is possible, but also provide estimates on the frequency of anticonformity, which is of the same order as the critical frequency required to depolarize our agent systems. Hence, we believe that the computational experiments we conducted provide valuable insight into the interplay of anticonformity and polarization and that the proposed concept of strategic anticonformity as a depolarizing intervention displays strong potential for real-world applications.","Arkadiusz Lipiecki, Katarzyna Sznajd-Weron",Atrium,Posters III,35,,787
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Impact of Cognitive Dissonance on Social Hysteresis: Insights from the Expressed and Private Opinions Model.,"It is quite common that people do not always verbalize what they truly think. Therefore opinion dynamics models that distinguish between publicly expressed opinions and private beliefs, so-called expressed and private opinions (EPOs) models gain significant attention. They have been employed to investigate various social phenomena, such as pluralistic ignorance or the spiral of silence. However, they have not been used to better understand social hysteresis - a concept essential for explaining the delayed societal responses to rapid changes in the modern world [1]. Within this research, we attempt to fill this gap and address the question about the impact of cognitive dissonance on the emergence of social hysteresis. We use $q$-voter type model of expressed and private opinions (EPOs) [2] based on the noisy q-voter model [3]. Here, the state of each agent (also called a voter here) indexed by $k = 1, ..., N$ is described by two binary dynamic variables. Expressed opinion visible for others, in the literature also called as public or external, is represented by $S_k = \pm 1$, while $\sigma_k = \pm 1$ stands for private (or internal), known only to the given voter. This binary format of response suits all cases when agents may answer yes/no, be for or against given issue, as well as adopt or not given behavior or new product. Cognitive dissonance, as defined in this work, arises when an agentÕs expressed opinion contradicts its private opinion, i.e., when $S_k = - \sigma_k$, which is consistent with the concept in social psychology [4]. Opinions on both levels, expressed and private, evolve under two types of social response, namely independence (with probability $p$) and conformity (with probability $1-p$). In the first case the agent selected to update its opinion does not take into account anyone else, while the latter requires interaction with the group of $q$ other agents ($q$-panel), who are the source of social influence. We adapt this model to include a mechanism that mitigates cognitive dissonance. We put additional restriction that conformity on the private level cannot lead to dissonance, hence an agent complies with the group only if its expressed opinion is the same as that of the $q$-panel. In this way, we take into account not only the fact that private beliefs shape publicly verbalized opinions, but also that behavior can influence internal beliefs. To describe the macroscopic state of the system, we observe fractions of agents with positive opinions at the expressed ($c_S$) and private ($c_{\sigma}$) level as a function of the probability of independence $p$. We distinguish two qualitatively different stationary states of the system: agreement, when there is a majority of agents selecting the same option ($c_S \neq 1/2, c_\sigma \neq 1/2$), and disagreement, when opinions are divided half by half ($c_S = c_\sigma = 1/2$). We analyze the model both analytically and through Monte Carlo simulations. We find that a mechanism for mitigating cognitive dissonance supports the emergence of social hysteresis indicated by a discontinuous phase transition between agreement and disagreement already observed for a smaller group of influence ($q \ge 3$) as presented in Fig. 1. This means that agreement and disagreement are both stable stationary states and which one is reached depends on the initial situation. Furthermore, aforementioned mechanism also promotes disagreement which is observed for wider range of probability of independence $p$. Therefore, although cognitive dissonance is uncomfortable at an individual level, not avoiding it may facilitate consensus building. This has potential implications for strategies that could be employed to manage societal responses to change. References [1] Sznajd-Weron, K., Jedrzejewski, A., Kami_ska, B., 2024. Toward understanding of the social hysteresis: Insights from agent-based modeling. Perspectives on Psychological Science 19, 511Ð521. doi:10.1177/17456916231195361. [2] Jedrzejewski, A., Marcjasz, G., Nail, P.R., Sznajd-Weron, K., 2018. Think then act or act then think? PLOS ONE 13, 1Ð19. doi:10.1371/journal. pone.0206166. [3] Nyczka, P., Sznajd-Weron, K., Cis_o, J. (2012). Phase transitions in the q-voter model with two types of stochastic driving. Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics, 86(1 Pt 1), 011105. doi:10.1103/PhysRevE.86.011105 [4] Festinger, L., 1957. A theory of cognitive dissonance. Stanford University Press.","Barbara Kamińska, Katarzyna Sznajd-Weron",Atrium,Posters III,36,,516
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Unveiling Bias in Opinion Models: The Role of Network Structure vs. Demographic Attributes,"In this work, we investigate opinion models from a different perspective. Our goal is to answer the question of whether the predictions made by models are prone to systemic bias that can be linked to the existence of minorities in networks and if structural- and attribute-wise features can lead to better prediction of final opinions for those subgroups. We used the dataset of interactions between students at the University of Notre Dame and the answers to questionnaires they filled out after each semester of study (NetSense study [1]). This data has been used as a foundation for the CoDiNG model [2], an extension of the Naming Game model that introduces an opinion formation mechanism grounded in cognitive science. To initialize the model with starting opinions, we used ground-truth data from the first survey. Afterward, we run the CoDiNG model based on the metadata of students' mobile phone interactions. Finally, CoDiNG-modelled opinions of agents were compared against the ground truth (answers of students in the surveys). By knowing when the CoDiNG model incorrectly assigned opinions, we investigated whether this could be linked to the positions of nodes in the communication network or their demographic attributes -- this part of the study involved machine learning to determine which type of input contributes more to the opinion-model's performance in the case of different minorities: the one that derivatives from the topology of the social network, or the one based on agents' demographic attributes. We run the experiments for six survey questions related to topics such as acceptance of euthanasia or marijuana, social security or equal rights in society. To identify minorities we looked at gender, ethnicity, privacy mindset, being English native speaker, parents' income and education, as well as parents' religion. Network attributes were variety of centrality-related measures run on top of a network that has been built by using students' mobile phone interactions, and demography-based features included multiplicity of answers on questions related to students' background. Our results indicate that the demographic data is actually not predictive in cases where the CoDiNG opinion model assigns a correct opinion (in line with ground truth), and, therefore, self-reported data is not helpful here. In contrast, the use of network-based features for the same minorities provides a better F1 score for the classification of opinion. This indicates that the topology of the network is more informative in terms of predicting the final opinion of minorities as compared to demography-based data. A preliminary conclusion from this study is that minorities are more expressive in their actual behaviour (metadata on communication) compared to self-reported data in surveys. This can be observed as the difference between blue and orange bars in Fig.~\ref{fig:comparison}). Moreover, when comparing to the whole population (dashed lines vs. bars for T-B approach), one sees that behavioural data for minorities enables predicting their actual opinions better than those of the whole population.","Stanisław Stępień, Michalina Janik, Mateusz Nurek, Akrati Saxena, Radosław Michalski",Atrium,Posters III,37,,236
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,"PATCH: Network Inequality through Preferential Attachment, Triadic Closure and Homophily","Social networks often show strong degree inequality, with a few people receiving most of the connections, which can limit others’ access to opportunities and information. This work explores three main factors behind this imbalance. First, popular individuals tend to attract even more connections, a mechanisms known as preferential attachment. Second, friends-of-friends are more likely to connect, or triadic closure. Third, people often prefer to interact with those who are similar to themselves, which is called homophily. We introduce PATCH, a network growth model that simulates how these factors work together to shape a network. By adjusting the model to reflect different scenarios, such as whether triadic closure connections are formed randomly or with a homophily bias, we find that a stronger homophily increase the network segregation independently of triadic closure. Meanwhile, preferential attachment boosts overall inequality, especially when individuals favor connections outside their group. PATCH shows that even if one group dominates the network, this advantage often benefits only a few members rather than the entire group. Applying the model to real-world scientific collaboration networks, a variant with preferential attachment and unbiased, but strong triadic closure and moderately high homophily best explains the empirical network inequalities. The findings suggest that any effort to reduce inequality in social networks must carefully address these intertwined factors, rather than targeting just one aspect.","Jan Bachmann, Samuel Martin-Gutierrez, Lisette Espin-Noboa, Nicola Cinardi, Fariba Karimi",Atrium,Posters III,38,,659
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Algorithmically Created Cultural Tastes: How Recommendation Algorithms in Digital Platforms Control Individuals' Music Tastes,"In today’s digital ecosystem, recommendation algorithms play a pivotal role in shaping cultural consumption and influencing individual music tastes. In this study, I simulate user interactions on Spotify by creating controlled accounts with distinct taste profiles. A co-genre network is constructed to quantify two key measures: variety (), representing the breadth of genres, and atypicality (), representing the degree of deviation from conventional genre boundaries. Statistical analyses—including one-way ANOVA and post-hoc Tukey’s HSD tests—demonstrate that, for control accounts, both  and  significantly decline (from  and  to  and , respectively). Conversely, for mono-purist accounts, the algorithm expands exposure within similar cultural confines, with  increasing from  to approximately  and  rising from  to around . These findings, with significance levels of , indicate that while recommendation systems tend to narrow overall musical diversity for general users, they can simultaneously introduce subtle diversification for users with initially narrow preferences. This dual behavior underscores the complex role of algorithmic mediation in cultural consumption and highlights the need for more balanced recommendation systems that support both personalization and cultural diversity.",Hiroki Oda,Atrium,Posters III,39,,644
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Cross-Linguistic Topic Detection and Analysis in the Metadata of Popular Chinese and Japanese Web Romance Novels,"In recent years, web novel-posting platforms have rapidly gained traction in both Japan and China, leading to a surge in related research. However, most existing studies have yet to adopt a comparative perspective between the two countries. In this study, I utilize a multilingual topic modeling approach to analyze the synopses of popular romance novels posted on ChinaÕs ÒJinjiang Literature WebsiteÓ and JapanÕs ÒBecome a novelist.Ó Specifically, I employ a cross-lingual model based on BERT to train on data from both platforms, aiming to extract highly interpretable topics and to elucidate the similarities and differences in content between the two sites.",Huang Chenwen,Atrium,Posters III,40,,401
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Datafication of Ottoman Sijils Using Large Language Models,"Ottoman sharia court records (kadı sicilleri)—the written summaries of legal cases—have long served as a valuable primary source in historical, sociological, and legal scholarship on Ottoman Empire. Given the empire’s extensive duration (r. between XIII and XX centuries) and broad territorial reach, these records (over 20,000 defters and 10 million cases) contain rich information across vast geographies and time periods. Although many individual researchers have extracted data from these sources, there is currently no common dataset openly available to the wider research community. This study aims to contribute a datafication pipeline by leveraging Large Language Models (LLMs) to annotate publicly available Ottoman court records, with the ultimate goal creating a sicil dataset containing information about the several aspects of the cases, like The Proceedings of The Old Bailey project. This proof-of-concept project is currently in progress. Its objectives include 1) conceptualization of variables, that is collaborating with experts in history and law to define social and legal variables relevant to the annotation of court records; 2) developing detailed annotation manuals; 3) LLM-based annotation, that is experimenting with different approaches—ranging from chain-of-thought to few-shot prompting—using various large language models (both open-source and closed-source); and 4) evaluation & refinement, that is comparing machine-generated annotations against human-annotated “ground truth” datasets to measure performance and apply techniques such as fine-tuning to enhance accuracy. Initially, we (as legal historians in the project) have identified a set of legal and societal variables. These variables reflect both historical Islamic legal classifications—no longer in use in Turkey—and contemporary legal frameworks. Each case record is annotated with 1) case information, that is topic area (in historical/legal context), subject matter in modern legal terms, and details about the court and the presiding judge, and 2) demographic details, that is neighborhood/district names, names of plaintiffs, defendants, witnesses, and observers (şuhudü’l-hâl), along with their titles, religions, professions, ethnicities, genders, and the plaintiff-defendant relationship. To test this annotation schema, we randomly selected 200 cases from the Ottoman Üsküdar Court Record No. 531 (covering 1790–1793). Two legal experts manually annotated this subset to produce a gold-standard dataset. The next phase (currently underway) involves applying multiple LLMs to automate annotations, benchmarking their performance against this human-annotated dataset, and iterating on prompts or fine-tuning procedures. Once acceptable accuracy is achieved, we will use LLMs to annotate the entire set of records, and randomly sample machine-annotated entries for manual verification. Ottoman court records exhibit linguistic variety across different centuries and regions, reflecting shifts in language usage and style. Thus, the transferability of our methods to other courts and eras will depend on robust, adaptable annotation strategies. After completing this initial proof-of-concept on late 18th-century Turkish records, we plan to generalize the models to records spanning different centuries and locales (e.g., Diyarbakır, Konya, Sofia, Sarajevo, Crimea, Jerusalem, Cairo). By making annotated datasets openly available, we aim to facilitate computational social science research on historical legal documents, bridging data gaps and enabling new interdisciplinary insights in history, law, and sociology.","Yasin Yılmaz, Nur Şirin Atsızelti, Şükrü Atsızelti, Yunus Uğur",Atrium,Posters III,41,,857
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,When and How Often? Effects of Warning Labels on Dubious Video Sharing,"Although warning interventions are increasingly used to curb the spread of misinformation, their effectiveness varies significantly depending on implementation. This study used online survey experiments to examine how the timing and frequency of warnings affect the sharing intention of dubious videos. Participants evaluated videos featuring politicians they support and made decisions about sharing the videos on social media. In Study 1 (n = 558), a warning label was presented either during or after watching a single video; in Study 2 (n = 631), participants successively watched multiple videos with a warning label. The results revealed that warnings presented during video watching reduced sharing intentions in single-exposure scenarios. However, this effect disappeared with repeated exposure, and notably, warnings presented after watching the videos paradoxically increased sharing intentions, compared to the no warning control condition. These findings highlighted the critical importance of strategic warning implementation to counter visual misinformation.","Jiayu Chen, Bruno T. Sugano, Tasuku Igarashi, Kazutoshi Sasahara",Atrium,Posters III,42,,82
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Exposure and Engagement: Analyzing the Impact of Visual Strategies by Fitness Influencers on Social Media,"Fitness content creators have emerged as key opinion leaders promoting healthy lifestyles on social media platforms, yet existing research has disproportionately focused on their positive influences. Notably, to achieve higher user engagement metrics, these creators increasingly adopt visual content strategies characterized by suggestive elements. Employing supervised computer vision methods, this study analyzed 99,046 images and 25,989 posts from 50 leading fitness content creators on Weibo. Through multi-level analysis of visual content, post text, and creator characteristics, we empirically demonstrated the prevalence and significance of fitness content creators' utilization of suggestive strategies to enhance content visibility.",Wenchang Wang,Atrium,Posters III,43,,53
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Topic Diversity Assessment and Visualization in Public Comments: A Quantitative Approach Based on LDA,"This study examines public comments as a system of public participation, quantitatively assessing and visualizing the diversity of topics within them to evaluate whether public comments contribute to enhancing transparency in policymaking. By doing so, this study aims to present a preliminary discussion toward achieving more inclusive public participation. The analysis focuses on the public comments collected during the formulation of the Fifth and Sixth Basic Environmental Plans, employing LDA (Latent Dirichlet Allocation) for topic modeling and multiple diversity evaluations based on the classification results. Furthermore, cosine similarity based on topic attribution probabilities was used as edges to visualize the relationships between submitted opinions in a network diagram. Through these analyses, it was demonstrated that the two instances of public comments in the formulation of the Basic Environmental Plan ensured different aspects of diversity and contributed to improving transparency in policymaking. Additionally, this study highlights the effectiveness of the proposed diversity indices in measuring the diversity of public comments. In this way, this study presents a preliminary discussion on enhancing transparency in policymaking by introducing and applying a concrete evaluation method for diversity, as explained by Fishkin (2009) as one of the conditions for the quality of deliberation.","Kohei Ishii, Akihiro Kameda",Atrium,Posters III,44,,970
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,"Exclusive Jargon, Secretive Meetings: Speech Dynamics at the Federal Reserve","Central banks, with their control over monetary policy, significantly impact the economy. With their “exclusive jargon and secretive meetings,” (Rajan, 2017) central banks’ decision-making is seen by many as opaque, raising questions about their legitimacy. This paper examines deliberation at the US Federal Reserve. Indeed, US monetary policy is not determined by a single individual but by a committee of central bankers, the Federal Open Market Committee (FOMC). By design, the FOMC includes members from diverse perspectives and backgrounds, such as politically appointed Board members and presidents of regional Federal Reserve Banks. It is also diverse in terms of education, work experience, inflation preferences, and gender. What are the implications of this diversity for deliberation? As Blinder (2007, p. 121) argues, there is a subtle balance to be struck: an ideal monetary policy committee should be ""individualistic enough to reap the benefits of diversity, yet collegial and disciplined enough to project a clear and transparent message."" A unique feature of America's central bank is that the transcripts of the FOMC meetings are made public after a 5-year lag, offering the opportunity to apply textual analysis and opening the door to understanding how central bankers make decisions. We analyze the transcripts of 358 FOMC meetings from 1976 to 2018, recording the interventions of the twelve voting members (including the Fed Chair) and nonvoting Reserve Bank presidents. The goal of the paper is to study lexical similarity across meetings and explore whether, as committee members repeatedly interact meeting after meeting, they converge to use similar words during deliberation. By examining speaking patterns, as in Barron et al. (2018), our analysis can help us understand how and by whom new ideas emerge in central bank discussions, and how they are adopted or discarded by the participants in the meetings. We build two measures of text similarity across meetings based on the standard TF-IDF method combined with cosine similarity, extending it in line with Kelly et al. (2021) to allow the IDF weights to evolve over time as some terms become more or less common over the years. The first similarity measure is the degree of 'backward similarity' (BS), which reflects the extent to which individual's speeches at meeting are similar to speeches in previous meetings (up to a certain lag) by all committee members. The idea is that speeches with low BS can be considered 'novel.' Next, we build a measure of 'forward similarity,' (FS) which evaluates how speeches in future meetings by all committee members are similar to an individual member's speeches at time. Speeches with high FS can be considered influential in driving future deliberation. Finally, we build a measure of \textit{pivotality} given by the ratio between forward and backward similarity for each FOMC member at meeting. Novel speeches that also influence future discourse can be considered pivotal points in speech dynamics. For our three similarity measures, we can rank committee members and investigate how these measures are related to members' personal characteristics. Results show that among FOMC members, the Fed Chairs generally have the highest BS and FS similarity—precisely because they summarize and, at the same time, guide the discussion. Due to their role as consensus builders, however, Chairs tend to have lower pivotality. Among other results, we find that female FOMC members have higher BS and FS measures compared to their male counterparts, and interestingly, women tend to be more pivotal than their male peers. We then examine the impact of FOMC tenure on the development and persistence of word-use patterns. Using fixed effect models, we find that as seniority grows, members not only build on past discussions (i.e., BS increases) but also become more influential in shaping future deliberations (i.e., FS increases as well). The pivotality index, however, is not significantly related to seniority. This suggests that over time, members become more integrated within the committee, potentially improving outcomes. Finally, we find that both measures of similarity fluctuate over time, displaying a downward trend. This could be an indication of increasing cultural differences and less effective deliberation, or, on a more positive note, as a sign of greater originality in discussions. To address this issue, the final part of the paper computes measures of deliberation quality (e.g., topic heterogeneity, obtained using LDA) and inflation preferences (relying on the RoBERTa-large model fine-tuned by Shah et al. (2023) to evaluate the hawkishness or dovishness towards inflation in FOMC statements) and relates these to our similarity measures.","Adrien Letellier, Alessandro Riboni, Francisco Ruge-Murcia",Atrium,Posters III,45,,170
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Friends In The Making: The Co-Development of Friendships and Personality,"This study explores the reciprocal influence between personality and peer relationships during adolescence. The co-development of three Big Five personality traits and friendships was simulated in RSiena using a social network approach and longitudinal data on school-based friendship networks. Friendship nominations were linked to higher levels of extraversion and lower levels of agreeableness. Openness to experience predicted the number of received friendship nominations. Furthermore, friends significantly influenced personality traits, leading to greater similarity over time. The findings provide insights regarding the mechanisms of social selection and social influence among already acquainted individuals, enhancing our understanding of personality development and friendship formation in adolescence.",Ina Ni,Atrium,Posters III,46,,969
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Optimal mental representation of social networks explains biases in social learning and perception,"Social networks modulate our beliefs and choices in a wide range of activities. Interestingly, when making decisions within complex social networks, it is often impossible to consider the topological structure of entire network. So which social connections are considered and which are ignored, how will the streamlined representation of network affect our perception and navigation of the social world? Here we propose a computational account whereby individuals with limited cognitive resource construct simplified social network representations flexibly and optimally to facilitate social learning. Using data from 4 separate lab and field studies, we show that network representations derived from our model were similar to those revealed by subjects choices and graph neural network (GNN) trained to mimic human learning. Our model offers a normative explanation for DeGroot learning, one of the most influential heuristics for learning on networks; unifies a variety of seemingly disparate biases previously reported in social relationship perception; provides a window into the cognitive root of some important societal conundrums; and points to potential connections in network representation learning between machine and human intelligence.","Yulin Dong, Lusha Zhu",Atrium,Posters III,47,,323
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Epidemic modelling with human behaviour: An interdisciplinary framework for the collection of empirical behavioural data across countries,"Human behavior both shapes and is shaped by epidemic dynamics, yet many existing models underrepresent this reciprocal influence. To address this gap, we developed an interdisciplinary framework that integrates behavioral science theory with modern epidemic modeling. Drawing on the COM-B (ÒCapability, Opportunity, MotivationÓ) model, we designed and administered an online survey in six European countries (Italy, France, Germany, Hungary, Spain, and the UK), gathering 21,318 responses on COVID-19 vaccination, influenza and routine childhood vaccine uptake, mask use, and self-isolation. We captured key behavioral antecedentsÑsuch as time-varying Òwillingness to vaccinateÓ and Òperceived riskÓÑand contextual information on individualsÕ social contacts and exposure to information sources. Our findings validated Òwillingness to vaccinateÓ as a useful yet imperfect proxy for actual vaccine uptake: despite high willingness correlating with timely vaccination, some individuals remained unvaccinated or stopped vaccinating after earlier doses. Parallel analyses in Italy and France revealed dynamic shifts in perceived severity of COVID-19 and vaccine willingness over time, highlighting variations in cultural contexts. By systematically incorporating empirically grounded behavioral parameters, our framework offers new avenues for developing epidemic models that more accurately represent how individual attitudes and behaviors evolve, ultimately supporting more effective disease control strategies.","Vittoria Offeddu, Elisabetta Colosi, Maria Cucciniello, Lorenzo Lucchini, Laura P. Leone, Duilio Balsamo, Chiara Chiavenna, Elena D'agnese, Julia Koltai, Vittoria Colizza, Yamir Moreno, Marton Karsai, Emilio Zagheni, Renu Singh, Filippo Trentini, Alessia Melegaro",Atrium,Posters III,48,,1012
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Quantifying fairness of infectious disease models,"Infectious disease modelling is a key tool to inform outbreak response and guide policymakers in the adoption of interventions [1]. For example, during the COVID-19 pandemic, computational models of infectious disease spread have been extensively used to assess the impact of non-pharmaceutical interventions, evaluate scenarios, and design mitigation strategies [2]. At the same time, the COVID-19 pandemic has been characterized by massive inequities showing a disproportionate health impact among vulnerable groups, and minorities, and in several cases, intervention strategies have amplified such disparities, instead of reducing them [3,4]. The urgent need for equitable intervention strategies has led to the call for epidemic models that can integrate aspects of equity into their mechanisms, leading to more realistic descriptions of the epidemic burden between different socioeconomic groups and demographics [5]. Moreover, the lack of equitable computational modeling frameworks to simulate infectious disease epidemics is accompanied by a lack of standard methods to evaluate model fairness. In recent years, due to its increasing relevance in real-world decision-making, the machine learning community has been confronted with the concept of fairness, leading to an extensive literature [6]. Although epidemic modelling similarly has a relevant impact on policy decisions, a commonly agreed definition of the fairness of infectious disease models remains elusive. In this work, we address this gap by providing a first general definition of fairness for models of infectious disease spread. We define the fairness of an epidemic model as the model's ability to capture the (un)equal distribution of disease burden according to one or more equity-related features. Given a demographic or socioeconomic trait that is a known determinant of health for the population and the disease under study, an epidemic model will be fair if it captures the observed inequality in health outcomes according to such variable. We then operationalize our definition by providing quantitative fairness measures for different epidemic scenarios, introducing a set of metrics that quantify the fairness of a model in different cases. Following the traditional literature of social epidemiology [7], we consider three distinct types of health inequalities: (i) ordered social groups, (ii) unordered social groups, and (iii) spatially structured populations. For each type, we introduce a specific metric that quantifies a model's fairness: the relative concentration index fairness, the Theil-index fairness, and the spatial fairness. The first one quantifies a model accuracy to capture the health gradients associated with naturally ordered social groups, such as income, education, or age. The second scores the modelÕs accuracy in the case of unordered social groups, such as racial or ethnic groups. The third measures a model fairness in capturing the spatial heterogeneity of disease burden, whether associated with ordered or unordered groups. We explore the application of our definitions of fairness with numerical simulations of COVID-19 spread in the USA (see Fig.1), the UK, and Chile, and of Zika virus in Colombia. Our results show that our definition of fairness can be consistently applied to a range of modelling approaches and disease scenarios. Moreover, we demonstrate that increasing a modelÕs complexity through additional data layers or compartments, does not always enhance its fairness. Instead, we show how the fairness of an epidemic model may depend on its mathematical assumptions, such as the use of contact matrices and the assumed distribution of disease parameters. Our work provides modellers and public health officials with a new tool that can help evaluate modelling outcomes through the lens of equity, thus reducing socioeconomic biases in outbreak management and response. References 1. Lofgren, E. T., et al. (2014). Mathematical models: A key tool for outbreak response. Proceedings of the National Academy of Sciences, 111(51), 18095-18096. 2. Vespignani, A., et al. (2020). Modelling covid-19. Nature Reviews Physics, 2(6), 279-281. 3 .Tizzoni, M., et al. (2022). Addressing the socioeconomic divide in computational modeling for infectious diseases. Nature Communications, 13(1), 2897 4. Alberti, P. et al. (2020). Equitable pandemic preparedness and rapid response: lessons from COVID-19 for pandemic health equity. Journal of health politics, policy and law, 45(6), 921-935. 5. Zelner, J., et al. (2022). There are no equal opportunity infectors: Epidemiological modelers must rethink our approach to inequality in infection risk. PLoS computational biology, 18(2), e1009795. 6. Caton, S., & Haas, C. (2024). Fairness in machine learning: A survey. ACM Computing Surveys, 56(7), 1-38. 7. Oakes, J. Michael, and Jay S. Kaufman, eds. Methods in social epidemiology. John Wiley & Sons, 2017.","Yuhan Li, Nicolò Gozzi, Nicola Perra, Michele Tizzoni",Atrium,Posters III,49,,166
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Effective Propagation Distance: A novel approach to source localization in complex networks,"Identifying the origin of a spreading process -- whether it be an epidemic outbreak or the diffusion of information — is a fundamental challenge in network science. Research in this area was initiated by Shah and Zaman [1], and the most seminal works include articles by Pinto et al. [2], Brockmann and Helbing [3] and Lokhov et al. [4]. Source location methods can be divided into two types depending on how we observe propagation in the network [5]: snapshot-based and observer-based. Snapshot provides the knowledge of the states of all or part of nodes at a given time $t$. Observers are the nodes $\{o_i\}$ which reveal times $\{t_i\}$ at which they got infected or informed. A recent review [6] shows that the correlation-based approach typically (but not always) demonstrates the highest source localization performance among observer-based methods. These methods search for a node $s$ that maximizes the correlation coefficient $r_s \equiv r (\vec{t}, \vec{d_s})$ of observed infection times $\vec{t} = \{t_i\}$ and the distances $\vec{d_s} = \{d(s,o_i)\}$ between node $s$ and the observers $\vec{o} = \{o_i\}$, i.e., $s^\ast = \arg \max r_s$. The above procedure is based on the assumption that the further the observer is from the source, the later it should become infected. This approach was first used by Xu et al. [7] and Wang [8], with the former using Pearson's correlation coefficient and the latter using Spearman's. The common denominator of these two works is the choice of geodesic distance as the distance metric in the network. Our research aims to improve the correlation-based approach by utilizing a more suitable correlation function and a more realistic distance metric. Following the insights from the work of Paluch et al. [9] that information from the first observers is the most valuable, we use the weighted Pearson correlation, where observer weight decreases with the observer rank, i.e., $w_i = \textrm{rank}(t_i)^{-\alpha}$. The $\alpha$ coefficient regulates the strength and direction of the observers' prioritization so that for $\alpha>0$, the first observers have higher weights, and for $\alpha<0$, it is the opposite. If $\alpha=0$, then the correlation is unweighted. Based on the conclusions from the work of Gajewski et al. [10], we note that the assumption that a signal propagates only along the shortest paths in a network may be incorrect in many situations. If the signal is highly stochastic and the number of paths between nodes is large, the geodesic distance may not be the best predictor of the time it takes for information to travel from the source to the observer. Therefore, we propose a novel measure — Effective Propagation Distance (EPD) — which considers all possible propagation paths in the network. The EPD is based on the Susceptible-Infected model, a well-established tool in epidemics studies. To determine the EPD between node $s$ and the remaining nodes in the network, it is necessary to run the SI dynamics $n$ times starting from vertex $s$, and then average the infection times of the remaining nodes over the process realizations, i.e., $EPD(s, k) = \frac{\lambda_{EPD}}{n} \sum_{l=1}^{n} t_l(s,k)$, where $\lambda_{EPD}$ is the infection rate. To measure the effectiveness of our approach, we performed multiple numerical experiments on three real networks. Each experiment consists of several thousand trials, including the selection of a random source and random observers, the simulation of a propagation process, and finally, the source location. We use the same transmission model as in [2], i.e., we assign random delays $\{\theta_{ij}\} \sim N(\mu,\sigma)$ to all edges in the graph, and then we compute an observer's infection time as the sum of delays along the shortest weighted paths between the source and this observer. The number of observers is proportional to the number of nodes in the network, i.e., $N_{obs} = \rho |V|$, where $\rho=0.2$. The relative standard deviation of the propagation process $RSD = \frac{\sigma}{\mu} = 0.6$ in our experiments. Figure 1 presents the results of numerical experiments. It shows how the average precision of source detection depends on the $\alpha$ and the $\lambda_{EPD}$ parameters. It can be seen that the weighted Pearson correlation ($\alpha>0$) provides higher average precision than the unweighted correlation ($\alpha = 0$). Another insight from Fig. 1 is that the optimal value of the $\alpha$ parameter is not constant and depends on the network topology, the $\lambda_{EPD}$ parameter and probably also other parameters, such as $\rho$ and $RSD$. Last but not least, Fig. 1 shows that EPD outperforms geodesic distance in all experiments performed for given networks and a given transmission model. In summary, our proposed approach significantly improves the efficiency of propagation source localization in complex networks. The next research step is to conduct tests to detect real propagation sources.","Robert Paluch, Robert Jankowski",Atrium,Posters III,50,,971
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,A Flexible Agent-Based Model for Replicating Evolutionary Dynamics in Prisoner’s Dilemma Studies,"The evolution of cooperation has long been a focus of social science, with evolutionary game theory and agent-based models (ABMs) providing increasingly sophisticated tools for investigation. Today, a wide range of studies examine how factors such as kin selection, tag-based strategies, and network structure influence cooperation. However, a key question remains: how robust are these simulations to parameters that researchers have not explicitly varied, or to alternative model assumptions? Here, we present a flexible, computationally efficient ABM designed to replicate studies on the emergence and stability of cooperative behaviour. Our framework supports multiple decision paradigms (e.g., rational choice or dual-process cognition), different population structures, and a range of parameter settings - allowing us to replicate a diverse set of studies. By validating known results and systematically examining their dependence on key parameters or model assumptions, this work advances transparency, reproducibility, and reliability in computational social science.",Sascha Grehl,Atrium,Posters III,51,,841
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Success-driven Users and the Rise of Digital Polarization. A Simulation Study based on the Axelrod-model,"Online social networks are often seen as breeding grounds for polarization. This simulation study offers an additional explanation, linking polarization to success-driven user behavior. Using an agent-based model, we show that polarization increases when users become more active following rewarding interactions on the platform. We compare a basic version of Axelrod's model of cultural dissemination, which does not account for success-driven activity, with an extended version that includes this mechanism. Our analyses replicate key findings from existing literature and demonstrate that success-driven activity consistently amplifies polarization, even in scenarios where Axelrod's model would typically predict uniformity, such as in complete networks or those with minimal clustering. This activity triggers a ""rich-get-richer"" effect, where success leads to more engagement, further skewing success distribution. As a result, a small number of highly successful users dominate discussions, leading to local convergence and fragmentation into distinct groups. This polarization emerges in a model devoid of biased media, polarized elites, algorithmic echo chambers, or users intentionally segregating themselves. We explore the implications of this finding for designing online social networks that minimize polarization and for developing digital twins of these platforms for regulatory and analytical purposes.","Sophia Horn, Michael Maes",Atrium,Posters III,52,,530
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Human-AI Cooperation: Leveraging AI Norm Reinforcement in a Public Goods Game,"Artificial Intelligence (AI) is increasingly integrated into everyday life, influencing decision-making, social interactions, and group behavior. As AI takes on more autonomous roles in workplaces, governance, and digital platforms, understanding human-AI cooperation has become a critical research challenge. While prior studies have explored AI as a social actor affecting trust, emotions, and social identity, much of this research focuses on dyadic interactions, overlooking the complexities of group cooperation and the role of social norms. Social norms play a key role in sustaining cooperation by establishing shared expectations and mitigating free-riding behavior, particularly in public goods dilemmas. In human-AI interactions, AI can actively shape these norms by either reinforcing cooperative behavior or facilitating norm erosion through non-cooperative actions. To empirically investigate AIÕs influence on social norms, experimental approaches that capture the emergence and enforcement of cooperative norms and behaviors are needed. This study employs the Public Goods Game (PGG) as a framework to analyze how AI agents influence cooperation within human-AI groups. The experiment consists of an online, repeated PGG played over ten rounds in groups of four. In each round, participants allocate tokens between a private account, which directly converts into their profit, and a group account, where contributions are doubled and evenly distributed among all members. Participants receive feedback on the contributions and earnings of their group after each round. The study includes a control condition, where two human participants interact with two AI bots that are mislabeled as human players, and treatment conditions, where the two bots are explicitly labeled as AI agents. AI agents follow one of three predefined decision strategies: an unconditional cooperator, which consistently contributes to reinforce cooperative norms; a conditional cooperator, which adjusts contributions in response to human players; and a free-rider, which rarely contributes, modeling non-cooperative behavior. By analyzing contributions to the public good as the primary dependent variable, this study examines the extent to which AI labeling and decision strategy influence cooperation. Additionally, data on trust, group cohesion, social perception, and normative pressures will be collected to assess broader social dynamics. By comparing human-labeled and AI-labeled agents across different cooperation strategies, this study aims to provide insights into AIÕs role in shaping cooperative behavior in hybrid groups. Findings will contribute to understanding how AI can be leveraged to foster cooperation or, conversely, how it may disrupt social norms in mixed-agent environments, informing the design of AI systems that interact with humans in social and economic settings.","Nico Mutzner, Taha Yasseri, Heiko Rauhut",Atrium,Posters III,53,,542
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Investigating the psychological mechanisms of social dilemmas with cognitive institutional agents,"Discourse around the social dilemmas understands their psychological bases as primarily anticipatory: a ""race to the bottom"" driven by anticipation and the self-fulfilling prophecy of prospective loss. However, in scenarios like the common pool resource game, the standard static game theoretic analysis, via Nash equilibrium, makes no cognitive claim beyond utility maximization and provides no more basis for expecting a resource crash than a gradual linear or even exponential decay in resource availability. This allows that resource decline may be driven by other psychological mechanisms, may follow other functional forms, and be treated in different ways depending on the underlying psychological driver. For example, imagine a more passive adaptive mechanism in which contributors who are otherwise prosocial norm their own behavior to their observations of a small number of visible defectors. These alternative psychological mechanisms are important to consider because they can form the basis of dynamic theories, and help predict when a commons will be vulnerable to decelerating, constant, or accelerating decline. And by mapping the cognitive drivers of resource dilemmas to their varied dynamics, we can predict the sensitivity of limited resources to social factors.","Seth Frey, Christopher K. Frantz",Atrium,Posters III,54,,483
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Public Attention Towards Sustainability in the EU: An Exploration of Google Trends Data,"This research explores public attention towards sustainability in the European Union (EU) using Google Trends data. By leveraging Google’s Trends API, the study assesses the evolution and composition of public attention towards sustainability across EU member states. The analysis reveals a steady increase in public engagement with sustainability issues since 2018, with notable regional disparities between Western and Eastern Europe. The research identifies the most common topics associated with sustainability, such as energy, sustainable development, and environmental issues, while also highlighting the growing influence of economic and corporate dimensions in public discourse. This methodological approach provides a data-driven perspective on sustainability awareness, offering valuable insights for policymakers, businesses, and civil society organizations aiming to enhance public engagement and inform sustainability strategies.","Nora Svensson Hahr, Davide Beraldo, Martin Brohol Trans",Atrium,Posters III,55,,141
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Science and Technology in Science Fiction: A Pre- and Post-WWII Comparison through Word Embedding and Mixed-Method Topic Modelling,"Science Fiction literature (SciFi) research has long focused on the thematic shifts of SciFi works over time, but there are still two gaps that remain unresolved. First, qualitative SciFi studies often concentrate on individual works from specific authors or periods, lacking large-scale analysis across extended timeframes, which may overlook marginalized works. Second, there has been no systematic examination of how SciFi imagines and represents science and technology. This study aims to address both issues by comparing SciFi works from before and after World War II (WWII), employing a mixed-methods approach with natural language processing. To avoid bias caused by differences in the length of works, this study uses book summaries with stable lengths for analysis. Given the development of large language models (LLMs), obtaining high-quality book summaries will likely become easier in the future, making this methodological approach valuable. The study aims to identify differences in the representation of science and technology in SciFi works before and after WWII, which may reflect the influence of the arms race and Cold War ideologies on broader technological culture. To mitigate biases arising from differences in text length, we analyze book summaries rather than full texts. Our dataset ($N=852$) is sourced from the Gutenberg Project, which collects public-domain works based on topic rather than author prominence or ideological influence. We developed a Python web scraper to extract SiFi books that contain summaries and retrieved missing publication dates using Wikipedia. The dataset is restricted to English-language SiFi novels, divided into two subsets using 1949 as the temporal boundary ($N_{\text{pre}} = 389$, $N_{\text{post}} = 463$). We identify key thematic dimensions in SiFi through a combination of inductive content analysis and Correlation Explanation (CorEx) topic modeling. This yields two analytical dimensions: \textit{Individual Story} vs. \textit{Macro Narrative} and \textit{External Exploration} vs. \textit{Internal Conflict}. Using Word2Vec, we generate word embeddings for pre- and post-WWII corpora, normalizing vector spaces using z-score for comparability. The position of target words such as ""science"" and ""technology"" along these dimensions is computed using cosine similarity: $$ l_{\textbf{v}} = \text{mean}(\cos (\textbf{v}, \text{attribute}_{\text{positive}, i})) - \text{mean}(\cos (\textbf{v}, \text{attribute}_{\text{negative}, j})) $$ The results for five target words (""science"", ""technology"", ""scientific"", ""technological"" and ""technical"") are reported separately, along with their average effect. All effects are negative, and the average effect is significant at the 0.1 level. This indicates that post-WWII SciFi represents science and technology more in the context of macro narratives (such as civilizations, politics, and authority) and internal conflicts (such as war, conflict, and military). In contrast, pre-WWII SciFi constructs science and technology more in relation to individual stories and emotions (such as adventure, longing, and bravery), as well as external exploration (such as discovery, creatures, and the cosmos). We repeatedly adjusted the modelÕs hyperparameters, attribute word combinations, and dataset partitioning rules. Additionally, for books with missing original publication years, we imputed the data using the average of the author's birth and death years to expand the sample size. The results remained robust. This study makes contributions both methodologically and theoretically. Methodologically, it demonstrates that topic modeling combined with word embedding techniques is an effective approach for extracting information from book summaries and comparing semantic differences across periods or genres, allowing for a comprehensive examination of large-scale literary works with relatively low computational and time costs while mitigating biases caused by variations in text length or authorsÕ productivity. Future research could leverage fine-tuned or self-trained LLMs to generate book summaries, enabling more precise and targeted information extraction. Theoretically, this study provides quantitative evidence on how representations of science and technology evolve over time, illustrating that SciFi is not merely a product of imagination but also a reflection of social and political contexts. Specifically, we find that post-WWII works embed science and technology within narratives of politics and warfare, whereas earlier works emphasize individual heroism and cosmic exploration. This insight offers a heuristic analytical framework for the study of SciFi.",Zeyuan Chen,Atrium,Posters III,56,,57
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,The Contemporary Debate on Secularization and Its Cross-National Variation: A Systematic Analysis through Topic Modeling,"Secularization is one of the most important yet contested terms in the social sciences to describe the decline and transformation of religion facing modernity. This study applies structural topic modeling (STM) to 1638 academic articles published between 2001 and 2022, offering a data-driven systematization of the debate. The analysis identifies 13 topics grouped into four thematic clusters: institutional secularization, individual religious trajectories, theoretical critiques, and religious traditions. A cross-national comparison further examines institutional parochialism, or the tendency of scholars to study their own cultural contexts. A linear regression model is estimated to study the relationship between authorsÕ institutional affiliation and topic prevalence. While research on non-Western religions is expanding, the debate remains dominated by Western-based scholars, shaping the discourse on secularization.","Valeria Rainero, Ruud Luijkx",Atrium,Posters III,57,,182
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Entangled Webs: Network Structures in Public Procurement for Policy,"The resurgence of industrial policy has brought public procurement back into the spotlight. However, the essential mechanics of firm behavior in public procurement markets have largely been overlooked. In this contribution, we analyze firm behavior in these markets using methods from network analysis and economic complexity. Our study is based on two network representations: Firm-firm co-bidding networks, which reveal hierarchical structures within procurement markets; and a proximity structure that connects procurement activities. We leverage this proximity structure to examine the role of knowledge relatedness in firm diversification behavior. Our findings indicate that firms are more likely to develop comparative advantages in activities that are closer to their existing knowledge base and tend to retain those activities they are most related to. By adopting network-based structures, we open new avenues for research in public procurement, offering a more accurate representation of the complex market dynamics between firms and the public sector.","Niclas Frederic Sturm, Cristian Candia, Bruno Damásio, Flávio L. Pinheiro",Atrium,Posters III,58,,442
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Modelling the collapse of complex societies,"The presentation will provide an overview on modelling long-term societal evolution and the potential for collapse. As a specific example we propose a simplified model of a socio-environmental system that accounts for population, resources, and wealth, with a quadratic population contribution in the resource extraction term. Given its structure, an analytical treatment of attractors and bifurcations is possible. In particular, a Hopf bifurcation from a stable fixed point to a limit cycle emerges above a critical value of the extraction rate parameter. The stable fixed-point attractor can be interpreted as a sustainable regime, and a large-amplitude limit cycle as an unsustainable regime. The model is generalized to multiple interacting systems, with chaotic dynamics emerging for small non-uniformities in the interaction matrix. In contrast to systems where a specific parameter choice or a high number of dimensions is necessary for chaos to emerge, chaotic dynamics here appears as a generic feature of the system. In addition, we show that diffusion can stabilize networks of sustainable and unsustainable societies, and thus, interconnection could be a way of increasing resilience in global networked systems. Overall, the multi-systems model provides a timescale of predictability (300-1000 years) for societal dynamics comparable to results from other studies, while indicating that the emergent dynamics of networks of interacting societies over longer time spans is likely chaotic and hence unpredictable.",Sabin Roman,Atrium,Posters III,59,,390
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,How government use of AI impacts its trustworthiness: evidence from a survey experiment,"Artificial intelligence (AI) has received a lot of attention as an avenue for achieving much needed gains in efficiency and productivity in the public sector and for improving the quality of public services [1]. On the one hand, there is clear evidence that algorithms can help humans make better decisions and can outperform even human experts [2] Ð which supports the case for implementing AI. On the other hand, studies show that people hold profound aversions against algorithms irrespective of their performance [3]. This would suggest that however successful a proliferation of AI in the public sector may be Ð citizens will tend to prefer Òthe human touchÓ over any version of public institutions that are Òpowered by AIÓ. While much is known about the magnitude and circumstances of algorithmic aversion, less is known about whether this aversion affects other attitudes towards the public sector Ð for instance whether the use of AI by a public institution impacts attitudes towards the institution itself. In this study, we examine the causal influence of AI on trust in the institutions who have implemented AI in their work. We perform a survey experiment with an information treatment and measure the causal effect of AI on trust in public institutions. In the context of Denmark Ð that has the most digitized public sector in the world [4] Ð we survey citizens about their trust in a set of public institutions (police, social services, hospitals and nursing homes). We first measure participantsÕ overall trust in the public sector and then treat them with vignettes describing how the above-mentioned set of public institutions execute their mandated tasks, with and without mentioning their widespread use of AI in doing so (see Figure 1). Each participant is exposed to one use case and potential information treatment, selected from one of the four different AI use cases from different institutions. After the information treatment, participants will answer a set of auxiliary questions regarding their perception of AI in the public sector and their own experience with and knowledge about AI. Additionally, we also examine who is impacted most by AI regarding their trust in public institutions. To this end, we couple the survey responses with highly detailed Danish administrative data with rich information about sociodemographic background and the social networks of participants. We then perform a heterogeneity analysis of the treatment effects to shed light on the perceptions of vulnerable stakeholders, following the authors of [5] and work within the fields of participatory design of AI systems [6]. Denmark offers a unique context for this research, since the Danish public sector has extensively implemented algorithms in the inner workings of administrative processes and for decision support without widespread public awareness about this implementation. The survey experiment will run in April and May 2025, with preliminary results ready for the IC2S2 conference in July 2025. References [1] Misuraca, G. & Van Noordt, C. AI Watch Ð Artificial Intelligence in public services: Overview of the use and impact of AI in public services in the EU. JRC Research Reports (2020). [2] Vaccaro, M., Almaatouq, A. & Malone, T. When combinations of humans and AI are useful: A systematic review and meta-analysis. Nat Hum Behav 8, 2293Ð2303 (2024). [3] Dietvorst, B., Simmons, J., Masset, C. Algorithm Aversion: People erroneously avoid algorithms after seeing them err. Journal of Experimental Psychology. (2014). [4] United Nations. UN E-Government Survey 2024. (2024). [5] Dong, M., Bonnefon, JF., Rahwan, I. False Consensus Biases AI Against Vulnerable Stakeholders. (2024) [6] Birhane, A. et al. Power to the people? Opportunities and challenges for participatory AI. (2022)","Daniel Juhász Vigild, Vedran Sekara, Andreas Bjerre-Nielsen",Atrium,Posters III,60,,178
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Public Trust and Blame Attribution in Human-AI Interactions: A Comparison Between Air Traffic Control and Vehicle Driving,"Artificial Intelligence (AI) has potential to address the increasing demand for capacity in Air Traffic Control (ATC). However, its integration poses several challenges and requires deep understanding of public perception. Insights from the context of Autonomous Vehicles (AVs), in which more studies have been done, can inform such understanding. In this study, we investigate how the public perceives the automated future of ATC compared to AVs. We conducted two studies (N=1289; including one with a nationally representative sample) to examine public trust and blame attribution toward human and AI operators in different Human-AI Interaction (HAI) models. We also explored their perceptions of ATC and vehicle driving (VD) by using ten task-related measures (e.g., familiarity, expertise, uncertainty) and five agent-related characteristics (e.g., capability, robustness). The results showed generally greater trust and less blame attributed to humans in both ATC and VD. Our findings provide evidence-based insights into how the public attribute trust and blame to the operators in ATC and VD.","Peidong Mei, Richard Cannon, Jim Everett, Peng Liu, Edmond Awad",Atrium,Posters III,61,,607
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Leveraging the Power of Social Interactions to Build Trust in Crowdsourced Data,"In this paper, we explore how to build trust in crowdsourced data leveraging the power of social interaction as a conduit to exchange data among eligible participants. We rely on people's honesty as a shaping factor for data-dissemination-based social interactions. We think people's honesty is a precious resource that, despite not guaranteed for everyone, is abundant enough to count on, as is also assumed at the core of cryptocurrency systems. In this work we introduce an initial exploration of this concept and seek to answer these questions 1) How can we structure crowdsourcing in a practical peer-to-peer model? 2) How can we build trust in the collected data based on social interaction? 3) How would that be impacted by the main factors characterizing this process?",Amr Hilal,Atrium,Posters III,62,,932
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Large Language Model-Informed Feature Discovery Improves Prediction and Interpretation of Credibility Perceptions of Visual Content,"Given the prevalence of visual content in today's media landscape, accurately assessing human credibility perceptions of visual media and identifying key message features that influence these judgments are essential for combating misinformation and prioritizing high-risk posts. These tasks remain challenging due to the vast range of content features and the complexity of visual data analysis. We introduce a Large Language Model (LLM)-informed feature discovery framework that leverages multimodal LLMs like GPT-4o to systematically evaluate content credibility and explain its reasoning. We then extract interpretable features from its reasoning, quantify these features using targeted prompts, and integrate them into machine learning models to enhance credibility predictions. We applied this approach to a dataset of visual social media posts (N = 4,191) spanning eight diverse topics in science, health, and politics, with credibility ratings from crowdsourced workers (N = 5,355). Our method not only significantly outperformed zero-shot GPT-based predictions for credibility ratings (achieving a 13\% increase in $R^2$) but also revealed influential and interpretable content features, such as information concreteness and image format. We discuss the implications for misinformation mitigation, research on visual media, and the role of LLMs in social science.","Yilang Peng, Sijia Qian, Yingdan Lu, Cuihua Shen",Atrium,Posters III,63,,468
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Towards Artificial Intelligence for the Public Sector: Bridging Academia and Practice,"As academic knowledge expands, it becomes increasingly difficult for academics and practitioners to keep track of new developments, identify relevant studies on a topic of interest, assess the content and quality of existing evidence and even select what evidence to build upon to advance a field of knowledge. This is particularly true for the nascent, yet burgeoning field of research related to the use of Artificial Intelligence (AI) in the public sector. Consequently, policy practitioners looking to explore how to effectively leverage AI in their organizations may encounter a fragmented academic landscape that is becoming increasingly difficult to navigate. This paper therefore proposes a functional framework that organizes and links academic scholarship in this field to the functions of public governance public sector organizations are generally oriented around. To test this framework, we employ a novel, computational approach. First, we conduct a systematic literature review of relevant, peer-reviewed academic journal abstracts pulled from OpenAlex API. We then utilize a pre-trained Bidirectional Encoder Representations from Transformers (BERT) large language model (LLM) to generate unsupervised topic representations, or themes, from this corpus of academic abstracts. Lastly, we classify the topic representations and their semantically similar articles using our functional framework. In addition to using a novel computational approach for conducting a systematic literature review that is transparent, reproducible, easily updated, and efficient, this paper aims to provide a practical resource for both academics and policy professionals interested in exploring the applications of AI technologies in the public sector.","Alexander Mintz, Ji Ma",Atrium,Posters III,64,,2
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Suspense and Surprise in the Book of Technology: Understanding Innovation Dynamics,"We envision future technologies through strategic planning frameworks, academic research, and even the imaginative narratives of science fiction. Yet, like any good story, the progression of technological innovation is full of twists and turns, indicating its inherent uncertainty. Some developments align with our expectations, while others surprise us with unexpected outcomes that reshape our understanding. Here, we analyze U.S. patents to classify these mismatches between ex-ante projections and ex-post outcomes using two key concepts: suspense and surprise. Suspense captures the buildup of uncertainty as we anticipate how technology might unfold before its realization, whereas surprise represents a dramatic shift in understanding when development occurs in an entirely unexpected way. In this study, we develop an innovation prediction model and quantify the disagreement between prediction and realization using the concepts of suspense and surprise. The model predicts potential connections based on the popularity and similarity of technology pairs. By fitting the model to a dataset of realized connections, we calculate the belief score at time $t$, denoted as $B_{AB}(t)$, which reflects the likelihood that a currently unrealized pair will eventually form a connection. Suspense and surprise are defined in the context of technological innovation. A threshold $B_{\theta}$ represents the model's confidence level, serving as the criteria of the prediction. Suspense captures the accumulation of uncertainty over time. A new link is considered suspense if its belief score surpasses the threshold $B_{\theta}$ at least once before the connection is realized. Suspense indicates that the model anticipates the connection could occur at any time, with uncertainty cumulated as time progresses. Conversely, surprise captures a sudden shift in belief. A new link is classified as a surprise if the belief score remains below the threshold $B_{\theta}$ before the connection, suggesting that the model did not anticipate the event. To explore suspense and surprise within the technological innovation, we utilize the United States Patent and Trademark Office (USPTO) patent dataset, focusing on the United States Patent Classification (USPC) codes at the 2-digit main class level. The dataset comprises 8,884,966 utility patents, encompassing 438 technology codes from 1940 to 2015. Our analysis identified 53,533 suspense pairs and 16,723 surprise pairs using an optimal threshold value from the ROC curve. The proportion of suspenseful and surprising connections remained relatively consistent over time. We compared the suspense and surprise in the innovations of Edison and Tesla. Both inventors exhibited fewer suspenseful but more surprising connections than the overall dataset. However, Edison showed a balance between average and extreme connections, indicating a focus on institutional inventions, while Tesla emphasized pure engineering innovations. Furthermore, suspenseful connections tended to be more widely accepted, whereas surprising connections had a lesser impact. By tracking the trends of suspense and surprise, we identified common patterns in the technology lifecycle. Recent and innovative technologies, such as Electric Lamp and Discharge Devices, are characterized by an initial phase of surprise followed by suspense, contrasting with conventional technologies like Planting, which exhibit leading suspense followed by surprise. This observation suggests a lifecycle for innovative technology, beginning with surprise, progressing through early adoption marked by suspense, and culminating in widespread acceptance. In this work, we categorize technological innovations into suspense and surprise events. Through the cases of Edison and Tesla, we demonstrate that suspense innovations tend to achieve broader acceptance, while surprise innovations highlight the uniqueness of an idea relative to other combinations. We extend these concepts to the broad technology fields, examining how technologies are interconnected throughout their lifecycle. Our findings indicate that technologies characterized by higher levels of surprise exhibit distinct impacts, with clear stages of early growth and acceptance marked by both suspense and surprise. The framework of suspense and surprise can be extended to other domains, such as academia or literature, where we can define combinations of ideas, such as the encounter of characters or the fusion of concepts. In these systems, a link prediction task can be established using a prediction model, allowing us to categorize suspenseful and surprising links based on the deviation between expectations and reality. Additionally, various prediction models can be adapted to signify specific predictive mechanisms, and the definitions of suspense and surprise can be modified to suit the context.","Ohhyun Kwon, Jisung Yoon, Lav R. Varshney, Woo-Sung Jung, Hyejin Youn",Atrium,Posters III,65,,291
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Dependency of ERC-funded research on US collaborations,"Annually, leading funding agencies such as the ERC in Europe and the NSF in the United States allocate resources to promote research excellence. By analyzing the careers of all ERC and NSF awardees since 2008, in this work we observe that EU-based researchers rely strongly on US collaborations to secure top EU funding, while the reverse is much less common. ERC winners have the largest share of US-based collaborations early in their career, in particular prior to the award, dropping such collaborations after receiving an ERC grant. By contrast, no significant temporal trend is observed for NSF awardees, whose fraction of European collaborators remains approximately constant over a career, and is independent on the award of American national grants. Such cross-continental EU-US imbalance in collabo- ration patterns is observed across the largest 10 disciplinary fields, and in all ERC panels. Moreover, our study indicates a higher mobility of ERC awardees before winning the award when compared to their NSF counterparts, in particular towards American universities. Our analysis draws a worrying picture of the EU-US research ecosystem, as such selection bias might push European researchers, in particular early-career researchers, into conforming with US community interests to achieve academic success, thereby subordinating the European research agenda to that of the United States. Taken together, our results reveal the potentially subordinate role of the European research community with respect to the American one.",Federico Battiston,Atrium,Posters III,66,,238
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Funded and unfunded science in Russia: A new dataset and longitudinal analysis,"Scientific funding shapes research priorities, yet the extent to which certain topics and researchers remain unfunded is not well understood, in part because data about unfunded grant proposals is difficult to get access to. This study introduces a novel web-scraped dataset of 326,661 grant applicationsÑboth funded and rejectedÑsubmitted to the Russian Foundation for Basic Research (RFBR) between 1994 and 2016. Russia in particular is an interesting case to study how politics and national strategies may influence scientific funding given the identifiable sociopolitical changes over the past 30 years, offering unique insights relevant for understanding the political nature of scientific funding worldwide. Analyzing funding dynamics over time and across disciplines, our results reveal how sociopolitical changes influence whose research gets funded. We find a substantial gender disparity in funding success: Across nearly all disciplines, womenÕs proposals are significantly less likely to be funded than menÕs, with the largest gap in information technology. In addition, while women are more likely to apply for and receive early-career grants, these grants are smaller and less prestigious than other awards. Finally, we find these gender gaps have *worsened* with recent sociopolitical changes in Russia. By integrating large-scale data analysis with political and social context, this study contributes to the science of science and computational social science, providing new insights into the intersection of governmental agendas and researcher demographics. The dataset will be released to facilitate further research on systemic inequalities in scientific funding.","Elena Chechik, Xinzhe Li, Vinicius Muraro, Katie Spoon",Atrium,Posters III,67,,239
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Quantifying the Effect of Individual and Institutional Collaboration Networks on Scientific Mobility,"Individual and institutional connections shape a researcher’s opportunity space. However, it is not clear how these forms of capital interact and how they influence an individual’s mobility and migration decisions. The relevance of personal and institutional connections for finding labor market opportunities is well-documented. These connections also significantly influence the direction of migration flows by providing information and social support. International mobility of scholars, a specific type of high-skilled migration, is heavily driven by scientific collaboration networks. Our study aims to disentangle the effect of individual and institutional collaboration networks and how they influence scholarly mobility. We use bibliometric data from Scopus to construct the mobility histories of ca 172 thousand scholars. By cross-validating our results using multiple methods such as multinomial logistic regressions, and discrete choice modelling, we find that not only first-order but also second-order connections, i.e., the coauthors of a scholar’s coauthors, represent important ties. In general, we find that both institutional embedding and individual connections influence the direction of a move. In addition, with larger coauthor networks as well as for international moves, the importance of individual connections is more pronounced compared to institutional ones. These effects vary by academic field, but not by gender. Our results reveal how network embedding shapes the direction of scholars’ migration, highlighting how personal and institutional ties shape the opportunity spaces of individuals.","Alexandra Rottenkolber, Ola Ali, Gergely Mónus, Jiaxuan Li, JISU KIM, Daniela Perrotta, Aliakbar Akbaritabar",Atrium,Posters III,68,,744
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Understanding doctoral student experience via social media data,"Improving the experience and well-being of doctoral students requires a deep and nuanced understanding of the challenges they face. Traditionally, researchers have used reactive methods, such as surveys and interviews, to get such understanding. However, some topics may be difficult to capture through these approaches, particularly sensitive topics that students may be reluctant to discuss openly. In this paper, we propose an approach using non-reactive data sources from social media platforms to identify these issues. We collected more than 7,000 questions asked by doctoral students on Academia Stack Exchange and X (formerly Twitter). Using text embeddings, clustering techniques, and automatic annotation via LLMs, we identified 60 clusters of common topics discussed by doctoral students. By measuring the proportion of anonymous questions within each cluster, we determined which topics students consider sensitive. Our results reveal that the most prominent sensitive topics are supervisory relationships, mental health concerns, and potential academic misconduct. We also find that many clusters relate to academic norms and practices, with students frequently asking about the appropriateness of behaviours, reputational risks, and prestige of various achievements. By using social media data and large language models, our approach provides a comprehensive view of graduate student concerns that might remain invisible through official channels. Our findings highlight the prevalence of questions about basic academic practices that should be normally addressed by supervisors. This challenges the assumption that doctoral supervision alone can adequately support students' professional development and suggests that universities should complement supervisory relationships with structured training programs and alternative mentoring channels to ensure all students can access essential guidance without fear of judgement.","Ivan Smirnov, Saule Bekova",Atrium,Posters III,69,,484
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,A Tale of Two Sciences: Exploring Cross-Disciplinary Divides in Computational Social Science,"Computational social science (CSS) has emerged as a transformative field, integrating computational techniques with social science theory to address complex societal challenges (Lazer et al. [2009]). While CSS aspires to be an interdisciplinary confluence, the extent to which researchers from different disciplinary backgrounds interact and integrate remains an open question. This study systematically examines citation patterns within CSS to assess whether the field exhibits disciplinary segregation, revealing persistent divides between authors housed in social science departments and their complement Theoretical Contribution. C.P. SnowÕs seminal essay on the ÒTwo CulturesÓ [Snow, 1959] famously articulated the gulf between the sciences and the humanities, a divide that remains instructive for contemporary efforts at interdisciplinary integration. Indeed, the tension between the promise of cross-domain innovation and the practical challenges of bridging disciplinary cultures persists across many fields. Recent pandemic-focused analyses highlight how large influxes of non-expert contributors can hamper domain-informed scientific collaboration unless supported by robust bridging structures [Sikdar et al., 2024]. Theoretical debates in interdisciplinary research suggest that knowledge integration is contingent on shared conceptual frameworks and collaborative networks (Bronstein [2003] and Mariano [1989]). If CSS is truly interdisciplinary, we should expect cross-disciplinary citations to be common, with shared intellectual traditions forming at the intersection of social science and computational methods. Alternatively, if epistemic divides persist, citation behavior should reflect disciplinary silos, with authors preferentially citing within their own academic traditions. Data and Methods: We construct a large-scale citation network using a curated corpus of CSS papers from OpenAlex. Following Bao et al. [2024], We label CSS papers with the ÒAwesome Computational Social ScienceÓ list from GESIS and abstracts from representative CSS journals; non-CSS papers are drawn from various social science disciplines, with computationally adjacent terms excluded via a Word2Vec model. After preprocessing and generating dense embeddings using SPECTER2, we validate labels and feature quality by training an ensemble of classifiers (SVM, logistic regression, random forest, gradient boosting). The resulting network consists of 27,038 CSS papers, 139,258 unique authors, and over 158,368 referenced works. Citation segregation is assessed through assortativity measures and permutation tests. We define author background assortativity ($r_a$) as the tendency for citations to occur between authors of the same background. We also define subfield assortativity ($r_s$) to measure citation clustering within topic-based communities. To test whether author background segregation persists beyond topic-based clustering, we construct a null model that preserves subfield structures while randomizing author backgrounds. Findings: Results indicate modest but statistically significant citation segregation by author background ($r_a > 0$; $p < 0.01$). While subfields span both social and hard science authors, citations within them remain disproportionately within-background, suggesting that epistemic divides persist even in shared research domains. A chi-squared test confirms a strong correlation between author background and subfield affiliation ($\chi^2 = 519.61$, $p < 0.001$), indicating that researchers from different backgrounds tend to work on distinct problem spaces within CSS. However, the null model analysis shows that observed same-background citation proportions are significantly higher than expected under randomized conditions ($z = 19.60$, $p < 0.01$). These findings suggest that author background influences citation patterns beyond what subfield clustering alone would predict. Conclusion and Impact: This study provides empirical evidence that computational social science, despite its interdisciplinary aspirations, remains divided along disciplinary lines. These divides risk limiting knowledge integration and the development of truly interdisciplinary paradigms. Addressing these barriers requires intentional efforts in academic incentives, funding structures, and community-building initiatives that actively foster cross-disciplinary collaboration. Our findings underscore the need for structural interventions to ensure CSS realizes its potential as a bridge between computational and human-centered approaches.","Joshua Rosen, Daniel O'Brien",Atrium,Posters III,70,,97
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Replicative Experiments: A Framework to Design Virtual Labs for Open Science,"The widespread replication crisis in the social sciences, including Computational Social Science (CSS), demands new methodological approaches that prioritize open science practices. If we see value in reproducibility, we should design digital experiments in a way that is easy to reproduce. We propose ""replicative experiments,"" a framework for designing and conducting experiments with explicit focus on facilitating future replication. This framework integrates six key steps: (1) simulation-based power analysis, (2) ""baked-in"" preregistration linked to a public database of replications, (3) a detailed ""recipe"" for experimental manipulations, (4) deployment in readily accessible virtual labs, (5) bounded confirmatory analysis scripts, and (6) active post-deployment support for replicators. We present a proof-of-concept by adapting a classic social influence experiment (Watts, 2009) into a replicative format using a publicly available Shiny app. We argue this approach promotes robust and cumulative scientific progress in CSS.",Vsevolod Suschevskiy,Atrium,Posters III,71,,746
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Text Mining Systematic Reviews: New Directions for Qualitative Research Synthesis,"As the number of publications in most fields continues to grow exponentially, it becomes increasingly unfeasible for scholars to remain informed about the entire literature. Moreover, narrative reviews are subjective and susceptible to a variety of biases, including confirmation bias. Innovations in the machine learning domain of text mining can be used to synthesize the burgeoning literature in a relatively objective and scalable manner. This presentation discusses pioneering work on Text Mining Systematic Reviews (TMSR, Van Lissa 2021). TMSR is an umbrella term for quantitatively aided qualitative research synthesis methods that use Natural Language Processing to extract knowledge from published scientific literature. I present two studies that used different TMSR pipelines to extract a latent nomological network from the published literature in a particular subfield. The first used classical computational analysis methods for text (specifically, Part-Of-Speech tagging, lemmatization, and dictionary-based classification) to investigate phenomena associated with adolescentsÕ emotion regulation. A second study examined factors associated with cooperation in a comprehensive database of all experimental studies on human cooperation in prisonerÕs dilemma-style games (the Cooperation Databank, Spadaro et al., 2022). Addressing several shortcomings of the first generation of TMSR methods, this paper used innovative large language models to obtain numeric embeddings of word meaning in context, non-parametric dimension reduction with UMAP, and noisy clustering with HDBSCAN (Joireman et al., 2025). Figure 1 showcases the resulting nomological network, which was derived with minimal expert oversight and validated by three domain experts. Further evidence of validity was provided by conducting meta-analyses, which confirmed a moderate correlation between constructs most strongly associated with cooperation in this nomological network, and the magnitude of the pooled effect (i.e., constructs that were often mentioned in conjunction with cooperation tended to have stronger effects on cooperation). Third, I present one application of TMSR that set out to identify causal claims in the literature (Norouzi et al., 2024). In fields where causal assumptions are rarely made explicit (especially social science), extracting the latent causal network from the published literature may advance a more explicit discussion about causality and formal theory, and can be used as a starting point for theory development and causal inference. Moreover, from a research synthesis perspective, TMSR can help researchers find their bearings in the literature, and identify knowledge gaps and relevant control variables. To conclude, I will reflect on general considerations regarding the use of text mining in research synthesis.",Caspar J. Van Lissa,Atrium,Posters III,72,,1053
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Large Language Models for Research Synthesis and Evaluation,"An exponential increase in research publications has made it challenging to identify which studies effectively inform predictions for real-world interventions. To address this, we employ large language models (LLMs) in conjunction with an integrative experiment design to both synthesize and evaluate research at scale. As a case study, we focus on a public goods game (PGG) benchmark that systematically varies 14 parametersÑsuch as group size, game length, return ratios, peer communication, and punishmentÕs cost and effectiveness. Because punishment effectiveness exhibits significant heterogeneity and the dataset remains unpublished, this setting provides a rigorous test for both human and LLM-based predictions. We compile metadata and full text from 1,259 papers on punishment in human cooperative behavior. Each paper is subjected to an LLM-driven structured analysis, identifying which of the 14 parameters are mentioned or manipulated, and predicting how these parameters influence punishment effectiveness. Augmenting LLM prompts with these structured analyses consistently improves predictive performance on the PGG benchmark, surpassing that of expert human forecasts. Notably, this improvement is more reliable than prompting with full-text manuscripts alone. Further investigation reveals that many papers neither discuss all relevant parameters nor systematically vary them, leading to highly inconsistent performance gains across LLMs. Moreover, metadataÑsuch as citation count, publication year, journal, or disciplineÑfails to predict which papers enhance LLM forecasts. Finally, integrating multiple paper analyses does not necessarily improve accuracy, indicating the complexities of synthesizing diverse findings. These results underscore the need for metascientific dialogue on how to generate and evaluate research that can be more effectively mapped onto heterogeneous parameter spaces, thereby enabling solution-oriented social science.","Robin Na, Abdullah Almaatouq",Atrium,Posters III,73,,1035
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,A Collective Turing Test of LLMs,"Social media platforms shape public discourse but pose challenges like misinformation and polarization. While policy interventions exist, controlled experiments on real platforms are difficult. Generative Agent-Based Modeling (GABM) offers a way to simulate online discussions using Large Language Models (LLMs), but its validity remains untested. We introduce a Collective Turing Test to assess whether LLMs can convincingly replicate human conversations. In a within-subject experiment, participants compare human and AI-generated Reddit discussions, varying by model (Llama 3 70B vs. GPT-4), temperature, and conversation length. Results show that AI-generated conversations deceive users 32% of the time, surpassing the 30% Turing Test threshold. Familiarity with Reddit and AI assistants significantly affects detection accuracy, with experienced users being harder to fool. Our findings provide insights into LLM-based social simulations, helping refine their use in policy evaluation and online harm mitigation.","Azza Bouleimen, Giordano de Marzo, Taehee Kim, Hannah Metzler, Silvia Giordano, David Garcia",Atrium,Posters III,74,,365
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Opportunities and risks of LLMs in survey research,"Considering the trends in both product design and academic research regarding large-language-models (LLMs) and surveys, along with our own experiences using LLMs in surveys that we detail throughout this paper, we argue that an under-explored use of LLMs is for augmenting human experts (relative to replacing human respondents) especially in creating and testing surveys prior to deployment, and in data cleaning and analytics. We outline potential opportunities for integrating LLMs into survey methods and tools, review literature on the risks of each potential application to the survey creation process, and suggest recommended areas for future research. At each stage, we synthesize knowns and unknowns into outstanding questions for the survey research community in order to engage a robust dialogue around LLMs in survey research. The first three sections of the paper progress from lower to higher risk, with decreased agency for humans but increasing potential opportunities in each successive section: editing questions with LLMs, generating questions with LLMs, and interactive surveys run by LLM-based agents. After that, we explore the use of synthetic responses, not to replace human responses, but to enhance pilot testing, focus targeting, and prepare data analytics (i.e., as a supplement to survey ideation and data analytics). We conclude with a discussion on the longer-term affects of this disruption on the both the research and industry.","David Rothschild, Hope Schroeder, Jenny Shan Wang",Atrium,Posters III,75,,629
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Total Error Framework for LLM-Based Survey Simulations,"Large language models (LLMs) have attracted widespread attention for their ability to mimic human responses. Social scientists have begun examining whether LLMs can simulate survey respondents. Compared to traditional surveys, simulations using LLMs promise lower cost, faster data collection, increased diversity, and reduced human-subject risks. However, LLM-based simulations also face significant biases stemming from training data, model algorithms, and prompt design. This work proposes a Òtotal error frameworkÓ for LLM-based survey simulations, adapting ideas from total error frameworks designed for surveys and digital trace data (Groves, 2005; Sen et al., 2021). By systematically identifying measurement and representation errors specific to LLM-based survey data, it aims to help researchers design and evaluate simulations more rigorously. Pulling factorsÑnotably cost, speed, diversity of (simulated) participants, and participant protectionÑmotivate researchers to experiment with LLM-based survey simulations. LLM simulations offer rapid responses and avoid many constraints of working with human subjects (e.g., declining response rates, ethical restrictions, and privacy rules and laws). The ability to mimic different perspectives also raises the prospect of exploring hard-to-reach populations and unethical experiments (e.g., replications of the Milgram study). Pushing factors, however, like bias in training data, underrepresentation of specific languages and cultures, and algorithmic tendencies (such as maximum-likelihood outputs that ÒflattenÓ within-group variation) present serious concerns. These biases may render certain subpopulations poorly replicated (e.g., marginalized groups). Debiasing efforts, ironically, can remove exactly the real-world distributions that researchers are hoping to study. Inspired by classic total survey error and its adaptation to digital trace data, this framework identifies error sources at each step of an LLM-based simulation. Firstly, during model selection, biases arise from training data coverage errors, where certain groups or languages are underrepresented, and group mismatch errors, where the model represent out-group biases as in-group ideas. Additionally, the model-change by time issue affects replicability, as closed-source LLMs update. In the phase of model parameter tuning and prompt design, flattening reduces within-group variability, while essentialization assigns fixed, static traits to identities, reinforcing stereotypes. Measurement errors in this phase include prompt-dependence error, where slight changes in wording can unpredictably alter model outputs. During data collection and analysis, bound-to-answer bias emerges because LLMs might forced to respond, unlike human participants who may skip questions, affecting validity. Further biases can occur through output selection and transformation errors, where textual responses are converted into scores, potentially distorting results. By addressing these points, researchers can systematically plan LLM-based simulations, document potential pitfalls, and evaluate which errors are most likely to undermine validity. In addition to that, this framework creates a lingua franca through which LLM researchers can discuss their studies using a common language. References Groves, R. M. (2005). Survey errors and survey costs. John Wiley and Sons. Sen, I., Flck, F., Weller, K., Wei§, B., Wagner, C. (2021). A total error framework for digital traces of human behavior on online platforms. Public Opinion Quarterly, 85(S1), 399-422.",Şükrü Atsızelti,Atrium,Posters III,76,,859
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,LLM-driven Bot Infiltration: Protecting Web Surveys through Prompt Injections,"Cost- and time-efficient web surveys potentially help covering the increasing survey data demand. However, since web surveys face low response rates, researchers consider alternative ways of respondent recruitment, including social media platforms. Although these platforms provide targeting tools, data quality and integrity might be threatened by bots. This similarly applies to click worker platforms and river sampling approaches. Established bot detection strategies are not reliable when it comes to LLM-driven bots linked to Large Language Models (LLMs). We therefore investigate whether prompt injections help detecting LLM-driven bots in web surveys. We instructed two LLM-driven bots with cumulative skillsets (LLM and LLM+) to respond to an open-ended question. This question included no injection, a jailbreaking injection, or a prompt leaking injection. Our results indicate that both bots react differently to prompt injections. While the less sophisticated LLM bot falls for the jailbreaking injection, the more sophisticated LLM+ bot falls for the prompt leaking injection. This indicates that prompt injections should be tailored to bot sophistication.","Joshua Claassen, Jan Karem Höhne, Ben Lasse Wolf",Atrium,Posters III,77,,566
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Demonstrating the Feasibility for Creating Agent-based Models with Large Language Models: Two Modeling Examples,"Large language models (LLMs) play an important role in AI-powered code assistants such as code completion, debugging, and documentation. Such models can be further fine-tuned on smaller amount of data for specific tasks, often with the improvement of performance compared to generic LLMs. However, such fine-tuning techniques are seldomly used in generating sophisticated agent-based models (ABMs), because they are often implemented as software that demands extra standards such as the ÒOverview, Design concepts, and DetailsÓ (ODD) protocol. This research examines how we can bridge this gap by utilizing LLMs in designing or conceptualizing, building, and running agent-based models in the form of user prompts. In this work, two models are created to demonstrate the proposed method. Specifically, SakodaÕs checkerboard model of social interaction is created by LLM from explicit design and description through prompts. The other model stimulates consumer preferences and restaurant visits as designed and implemented by a LLM. These models are evaluated by human experts on their code correctness and quality for both verification and validation purposes. This work serves as a first step towards fine-tuned LLMs on existing models and documentations to create high-quality and functional ABMs based on either user prompts or standard protocols, contributing to further exploration on the future of AI-assisted geospatial simulation development.","Na Jiang, Boyu Wang, Andrew Crooks",Atrium,Posters III,78,,592
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Dialogue React: Enhancing Conversation Synthesis for LLM-based Social Simulations,"Introduction Large Language Models (LLMs) have demonstrated remarkable capabilities in generating human-like text, opening new possibilities for computational social science research. While agent-based models (ABMs) are widely used to study social phenomena [4], they often rely on simplified rules for agent interactions, particularly in modeling communication. More complex and nuanced simulations involving interpersonal communication between agents remain challenging with traditional rule-based approaches, as factors like personal background, communication mechanisms, and personality traits are difficult to model explicitly. Recent work has suggested that LLMs could enhance ABMs by enabling more realistic agent interactions [1], offering a scalable alternative to both rule-based systems and data collection from human interactions. Within this emerging paradigm, the ability to generate realistic conversations between agents emerges as a fundamental re-quirement: many social phenomena, from the spread of misinformation to the dynamics of online communities, are primarily mediated through dialogue. While existing approacheslike PLACES [3] have shown promising results in conversation generation using single LLM calls, they face inherent limitations in modeling truly independent agent interactions. Our framework, Dialogue React, addresses these limitations by combining agentic approaches with structured reasoning techniques from computational linguistics. Method Our framework addresses two key limitations in current conversation synthesis approaches: the ÓpuppeteeringÓ problem, where a single model generates entire conversations, and the lack of structured reasoning in dialogue generation. Building on recent advances in LLM prompting techniques, particularly Chain-of-Thought [6] and ReAct [7], we propose an architecture where each utterance is generated by an independent LLM call. Each agentÕs responses are guided by dialogue acts [2] and structured reasoning that combines step-by-step thought processes with self-reflection mechanisms. As shown in Figure 1, we systematically build upon a baseline implementation by adding agentic components, memory/reflection mechanisms, and finally dialogue acts, allowing us to assess the con- tribution of each component through ablation studies. The detailed workflow of how each approachÕs conversations were generated is illustrated in Figure 3. Results We evaluate our framework against a non-agentic baseline through both quantitative metrics and qualitative assessments. Our evaluation combines automated metrics with LLM-as-judge assessments, following recent work in dialogue evaluation. While auto- mated metrics showed comparable performance across approaches in terms of lexical diversity (Distinct-n), the LLM-as-judge evaluations revealed more nuanced differences. In single-conversation quality assessments, Dialogue React consistently received higher ratings for coherence and naturalness compared to both the baseline and basic agentic approaches. These findings were further supported by pairwise comparisons between approaches, with results shown in Figure 2. The Bradley-Terry rankings demonstrate that Dialogue React significantly outperformed both the baseline (winning 75% of matchups with Mixtral 8x7B, 71% with Gemma 2 27B) and the basic agentic approach (winning 88% with Mixtral, 83% with Gemma), with p < 0.01 across all comparisons. The consistency of these rankings across different model backends suggests that the benefits represent fundamental improvements rather than model-specific effects. We are currently conducting additional validation through pairwise human evaluation to further strengthen these findings. Conclusion Our results suggest that breaking down conversation generation into independent agent actions, guided by dialogue acts and structured reasoning, leads to more natural and higher-quality interactions. This has important implications for social science simulations, particularly in studying phenomena that emerge from complex communication patterns [5]. The frameworkÕs ability to generate coherent yet complex conversations while maintaining agent independence makes it particularly suitable for studying emergent social phenomena in simulated environments. This work contributes to the growing intersection of LLMs and computational social science [1] by providing: (1) a framework for agentic conversation generation in social simulations, (2) empirical evidence supporting the effectiveness of agentic strategies in dialogue synthesis, and (3) a novel prompting technique incorporating self-reflection and dialogue acts. Future work will focus on validating these approaches in full ABM implementations and extending the framework to multi-agent conversations.","Ruggero Marino Lazzaroni, Jana Lasser, Joao Pinheiro Neto",Atrium,Posters III,79,,360
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,When Transformers Assemble: Social Structure in Agentic Systems,"Large Language Models (LLMs) have recently gained traction as a novel means of simulating human-like behavior, offering new opportunities to explore enduring sociological questions. In parallel, multi-agent AI research demonstrates that groups of agents often outperform single-agent approaches, prompting a core inquiry at the intersection of sociology and AI: Why do teams and organizations exist? We address this by leveraging sociological theories (e.g., division of labor, shared goals) and AI principles (e.g., improved search, information aggregation). Through systematic experimentsÑvarying tasks and network structures (hierarchical vs. decentralized)Ñwe examine how collective behavior arises and how organizational frameworks shape efficiency, decision-making, and outcomes. By studying agentic systems that operate without uniquely human biases, we distinguish universally fundamental cooperation drivers from those stemming from human-specific attributes. This work connects computational social science, organizational science, sociology, and AI to shed light on emergent machine behaviors and the socio-cognitive factors behind human cooperation.","Samuel Z Liu, Philipp Reineke",Atrium,Posters III,80,,793
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Agent-Based Model of Peer Discussion,"We propose a model to mimic the educational phenomenon where the correct answer is reached through group discussions [1]. In our model, a student's opinion is represented as a three-dimensional unit vector, which evolves through peer influence with the memory effect taken into account. We also mimic the overall scaffolding effect of the correct answer in analogy to an external field in statistical mechanics models. While several previous studies have examined the social learning process within a classroom [2,3,4], they have not clearly shown a significant performance improvement through peer-collaborative activities, especially when initial opinions largely deviate from the correct answer and differ from each other. We have shown from our model study that opinion diversity within a group improves group performance. Our systematic numerical investigations have led us to the following findings. The group performance increases through discussionsÑ--even when none of the group members initially knows the correct answerÑ--as long as their initial opinions differ. It has also been observed that the enhancement of the group performance is larger when the initial opinion is more diverse, highlighting significant advancements in the performance of heterogeneous groups. Additionally, the memory horizon (or memory capacity) has been shown to affect both temporal dynamics and performances: The shorter memory horizon makes the consensus occur earlier but the final group performance becomes worse. As the memory horizon is increased, the increase of the group performance has been found to become slower but the final performance is enhanced. We have also reported that the group performance strongly depends on the group size, especially when the initial group performance is low. For all initial conditions we have tested in our work, there appear to exist the optimal group sizes (3-4) for fostering effective collaborative learning. We have also found that the improvement of the group performance is more driven by initial opinion diversity than by the initial group performance. This suggests that forming groups with diverse opinions is crucial for enhancing group performance.","Jibeom Seo, Beom Jun Kim",Atrium,Posters III,81,,732
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Real or Robotic? Assessing Whether LLMs Accurately Simulate Qualities of Human Responses in Dialogue,"Studying and building datasets for dialogue tasks is both expensive and time-consuming due to the need to recruit, train, and collect data from study participants. In response, much recent work has sought to use large language models (LLMs) to simulate both human-human and human-LLM interactions, as they have been shown to generate convincingly human-like text in many settings. However, to what extent do LLM-based simulations actually reflect human dialogues? In this work, we answer this question by generating a large-scale dataset of 100, 000 paired LLM-LLM and human-LLM dialogues from the WildChat dataset and quantifying how well the LLM simulations align with their human counterparts. Overall, we find relatively low alignment between simulations and human interactions, demonstrating a systematic divergence along the multiple textual properties, including style and content. Further, in comparisons of English, Chinese, and Russian dialogues, we find that models perform similarly. Our results suggest that LLMs generally perform better when the human themself writes in a way that is more similar to the LLMÕs own style.","Jonathan Ivey, Shivani Kumar, Jiayu Liu, Hua Shen, Sushrita Rakshit, Rohan Raju, Haotian Zhang, Aparna Ananthasubramaniam, Junghwan Kim, Bowen Yi, Dustin Wright, Abraham Israeli, Anders Giovanni Møller, Lechen Zhang, David Jurgens",Atrium,Posters III,82,,899
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Dynamic Practice Mapping: A Flexible and Temporal Approach to Analysing Communicative Patterns,"Practice Mapping is a method designed to identify patterns of shared actions amongst actors in digital environments, moving beyond traditional social network analysis that relies on direct interaction data (Bruns et al., 2024). It enables the clustering of actors based on similarities in their communicative practices. Building on this, we introduce Dynamic Practice Mapping, an extension that facilitates both analytical flexibility and temporal tracking. It is dynamic in two ways. First, it introduces an interactive dashboard that allows researchers to adjust key parameters Ð such as the weighting of different communicative practices (e.g., language choices, media sharing, URL references) Ð to refine how similarities between actors are assessed. This adaptability ensures that the method can be fine-tuned for different datasets and research questions. Second, it incorporates longitudinal analysis, which allows tracking the formation, evolution, and dissolution of discursive alliances with similar communicative practices over time. In this paper, we use Dynamic Practice Mapping for a longitudinal analysis (2018Ð2024) of climate discussions on Facebook in Australia and Brazil. This case study highlights whether and how climate-related discourse and actor positions have changed over time in different contexts.","Tariq Choucair, Kateryna Kasianenko, Ehsan Dehghan, Axel Bruns, Vish Padinjaredath Suresh, Felix Victor Münch, Sebastian Svegaard, Samantha Vilkins",Atrium,Posters III,83,,357
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Using semantic similarity to measure the echo of strategic communications,"Previous efforts to study messaging influence have aligned with research on information contagion in social networks and the behavioural patterns of coordinated campaigns or the influence of specific users. These approaches can be successful given well-defined keywords and actors, but struggle with wider contexts, as they may communicate the same message using different vocabularies. Identifying suitable keywords in a reference communication is also a time consuming process, and reduces the feasibility of deploying such techniques across multiple domains at scale. This presents a powerful opportunity for methods empowered by large language models to give new insights into how online discourse is shaped by strategic communications campaigns. We present a pair of echo metrics that use text embedding to encode meaning without reference to language choices. Given a message by some actor (source) and a set of texts created by some audience (potential receivers) we use embedding similarity to identify which messages are similar to the source text. A manually-validated threshold is applied to the cosine similarity between embeddings from the \textit{all-MiniLM-L6-v2} sentence transformer. The echo of a strategic communication is the difference in the volume of similar utterances by the receiver audience after the communication's release compared to the previous baseline. We calculate this in two ways: $\Delta_{raw}$ uses the absolute number of similar messages and $\Delta_{prop}$ uses the proportion of messages that are similar to account for variable receiver activity. Both metrics compare message volume before and after the strategic communication, that is: $$ \Delta_{raw} = \frac{1}{|\mathrm{Post}|}\sum_{i \in \mathrm{Post}} |S_i| - \frac{1}{|\mathrm{Pre}|}\sum_{j \in \mathrm{Pre}} |S_j|, \hspace{5mm} \Delta_{prop} = \frac{1}{|\mathrm{Post}|} \sum_{i \in \mathrm{Post}} \frac{|S_i|}{|T_i|} - \frac{1}{|\mathrm{Pre}|}\sum_{j \in \mathrm{Pre}} \frac{|S_j|}{|T_j|}, $$ where $S_i$ is the set of sufficiently similar messages on day $i$, $T_i$ is the set of all message on day $i$ and Pre and Post are the pre- and post-release days considered. Under this formulation, positive (negative) $\Delta$ values indicate an increase (decrease) in the discussion of the themes of the strategic communication relative to the preceding period. A negative value is included account for reactive messages or coincidental interest. While causation cannot be inferred, $\Delta$ does separate strategic communications which may have had impact from those that did not. We tested these new metrics on press releases from organisations and measured response in the Twitter conversation about climate change. Between 2019-11-01 and 2021-10-31 we collected 4,314 press releases from 10 environmentally-active organisations with large Twitter followings and 67,672,904 tweets using the keywords ""climate change"" or ""global warming"". For subsequent analyses, we focus on the 4,204 press releases with a full week of tweets before and after their release in our dataset. While the choice of parameters is free, our experiments with labelled pairs of texts showed that a cosine similarity threshold of 0.7, a pre-release window of seven days and a post-release window of three days were suitable for these data. Figure 2 shows the $\Delta$ metrics over the press releases in our dataset. The majority of press releases (2,364/4,221) have no similar tweets and are therefore excluded from Figure 2. Among those that remain we see a highly-skewed distribution of echo scores as most messages have very little impact on the wider discussion in the climate change space. Also of note are the vertical bands indicating temporal clusters of discussed press releases. These typically arise from notable events such as the release of the IPCC Sixth Assessment Report (2021-08-09). These metrics allow interested parties to gauge the response to their strategic communications both in terms of absolute response and also with respect to the other issues occupying the attention of their target audiences. Our experiments show that they are effective for distinguishing between messages that tap into public awareness and are relevant to the public discourse and those with limited reach. These metrics cannot, however, identify causation. Due to the wide range of unobservable confounding factors, metrics such as these can only highlight cases where influence may have occurred and which warrant further investigation. Given the highly-skewed distributions of $\Delta$, even a modest cutoff of 1\% change excludes more than 95\% of press releases from our sample and makes subsequent manual investigation more feasible.","Tristan J.B. Cann, Ben Dennes, Travis Coan, Saffron O'Neill, Hywel T.P. Williams",Atrium,Posters III,84,,356
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Mutual benefits of social learning and algorithmic mediation for cumulative culture,"The remarkable ecological success of humans is often attributed to our ability to develop complex cultural artifacts that enable us to cope with environmental challenges. The evolution of complex culture (cumulative cultural evolution) is usually modeled as a collective process in which individuals invent new artifacts (innovation) and copy information from others (social learning). This classic picture overlooks the growing role of intelligent algorithms in the digital age (e.g., search engines, recommender systems, large language models) in mediating information between humans, with potential consequences for cumulative cultural evolution. Building on a previous model, we investigate the combined effects of network-based social learning and a simplistic version of algorithmic mediation on cultural accumulation. We find that algorithmic mediation significantly impacts cultural accumulation and that this impact grows as social networks become less densely connected. Cultural accumulation is most effective when social learning and algorithmic mediation are combined, and the optimal ratio depends on the networkÕs density. This work is an initial step towards formalising the impact of intelligent algorithms on cumulative cultural evolution within an established framework. Models like ours provide insights into mechanisms of human-machine interaction in cultural contexts, guiding hypotheses for future experimental testing.","Agnieszka Czaplicka, Fabian Baumann, Iyad Rahwan",Atrium,Posters III,85,,583
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Agent modellers should not use statistical controls,"We show how the output of agent models can be analysed without the use of statistical controls and demonstrate the advantages of doing so. In two sets of illustrations involving seven agent models we present testing for a difference of means, and estimating linear relationships. Doing this will 1) reduce the amount of data required to identify an effect (as demonstrated by our first set of illustrations) and completely avoid any possibility of statistical bias (as demonstrated by our second set of illustrations) -- as when statistical controls are not used there can be no statistical bias.",Thomas Chesney,Atrium,Posters III,86,,110
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,"Heads, Tails, and AI Fails: The Very Human Problem of Randomness","Few things are as consistently human as our ability to perceive patterns. In contrast, however, humans are generally terrible at recognizing (and producing) randomness. Understanding the relation between randomness and human psychology has been a challenging goal for much of the 20th and 21st centuries. The combination of consistency and extensive documentation makes randomness production an ideal setting in which to analyze LLM mimicry of human biases, as a computational issue for behavioral science. We find that LLMs tend to exacerbate human bias across nearly all known avenues- and raise the question of whether or not we consider this increasing level of human-type bias a good thing.","Katherine Van Koevering, Jon Kleinberg",Atrium,Posters III,87,,778
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Mapping the landscape of behavioral reinforcement learning research,"Understanding the structure and evolution of scientific research is crucial for knowledge integration. In this study, we use a novel scientometric approach to map the interdisciplinary landscape of behavioral reinforcement learning, which spans psychology, neuroscience, economics, computer science, and psychiatry. Despite its broad impact, the field remains fragmented, with limited integration across research traditions. To address this, we combine systematic literature search, semantic network analysis, large language models, and clustering methods to analyze 5,448 articles published between 1970 and 2024. We construct similarity networks based on author, citation, and semantic relationships to identify key research strands and their connections. By visualizing this structure in a two-dimensional space, we uncover major intellectual traditions, clusters of highly interconnected research, and isolated subfields that may present opportunities for collaboration. Additionally, we examine differences in topical focus across research strands by extracting and clustering topic tags using a large language model. Our results reveal both widely shared topics (e.g., decision-making, computational modeling) and specialized themes (e.g., probability theory, brain stimulation), highlighting areas where theoretical and methodological integration could enhance the field. Beyond mapping the current state of behavioral reinforcement learning research, we provide an interactive tool that allows researchers to explore articles based on keywords and thematic relationships. By leveraging computational methods, our study offers a science-of-science perspective on the organization of this interdisciplinary domain, facilitating navigation, collaboration, and theoretical synthesis. More broadly, we demonstrate how scientometric techniques can be applied to complex research landscapes to foster interdisciplinary dialogue and advance scientific progress.","Anna Thoma, Florian Bolenz, Yujia Yang, Kevin Tiede, Ralph Hertwig, Stefano Palminteri, Dirk U. Wulff",Atrium,Posters III,88,,837
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Lost in Aggregation: How Large Language Models Amplify Social Stereotypes While Missing Individual Heterogeneity,"Large Language Models (LLMs), while effective at capturing broad cultural patterns, may systematically amplify social stereotypes by failing to account for individual variation in interpretation. Through a novel experimental paradigm using Rorschach blots and abstract art as culturally uninstitutionalized stimuli, we compared how humans and LLMs perform first-order interpretation tasks (direct interpretation) and second-order tasks (predicting group interpretations) across five dichotomized cultural groups. Analyzing responses from 600 human participants and GPT-4, we found that human interpretations maintain high heterogeneity but low group distinction in first-order tasks, while GPT-4 produces more standardized responses with high homogeneity. In second-order tasks, humans showed moderate increases in group distinction while maintaining heterogeneity, whereas GPT-4 exhibited extreme group separation and low variation. These findings demonstrate how LLMs, trained on aggregate cultural data, can oversimplify and exaggerate group-specific interpretative patterns while missing the essential complexity of human interpretation. Our results suggest that the process of training on aggregate data inherently leads to amplification of cultural stereotypes, creating representations that paradoxically represent no actual individual within these groups.","Xinrui Chloe Zhao, Amir Goldberg, Douglas Richard Guilbeault",Atrium,Posters III,89,,261
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Our Gender Biases Extend to Collaboration with AI,"This rise of artificial intelligent systems is reshaping our world, particularly with advances in generative AI and large language models such as Chat GPT-4. We may soon work alongside automated software systems or share roads with self-driving cars. It is important, therefore, to investigate whether humanÕs willingness to cooperate with others extends to interactions with machines. While that is likely to vary across cultures (1-2), recent studies showed that people cooperate with artificial agents significantly less than they do with humans (3,4). One reason for that is peopleÕs greater willingness to exploit cooperative machines for selfish gain compared to their willingness to exploit cooperative humans. A way to change this is to provide machines with human-like features. One understudied anthropomorphic feature of machinesÑyet, perfectly familiar to anyone who has used a voice-activated GPS device or smart home assistant deviceÑis machine gender. While there is some evidence that machine gender can influence peopleÕs behavioural dispositions, for example, willingness to donate money (5), how machine gender affects peopleÕs willingness to cooperate with them in mixed-motive ÒwhatÕs best-for-me-is-not-whatÕs-best-for-usÓ settings is largely unknown. On the one hand, providing machines with gender may make people treat machines similarly to how they treat fellow humans and, hence, increase peopleÕs willingness to cooperate with them. On the other hand, human interactions with gendered machines may produce unwelcome side-effects, such as the reinforcement of gender stereotypes and the spillover of the impact of those stereotypes on human behaviour from human-human to human-machine interactions, or vice versa. In this study, we address two questions: 1) Will human willingness to cooperate with gendered machines in mixed-motive settings be similar to their willingness to cooperate with fellow humans? 2) Will existing gender biases in human-human cooperation extend to peopleÕs interactions with machines? To find out, we recruited participants to interact with fellow humans and bots in the one-shot PrisonerÕs Dilemma game. To understand the motives behind peopleÕs willingness to cooperate with or defect against others, in addition to participantsÕ own choices, we elicited their predictions about their co-players. We found clear differences in participantsÕ motivations and willingness to cooperate across the genders of their interaction partners (see Figure 1). We discovered that participantsÕ overall cooperation (and defection) rates with gendered humans are comparable (that is, similar) to their overall cooperation (and defection) rates with gendered bots. However, when people defect, their motivation to exploit their partner is more prevalent in their interactions with bots compared to their interactions with humans. We found that gender biases present in human-human interactions extend to peopleÕs interactions with machines. In human-human interactions, people cooperate with females more than they do with males. However, when people defect, their motivation to exploit their partner is more prevalent in their interactions with females compared to their interactions with males. These gender biases observed in human-human interactions manifest themselves also in human-bot interactions. People display the highest level of cooperation with female humans and cooperate less with female bots than female humans as female bots are exploited more than female bots. Mistrust is high towards male humans compared to male bots.","Sepideh Bazazi, Jurgis Karpus, Taha Yasseri",Atrium,Posters III,90,,304
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,An Experimental Study of Gender Customization and Stereotyping in Social Chatbots,"Recent advances in generative AI technologies have significantly boosted the popularity of social chatbots, deepening their societal implications while challenging conventional patterns of HMC (human-machine communication). Notably, the opportunity to customize chatbots through DIY (Ódo it yourselfÓ) bot traits offers new possibilities for personalized interactions in HMC. While existing studies, under the CASA (Computers as Social Actors) paradigm,show that gender cues can lead people to ascribe gender-biased traits to chatbots, it is less wellunderstood how gender customization in social chatbots may moderate this gender affect and influence user experiences. We explore this gap in research with a 2x2 between-subjects design with two chatbot gender conditions (pre-assigned and customized) and two bot genders (female and male). Our findings show that chatbot gender customization is not simply a functional design choice but reshapes stereotypical patterns in HMC, suggesting its potential to promote equitable human-bot relationships by mitigating social biases.",mengmeng wu,Atrium,Posters III,91,,403
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Who Gets Promoted? Examining Gender and Education Inequalities in Career Advancement,"Job promotions are key milestones in career progression, yet disparities in promotion likelihood persist across demographic and educational lines. In this study, we analyze over 625 thousand job transitions from a large-scale dataset to investigate how gender, education, and career level interact to shape promotion outcomes. Using a linear probability model, we identify four key trends: (1) a gender gap in promotions, particularly at mid-career and expert levels, (2) a reverse gender gap at the senior level (3) the increasing importance of educational attainment, with doctorate holders significantly more likely to be promoted than those with lower education levels, and (4) the varying impact of education across career stages, where advanced degrees provide substantial advantages at senior and expert levels but minimal benefits at entry-level positions.","Shehryar Subhani, Wifag Adnan, Bedoor AlShebli",Atrium,Posters III,92,,1016
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,The Girl Next Door? Childhood Cross-Group Exposure and Inter-Ethnic Marriage,"How do childhood experiences reshape boundaries between ethnic majorities and minorities? By linking geocoded US census data on boys aged 0Ð18 in 1880 to their records in 1900, we analyze the impact of having a next-door neighbor of different ethnicity on the probability of forming an inter-ethnic marriage in adulthood. Combining this rich data with coarsened exact matching and a novel machine learning algorithm to control for socioeconomic factors and neighborhood characteristics, we find a positive effect of childhood exposure to diversity for members of ethnic majorities and minorities. While these findings are robust for majority group members, high neighborhood heterogeneity weakens the association for minority group members. These findings underscore the potential of everyday contact for eroding 'us-them' barriers from a historical perspective, as childhood experiences forge inclusive identities with effects persisting into adulthood.","Leonard Wendering, Kerstin Ostermann, Nan Zhang",Atrium,Posters III,93,,63
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Causal Inference in the City: Evaluation of Policy Interventions' Impact using Mobility Networks,"Policy interventions play a vital role in shaping urban environments and enhancing residents' quality of life. Evaluating their effects requires advanced quasi-experimental causal techniques, as simple correlational analysis often falls short. Urban systems are inherently complex, with interconnected factors and human behaviors creating unforeseen spillovers that challenge traditional causal inference methods. For this reason, evaluating the impacts of policy interventions has proven to be challenging. However, the rise of big data has significantly advanced the exploration of urban behavior. High-resolution mobility data from sources like mobile phones, social media, and credit cards have deepened our understanding of human movements and interactions. This study leverages network science, causal inference, and mobility data to analyze the impact of public interventions. As an example, we study the effects of policy intervention in Boston's Fare-Free Transportation program. The City of Boston has made route 28 bus fare free from August 2021. Routes 28 run through areas of high social vulnerability and high-priority infrastructure investment areas. Using community detection algorithms, causal inference techniques and large scale georeferenced mobility data, we aim to evaluate the effect of this intervention in questions such as: Did the intervention increased use of public transportation? How is this increased accessibility affecting the points of interest POIs in those areas? How is it impacting the experienced economic segregation of those individuals? To answer these questions, we use a quasi-experimental setting using Synthetic Control Method (SCM). We define the treatment group as users directly affected by the intervention, specifically those residing in census block groups (CBGs) within 1 km of route 28. For the control group, we construct a synthetic control among the rest of CBGS using three strategies: traditional approaches of choosing CBGs more than 1 km from route 28 but near other bus routes and two other based on the behavioral mobility data: CBGs with minimal movement to the intervention area, and CBGs outside the intervention areaÕs mobility network community identified using community-finding algorithms on the flow network of people between CBGs. These approaches help minimize spillover effects and create a robust synthetic control group. Our results indicate that public intervention has a statistically significant effect on the treatment group compared to the control group, specifically in terms of visits to public transportation around Route 28. This effect is observed despite the temporal trends that affect visits independently of the treatment. Methodologically, we see that, not controlling for potential behavioral spillovers in the evaluation of the policy could lead to significant changes in the estimated Average Treatment Effect (ATE) of the intervention and to apparent detection of causality. This signals the importance of including behavioral mobility in the estimation of control and treated groups.","Bijin Joseph, Hamish Gibbs, Takahiro Yabe, Esteban Moro",Atrium,Posters III,94,,199
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Ethnic Diversity and Spatial Dynamics in Google Maps Reviews: Insights from a German Border City,"Understanding how individuals interact across online and offline spaces is key to studying social integration. This study examines whether Google Maps engagement patterns reflect offline demographic distributions or if unique spatial dynamics shape perceptions of community spaces. Focusing on Saarbrcken, GermanyÑa city with a complex migration history and cross-border influencesÑwe analyze Google Maps reviews across places of interest to explore the digital footprints of French, Turkish, and Syrian communities. By linking review data with official demographics, we investigate how ethnic diversity manifests in online interactions. Our findings highlight both alignments and divergences between digital and physical spaces, demonstrating the potential of location-based online services to reveal new insights into urban diversity, migration, and socio-spatial behavior.","Ethel Elikem Mensah, Ingmar Weber, Vikram Kamath Cannanure",Atrium,Posters III,95,,709
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,You Don't Have to Live Next to Me: Towards Demobilizing Individualistic Bias in Computational Approaches to Urban Segregation,"The global surge in social inequalities is one of the pressing issues of our times. The spatial expression of social inequalities at city scale gives rise to urban segregation, a common phenomenon across different local and cultural contexts. The increasing popularity of Big Data and computational models has inspired a growing number of computational social science studies that analyze, evaluate, and issue policy recommendations for urban segregation. Today's wealth in information and computational power could inform urban planning for equity. However, as we show here, segregation research is epistemologically interdependent with prevalent economic theories which overfocus on individual responsibility while neglecting systemic processes. This individualistic bias is also engrained in computational models of urban segregation. Our essay tells a cautionary tale through several contemporary examples of how Big Data, and the assumptions underlying its usage, influence (de)segregation patterns and policies. We highlight how a lack of consideration for data ethics can lead to the creation of computational models that have a real-life, further marginalizing impact on disadvantaged groups. With this essay, our aim is to develop a better discernment of the pitfalls and potentials of computational approaches to urban segregation, thereby fostering a conscious focus on systemic thinking about urban inequalities. We suggest setting an agenda for research and collective action that is directed at demobilizing individualistic bias, informing our thinking about urban segregation, but also more broadly our efforts to create sustainable cities and communities.","Anastassia Vybornova, Trivik Verma",Atrium,Posters III,96,,129
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Socioeconomic Segregation in Voicecall Networks: Analyzing the Impact of City Size in Chile and Brazil,"Since the late 1990s, research on activity spaces has shifted the focus of segregation studies beyond residential areas, incorporating both temporal and spatial dimensions [1]. These expanded measures of segregation complement traditional residential segregation indices by capturing real-world social interactions. This shift enables a transition from place-based to people-based measures of segregation, offering a more dynamic understanding of social divides. Early work by Hgerstrand introduced a methodological framework to explicitly define the geography of social interactions, inspiring a steady stream of research across the social and natural sciences [2]. His contributions elevated this framework into a distinct sub-discipline known as Time Geography. Although initially overlooked due to the significant challenges of data management and analysis, HgerstrandÕs approach has gained substantial traction in recent years. This resurgence is largely driven by advancements in technology, which have simplified the aggregation and analysis of individual trajectories, contextual factors, and infrastructural constraints across urban spaces [3]. For example, Alessandretti et al. [4] demonstrate, using mobile phone data, that despite the exploratory nature of human behavior, individuals tend to confine their activity spaces to a limited number of locations. This finding aligns with DunbarÕs assertion of a cognitive limitÑapproximately 100 stable social relationships that an individual can maintain [5]. In this study, we explore how segregation, measured through voice call interactions, varies across cities of different sizes and socioeconomic status (SES) using mobile phone data in Chile and Brazil. By merging SES information with a Call Detail Records (CDR) dataset from a major mobile phone provider, we assess segregation patterns in voice call interactions across a gradient of city sizes in Chile. We analyze 12.5 and 1,258 million anonymized voice calls in Chile and Brazil respectively (representing social events) between reliable users to construct voice call networks for cities of different sizes. These networks are tagged with the SES of callers, call duration, and urban distance between callers, allowing us to characterize the nature of directed interactions based on SES. The SES of each user is estimated by determining their most probable residential location. Segregation is evaluated using a modified exposure index ($E$) applied across SES quintiles, providing insights into the dynamics of social interactions within and between socioeconomic groups. More specifically, we evaluate $E$ between SES quintiles as following: $E_{\alpha\beta}=\frac{N}{N_{\alpha}N_{\beta}}\sum_t^T\frac{n_{t\alpha}n_{t\beta}}{n_t}$ [6]. Here, $\alpha$ and $\beta$ are SES, $N$ total population. $T$ is defined as the social space constructed from the egonet of diameter equal to three. These egonets were built for each user with known SES in the network. While city networks are generally sparseÑlikely due to the dataset representing only a fraction of the market shareÑseveral network indices help describe the social structure of voice call interactions across cities and over time. For instance, call reciprocity remains large and consistent across cities. Assortativity by SES is positive in all networks, indicating that users tend to connect with others of similar socioeconomic status. However, assortativity values are lower in the main component subnetworks compared to the complete networks, suggesting greater homophily in the complete networks. In other words, users within the main components of the networks interact more frequently with individuals of different SES, reflecting greater diversity in these interactions. $E$ increases for the principal components compared to the full networks. In the main component subnetworks, $E$ exhibits a strong increase as socioeconomic status (SES) becomes less affluent, indicating significant segryesegation patterns that intensify with higher wealth (Fig. 1). While this pattern is consistent across countries, it reveals that segregation manifests differently depending on the size of the urban system. In larger cities, E is significantly higher for the less affluent quintiles, while for the more affluent quintiles, E remains relatively invariant to city size. This aligns with a well-documented pattern in sociological literature: the social behavior of less privileged individuals requires stricter adjustments in larger cities, whereas more affluent individuals maintain consistent social interactions regardless of whether they are in smaller or larger urban areas.","Horacio Samaniego, Joaquín Ignacio Villagra Pacheco, Yerka Freire, Alexandre Evsukoff",Atrium,Posters III,97,,429
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,"Educated Men Aren’t Bowling Alone: Loneliness, Community, and Technology in France and the United States","The existence of a loneliness epidemic is widely debated, especially and most recently one among young men. Yet to date, research has been limited and often focuses on feelings of loneliness divorced from the everyday practices of social connection. Furthermore, little work investigates the intersection of social isolation and digital technologies that is also attuned to how these are moderated by gender and social class. Here we leverage three connected data sources and computational methods to provide a cross national comparison of the United States and France that contextualizes feelings of social isolation within broader Internet use and information sharing practices. We additionally focus on the different experiences of men and women. Our data connects a survey fielded in both countries (N=8,000) with a 7-day diary about novel information (N=23,982 entries from 4,204 respondents) and 9 million digital trace observations (from over 1,800 respondents). Across three levels of community structure, focused on (i) family and friends, (ii) acquaintances, and (iii) online only connections, we find that in both countries, college educated men routinely report the highest levels of community and U.S. respondents consistently report higher levels of community than respondents in France. Both education level and gender play key roles in determining the sense of community in both countries. Analysis of the diary data suggests that this strength of community is not necessarily reflected in informational discussions, with both isolated and connected individuals reporting frequent conservations with friends and family members. We conclude by remarking on future plans to investigate this relationship further.","Isabelle Langrock, Jen Schradie",Atrium,Posters III,98,,455
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Impact of Temporary Location Visitors on Mobile App Usage in French Cities: Implications for Socio-Economic Segregation Studies,"We analyze 4G mobile app usage in 20 French cities to determine whether it reflects local residentsÕ socioeconomic characteristics or the presence of temporary visitors. Using random forest models and accessibility metrics, we find that potential visitor characteristics outweigh land use and resident demographics in predicting mobile traffic. These findings challenge existing assumptions and highlight the need to account for visitor influence when using mobile data for socio-economic analysis.","Egor Kotov, Tom Theile, Ole Hexel, Elizabeth Jacobs, JISU KIM, Daniela Perrotta, Emilio Zagheni",Atrium,Posters III,99,,456
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,From Popularity to Meritocracy: Information Monopoly and Evolution of Excellence in Online Communities,"Helpfulness votes are the currency of evaluation on online platforms. To assess information quality, service providers enable users to cast binary votes—such as “helpful” or “not helpful”—based on their judgments of individual responses like customer reviews of products and expert answers to questions. While these votes aim to represent the excellence of information in aggregate, valuable responses may not receive proper attention due to biases inherent in voting process. By investigating the influence of position and herding biases along with their monopolistic reinforcement, we propose the Evolution of Excellence (EoE), a theoretical framework that explains the cascading dynamics of online evaluations in assessing interrelated responses. To quantify these biases, we map the diverse voting behaviors across 120 major StackExchange communities onto two behavioral axes, further clustering the communities into four distinct information categories. We also demonstrate the behavioral evolution of individual communities over the years, highlighting longitudinal insights into the underlying social process. Designing novel metrics to quantify information monopoly, our findings can help service providers secure community-specific insights and interventions that promote meritocracy.","Moontae Lee, Chang Liu, Ali Tafti",Atrium,Posters III,100,,330
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Leveraging LLM-based sentiment analysis for stock portfolio allocation with proximal policy optimization,"Portfolio optimization requires adaptive strategies to maximize returns while managing risk. Reinforcement learning (RL) has gained traction in financial decision-making, and proximal policy optimization (PPO) has demonstrated strong performance in dynamic asset allocation. However, traditional PPO relies solely on historical price data, ignoring market sentiment, which plays a crucial role in asset movements. We propose a sentiment-augmented PPO (SAPPO) model that integrates daily financial news sentiment extracted from Refinitiv using LLaMA 3.3, a large language model optimized for financial text analysis. The sentiment layer refines portfolio allocation by incorporating real-time market sentiment alongside price movements. We evaluate both PPO and SAPPO on a three-stock portfolio consisting of Google, Microsoft and Meta, and we compare performance against standard market benchmarks. Results show that SAPPO improves risk-adjusted returns with a superior Sharpe ratio and reduced drawdowns. Our findings highlight the value of integrating sentiment analysis into RL-driven portfolio management.","Kemal Kirtac, Guido Germano",Atrium,Posters III,101,,223
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,AOCI: Automatic Occupational Composite Index,"This paper introduces the Automatic Occupational Composite Index (AOCI), a replicable, fast, and flexible framework for estimating expected values of occupation-specific outcomes by combining historical observations with modern computational methods. By leveraging a language model to assign probabilistic weights to occupational descriptions, AOCI converts diverse source data into consistent, HISCO-level outcome measures. This approach overcomes limitations of traditional measures like OCCSCORE, providing a flexible, automated tool that adapts to different time periods and geographic contexts. The method also readily extends to outcomes such as skill, wealth, years of education, and more. This allows researchers in the social sciences to quickly and flexibly assign such measures to data containing occupational titles or descriptions, such as census data and marriage certificates. We demonstrate the method's utility through an application to historical US wage reports for 88,000 pairs of occupations and incomes across 130 different countries and US states spanning the entire 19th century. Combined with historical skill measures, we use this to estimate how skill-premiums were affected by the industrial revolution.","Christian Vedel, Torben S. D. Johansen, Julius Koschnick, Matthew Curtis",Atrium,Posters III,102,,606
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Social contagion emerges through individual-level social learning,"We developed a psychologically grounded model of social contagion that combines reinforcement learning with social learning to explain how individuals on social networks learn to weigh both social and non‐social features (e.g., network-wide popularity of content, popularity of content among direct connections, and novelty of a content) that predict reward in the form of “likes” from their connections. Implemented within an agent-based modeling framework, agents learn that adopting items with these features yields reward, and they become more likely to choose similar items in the future, resulting in diffusion patterns that mirror those observed in real-world social networks.","Oromia Sero, Björn Lindström",Atrium,Posters III,103,,396
2025-07-24 13:30:00,2025-07-24 14:30:00,session_presentation,Mapping the Complete Network of Sweden,"We map population-wide networks that integrate multiple social contexts (i.e. multiplex networks) by utilizing information from the Swedish population register data. We study the properties of the population-wide exposure networks, how they change over time, and the consequences they have for various social outcomes. Methodologically, we develop novel approaches for constructing, measuring, and analyzing full-population networks. Substantively, we provide novel insights into how interwoven and segregated multiplex exposures are, how influence between domains affect individual outcomes, and how individuals’ exposure networks develop from birth to death through the life course.","Károly Takács, Carl Nordlund, Martin Arvidsson, Petter Holme, Laura Fürsich, Maël Lecoursonnais, Elis Carlberg Larsson, Selcan Mutgan, Maria Brandén, Christian Steglich, Neha Gondal",Atrium,Posters III,104,,619